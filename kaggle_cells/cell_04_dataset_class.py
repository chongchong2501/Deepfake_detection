# Cell 4: æ•°æ®é›†ç±»å®šä¹‰

# å¿…è¦çš„å¯¼å…¥
import torch
import pandas as pd
import numpy as np
from torch.utils.data import Dataset
from PIL import Image

class DeepfakeVideoDataset(Dataset):
    """æ·±åº¦ä¼ªé€ è§†é¢‘æ•°æ®é›†ç±» - æ”¯æŒé¢„æå–å¸§å’Œå¤šæ¨¡æ€ç‰¹å¾"""
    
    def __init__(self, csv_file, max_frames=16, gpu_preprocessing=True, 
                 extract_fourier=True, extract_compression=True, transform=None):
        """
        åˆå§‹åŒ–æ•°æ®é›† - ä¸“ç”¨äºé¢„æå–å¸§çš„GPUé¢„å¤„ç†
        
        Args:
            csv_file: CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¿…é¡»åŒ…å«frame_pathåˆ—ï¼‰
            max_frames: æœ€å¤§å¸§æ•°
            gpu_preprocessing: æ˜¯å¦å¯ç”¨GPUé¢„å¤„ç†
            extract_fourier: æ˜¯å¦æå–å‚…é‡Œå¶ç‰¹å¾
            extract_compression: æ˜¯å¦æå–å‹ç¼©ç‰¹å¾
            transform: æ•°æ®å˜æ¢ï¼ˆå¯é€‰ï¼‰
        """
        self.csv_file = csv_file
        self.max_frames = max_frames
        self.gpu_preprocessing = gpu_preprocessing
        self.extract_fourier = extract_fourier
        self.extract_compression = extract_compression
        self.transform = transform  # æ·»åŠ transformå±æ€§
        
        # åŠ è½½æ•°æ®
        self.df = pd.read_csv(csv_file)
        
        # éªŒè¯å¿…é¡»åŒ…å«frame_pathåˆ—
        if 'frame_path' not in self.df.columns:
            raise ValueError(f"CSVæ–‡ä»¶ {csv_file} å¿…é¡»åŒ…å« 'frame_path' åˆ—ã€‚è¯·å…ˆè¿è¡Œé¢„æå–æµç¨‹ã€‚")
        
        print(f"âœ… é¢„æå–å¸§æ¨¡å¼ï¼Œå…± {len(self.df)} ä¸ªæ ·æœ¬")
        
        # GPUè®¾å¤‡
        self.device = torch.device('cuda' if torch.cuda.is_available() and gpu_preprocessing else 'cpu')
        
        # é¢„è®¡ç®—çš„æ ‡å‡†åŒ–å‚æ•°ï¼ˆImageNetæ ‡å‡†ï¼‰
        self.mean_tensor = torch.tensor([0.485, 0.456, 0.406], device=self.device).view(1, 3, 1, 1)
        self.std_tensor = torch.tensor([0.229, 0.224, 0.225], device=self.device).view(1, 3, 1, 1)
        
        # é¢„è®¡ç®—æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        self._compute_dataset_stats()
        
        print(f"âœ… æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ: {len(self)} ä¸ªæ ·æœ¬")
        print(f"ğŸš€ GPUé¢„å¤„ç†: {self.gpu_preprocessing} (è®¾å¤‡: {self.device})")
        if self.extract_fourier:
            print("ğŸ“Š å¯ç”¨é¢‘åŸŸç‰¹å¾æå–")
        if self.extract_compression:
            print("ğŸ” å¯ç”¨å‹ç¼©ä¼ªå½±åˆ†æ")

    def _compute_dataset_stats(self):
        """é¢„è®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        try:
            self.real_count = len(self.df[self.df['label'] == 0])
            self.fake_count = len(self.df[self.df['label'] == 1])
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—æ•°æ®ç»Ÿè®¡æ—¶å‡ºé”™: {e}")
            self.real_count = 0
            self.fake_count = 0
        
        print(f"ğŸ“Š æ•°æ®åˆ†å¸ƒ: çœŸå®={self.real_count}, ä¼ªé€ ={self.fake_count}")

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        """è·å–æ•°æ®é¡¹ - ä¸“ç”¨äºé¢„æå–å¸§çš„GPUé¢„å¤„ç†"""
        try:
            row = self.df.iloc[idx]
            label = row['label']
            frame_path = row['frame_path']

            # ä»é¢„æå–çš„å¸§æ–‡ä»¶åŠ è½½
            video_tensor = self._load_preextracted_frames(frame_path)
            
            # ç¡®ä¿å¸§æ•°ä¸€è‡´
            video_tensor = self._ensure_frame_count(video_tensor)
            
            # GPUé¢„å¤„ç†
            if self.gpu_preprocessing and video_tensor.device != self.device:
                video_tensor = video_tensor.to(self.device, non_blocking=True)
            
            # æ ‡å‡†åŒ–
            video_tensor = self._normalize_frames(video_tensor)
            
            # åº”ç”¨å˜æ¢ï¼ˆå¦‚æœæœ‰ï¼‰
            if self.transform:
                video_tensor = self._apply_transforms(video_tensor)

            # æå–å¤šæ¨¡æ€ç‰¹å¾
            additional_features = self._extract_additional_features(video_tensor)

            label_tensor = torch.tensor(label, dtype=torch.float32)
            
            # æ¸…ç†GPUå†…å­˜
            if self.gpu_preprocessing:
                torch.cuda.empty_cache()
            
            # è¿”å›æ•°æ®å’Œé¢å¤–ç‰¹å¾
            if additional_features:
                return video_tensor, label_tensor, additional_features
            else:
                return video_tensor, label_tensor
            
        except Exception as e:
            print(f"âš ï¸ è·å–æ•°æ®é¡¹ {idx} æ—¶å‡ºé”™: {e}")
            # è¿”å›é»˜è®¤æ•°æ®
            return self._get_default_item()

    def _extract_additional_features(self, frames_tensor):
        """æå–é¢å¤–çš„å¤šæ¨¡æ€ç‰¹å¾"""
        features = {}
        
        try:
            # å°†tensorè½¬æ¢ä¸ºnumpyè¿›è¡Œç‰¹å¾æå–
            if frames_tensor.device != torch.device('cpu'):
                frames_np = frames_tensor.cpu().numpy()
            else:
                frames_np = frames_tensor.numpy()
            
            # åæ ‡å‡†åŒ–ä»¥è·å¾—åŸå§‹åƒç´ å€¼
            mean_np = self.mean_tensor.cpu().numpy().reshape(1, 3, 1, 1)
            std_np = self.std_tensor.cpu().numpy().reshape(1, 3, 1, 1)
            frames_np = frames_np * std_np + mean_np
            frames_np = np.clip(frames_np * 255.0, 0, 255).astype(np.uint8)
            
            if self.extract_fourier:
                # æå–é¢‘åŸŸç‰¹å¾ï¼ˆä½¿ç”¨ä¸­é—´å¸§ï¼‰
                mid_frame_idx = len(frames_np) // 2
                mid_frame = frames_np[mid_frame_idx].transpose(1, 2, 0)  # CHW -> HWC
                
                try:
                    # æ£€æŸ¥å‡½æ•°æ˜¯å¦å­˜åœ¨
                    if 'extract_fourier_features' in globals():
                        fourier_features = extract_fourier_features(mid_frame)
                        if fourier_features:
                            features['fourier'] = fourier_features
                    else:
                        # å¦‚æœå‡½æ•°ä¸å­˜åœ¨ï¼Œåˆ›å»ºç®€å•çš„é¢‘åŸŸç‰¹å¾æ›¿ä»£
                        gray_frame = np.mean(mid_frame, axis=2)
                        fft = np.fft.fft2(gray_frame)
                        fft_magnitude = np.abs(fft)
                        features['fourier'] = {
                            'mean_magnitude': float(np.mean(fft_magnitude)),
                            'std_magnitude': float(np.std(fft_magnitude)),
                            'max_magnitude': float(np.max(fft_magnitude))
                        }
                except Exception as e:
                    print(f"âš ï¸ é¢‘åŸŸç‰¹å¾æå–å¤±è´¥: {e}")
            
            if self.extract_compression:
                # æå–å‹ç¼©ä¼ªå½±ç‰¹å¾
                compression_features = []
                for i in range(0, len(frames_np), 4):  # æ¯4å¸§é‡‡æ ·ä¸€æ¬¡
                    frame = frames_np[i].transpose(1, 2, 0)  # CHW -> HWC
                    try:
                        # æ£€æŸ¥å‡½æ•°æ˜¯å¦å­˜åœ¨
                        if 'analyze_compression_artifacts' in globals():
                            comp_feat = analyze_compression_artifacts(frame)
                            if comp_feat:
                                compression_features.append(comp_feat)
                        else:
                            # å¦‚æœå‡½æ•°ä¸å­˜åœ¨ï¼Œåˆ›å»ºç®€å•çš„å‹ç¼©ç‰¹å¾æ›¿ä»£
                            gray_frame = np.mean(frame, axis=2)
                            # ç®€å•çš„DCTèƒ½é‡è®¡ç®—
                            dct_energy = float(np.var(gray_frame))
                            # ç®€å•çš„è¾¹ç¼˜å¯†åº¦è®¡ç®—
                            edges = np.abs(np.gradient(gray_frame.astype(float)))
                            edge_density = float(np.mean(edges[0]**2 + edges[1]**2))
                            
                            comp_feat = {
                                'dct_energy': dct_energy,
                                'edge_density': edge_density,
                                'dct_mean': dct_energy,
                                'high_freq_energy': dct_energy * 0.1
                            }
                            compression_features.append(comp_feat)
                    except Exception as e:
                        print(f"âš ï¸ å‹ç¼©ç‰¹å¾æå–å¤±è´¥: {e}")
                        continue
                
                if compression_features:
                    # èšåˆå‹ç¼©ç‰¹å¾
                    features['compression'] = {
                        'dct_mean': np.mean([f.get('dct_mean', f.get('dct_energy', 0)) for f in compression_features]),
                        'dct_std': np.std([f.get('dct_mean', f.get('dct_energy', 0)) for f in compression_features]),
                        'dct_energy': np.mean([f.get('dct_energy', 0) for f in compression_features]),
                        'high_freq_energy': np.mean([f.get('high_freq_energy', f.get('dct_energy', 0) * 0.1) for f in compression_features]),
                        'edge_density': np.mean([f.get('edge_density', 0) for f in compression_features])
                    }
            
            # è®¡ç®—æ—¶åºä¸€è‡´æ€§ç‰¹å¾
            if len(frames_np) > 1:
                temporal_features = self._compute_temporal_consistency_tensor(frames_np)
                if temporal_features:
                    features['temporal'] = temporal_features
            
            return features if features else None
            
        except Exception as e:
            print(f"âš ï¸ æå–é¢å¤–ç‰¹å¾å¤±è´¥: {e}")
            return None

    def _compute_temporal_consistency(self, frames):
        """è®¡ç®—æ—¶åºä¸€è‡´æ€§ç‰¹å¾ï¼ˆå‘åå…¼å®¹ï¼‰"""
        try:
            # è®¡ç®—ç›¸é‚»å¸§ä¹‹é—´çš„å·®å¼‚
            frame_diffs = []
            for i in range(len(frames) - 1):
                diff = np.mean(np.abs(frames[i+1].astype(float) - frames[i].astype(float)))
                frame_diffs.append(diff)
            
            if frame_diffs:
                return {
                    'mean_frame_diff': np.mean(frame_diffs),
                    'std_frame_diff': np.std(frame_diffs),
                    'max_frame_diff': np.max(frame_diffs),
                    'temporal_smoothness': 1.0 / (1.0 + np.std(frame_diffs))
                }
            
            return None
            
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—æ—¶åºç‰¹å¾å¤±è´¥: {e}")
            return None
    
    def _compute_temporal_consistency_tensor(self, frames_np):
        """è®¡ç®—æ—¶åºä¸€è‡´æ€§ç‰¹å¾ï¼ˆtensorç‰ˆæœ¬ï¼‰"""
        try:
            # è®¡ç®—ç›¸é‚»å¸§ä¹‹é—´çš„å·®å¼‚
            frame_diffs = []
            for i in range(len(frames_np) - 1):
                diff = np.mean(np.abs(frames_np[i+1].astype(float) - frames_np[i].astype(float)))
                frame_diffs.append(diff)
            
            if frame_diffs:
                return {
                    'mean_frame_diff': np.mean(frame_diffs),
                    'std_frame_diff': np.std(frame_diffs),
                    'max_frame_diff': np.max(frame_diffs),
                    'temporal_smoothness': 1.0 / (1.0 + np.std(frame_diffs))
                }
            
            return None
            
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—æ—¶åºç‰¹å¾å¤±è´¥: {e}")
            return None

    def _load_preextracted_frames(self, frame_path):
        """ä»é¢„æå–çš„å¸§æ–‡ä»¶åŠ è½½æ•°æ®"""
        try:
            # ç›´æ¥åŠ è½½tensorï¼ˆæ•°æ®å‡†å¤‡é˜¶æ®µä¿å­˜çš„æ ¼å¼ï¼‰
            frames_tensor = torch.load(frame_path, map_location='cpu')
            
            # å¦‚æœåŠ è½½çš„æ˜¯å­—å…¸æ ¼å¼ï¼Œæå–frames
            if isinstance(frames_tensor, dict):
                frames_tensor = frames_tensor['frames']
            
            # ç¡®ä¿æ•°æ®ç±»å‹å’ŒèŒƒå›´æ­£ç¡®
            if frames_tensor.dtype != torch.float32:
                frames_tensor = frames_tensor.float()
            
            # æ•°æ®å‡†å¤‡é˜¶æ®µå·²ç»å°†åƒç´ å€¼æ ‡å‡†åŒ–åˆ°[0,1]ï¼Œè¿™é‡Œéœ€è¦æ¢å¤åˆ°[0,255]
            if frames_tensor.max() <= 1.0:
                frames_tensor = frames_tensor * 255.0
            
            return frames_tensor
            
        except Exception as e:
            print(f"åŠ è½½é¢„æå–å¸§å¤±è´¥ {frame_path}: {e}")
            return self._create_default_frames_tensor()
    

    
    def _create_default_frames_tensor(self):
        """åˆ›å»ºé»˜è®¤å¸§å¼ é‡"""
        # åˆ›å»ºéšæœºå™ªå£°å¸§è€Œä¸æ˜¯å…¨é›¶å¸§ï¼Œä½¿è®­ç»ƒæ›´æœ‰æ„ä¹‰
        frames_tensor = torch.randint(0, 50, (self.max_frames, 3, 224, 224), dtype=torch.float32)
        return frames_tensor
    
    def _ensure_frame_count(self, frames_tensor):
        """ç¡®ä¿å¸§æ•°ä¸€è‡´"""
        current_frames = frames_tensor.shape[0]
        
        if current_frames < self.max_frames:
            # é‡å¤æœ€åä¸€å¸§
            last_frame = frames_tensor[-1:]
            repeat_count = self.max_frames - current_frames
            repeated_frames = last_frame.repeat(repeat_count, 1, 1, 1)
            frames_tensor = torch.cat([frames_tensor, repeated_frames], dim=0)
        elif current_frames > self.max_frames:
            # æˆªå–å‰max_frameså¸§
            frames_tensor = frames_tensor[:self.max_frames]
        
        return frames_tensor
    
    def _normalize_frames(self, frames_tensor):
        """æ ‡å‡†åŒ–å¸§æ•°æ®"""
        # ç¡®ä¿åƒç´ å€¼åœ¨[0, 1]èŒƒå›´å†…
        if frames_tensor.max() > 1.0:
            frames_tensor = frames_tensor / 255.0
        
        # ç§»åŠ¨æ ‡å‡†åŒ–å‚æ•°åˆ°æ­£ç¡®è®¾å¤‡
        if self.mean_tensor.device != frames_tensor.device:
            self.mean_tensor = self.mean_tensor.to(frames_tensor.device)
            self.std_tensor = self.std_tensor.to(frames_tensor.device)
        
        # ImageNetæ ‡å‡†åŒ–
        frames_tensor = (frames_tensor - self.mean_tensor) / self.std_tensor
        
        # é™åˆ¶æ•°å€¼èŒƒå›´é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
        frames_tensor = torch.clamp(frames_tensor, -10, 10)
        
        return frames_tensor
    
    def _apply_transforms(self, frames_tensor):
        """åº”ç”¨æ•°æ®å˜æ¢"""
        try:
            # å°†tensorè½¬æ¢å›PILæ ¼å¼è¿›è¡Œå˜æ¢
            transformed_frames = []
            
            # åæ ‡å‡†åŒ–ä»¥è·å¾—åŸå§‹åƒç´ å€¼
            denorm_tensor = frames_tensor * self.std_tensor + self.mean_tensor
            denorm_tensor = torch.clamp(denorm_tensor * 255.0, 0, 255)
            
            for i in range(frames_tensor.shape[0]):
                frame = denorm_tensor[i].permute(1, 2, 0).cpu().numpy().astype(np.uint8)
                frame_pil = Image.fromarray(frame)
                transformed_frame = self.transform(frame_pil)
                
                # æ£€æŸ¥å˜æ¢åæ˜¯å¦æœ‰NaNæˆ–æ— ç©·å€¼
                if torch.isnan(transformed_frame).any() or torch.isinf(transformed_frame).any():
                    print(f"âš ï¸ æ£€æµ‹åˆ°NaN/Infå€¼ï¼Œè·³è¿‡å˜æ¢")
                    return frames_tensor
                
                transformed_frames.append(transformed_frame)
            
            return torch.stack(transformed_frames)
            
        except Exception as e:
            print(f"âš ï¸ æ•°æ®å˜æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {e}")
            return frames_tensor
    


    def _get_default_item(self):
        """è·å–é»˜è®¤æ•°æ®é¡¹ï¼ˆç”¨äºé”™è¯¯æ¢å¤ï¼‰"""
        frames = self._create_default_frames()
        video_tensor = torch.stack([
            torch.from_numpy(frame).permute(2, 0, 1) for frame in frames
        ]).float() / 255.0
        
        # æ ‡å‡†åŒ–
        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)
        video_tensor = (video_tensor - mean) / std
        
        label_tensor = torch.tensor(0.0, dtype=torch.float32)
        return video_tensor, label_tensor

    def _create_default_frames(self):
        """åˆ›å»ºé»˜è®¤å¸§æ•°æ®ï¼ˆnumpyæ ¼å¼ï¼‰"""
        # åˆ›å»ºéšæœºå™ªå£°å¸§è€Œä¸æ˜¯å…¨é›¶å¸§ï¼Œä½¿è®­ç»ƒæ›´æœ‰æ„ä¹‰
        frames = []
        for _ in range(self.max_frames):
            # åˆ›å»º224x224x3çš„éšæœºå¸§ï¼Œå€¼åœ¨[0, 50]èŒƒå›´å†…ï¼ˆä½å™ªå£°ï¼‰
            frame = np.random.randint(0, 50, (224, 224, 3), dtype=np.uint8)
            frames.append(frame)
        return frames



    def enable_ensemble_mode(self):
        """å¯ç”¨é›†æˆæ¨¡å¼ï¼Œæå–æ‰€æœ‰å¯ç”¨ç‰¹å¾"""
        self.extract_fourier = True
        self.extract_compression = True
        print("ğŸ¯ å¯ç”¨é›†æˆæ¨¡å¼ï¼šæ‰€æœ‰ç‰¹å¾æå–å·²æ¿€æ´»")

print("âœ… æ•°æ®é›†ç±»å®šä¹‰å®Œæˆ")