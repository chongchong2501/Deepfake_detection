# Cell 4: æ•°æ®é›†ç±»å®šä¹‰

import os
import numpy as np

class DeepfakeVideoDataset(Dataset):
    """æ·±åº¦ä¼ªé€ è§†é¢‘æ•°æ®é›†ç±» - Kaggle T4 ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, csv_file=None, data_list=None, transform=None, max_frames=16, 
                 gpu_preprocessing=True, cache_frames=False):
        if csv_file is not None:
            self.df = pd.read_csv(csv_file)
            self.data_list = None
        elif data_list is not None:
            self.data_list = data_list
            self.df = None
        else:
            raise ValueError("å¿…é¡»æä¾›csv_fileæˆ–data_list")
            
        self.transform = transform
        self.max_frames = max_frames
        self.gpu_preprocessing = gpu_preprocessing and torch.cuda.is_available()
        self.cache_frames = cache_frames
        
        # ä¼˜åŒ–ç¼“å­˜ç³»ç»Ÿ - ä½¿ç”¨LRUç¼“å­˜
        if cache_frames:
            from functools import lru_cache
            self.frame_cache = {}
            self.cache_hits = 0
            self.cache_misses = 0
            self.max_cache_size = 100  # é™åˆ¶ç¼“å­˜å¤§å°
        else:
            self.frame_cache = None
        
        # é¢„è®¡ç®—æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        self._compute_dataset_stats()
        
        print(f"âœ… æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ: {len(self)} ä¸ªæ ·æœ¬")
        if self.gpu_preprocessing:
            print("ğŸš€ å¯ç”¨GPUé¢„å¤„ç†")

    def _compute_dataset_stats(self):
        """é¢„è®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        if self.df is not None:
            self.real_count = len(self.df[self.df['label'] == 0])
            self.fake_count = len(self.df[self.df['label'] == 1])
        elif self.data_list is not None:
            self.real_count = sum(1 for item in self.data_list if item['label'] == 0)
            self.fake_count = sum(1 for item in self.data_list if item['label'] == 1)
        
        print(f"ğŸ“Š æ•°æ®åˆ†å¸ƒ: çœŸå®={self.real_count}, ä¼ªé€ ={self.fake_count}")

    def __len__(self):
        if self.df is not None:
            return len(self.df)
        return len(self.data_list)

    def __getitem__(self, idx):
        if self.data_list is not None:
            item = self.data_list[idx]
            video_path = item['video_path']
            frames = item['frames']
            label = item['label']
        else:
            row = self.df.iloc[idx]
            video_path = row['video_path']
            label = row['label']
            frames = None

        # ç¼“å­˜æ£€æŸ¥
        cache_key = f"{video_path}_{self.max_frames}"
        if self.frame_cache is not None and cache_key in self.frame_cache:
            frames = self.frame_cache[cache_key]
            self.cache_hits += 1
        else:
            if frames is None:
                frames = extract_frames_memory_efficient(
                    video_path, 
                    max_frames=self.max_frames,
                    target_size=(224, 224)
                )
            
            # æ·»åŠ åˆ°ç¼“å­˜
            if self.frame_cache is not None and len(self.frame_cache) < self.max_cache_size:
                self.frame_cache[cache_key] = frames
                self.cache_misses += 1

        if len(frames) == 0:
            # åˆ›å»ºé»‘è‰²å¸§ä½œä¸ºfallback
            frames = [np.zeros((224, 224, 3), dtype=np.uint8) for _ in range(self.max_frames)]

        # ç¡®ä¿å¸§æ•°ä¸€è‡´
        while len(frames) < self.max_frames:
            frames.append(frames[-1] if frames else np.zeros((224, 224, 3), dtype=np.uint8))
        frames = frames[:self.max_frames]

        # GPUé¢„å¤„ç†
        if self.gpu_preprocessing:
            try:
                # è½¬æ¢ä¸ºtensorå¹¶ç§»åŠ¨åˆ°GPU
                video_tensor = torch.stack([
                    torch.from_numpy(frame).permute(2, 0, 1) for frame in frames
                ])  # (T, C, H, W)
                
                # ç§»åŠ¨åˆ°GPUå¹¶å½’ä¸€åŒ–
                video_tensor = video_tensor.to('cuda', non_blocking=True, dtype=torch.float32) / 255.0
                
                # GPUä¸Šè¿›è¡Œæ•°æ®å¢å¼º
                if self.transform is None and hasattr(self, '_is_training') and self._is_training:
                    video_tensor = self._gpu_augmentation(video_tensor)
                
                # æ ‡å‡†åŒ–
                mean = torch.tensor([0.485, 0.456, 0.406], device='cuda').view(1, 3, 1, 1)
                std = torch.tensor([0.229, 0.224, 0.225], device='cuda').view(1, 3, 1, 1)
                video_tensor = (video_tensor - mean) / std
                
                # åˆ›å»ºæ ‡ç­¾tensor
                label_tensor = torch.tensor(label, dtype=torch.float32)
                label_tensor = label_tensor.to('cuda', non_blocking=True)
                
                return video_tensor, label_tensor
                
            except Exception as e:
                print(f"GPUé¢„å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}")
                # å›é€€åˆ°CPUå¤„ç†
                pass

        # CPUå¤„ç†è·¯å¾„
        video_tensor = torch.stack([
            torch.from_numpy(frame).permute(2, 0, 1) for frame in frames
        ]).float() / 255.0  # (T, C, H, W)

        # åº”ç”¨å˜æ¢
        if self.transform:
            transformed_frames = []
            for frame in video_tensor:
                frame_pil = transforms.ToPILImage()(frame)
                transformed_frame = self.transform(frame_pil)
                transformed_frames.append(transformed_frame)
            video_tensor = torch.stack(transformed_frames)
        else:
            # é»˜è®¤æ ‡å‡†åŒ–
            mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)
            std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)
            video_tensor = (video_tensor - mean) / std

        label_tensor = torch.tensor(label, dtype=torch.float32)
        return video_tensor, label_tensor

    def _gpu_augmentation(self, video_tensor):
        """GPUä¸Šçš„ç®€å•æ•°æ®å¢å¼º"""
        # éšæœºæ°´å¹³ç¿»è½¬
        if torch.rand(1) > 0.5:
            video_tensor = torch.flip(video_tensor, dims=[3])
        
        # éšæœºäº®åº¦è°ƒæ•´
        if torch.rand(1) > 0.5:
            brightness_factor = 0.8 + 0.4 * torch.rand(1).item()
            video_tensor = torch.clamp(video_tensor * brightness_factor, 0, 1)
        
        return video_tensor

    def get_cache_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if self.frame_cache is not None:
            total_requests = self.cache_hits + self.cache_misses
            hit_rate = self.cache_hits / total_requests if total_requests > 0 else 0
            return {
                'cache_hits': self.cache_hits,
                'cache_misses': self.cache_misses,
                'hit_rate': hit_rate,
                'cache_size': len(self.frame_cache)
            }
        return None

print("âœ… æ•°æ®é›†ç±»å®šä¹‰å®Œæˆ")