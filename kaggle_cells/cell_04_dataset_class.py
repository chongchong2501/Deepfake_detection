# Cell 4: æ•°æ®é›†ç±»å®šä¹‰

import os
import numpy as np
import torch
import pandas as pd
from torch.utils.data import Dataset
from torchvision import transforms

class DeepfakeVideoDataset(Dataset):
    """æ·±åº¦ä¼ªé€ è§†é¢‘æ•°æ®é›†ç±» - é›†æˆMTCNNå’Œå¤šæ¨¡æ€ç‰¹å¾"""
    
    def __init__(self, csv_file=None, data_list=None, transform=None, max_frames=16, 
                 gpu_preprocessing=False, cache_frames=False, use_mtcnn=True, 
                 extract_fourier=False, extract_compression=False):
        if csv_file is not None:
            try:
                self.df = pd.read_csv(csv_file)
                self.data_list = None
                print(f"âœ… æˆåŠŸåŠ è½½CSVæ–‡ä»¶: {csv_file}")
            except FileNotFoundError:
                print(f"âš ï¸ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}ï¼Œåˆ›å»ºç©ºæ•°æ®é›†")
                self.df = pd.DataFrame(columns=['video_path', 'label'])
                self.data_list = None
        elif data_list is not None:
            self.data_list = data_list
            self.df = None
        else:
            raise ValueError("å¿…é¡»æä¾›csv_fileæˆ–data_list")
            
        self.transform = transform
        self.max_frames = max_frames
        self.gpu_preprocessing = gpu_preprocessing and torch.cuda.is_available()
        self.cache_frames = cache_frames
        self.use_mtcnn = use_mtcnn and globals().get('MTCNN_AVAILABLE', False)
        self.extract_fourier = extract_fourier and globals().get('SCIPY_AVAILABLE', False)
        self.extract_compression = extract_compression
        
        # ä¼˜åŒ–ç¼“å­˜ç³»ç»Ÿ - ä½¿ç”¨LRUç¼“å­˜
        if cache_frames:
            from functools import lru_cache
            self.frame_cache = {}
            self.cache_hits = 0
            self.cache_misses = 0
            self.max_cache_size = 100  # é™åˆ¶ç¼“å­˜å¤§å°
        else:
            self.frame_cache = None
        
        # é¢„è®¡ç®—æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        self._compute_dataset_stats()
        
        print(f"âœ… æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ: {len(self)} ä¸ªæ ·æœ¬")
        if self.gpu_preprocessing:
            print("ğŸš€ å¯ç”¨GPUé¢„å¤„ç†")
        if self.use_mtcnn:
            print("ğŸ‘ï¸ å¯ç”¨MTCNNäººè„¸æ£€æµ‹")
        if self.extract_fourier:
            print("ğŸ“Š å¯ç”¨é¢‘åŸŸç‰¹å¾æå–")
        if self.extract_compression:
            print("ğŸ” å¯ç”¨å‹ç¼©ä¼ªå½±åˆ†æ")

    def _compute_dataset_stats(self):
        """é¢„è®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if self.df is not None and len(self.df) > 0:
                self.real_count = len(self.df[self.df['label'] == 0])
                self.fake_count = len(self.df[self.df['label'] == 1])
            elif self.data_list is not None:
                self.real_count = sum(1 for item in self.data_list if item['label'] == 0)
                self.fake_count = sum(1 for item in self.data_list if item['label'] == 1)
            else:
                self.real_count = 0
                self.fake_count = 0
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—æ•°æ®ç»Ÿè®¡æ—¶å‡ºé”™: {e}")
            self.real_count = 0
            self.fake_count = 0
        
        print(f"ğŸ“Š æ•°æ®åˆ†å¸ƒ: çœŸå®={self.real_count}, ä¼ªé€ ={self.fake_count}")

    def __len__(self):
        if self.df is not None:
            return len(self.df)
        return len(self.data_list) if self.data_list else 0

    def __getitem__(self, idx):
        try:
            if self.data_list is not None:
                item = self.data_list[idx]
                video_path = item['video_path']
                frames = item.get('frames', None)
                label = item['label']
            else:
                row = self.df.iloc[idx]
                video_path = row['video_path']
                label = row['label']
                frames = None

            # å¦‚æœæ²¡æœ‰é¢„æå–çš„å¸§ï¼Œåˆ™å®æ—¶æå–
            if frames is None:
                try:
                    from .cell_03_data_processing import extract_frames_memory_efficient
                    frames = extract_frames_memory_efficient(
                        video_path, 
                        max_frames=self.max_frames,
                        use_mtcnn=self.use_mtcnn
                    )
                except Exception as e:
                    print(f"âš ï¸ å®æ—¶å¸§æå–å¤±è´¥: {e}")
                    frames = self._create_default_frames()
            
            # å¦‚æœä»ç„¶æ²¡æœ‰å¸§ï¼Œåˆ›å»ºé»˜è®¤å¸§
            if not frames:
                frames = self._create_default_frames()
            
            # ç¡®ä¿å¸§æ•°ä¸€è‡´
            while len(frames) < self.max_frames:
                frames.append(frames[-1] if frames else np.zeros((224, 224, 3), dtype=np.uint8))
            frames = frames[:self.max_frames]

            # æå–å¤šæ¨¡æ€ç‰¹å¾
            additional_features = self._extract_additional_features(frames)

            # å§‹ç»ˆä½¿ç”¨CPUå¤„ç†è·¯å¾„ç¡®ä¿ç¨³å®šæ€§
            video_tensor = torch.stack([
                torch.from_numpy(frame).permute(2, 0, 1) for frame in frames
            ]).float() / 255.0  # (T, C, H, W)

            # åº”ç”¨å˜æ¢
            if self.transform:
                try:
                    transformed_frames = []
                    for frame in video_tensor:
                        frame_pil = transforms.ToPILImage()(frame)
                        transformed_frame = self.transform(frame_pil)
                        transformed_frames.append(transformed_frame)
                    video_tensor = torch.stack(transformed_frames)
                except Exception as e:
                    print(f"âš ï¸ æ•°æ®å˜æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {e}")
            
            # é»˜è®¤æ ‡å‡†åŒ–
            try:
                mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)
                std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)
                video_tensor = (video_tensor - mean) / std
            except Exception as e:
                print(f"âš ï¸ æ ‡å‡†åŒ–å¤±è´¥: {e}")

            label_tensor = torch.tensor(label, dtype=torch.float32)
            
            # è¿”å›æ•°æ®å’Œé¢å¤–ç‰¹å¾
            if additional_features:
                return video_tensor, label_tensor, additional_features
            else:
                return video_tensor, label_tensor
            
        except Exception as e:
            print(f"âš ï¸ è·å–æ•°æ®é¡¹ {idx} æ—¶å‡ºé”™: {e}")
            # è¿”å›é»˜è®¤æ•°æ®
            return self._get_default_item()

    def _extract_additional_features(self, frames):
        """æå–é¢å¤–çš„å¤šæ¨¡æ€ç‰¹å¾"""
        features = {}
        
        try:
            if self.extract_fourier:
                # æå–é¢‘åŸŸç‰¹å¾ï¼ˆä½¿ç”¨ä¸­é—´å¸§ï¼‰
                mid_frame = frames[len(frames) // 2]
                from .cell_03_data_processing import extract_fourier_features
                fourier_features = extract_fourier_features(mid_frame)
                if fourier_features:
                    features['fourier'] = fourier_features
            
            if self.extract_compression:
                # æå–å‹ç¼©ä¼ªå½±ç‰¹å¾
                compression_features = []
                for frame in frames[::4]:  # æ¯4å¸§é‡‡æ ·ä¸€æ¬¡
                    from .cell_03_data_processing import analyze_compression_artifacts
                    comp_feat = analyze_compression_artifacts(frame)
                    if comp_feat:
                        compression_features.append(comp_feat)
                
                if compression_features:
                    # èšåˆå‹ç¼©ç‰¹å¾
                    features['compression'] = {
                        'mean_dct_energy': np.mean([f['dct_energy'] for f in compression_features]),
                        'mean_edge_density': np.mean([f['edge_density'] for f in compression_features]),
                        'std_dct_energy': np.std([f['dct_energy'] for f in compression_features])
                    }
            
            # è®¡ç®—æ—¶åºä¸€è‡´æ€§ç‰¹å¾
            if len(frames) > 1:
                temporal_features = self._compute_temporal_consistency(frames)
                if temporal_features:
                    features['temporal'] = temporal_features
            
            return features if features else None
            
        except Exception as e:
            print(f"âš ï¸ æå–é¢å¤–ç‰¹å¾å¤±è´¥: {e}")
            return None

    def _compute_temporal_consistency(self, frames):
        """è®¡ç®—æ—¶åºä¸€è‡´æ€§ç‰¹å¾"""
        try:
            # è®¡ç®—ç›¸é‚»å¸§ä¹‹é—´çš„å·®å¼‚
            frame_diffs = []
            for i in range(len(frames) - 1):
                diff = np.mean(np.abs(frames[i+1].astype(float) - frames[i].astype(float)))
                frame_diffs.append(diff)
            
            if frame_diffs:
                return {
                    'mean_frame_diff': np.mean(frame_diffs),
                    'std_frame_diff': np.std(frame_diffs),
                    'max_frame_diff': np.max(frame_diffs),
                    'temporal_smoothness': 1.0 / (1.0 + np.std(frame_diffs))
                }
            
            return None
            
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—æ—¶åºç‰¹å¾å¤±è´¥: {e}")
            return None

    def _create_default_frames(self):
        """åˆ›å»ºé»˜è®¤å¸§æ•°æ®"""
        # åˆ›å»ºéšæœºå™ªå£°å¸§è€Œä¸æ˜¯å…¨é›¶å¸§ï¼Œä½¿è®­ç»ƒæ›´æœ‰æ„ä¹‰
        frames = []
        for i in range(self.max_frames):
            # åˆ›å»ºå¸¦æœ‰è½»å¾®éšæœºå™ªå£°çš„å¸§
            frame = np.random.randint(0, 50, (224, 224, 3), dtype=np.uint8)
            frames.append(frame)
        return frames

    def _get_default_item(self):
        """è·å–é»˜è®¤æ•°æ®é¡¹ï¼ˆç”¨äºé”™è¯¯æ¢å¤ï¼‰"""
        frames = self._create_default_frames()
        video_tensor = torch.stack([
            torch.from_numpy(frame).permute(2, 0, 1) for frame in frames
        ]).float() / 255.0
        
        # æ ‡å‡†åŒ–
        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)
        video_tensor = (video_tensor - mean) / std
        
        label_tensor = torch.tensor(0.0, dtype=torch.float32)
        return video_tensor, label_tensor

    def get_cache_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if self.frame_cache is not None:
            total_requests = self.cache_hits + self.cache_misses
            hit_rate = self.cache_hits / total_requests if total_requests > 0 else 0
            return {
                'cache_hits': self.cache_hits,
                'cache_misses': self.cache_misses,
                'hit_rate': hit_rate,
                'cache_size': len(self.frame_cache)
            }
        return None

    def enable_ensemble_mode(self):
        """å¯ç”¨é›†æˆæ¨¡å¼ï¼Œæå–æ‰€æœ‰å¯ç”¨ç‰¹å¾"""
        self.extract_fourier = globals().get('SCIPY_AVAILABLE', False)
        self.extract_compression = True
        self.use_mtcnn = globals().get('MTCNN_AVAILABLE', False)
        print("ğŸ¯ å¯ç”¨é›†æˆæ¨¡å¼ï¼šæ‰€æœ‰ç‰¹å¾æå–å·²æ¿€æ´»")

print("âœ… æ•°æ®é›†ç±»å®šä¹‰å®Œæˆ")