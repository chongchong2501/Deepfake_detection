{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10125851,"sourceType":"datasetVersion","datasetId":6248577}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cell 1: å¯¼å…¥åº“å’Œç¯å¢ƒè®¾ç½®","metadata":{}},{"cell_type":"code","source":"# Cell 1: å¯¼å…¥åº“å’Œç¯å¢ƒè®¾ç½®\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport random\nimport warnings\nimport gc\nimport json\nimport time\nimport sys\nfrom pathlib import Path\nfrom datetime import datetime\nwarnings.filterwarnings('ignore')\n\n# PyTorchç›¸å…³\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as TF\nimport torchvision.models as models\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\nfrom torch.cuda.amp import GradScaler, autocast\n\n# æœºå™¨å­¦ä¹ æŒ‡æ ‡\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    roc_auc_score, confusion_matrix, classification_report,\n    roc_curve, auc, precision_recall_curve, balanced_accuracy_score\n)\nfrom sklearn.model_selection import train_test_split\n\n# æ•°æ®å¢å¼º\ntry:\n    import albumentations as A\n    from albumentations.pytorch import ToTensorV2\n    ALBUMENTATIONS_AVAILABLE = True\nexcept ImportError:\n    ALBUMENTATIONS_AVAILABLE = False\n    print(\"è­¦å‘Š: albumentationsæœªå®‰è£…ï¼Œå°†ä½¿ç”¨åŸºç¡€æ•°æ®å¢å¼º\")\n\nprint(\"âœ… æ‰€æœ‰åº“å¯¼å…¥å®Œæˆ\")","metadata":{"_uuid":"f6ebcf0d-d34a-4e53-b9c4-c85254661e41","_cell_guid":"4883bd2d-9463-4607-9e61-df4d76492a78","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-05T09:40:07.348947Z","iopub.execute_input":"2025-07-05T09:40:07.349307Z","iopub.status.idle":"2025-07-05T09:40:18.524845Z","shell.execute_reply.started":"2025-07-05T09:40:07.349271Z","shell.execute_reply":"2025-07-05T09:40:18.524222Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 2: å…¨å±€é…ç½®å’Œå·¥å…·å‡½æ•°","metadata":{}},{"cell_type":"code","source":"# Cell 2: å…¨å±€é…ç½®å’Œå·¥å…·å‡½æ•°\n\ndef set_seed(seed=42):\n    \"\"\"è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n# æ£€æŸ¥GPUå¯ç”¨æ€§\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPUå‹å·: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n\n# åˆ›å»ºå¿…è¦çš„ç›®å½•\nfor dir_name in ['./data', './models', './logs', './results', './results/evaluation']:\n    os.makedirs(dir_name, exist_ok=True)\n\n# æ£€æŸ¥æ˜¯å¦åœ¨Kaggleç¯å¢ƒä¸­\nIS_KAGGLE = os.path.exists('/kaggle')\nBASE_DATA_DIR = '/kaggle/input/ff-c23/FaceForensics++_C23' if IS_KAGGLE else './FaceForensics++_C23'\n\nprint(f\"ç¯å¢ƒ: {'Kaggle' if IS_KAGGLE else 'æœ¬åœ°'}\")\nprint(f\"æ•°æ®åŸºç¡€è·¯å¾„: {BASE_DATA_DIR}\")\nprint(\"âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.525772Z","iopub.execute_input":"2025-07-05T09:40:18.526181Z","iopub.status.idle":"2025-07-05T09:40:18.650314Z","shell.execute_reply.started":"2025-07-05T09:40:18.526162Z","shell.execute_reply":"2025-07-05T09:40:18.649509Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 3: æ•°æ®å¤„ç†æ¨¡å—\n","metadata":{}},{"cell_type":"code","source":"# Cell 3: æ•°æ®å¤„ç†æ¨¡å—\n\ndef extract_frames_memory_efficient(video_path, max_frames=24, target_size=(160, 160),\n                                   quality_threshold=30, skip_frames=2):\n    \"\"\"å†…å­˜å‹å¥½çš„å¸§æå–å‡½æ•°\"\"\"\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n\n    if not cap.isOpened():\n        print(f\"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}\")\n        return frames\n\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    if total_frames == 0:\n        cap.release()\n        return frames\n\n    # å‡åŒ€é‡‡æ ·ç­–ç•¥\n    if total_frames <= max_frames:\n        frame_indices = list(range(0, total_frames, skip_frames))\n    else:\n        step = max(1, total_frames // max_frames)\n        frame_indices = list(range(0, total_frames, step))[:max_frames]\n\n    frame_count = 0\n    for frame_idx in frame_indices:\n        if frame_count >= max_frames:\n            break\n\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n        ret, frame = cap.read()\n\n        if ret:\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            \n            # ç®€åŒ–è´¨é‡æ£€æµ‹\n            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n            quality = cv2.Laplacian(gray, cv2.CV_64F).var()\n\n            if quality > quality_threshold:\n                frame = cv2.resize(frame, target_size)\n                frames.append(frame)\n                frame_count += 1\n\n    cap.release()\n\n    # å¦‚æœå¸§æ•°ä¸è¶³ï¼Œé‡å¤æœ€åä¸€å¸§\n    while len(frames) < max_frames and len(frames) > 0:\n        frames.append(frames[-1].copy())\n\n    return frames[:max_frames]\n\ndef process_videos_simple(base_data_dir, max_videos_per_class=80, max_frames=24):\n    \"\"\"ç®€åŒ–çš„è§†é¢‘å¤„ç†å‡½æ•°\"\"\"\n    data_list = []\n    fake_methods = ['Deepfakes', 'Face2Face', 'FaceShifter', 'FaceSwap', 'NeuralTextures']\n\n    print(\"å¼€å§‹å¤„ç†çœŸå®è§†é¢‘...\")\n    # å¤„ç†çœŸå®è§†é¢‘\n    original_dir = os.path.join(base_data_dir, 'original')\n    if os.path.exists(original_dir):\n        video_files = [f for f in os.listdir(original_dir)\n                      if f.endswith(('.mp4', '.avi', '.mov'))]\n        \n        if len(video_files) > max_videos_per_class:\n            video_files = random.sample(video_files, max_videos_per_class)\n\n        print(f\"æ‰¾åˆ° {len(video_files)} ä¸ªçœŸå®è§†é¢‘\")\n\n        for video_file in tqdm(video_files, desc=\"å¤„ç†çœŸå®è§†é¢‘\"):\n            try:\n                video_path = os.path.join(original_dir, video_file)\n                frames = extract_frames_memory_efficient(video_path, max_frames)\n                \n                if len(frames) >= max_frames // 2:  # è‡³å°‘è¦æœ‰ä¸€åŠçš„å¸§\n                    data_list.append({\n                        'video_path': video_path,\n                        'frames': frames,\n                        'label': 0,  # çœŸå®è§†é¢‘\n                        'method': 'original'\n                    })\n            except Exception as e:\n                print(f\"å¤„ç†è§†é¢‘ {video_file} æ—¶å‡ºé”™: {e}\")\n                continue\n\n    # å¤„ç†ä¼ªé€ è§†é¢‘\n    print(\"å¼€å§‹å¤„ç†ä¼ªé€ è§†é¢‘...\")\n    for method in fake_methods:\n        method_dir = os.path.join(base_data_dir, method)\n        if os.path.exists(method_dir):\n            video_files = [f for f in os.listdir(method_dir)\n                          if f.endswith(('.mp4', '.avi', '.mov'))]\n            \n            if len(video_files) > max_videos_per_class:\n                video_files = random.sample(video_files, max_videos_per_class)\n\n            print(f\"å¤„ç† {method}: {len(video_files)} ä¸ªè§†é¢‘\")\n\n            for video_file in tqdm(video_files, desc=f\"å¤„ç†{method}\"):\n                try:\n                    video_path = os.path.join(method_dir, video_file)\n                    frames = extract_frames_memory_efficient(video_path, max_frames)\n                    \n                    if len(frames) >= max_frames // 2:\n                        data_list.append({\n                            'video_path': video_path,\n                            'frames': frames,\n                            'label': 1,  # ä¼ªé€ è§†é¢‘\n                            'method': method\n                        })\n                except Exception as e:\n                    print(f\"å¤„ç†è§†é¢‘ {video_file} æ—¶å‡ºé”™: {e}\")\n                    continue\n\n    print(f\"\\nâœ… æ•°æ®å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(data_list)} ä¸ªè§†é¢‘\")\n    return data_list\n\ndef create_dataset_split(data_list, test_size=0.2, val_size=0.1):\n    \"\"\"åˆ›å»ºæ•°æ®é›†åˆ’åˆ†\"\"\"\n    # åˆ†ç¦»çœŸå®å’Œä¼ªé€ æ•°æ®\n    real_data = [item for item in data_list if item['label'] == 0]\n    fake_data = [item for item in data_list if item['label'] == 1]\n    \n    print(f\"çœŸå®è§†é¢‘: {len(real_data)} ä¸ª\")\n    print(f\"ä¼ªé€ è§†é¢‘: {len(fake_data)} ä¸ª\")\n    \n    # åˆ†åˆ«åˆ’åˆ†çœŸå®å’Œä¼ªé€ æ•°æ®\n    real_train, real_temp = train_test_split(real_data, test_size=test_size+val_size, random_state=42)\n    real_val, real_test = train_test_split(real_temp, test_size=test_size/(test_size+val_size), random_state=42)\n    \n    fake_train, fake_temp = train_test_split(fake_data, test_size=test_size+val_size, random_state=42)\n    fake_val, fake_test = train_test_split(fake_temp, test_size=test_size/(test_size+val_size), random_state=42)\n    \n    # åˆå¹¶æ•°æ®\n    train_data = real_train + fake_train\n    val_data = real_val + fake_val\n    test_data = real_test + fake_test\n    \n    # æ‰“ä¹±æ•°æ®\n    random.shuffle(train_data)\n    random.shuffle(val_data)\n    random.shuffle(test_data)\n    \n    return train_data, val_data, test_data\n\ndef save_dataset_to_csv(data_list, filename):\n    \"\"\"å°†æ•°æ®é›†ä¿å­˜ä¸ºCSVæ–‡ä»¶\"\"\"\n    df_data = []\n    for item in data_list:\n        df_data.append({\n            'video_path': item['video_path'],\n            'label': item['label'],\n            'method': item['method'],\n            'num_frames': len(item['frames'])\n        })\n    \n    df = pd.DataFrame(df_data)\n    df.to_csv(filename, index=False)\n    print(f\"æ•°æ®é›†å·²ä¿å­˜åˆ°: {filename}\")\n    return df\n\nprint(\"âœ… æ•°æ®å¤„ç†å‡½æ•°å®šä¹‰å®Œæˆ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.651216Z","iopub.execute_input":"2025-07-05T09:40:18.651518Z","iopub.status.idle":"2025-07-05T09:40:18.672009Z","shell.execute_reply.started":"2025-07-05T09:40:18.651499Z","shell.execute_reply":"2025-07-05T09:40:18.671262Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 4: æ•°æ®é›†ç±»å®šä¹‰\n","metadata":{}},{"cell_type":"code","source":"# Cell 4: æ•°æ®é›†ç±»å®šä¹‰\n\nclass DeepfakeVideoDataset(Dataset):\n    \"\"\"æ·±åº¦ä¼ªé€ è§†é¢‘æ•°æ®é›†ç±»\"\"\"\n    \n    def __init__(self, csv_file=None, data_list=None, transform=None, max_frames=32):\n        if csv_file is not None:\n            self.df = pd.read_csv(csv_file)\n            self.data_list = None\n        elif data_list is not None:\n            self.data_list = data_list\n            self.df = None\n        else:\n            raise ValueError(\"å¿…é¡»æä¾›csv_fileæˆ–data_list\")\n            \n        self.transform = transform\n        self.max_frames = max_frames\n    \n    def __len__(self):\n        if self.df is not None:\n            return len(self.df)\n        return len(self.data_list)\n    \n    def __getitem__(self, idx):\n        if self.data_list is not None:\n            # ç›´æ¥ä»å†…å­˜ä¸­çš„æ•°æ®åˆ—è¡¨è·å–\n            item = self.data_list[idx]\n            frames = item['frames']\n            label = item['label']\n        else:\n            # ä»CSVæ–‡ä»¶è·å–è·¯å¾„å¹¶é‡æ–°æå–å¸§\n            row = self.df.iloc[idx]\n            video_path = row['video_path']\n            label = row['label']\n            frames = extract_frames_memory_efficient(video_path, self.max_frames)\n        \n        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å¸§\n        if len(frames) == 0:\n            # åˆ›å»ºé»‘è‰²å¸§ä½œä¸ºfallback\n            frames = [np.zeros((160, 160, 3), dtype=np.uint8) for _ in range(self.max_frames)]\n        \n        while len(frames) < self.max_frames:\n            frames.append(frames[-1].copy() if frames else np.zeros((160, 160, 3), dtype=np.uint8))\n        \n        frames = frames[:self.max_frames]\n        \n        # åº”ç”¨å˜æ¢\n        if self.transform:\n            frames = [self.transform(frame) for frame in frames]\n        else:\n            # é»˜è®¤å˜æ¢\n            frames = [torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0 for frame in frames]\n        \n        # å †å å¸§ (T, C, H, W)\n        video_tensor = torch.stack(frames)\n        label_tensor = torch.tensor(label, dtype=torch.float32)\n        \n        return video_tensor, label_tensor\n\nprint(\"âœ… æ•°æ®é›†ç±»å®šä¹‰å®Œæˆ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.673755Z","iopub.execute_input":"2025-07-05T09:40:18.673991Z","iopub.status.idle":"2025-07-05T09:40:18.693453Z","shell.execute_reply.started":"2025-07-05T09:40:18.673967Z","shell.execute_reply":"2025-07-05T09:40:18.692738Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 5: æ¨¡å‹å®šä¹‰","metadata":{}},{"cell_type":"code","source":"# Cell 5: æ¨¡å‹å®šä¹‰\n\nclass OptimizedDeepfakeDetector(nn.Module):\n    \"\"\"ä¼˜åŒ–çš„æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹\"\"\"\n    \n    def __init__(self, backbone='resnet50', hidden_dim=512, num_layers=2, \n                 dropout=0.3, use_attention=True):\n        super(OptimizedDeepfakeDetector, self).__init__()\n        \n        self.use_attention = use_attention\n        \n        # ç‰¹å¾æå–å™¨\n        if backbone == 'resnet50':\n            self.backbone = models.resnet50(pretrained=True)\n            feature_dim = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        elif backbone == 'resnet18':\n            self.backbone = models.resnet18(pretrained=True)\n            feature_dim = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        else:\n            raise ValueError(f\"ä¸æ”¯æŒçš„backbone: {backbone}\")\n        \n        # æ—¶åºå»ºæ¨¡\n        self.lstm = nn.LSTM(\n            input_size=feature_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0,\n            bidirectional=True\n        )\n        \n        lstm_output_dim = hidden_dim * 2  # åŒå‘LSTM\n        \n        # æ³¨æ„åŠ›æœºåˆ¶\n        if self.use_attention:\n            self.attention = nn.MultiheadAttention(\n                embed_dim=lstm_output_dim,\n                num_heads=8,\n                dropout=dropout,\n                batch_first=True\n            )\n        \n        # åˆ†ç±»å™¨ (ç§»é™¤ Sigmoidï¼Œå› ä¸ºä½¿ç”¨ BCEWithLogitsLoss)\n        self.classifier = nn.Sequential(\n            nn.Linear(lstm_output_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, 1)\n        )\n        \n    def forward(self, x):\n        # x shape: (batch_size, num_frames, channels, height, width)\n        batch_size, num_frames = x.shape[:2]\n        \n        # é‡å¡‘ä¸º (batch_size * num_frames, channels, height, width)\n        x = x.view(-1, *x.shape[2:])\n        \n        # ç‰¹å¾æå–\n        features = self.backbone(x)  # (batch_size * num_frames, feature_dim)\n        \n        # é‡å¡‘å›æ—¶åºæ ¼å¼\n        features = features.view(batch_size, num_frames, -1)\n        \n        # LSTMå¤„ç†\n        lstm_out, _ = self.lstm(features)  # (batch_size, num_frames, hidden_dim*2)\n        \n        # æ³¨æ„åŠ›æœºåˆ¶\n        attention_weights = None\n        if self.use_attention:\n            attended_out, attention_weights = self.attention(lstm_out, lstm_out, lstm_out)\n            # å…¨å±€å¹³å‡æ± åŒ–\n            pooled = attended_out.mean(dim=1)  # (batch_size, hidden_dim*2)\n        else:\n            # ç®€å•çš„å…¨å±€å¹³å‡æ± åŒ–\n            pooled = lstm_out.mean(dim=1)\n        \n        # åˆ†ç±»\n        output = self.classifier(pooled)\n        \n        return output.squeeze(-1), attention_weights\n\nprint(\"âœ… æ¨¡å‹å®šä¹‰å®Œæˆ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.694146Z","iopub.execute_input":"2025-07-05T09:40:18.694379Z","iopub.status.idle":"2025-07-05T09:40:18.713995Z","shell.execute_reply.started":"2025-07-05T09:40:18.694346Z","shell.execute_reply":"2025-07-05T09:40:18.713327Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 6: æŸå¤±å‡½æ•°å’Œå·¥å…·ç±»","metadata":{}},{"cell_type":"code","source":"# Cell 6: æŸå¤±å‡½æ•°å’Œå·¥å…·ç±»\n\nclass FocalLoss(nn.Module):\n    \"\"\"ç„¦ç‚¹æŸå¤±å‡½æ•° - è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜\"\"\"\n    \n    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        # ä½¿ç”¨ BCEWithLogitsLoss ä»¥å…¼å®¹ autocast\n        ce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n        # è®¡ç®—æ¦‚ç‡ç”¨äºfocal weight\n        pt = torch.exp(-ce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n\n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        else:\n            return focal_loss\n\nclass EarlyStopping:\n    \"\"\"æ—©åœæœºåˆ¶\"\"\"\n    \n    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.restore_best_weights = restore_best_weights\n        self.best_loss = None\n        self.counter = 0\n        self.best_weights = None\n\n    def __call__(self, val_loss, model):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n            self.save_checkpoint(model)\n        elif val_loss < self.best_loss - self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0\n            self.save_checkpoint(model)\n        else:\n            self.counter += 1\n\n        if self.counter >= self.patience:\n            if self.restore_best_weights:\n                model.load_state_dict(self.best_weights)\n            return True\n        return False\n\n    def save_checkpoint(self, model):\n        self.best_weights = model.state_dict().copy()\n\ndef get_transforms(mode='train', image_size=160):\n    \"\"\"è·å–æ•°æ®å˜æ¢\"\"\"\n    if mode == 'train':\n        return transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((int(image_size * 1.1), int(image_size * 1.1))),\n            transforms.RandomCrop((image_size, image_size)),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n            transforms.RandomRotation(degrees=10),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))\n        ])\n    else:\n        return transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((image_size, image_size)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\nprint(\"âœ… æŸå¤±å‡½æ•°å’Œå·¥å…·ç±»å®šä¹‰å®Œæˆ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.714907Z","iopub.execute_input":"2025-07-05T09:40:18.715604Z","iopub.status.idle":"2025-07-05T09:40:18.735617Z","shell.execute_reply.started":"2025-07-05T09:40:18.715581Z","shell.execute_reply":"2025-07-05T09:40:18.735066Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 7: è®­ç»ƒå’ŒéªŒè¯å‡½æ•°","metadata":{}},{"cell_type":"code","source":"# Cell 7: è®­ç»ƒå’ŒéªŒè¯å‡½æ•°\n\ndef train_epoch(model, train_loader, criterion, optimizer, device, scaler=None):\n    \"\"\"è®­ç»ƒä¸€ä¸ªepoch\"\"\"\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n\n    pbar = tqdm(train_loader, desc='Training', leave=False)\n\n    for batch_idx, (data, target) in enumerate(pbar):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n\n        if scaler is not None:\n            with autocast():\n                output, _ = model(data)\n                loss = criterion(output, target)\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            output, _ = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n\n        total_loss += loss.item()\n        # åº”ç”¨ sigmoid è·å¾—æ¦‚ç‡è¿›è¡Œé¢„æµ‹\n        probs = torch.sigmoid(output)\n        predicted = (probs > 0.5).float()\n        total += target.size(0)\n        correct += (predicted == target).sum().item()\n\n        all_preds.extend(probs.detach().cpu().numpy())\n        all_targets.extend(target.detach().cpu().numpy())\n\n        pbar.set_postfix({\n            'Loss': f'{loss.item():.4f}',\n            'Acc': f'{100.*correct/total:.2f}%'\n        })\n\n    avg_loss = total_loss / len(train_loader)\n    accuracy = 100. * correct / total\n\n    try:\n        auc_score = roc_auc_score(all_targets, all_preds)\n    except:\n        auc_score = 0.0\n\n    return avg_loss, accuracy, auc_score\n\ndef validate_epoch(model, val_loader, criterion, device):\n    \"\"\"éªŒè¯ä¸€ä¸ªepoch\"\"\"\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n        pbar = tqdm(val_loader, desc='Validation', leave=False)\n\n        for data, target in pbar:\n            data, target = data.to(device), target.to(device)\n            output, _ = model(data)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            # åº”ç”¨ sigmoid è·å¾—æ¦‚ç‡è¿›è¡Œé¢„æµ‹\n            probs = torch.sigmoid(output)\n            predicted = (probs > 0.5).float()\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n            all_preds.extend(probs.cpu().numpy())\n            all_targets.extend(target.cpu().numpy())\n\n            pbar.set_postfix({\n                'Loss': f'{loss.item():.4f}',\n                'Acc': f'{100.*correct/total:.2f}%'\n            })\n\n    avg_loss = total_loss / len(val_loader)\n    accuracy = 100. * correct / total\n\n    try:\n        auc_score = roc_auc_score(all_targets, all_preds)\n    except:\n        auc_score = 0.0\n\n    return avg_loss, accuracy, auc_score\n\nprint(\"âœ… è®­ç»ƒå’ŒéªŒè¯å‡½æ•°å®šä¹‰å®Œæˆ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.736344Z","iopub.execute_input":"2025-07-05T09:40:18.737079Z","iopub.status.idle":"2025-07-05T09:40:18.755906Z","shell.execute_reply.started":"2025-07-05T09:40:18.737055Z","shell.execute_reply":"2025-07-05T09:40:18.755245Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 8: è¯„ä¼°å‡½æ•°å’Œå¯è§†åŒ–","metadata":{}},{"cell_type":"code","source":"# Cell 8: è¯„ä¼°å‡½æ•°å’Œå¯è§†åŒ–\n\ndef evaluate_model_optimized(model, test_loader, criterion, device):\n    \"\"\"ä¼˜åŒ–çš„æ¨¡å‹è¯„ä¼°å‡½æ•°\"\"\"\n    model.eval()\n    total_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    all_scores = []\n    \n    inference_times = []\n    \n    print(\"ğŸš€ å¼€å§‹æ¨¡å‹è¯„ä¼°...\")\n    \n    with torch.no_grad():\n        for batch_idx, (data, target) in enumerate(tqdm(test_loader, desc=\"è¯„ä¼°è¿›åº¦\")):\n            data, target = data.to(device), target.to(device)\n            \n            # è®°å½•æ¨ç†æ—¶é—´\n            start_time = time.time()\n            output, attention_weights = model(data)\n            inference_time = time.time() - start_time\n            inference_times.append(inference_time)\n            \n            # è®¡ç®—æŸå¤±\n            loss = criterion(output, target)\n            total_loss += loss.item()\n            \n            # æ”¶é›†é¢„æµ‹ç»“æœ (åº”ç”¨ sigmoid è·å¾—æ¦‚ç‡)\n            probs = torch.sigmoid(output)\n            predictions = (probs > 0.5).float()\n            all_predictions.extend(predictions.cpu().numpy())\n            all_targets.extend(target.cpu().numpy())\n            all_scores.extend(probs.cpu().numpy())\n    \n    avg_loss = total_loss / len(test_loader)\n    avg_inference_time = np.mean(inference_times)\n    total_inference_time = np.sum(inference_times)\n    \n    print(f\"âœ… è¯„ä¼°å®Œæˆ\")\n    print(f\"å¹³å‡æŸå¤±: {avg_loss:.4f}\")\n    print(f\"å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time*1000:.2f} ms/batch\")\n    \n    return {\n        'loss': avg_loss,\n        'predictions': np.array(all_predictions),\n        'targets': np.array(all_targets),\n        'scores': np.array(all_scores),\n        'avg_inference_time': avg_inference_time,\n        'total_inference_time': total_inference_time\n    }\n\ndef calculate_comprehensive_metrics(predictions, targets, scores):\n    \"\"\"è®¡ç®—å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡\"\"\"\n    # åŸºç¡€æŒ‡æ ‡\n    accuracy = accuracy_score(targets, predictions)\n    balanced_acc = balanced_accuracy_score(targets, predictions)\n    precision = precision_score(targets, predictions, zero_division=0)\n    recall = recall_score(targets, predictions, zero_division=0)\n    f1 = f1_score(targets, predictions, zero_division=0)\n    \n    # æ··æ·†çŸ©é˜µ\n    cm = confusion_matrix(targets, predictions)\n    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n    \n    # ç‰¹å¼‚æ€§å’Œè´Ÿé¢„æµ‹å€¼\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n    \n    # AUCæŒ‡æ ‡\n    try:\n        auc_roc = roc_auc_score(targets, scores)\n    except:\n        auc_roc = 0.0\n    \n    try:\n        precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)\n        auc_pr = auc(recall_curve, precision_curve)\n    except:\n        auc_pr = 0.0\n    \n    return {\n        'accuracy': accuracy,\n        'balanced_accuracy': balanced_acc,\n        'precision': precision,\n        'recall': recall,\n        'specificity': specificity,\n        'f1': f1,\n        'auc_roc': auc_roc,\n        'auc_pr': auc_pr,\n        'npv': npv,\n        'confusion_matrix': cm,\n        'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n    }\n\ndef plot_enhanced_confusion_matrix(cm, save_path):\n    \"\"\"ç»˜åˆ¶å¢å¼ºçš„æ··æ·†çŸ©é˜µ\"\"\"\n    plt.figure(figsize=(10, 8))\n    \n    # è®¡ç®—ç™¾åˆ†æ¯”\n    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n    \n    # åˆ›å»ºæ ‡ç­¾\n    labels = np.array([[\n        f'{cm[i,j]}\\n({cm_percent[i,j]:.1f}%)' \n        for j in range(cm.shape[1])\n    ] for i in range(cm.shape[0])])\n    \n    # ç»˜åˆ¶çƒ­å›¾\n    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', \n                xticklabels=['çœŸå®', 'ä¼ªé€ '],\n                yticklabels=['çœŸå®', 'ä¼ªé€ '],\n                cbar_kws={'label': 'æ ·æœ¬æ•°é‡'})\n    \n    plt.title('å¢å¼ºæ··æ·†çŸ©é˜µ', fontsize=16, fontweight='bold')\n    plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)\n    plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=12)\n    \n    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯\n    tn, fp, fn, tp = cm.ravel()\n    accuracy = (tp + tn) / (tp + tn + fp + fn)\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    stats_text = f'å‡†ç¡®ç‡: {accuracy:.3f}\\nç²¾ç¡®ç‡: {precision:.3f}\\nå¬å›ç‡: {recall:.3f}\\nF1åˆ†æ•°: {f1:.3f}'\n    plt.text(2.1, 0.5, stats_text, fontsize=10, \n             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n    \n    plt.tight_layout()\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n    print(f\"æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {save_path}\")\n\ndef plot_roc_pr_curves(targets, scores, save_path):\n    \"\"\"ç»˜åˆ¶ROCå’ŒPRæ›²çº¿\"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n    \n    # ROCæ›²çº¿\n    fpr, tpr, _ = roc_curve(targets, scores)\n    roc_auc = auc(fpr, tpr)\n    \n    ax1.plot(fpr, tpr, color='darkorange', lw=2,\n             label=f'ROCæ›²çº¿ (AUC = {roc_auc:.4f})')\n    ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    ax1.set_xlim([0.0, 1.0])\n    ax1.set_ylim([0.0, 1.05])\n    ax1.set_xlabel('å‡æ­£ç‡')\n    ax1.set_ylabel('çœŸæ­£ç‡')\n    ax1.set_title('ROCæ›²çº¿')\n    ax1.legend(loc='lower right')\n    ax1.grid(True, alpha=0.3)\n    \n    # PRæ›²çº¿\n    precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)\n    pr_auc = auc(recall_curve, precision_curve)\n    \n    ax2.plot(recall_curve, precision_curve, color='darkgreen', lw=2,\n             label=f'PRæ›²çº¿ (AUC = {pr_auc:.4f})')\n    ax2.set_xlim([0.0, 1.0])\n    ax2.set_ylim([0.0, 1.05])\n    ax2.set_xlabel('å¬å›ç‡')\n    ax2.set_ylabel('ç²¾ç¡®ç‡')\n    ax2.set_title('ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿')\n    ax2.legend(loc='lower left')\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n    print(f\"ROC/PRæ›²çº¿å·²ä¿å­˜åˆ°: {save_path}\")\n\nprint(\"âœ… è¯„ä¼°å‡½æ•°å’Œå¯è§†åŒ–å®šä¹‰å®Œæˆ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.756640Z","iopub.execute_input":"2025-07-05T09:40:18.756856Z","iopub.status.idle":"2025-07-05T09:40:18.777479Z","shell.execute_reply.started":"2025-07-05T09:40:18.756830Z","shell.execute_reply":"2025-07-05T09:40:18.776832Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 9: æ•°æ®å¤„ç†å’Œå‡†å¤‡\n","metadata":{}},{"cell_type":"code","source":"# Cell 9: æ•°æ®å¤„ç†å’Œå‡†å¤‡\n\n# å¦‚æœéœ€è¦å¤„ç†æ•°æ®ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰\nif not os.path.exists('./data/train.csv'):\n    print(\"ğŸ“ å¼€å§‹æ•°æ®å¤„ç†...\")\n    data_list = process_videos_simple(BASE_DATA_DIR, max_videos_per_class=200, max_frames=32)\n    \n    if len(data_list) == 0:\n        print(\"âŒ æœªæ‰¾åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„\")\n        raise ValueError(\"æ•°æ®è·¯å¾„é”™è¯¯æˆ–æ•°æ®ä¸å­˜åœ¨\")\n    \n    train_data, val_data, test_data = create_dataset_split(data_list)\n    \n    # ä¿å­˜æ•°æ®é›†\n    save_dataset_to_csv(train_data, './data/train.csv')\n    save_dataset_to_csv(val_data, './data/val.csv')\n    save_dataset_to_csv(test_data, './data/test.csv')\n    \n    print(f\"è®­ç»ƒé›†: {len(train_data)} ä¸ªæ ·æœ¬\")\n    print(f\"éªŒè¯é›†: {len(val_data)} ä¸ªæ ·æœ¬\")\n    print(f\"æµ‹è¯•é›†: {len(test_data)} ä¸ªæ ·æœ¬\")\nelse:\n    print(\"ğŸ“Š æ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®å¤„ç†æ­¥éª¤\")\n    # è¯»å–ç°æœ‰æ•°æ®é›†ä¿¡æ¯\n    train_df = pd.read_csv('./data/train.csv')\n    val_df = pd.read_csv('./data/val.csv')\n    test_df = pd.read_csv('./data/test.csv')\n    \n    print(f\"è®­ç»ƒé›†: {len(train_df)} ä¸ªæ ·æœ¬\")\n    print(f\"éªŒè¯é›†: {len(val_df)} ä¸ªæ ·æœ¬\")\n    print(f\"æµ‹è¯•é›†: {len(test_df)} ä¸ªæ ·æœ¬\")\n    \n    # æ˜¾ç¤ºæ•°æ®åˆ†å¸ƒ\n    print(\"\\næ•°æ®åˆ†å¸ƒ:\")\n    print(\"è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ:\")\n    print(train_df['label'].value_counts())\n    print(\"\\néªŒè¯é›†æ ‡ç­¾åˆ†å¸ƒ:\")\n    print(val_df['label'].value_counts())\n    print(\"\\næµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ:\")\n    print(test_df['label'].value_counts())\n\nprint(\"âœ… æ•°æ®å‡†å¤‡å®Œæˆ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:48:58.128768Z","iopub.execute_input":"2025-07-05T09:48:58.129254Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 10: åˆ›å»ºæ•°æ®åŠ è½½å™¨\n","metadata":{}},{"cell_type":"code","source":"# Cell 10: åˆ›å»ºæ•°æ®åŠ è½½å™¨\n\nprint(\"ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...\")\n\n# è·å–æ•°æ®å˜æ¢\ntrain_transform = get_transforms('train')\nval_transform = get_transforms('val')\n\n# åˆ›å»ºæ•°æ®é›†\ntrain_dataset = DeepfakeVideoDataset('./data/train.csv', transform=train_transform)\nval_dataset = DeepfakeVideoDataset('./data/val.csv', transform=val_transform)\ntest_dataset = DeepfakeVideoDataset('./data/test.csv', transform=val_transform)\n\n# æ ¹æ®GPUå†…å­˜è°ƒæ•´æ‰¹æ¬¡å¤§å° - é’ˆå¯¹T4*2 GPUä¼˜åŒ–\nif torch.cuda.is_available():\n    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n    gpu_count = torch.cuda.device_count()\n    print(f\"æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUï¼Œæ¯ä¸ªGPUå†…å­˜: {gpu_memory:.1f} GB\")\n    \n    # T4*2é…ç½®ä¼˜åŒ–\n    if gpu_count >= 2 and gpu_memory >= 15:  # T4*2é…ç½®\n        batch_size = 24\n    elif gpu_memory >= 16:\n        batch_size = 20\n    elif gpu_memory >= 8:\n        batch_size = 12\n    else:\n        batch_size = 6\nelse:\n    batch_size = 2\n\nprint(f\"ä½¿ç”¨æ‰¹æ¬¡å¤§å°: {batch_size}\")\n\n# åˆ›å»ºæ•°æ®åŠ è½½å™¨ - é’ˆå¯¹T4*2 GPUä¼˜åŒ–\nnum_workers = min(8, torch.cuda.device_count() * 4) if torch.cuda.is_available() else 2\nprint(f\"ä½¿ç”¨ {num_workers} ä¸ªæ•°æ®åŠ è½½worker\")\n\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=batch_size, \n    shuffle=True, \n    num_workers=num_workers,\n    pin_memory=torch.cuda.is_available(),\n    drop_last=True,\n    persistent_workers=True if num_workers > 0 else False\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=num_workers,\n    pin_memory=torch.cuda.is_available(),\n    persistent_workers=True if num_workers > 0 else False\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=num_workers,\n    pin_memory=torch.cuda.is_available(),\n    persistent_workers=True if num_workers > 0 else False\n)\n\nprint(f\"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}\")\nprint(f\"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}\")\nprint(f\"æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}\")\n\n# æµ‹è¯•æ•°æ®åŠ è½½å™¨\nprint(\"\\nğŸ” æµ‹è¯•æ•°æ®åŠ è½½å™¨...\")\ntry:\n    sample_batch = next(iter(train_loader))\n    videos, labels = sample_batch\n    print(f\"è§†é¢‘å¼ é‡å½¢çŠ¶: {videos.shape}\")\n    print(f\"æ ‡ç­¾å¼ é‡å½¢çŠ¶: {labels.shape}\")\n    print(f\"è§†é¢‘æ•°æ®ç±»å‹: {videos.dtype}\")\n    print(f\"æ ‡ç­¾æ•°æ®ç±»å‹: {labels.dtype}\")\n    print(f\"è§†é¢‘æ•°æ®èŒƒå›´: [{videos.min():.3f}, {videos.max():.3f}]\")\n    print(f\"æ ‡ç­¾åˆ†å¸ƒ: {labels.unique(return_counts=True)}\")\n    print(\"âœ… æ•°æ®åŠ è½½å™¨æµ‹è¯•æˆåŠŸ\")\nexcept Exception as e:\n    print(f\"âŒ æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}\")\n    raise e\n\nprint(\"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 11: æ¨¡å‹åˆå§‹åŒ–å’Œè®­ç»ƒé…ç½®\n","metadata":{}},{"cell_type":"code","source":"# Cell 11: æ¨¡å‹åˆå§‹åŒ–å’Œè®­ç»ƒé…ç½®\n\nprint(\"ğŸ¤– åˆ›å»ºå’Œé…ç½®æ¨¡å‹...\")\n\n# åˆ›å»ºæ¨¡å‹ - é’ˆå¯¹T4*2 GPUä¼˜åŒ–\nmodel = OptimizedDeepfakeDetector(\n    backbone='resnet50',  # ä½¿ç”¨ResNet50ä»¥å……åˆ†åˆ©ç”¨T4*2 GPUæ€§èƒ½\n    hidden_dim=512,      # å¢åŠ éšè—å±‚ç»´åº¦\n    num_layers=2,        # å¢åŠ LSTMå±‚æ•°\n    dropout=0.4,         # é€‚å½“å¢åŠ dropouté˜²æ­¢è¿‡æ‹Ÿåˆ\n    use_attention=True\n).to(device)\n\n# å¤šGPUæ”¯æŒ - å……åˆ†åˆ©ç”¨T4*2é…ç½®\nif torch.cuda.device_count() > 1:\n    print(f\"ä½¿ç”¨ {torch.cuda.device_count()} ä¸ªGPUè¿›è¡Œå¹¶è¡Œè®­ç»ƒ\")\n    model = nn.DataParallel(model)\nelse:\n    print(\"ä½¿ç”¨å•GPUè®­ç»ƒ\")\n\n# è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"æ¨¡å‹æ€»å‚æ•°æ•°é‡: {total_params:,}\")\nprint(f\"å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}\")\nprint(f\"æ¨¡å‹å¤§å°ä¼°è®¡: {total_params * 4 / 1024**2:.1f} MB\")\n\n# æŸå¤±å‡½æ•°\ncriterion = FocalLoss(alpha=1, gamma=2)\nprint(\"ä½¿ç”¨ç„¦ç‚¹æŸå¤±å‡½æ•° (Focal Loss)\")\n\n# ä¼˜åŒ–å™¨ - é’ˆå¯¹ResNet50ä¼˜åŒ–\noptimizer = optim.AdamW(\n    model.parameters(), \n    lr=2e-4,  # ç¨å¾®æé«˜å­¦ä¹ ç‡ä»¥é€‚åº”æ›´å¤§æ¨¡å‹\n    weight_decay=1e-4,\n    betas=(0.9, 0.999)\n)\nprint(\"ä½¿ç”¨AdamWä¼˜åŒ–å™¨ (lr=2e-4)\")\n\n# å­¦ä¹ ç‡è°ƒåº¦å™¨ - æ›´ä¿å®ˆçš„è°ƒåº¦\nscheduler = ReduceLROnPlateau(\n    optimizer, \n    mode='min', \n    factor=0.6,  # æ›´ä¿å®ˆçš„è¡°å‡å› å­\n    patience=4,  # å¢åŠ patience\n    verbose=True,\n    min_lr=1e-7\n)\nprint(\"ä½¿ç”¨ReduceLROnPlateauå­¦ä¹ ç‡è°ƒåº¦å™¨ (factor=0.6, patience=4)\")\n\n# æ—©åœæœºåˆ¶ - å¢åŠ patienceä»¥é€‚åº”æ›´å¤§æ¨¡å‹\nearly_stopping = EarlyStopping(patience=8, min_delta=0.001)\nprint(\"é…ç½®æ—©åœæœºåˆ¶ (patience=8)\")\n\n# æ··åˆç²¾åº¦è®­ç»ƒ\nif torch.cuda.is_available():\n    scaler = GradScaler()\n    print(\"å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP)\")\nelse:\n    scaler = None\n    print(\"CPUæ¨¡å¼ï¼Œä¸ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ\")\n\n# è®­ç»ƒé…ç½® - é’ˆå¯¹T4*2 GPUå’Œæ›´å¤§æ•°æ®é›†ä¼˜åŒ–\nnum_epochs = 25  # å¢åŠ è®­ç»ƒè½®æ•°ä»¥å……åˆ†è®­ç»ƒæ›´å¤§çš„æ¨¡å‹\nprint(f\"è®­ç»ƒè½®æ•°: {num_epochs}\")\n\n# æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­\nprint(\"\\nğŸ” æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...\")\ntry:\n    model.eval()\n    with torch.no_grad():\n        sample_batch = next(iter(train_loader))\n        videos, labels = sample_batch\n        videos, labels = videos.to(device), labels.to(device)\n        \n        # å‰å‘ä¼ æ’­\n        outputs, attention_weights = model(videos)\n        loss = criterion(outputs, labels)\n        \n        print(f\"è¾“å…¥å½¢çŠ¶: {videos.shape}\")\n        print(f\"è¾“å‡ºå½¢çŠ¶: {outputs.shape}\")\n        print(f\"æŸå¤±å€¼: {loss.item():.4f}\")\n        print(f\"LogitsèŒƒå›´: [{outputs.min():.3f}, {outputs.max():.3f}]\")\n        \n        # æ˜¾ç¤ºæ¦‚ç‡èŒƒå›´\n        probs = torch.sigmoid(outputs)\n        print(f\"æ¦‚ç‡èŒƒå›´: [{probs.min():.3f}, {probs.max():.3f}]\")\n        \n        if attention_weights is not None:\n            print(f\"æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {attention_weights.shape}\")\n        \n        print(\"âœ… æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•æˆåŠŸ\")\nexcept Exception as e:\n    print(f\"âŒ æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}\")\n    raise e\n\nprint(\"âœ… æ¨¡å‹é…ç½®å®Œæˆï¼Œå‡†å¤‡å¼€å§‹è®­ç»ƒ\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 12: æ¨¡å‹è®­ç»ƒä¸»å¾ªç¯\n","metadata":{}},{"cell_type":"code","source":"# Cell 12: æ¨¡å‹è®­ç»ƒä¸»å¾ªç¯\n\nprint(\"ğŸ¯ å¼€å§‹è®­ç»ƒæ¨¡å‹...\")\nprint(\"=\" * 60)\n\n# è®­ç»ƒå†å²è®°å½•\ntrain_history = {\n    'train_loss': [],\n    'train_acc': [],\n    'train_auc': [],\n    'val_loss': [],\n    'val_acc': [],\n    'val_auc': [],\n    'lr': []\n}\n\nbest_val_acc = 0\nbest_val_auc = 0\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    \n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    print(\"-\" * 50)\n    \n    # è®­ç»ƒé˜¶æ®µ\n    train_loss, train_acc, train_auc = train_epoch(\n        model, train_loader, criterion, optimizer, device, scaler\n    )\n    \n    # éªŒè¯é˜¶æ®µ\n    val_loss, val_acc, val_auc = validate_epoch(\n        model, val_loader, criterion, device\n    )\n    \n    # å­¦ä¹ ç‡è°ƒåº¦\n    scheduler.step(val_loss)\n    current_lr = optimizer.param_groups[0]['lr']\n    \n    # è®°å½•å†å²\n    train_history['train_loss'].append(train_loss)\n    train_history['train_acc'].append(train_acc)\n    train_history['train_auc'].append(train_auc)\n    train_history['val_loss'].append(val_loss)\n    train_history['val_acc'].append(val_acc)\n    train_history['val_auc'].append(val_auc)\n    train_history['lr'].append(current_lr)\n    \n    # è®¡ç®—epochæ—¶é—´\n    epoch_time = time.time() - epoch_start_time\n    \n    # æ‰“å°ç»“æœ\n    print(f\"è®­ç»ƒ - æŸå¤±: {train_loss:.4f}, å‡†ç¡®ç‡: {train_acc:.2f}%, AUC: {train_auc:.4f}\")\n    print(f\"éªŒè¯ - æŸå¤±: {val_loss:.4f}, å‡†ç¡®ç‡: {val_acc:.2f}%, AUC: {val_auc:.4f}\")\n    print(f\"å­¦ä¹ ç‡: {current_lr:.6f}\")\n    print(f\"Epochæ—¶é—´: {epoch_time:.1f}s\")\n    \n    # ä¿å­˜æœ€ä½³æ¨¡å‹\n    is_best = False\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        best_val_auc = val_auc\n        is_best = True\n        \n        # ä¿å­˜æ¨¡å‹\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'best_val_acc': best_val_acc,\n            'best_val_auc': best_val_auc,\n            'val_loss': val_loss,\n            'train_history': train_history\n        }, './models/best_model.pth')\n        \n        print(f\"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%, AUC: {val_auc:.4f})\")\n    \n    # æ—©åœæ£€æŸ¥\n    if early_stopping(val_loss, model):\n        print(f\"ğŸ›‘ æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ\")\n        print(f\"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\n        break\n    \n    # å†…å­˜æ¸…ç†\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    gc.collect()\n\n# è®­ç»ƒå®Œæˆ\ntotal_time = time.time() - start_time\nprint(f\"\\nğŸ‰ è®­ç»ƒå®Œæˆï¼\")\nprint(f\"æ€»è®­ç»ƒæ—¶é—´: {total_time/60:.1f} åˆ†é’Ÿ\")\nprint(f\"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\nprint(f\"æœ€ä½³éªŒè¯AUC: {best_val_auc:.4f}\")\nprint(\"=\" * 60)\n\n# ç»˜åˆ¶è®­ç»ƒå†å²\nprint(\"ğŸ“Š ç»˜åˆ¶è®­ç»ƒå†å²...\")\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n\n# æŸå¤±æ›²çº¿\nax1.plot(train_history['train_loss'], label='è®­ç»ƒæŸå¤±', color='blue')\nax1.plot(train_history['val_loss'], label='éªŒè¯æŸå¤±', color='red')\nax1.set_title('æŸå¤±æ›²çº¿')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# å‡†ç¡®ç‡æ›²çº¿\nax2.plot(train_history['train_acc'], label='è®­ç»ƒå‡†ç¡®ç‡', color='blue')\nax2.plot(train_history['val_acc'], label='éªŒè¯å‡†ç¡®ç‡', color='red')\nax2.set_title('å‡†ç¡®ç‡æ›²çº¿')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Accuracy (%)')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\n# AUCæ›²çº¿\nax3.plot(train_history['train_auc'], label='è®­ç»ƒAUC', color='blue')\nax3.plot(train_history['val_auc'], label='éªŒè¯AUC', color='red')\nax3.set_title('AUCæ›²çº¿')\nax3.set_xlabel('Epoch')\nax3.set_ylabel('AUC')\nax3.legend()\nax3.grid(True, alpha=0.3)\n\n# å­¦ä¹ ç‡æ›²çº¿\nax4.plot(train_history['lr'], label='å­¦ä¹ ç‡', color='green')\nax4.set_title('å­¦ä¹ ç‡å˜åŒ–')\nax4.set_xlabel('Epoch')\nax4.set_ylabel('Learning Rate')\nax4.set_yscale('log')\nax4.legend()\nax4.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('./results/training_history.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ… è®­ç»ƒå†å²å›¾è¡¨å·²ä¿å­˜\")\nprint(\"âœ… è®­ç»ƒé˜¶æ®µå®Œæˆï¼Œå‡†å¤‡è¿›è¡Œæ¨¡å‹è¯„ä¼°\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 13: æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æ\n","metadata":{}},{"cell_type":"code","source":"# Cell 13: æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æ\n\nprint(\"ğŸ“Š å¼€å§‹æ¨¡å‹è¯„ä¼°...\")\nprint(\"=\" * 60)\n\n# åŠ è½½æœ€ä½³æ¨¡å‹\nprint(\"ğŸ”„ åŠ è½½æœ€ä½³æ¨¡å‹...\")\ntry:\n    checkpoint = torch.load('./models/best_model.pth', map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    best_epoch = checkpoint['epoch']\n    best_val_acc = checkpoint['best_val_acc']\n    best_val_auc = checkpoint['best_val_auc']\n    \n    print(f\"âœ… æˆåŠŸåŠ è½½ç¬¬ {best_epoch+1} è½®çš„æœ€ä½³æ¨¡å‹\")\n    print(f\"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\n    print(f\"æœ€ä½³éªŒè¯AUC: {best_val_auc:.4f}\")\nexcept Exception as e:\n    print(f\"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}\")\n    print(\"ä½¿ç”¨å½“å‰æ¨¡å‹è¿›è¡Œè¯„ä¼°\")\n\n# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹\nprint(\"\\nğŸ” åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹...\")\neval_results = evaluate_model_optimized(model, test_loader, criterion, device)\n\n# è®¡ç®—å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡\nprint(\"\\nğŸ“ˆ è®¡ç®—è¯„ä¼°æŒ‡æ ‡...\")\nmetrics = calculate_comprehensive_metrics(\n    eval_results['predictions'], \n    eval_results['targets'], \n    eval_results['scores']\n)\n\n# æ‰“å°è¯¦ç»†ç»“æœ\nprint(\"\\nğŸ“Š è¯¦ç»†è¯„ä¼°ç»“æœ:\")\nprint(\"=\" * 50)\nprint(f\"æµ‹è¯•æŸå¤±: {eval_results['loss']:.4f}\")\nprint(f\"å‡†ç¡®ç‡: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\nprint(f\"å¹³è¡¡å‡†ç¡®ç‡: {metrics['balanced_accuracy']:.4f} ({metrics['balanced_accuracy']*100:.2f}%)\")\nprint(f\"ç²¾ç¡®ç‡: {metrics['precision']:.4f}\")\nprint(f\"å¬å›ç‡: {metrics['recall']:.4f}\")\nprint(f\"ç‰¹å¼‚æ€§: {metrics['specificity']:.4f}\")\nprint(f\"F1åˆ†æ•°: {metrics['f1']:.4f}\")\nprint(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")\nprint(f\"AUC-PR: {metrics['auc_pr']:.4f}\")\nprint(f\"è´Ÿé¢„æµ‹å€¼: {metrics['npv']:.4f}\")\n\n# æ··æ·†çŸ©é˜µè¯¦ç»†ä¿¡æ¯\nprint(\"\\nğŸ” æ··æ·†çŸ©é˜µåˆ†æ:\")\nprint(f\"çœŸè´Ÿä¾‹ (TN): {metrics['tn']}\")\nprint(f\"å‡æ­£ä¾‹ (FP): {metrics['fp']}\")\nprint(f\"å‡è´Ÿä¾‹ (FN): {metrics['fn']}\")\nprint(f\"çœŸæ­£ä¾‹ (TP): {metrics['tp']}\")\n\n# æ€§èƒ½åˆ†æ\nprint(\"\\nâš¡ æ€§èƒ½åˆ†æ:\")\nprint(f\"å¹³å‡æ¨ç†æ—¶é—´: {eval_results['avg_inference_time']*1000:.2f} ms/batch\")\nprint(f\"æ€»æ¨ç†æ—¶é—´: {eval_results['total_inference_time']:.2f} ç§’\")\nprint(f\"æ¯ä¸ªæ ·æœ¬æ¨ç†æ—¶é—´: {eval_results['avg_inference_time']*1000/batch_size:.2f} ms\")\n\n# è®¡ç®—é¢å¤–æŒ‡æ ‡\ntotal_samples = len(eval_results['targets'])\nreal_samples = np.sum(eval_results['targets'] == 0)\nfake_samples = np.sum(eval_results['targets'] == 1)\nreal_accuracy = np.sum((eval_results['predictions'] == 0) & (eval_results['targets'] == 0)) / real_samples if real_samples > 0 else 0\nfake_accuracy = np.sum((eval_results['predictions'] == 1) & (eval_results['targets'] == 1)) / fake_samples if fake_samples > 0 else 0\n\nprint(\"\\nğŸ“‹ ç±»åˆ«ç‰¹å®šåˆ†æ:\")\nprint(f\"æ€»æ ·æœ¬æ•°: {total_samples}\")\nprint(f\"çœŸå®è§†é¢‘æ ·æœ¬: {real_samples} ({real_samples/total_samples*100:.1f}%)\")\nprint(f\"ä¼ªé€ è§†é¢‘æ ·æœ¬: {fake_samples} ({fake_samples/total_samples*100:.1f}%)\")\nprint(f\"çœŸå®è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: {real_accuracy:.4f} ({real_accuracy*100:.2f}%)\")\nprint(f\"ä¼ªé€ è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: {fake_accuracy:.4f} ({fake_accuracy*100:.2f}%)\")\n\n# ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨\nprint(\"\\nğŸ“Š ç”Ÿæˆè¯„ä¼°å›¾è¡¨...\")\n\n# ç»˜åˆ¶å¢å¼ºæ··æ·†çŸ©é˜µ\nplot_enhanced_confusion_matrix(\n    metrics['confusion_matrix'], \n    './results/evaluation/confusion_matrix.png'\n)\n\n# ç»˜åˆ¶ROCå’ŒPRæ›²çº¿\nplot_roc_pr_curves(\n    eval_results['targets'], \n    eval_results['scores'], \n    './results/evaluation/roc_pr_curves.png'\n)\n\n# é¢„æµ‹åˆ†æ•°åˆ†å¸ƒå›¾\nplt.figure(figsize=(12, 5))\n\n# çœŸå®è§†é¢‘çš„é¢„æµ‹åˆ†æ•°åˆ†å¸ƒ\nplt.subplot(1, 2, 1)\nreal_scores = eval_results['scores'][eval_results['targets'] == 0]\nfake_scores = eval_results['scores'][eval_results['targets'] == 1]\n\nplt.hist(real_scores, bins=30, alpha=0.7, label='çœŸå®è§†é¢‘', color='blue', density=True)\nplt.hist(fake_scores, bins=30, alpha=0.7, label='ä¼ªé€ è§†é¢‘', color='red', density=True)\nplt.xlabel('é¢„æµ‹åˆ†æ•°')\nplt.ylabel('å¯†åº¦')\nplt.title('é¢„æµ‹åˆ†æ•°åˆ†å¸ƒ')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n# é¢„æµ‹åˆ†æ•°ç®±çº¿å›¾\nplt.subplot(1, 2, 2)\nscores_data = [real_scores, fake_scores]\nlabels = ['çœŸå®è§†é¢‘', 'ä¼ªé€ è§†é¢‘']\nplt.boxplot(scores_data, labels=labels)\nplt.ylabel('é¢„æµ‹åˆ†æ•°')\nplt.title('é¢„æµ‹åˆ†æ•°ç®±çº¿å›¾')\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('./results/evaluation/score_distribution.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ… è¯„ä¼°å›¾è¡¨ç”Ÿæˆå®Œæˆ\")\nprint(\"=\" * 60)\nprint(\"ğŸ‰ æ¨¡å‹è¯„ä¼°å®Œæˆï¼\")\nprint(\"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° ./results/evaluation/ ç›®å½•\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 14: ç»“æœä¿å­˜å’Œæ€»ç»“\n","metadata":{}},{"cell_type":"code","source":"# Cell 14: ç»“æœä¿å­˜å’Œæ€»ç»“\n\nprint(\"ğŸ’¾ ä¿å­˜å®éªŒç»“æœ...\")\nprint(\"=\" * 60)\n\n# å‡†å¤‡ä¿å­˜çš„ç»“æœæ•°æ®\nresults_summary = {\n    'experiment_info': {\n        'timestamp': datetime.now().isoformat(),\n        'model_architecture': 'OptimizedDeepfakeDetector',\n        'backbone': 'resnet18',\n        'total_epochs': len(train_history['train_loss']),\n        'best_epoch': best_epoch + 1 if 'best_epoch' in locals() else len(train_history['train_loss']),\n        'early_stopping': True,\n        'mixed_precision': torch.cuda.is_available()\n    },\n    'dataset_info': {\n        'train_samples': len(train_dataset),\n        'val_samples': len(val_dataset),\n        'test_samples': len(test_dataset),\n        'batch_size': batch_size,\n        'num_workers': 2\n    },\n    'training_config': {\n        'optimizer': 'AdamW',\n        'learning_rate': 1e-4,\n        'weight_decay': 1e-4,\n        'loss_function': 'FocalLoss',\n        'scheduler': 'ReduceLROnPlateau',\n        'early_stopping_patience': 5\n    },\n    'final_metrics': {\n        'test_loss': float(eval_results['loss']),\n        'accuracy': float(metrics['accuracy']),\n        'balanced_accuracy': float(metrics['balanced_accuracy']),\n        'precision': float(metrics['precision']),\n        'recall': float(metrics['recall']),\n        'specificity': float(metrics['specificity']),\n        'f1_score': float(metrics['f1']),\n        'auc_roc': float(metrics['auc_roc']),\n        'auc_pr': float(metrics['auc_pr']),\n        'npv': float(metrics['npv'])\n    },\n    'confusion_matrix': {\n        'tn': int(metrics['tn']),\n        'fp': int(metrics['fp']),\n        'fn': int(metrics['fn']),\n        'tp': int(metrics['tp'])\n    },\n    'performance': {\n        'avg_inference_time_ms': float(eval_results['avg_inference_time'] * 1000),\n        'total_inference_time_s': float(eval_results['total_inference_time']),\n        'samples_per_second': float(len(eval_results['targets']) / eval_results['total_inference_time'])\n    },\n    'training_history': {\n        'train_loss': [float(x) for x in train_history['train_loss']],\n        'train_acc': [float(x) for x in train_history['train_acc']],\n        'train_auc': [float(x) for x in train_history['train_auc']],\n        'val_loss': [float(x) for x in train_history['val_loss']],\n        'val_acc': [float(x) for x in train_history['val_acc']],\n        'val_auc': [float(x) for x in train_history['val_auc']],\n        'learning_rates': [float(x) for x in train_history['lr']]\n    },\n    'class_specific_metrics': {\n        'real_video_accuracy': float(real_accuracy),\n        'fake_video_accuracy': float(fake_accuracy),\n        'real_samples_count': int(real_samples),\n        'fake_samples_count': int(fake_samples)\n    }\n}\n\n# ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶\nresults_file = './results/experiment_results.json'\nwith open(results_file, 'w', encoding='utf-8') as f:\n    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n\nprint(f\"âœ… å®éªŒç»“æœå·²ä¿å­˜åˆ°: {results_file}\")\n\n# ä¿å­˜è®­ç»ƒå†å²åˆ°CSV\nhistory_df = pd.DataFrame(train_history)\nhistory_df.to_csv('./results/training_history.csv', index=False)\nprint(\"âœ… è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: ./results/training_history.csv\")\n\n# ä¿å­˜é¢„æµ‹ç»“æœ\npredictions_df = pd.DataFrame({\n    'true_label': eval_results['targets'],\n    'predicted_label': eval_results['predictions'],\n    'prediction_score': eval_results['scores']\n})\npredictions_df.to_csv('./results/test_predictions.csv', index=False)\nprint(\"âœ… æµ‹è¯•é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: ./results/test_predictions.csv\")\n\n# ç”Ÿæˆå®éªŒæŠ¥å‘Š\nprint(\"\\nğŸ“‹ ç”Ÿæˆå®éªŒæŠ¥å‘Š...\")\nreport = f\"\"\"\næ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹å®éªŒæŠ¥å‘Š\n{'='*50}\n\nå®éªŒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\næ¨¡å‹æ¶æ„: OptimizedDeepfakeDetector (ResNet18 + LSTM + Attention)\n\næ•°æ®é›†ä¿¡æ¯:\n- è®­ç»ƒæ ·æœ¬: {len(train_dataset):,}\n- éªŒè¯æ ·æœ¬: {len(val_dataset):,}\n- æµ‹è¯•æ ·æœ¬: {len(test_dataset):,}\n- æ‰¹æ¬¡å¤§å°: {batch_size}\n\nè®­ç»ƒé…ç½®:\n- ä¼˜åŒ–å™¨: AdamW (lr=1e-4, weight_decay=1e-4)\n- æŸå¤±å‡½æ•°: Focal Loss (alpha=1, gamma=2)\n- å­¦ä¹ ç‡è°ƒåº¦: ReduceLROnPlateau\n- æ—©åœæœºåˆ¶: patience=5\n- æ··åˆç²¾åº¦è®­ç»ƒ: {'å¯ç”¨' if torch.cuda.is_available() else 'ç¦ç”¨'}\n\næœ€ç»ˆæ€§èƒ½æŒ‡æ ‡:\n- å‡†ç¡®ç‡: {metrics['accuracy']*100:.2f}%\n- å¹³è¡¡å‡†ç¡®ç‡: {metrics['balanced_accuracy']*100:.2f}%\n- ç²¾ç¡®ç‡: {metrics['precision']:.4f}\n- å¬å›ç‡: {metrics['recall']:.4f}\n- F1åˆ†æ•°: {metrics['f1']:.4f}\n- AUC-ROC: {metrics['auc_roc']:.4f}\n- AUC-PR: {metrics['auc_pr']:.4f}\n\næ··æ·†çŸ©é˜µ:\n- çœŸè´Ÿä¾‹ (TN): {metrics['tn']}\n- å‡æ­£ä¾‹ (FP): {metrics['fp']}\n- å‡è´Ÿä¾‹ (FN): {metrics['fn']}\n- çœŸæ­£ä¾‹ (TP): {metrics['tp']}\n\nç±»åˆ«ç‰¹å®šæ€§èƒ½:\n- çœŸå®è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: {real_accuracy*100:.2f}%\n- ä¼ªé€ è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: {fake_accuracy*100:.2f}%\n\næ¨ç†æ€§èƒ½:\n- å¹³å‡æ¨ç†æ—¶é—´: {eval_results['avg_inference_time']*1000:.2f} ms/batch\n- å¤„ç†é€Ÿåº¦: {len(eval_results['targets'])/eval_results['total_inference_time']:.1f} samples/s\n\nè®­ç»ƒæ€»ç»“:\n- è®­ç»ƒè½®æ•°: {len(train_history['train_loss'])}\n- æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {max(train_history['val_acc']):.2f}%\n- æœ€ä½³éªŒè¯AUC: {max(train_history['val_auc']):.4f}\n\næ–‡ä»¶è¾“å‡º:\n- æ¨¡å‹æƒé‡: ./models/best_model.pth\n- è®­ç»ƒå†å²å›¾: ./results/training_history.png\n- æ··æ·†çŸ©é˜µå›¾: ./results/evaluation/confusion_matrix.png\n- ROC/PRæ›²çº¿å›¾: ./results/evaluation/roc_pr_curves.png\n- åˆ†æ•°åˆ†å¸ƒå›¾: ./results/evaluation/score_distribution.png\n- å®éªŒç»“æœ: ./results/experiment_results.json\n- è®­ç»ƒå†å²: ./results/training_history.csv\n- é¢„æµ‹ç»“æœ: ./results/test_predictions.csv\n\n{'='*50}\nå®éªŒå®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\"\"\"\n\n# ä¿å­˜æŠ¥å‘Š\nwith open('./results/experiment_report.txt', 'w', encoding='utf-8') as f:\n    f.write(report)\n\nprint(\"âœ… å®éªŒæŠ¥å‘Šå·²ä¿å­˜åˆ°: ./results/experiment_report.txt\")\n\n# æ‰“å°æœ€ç»ˆæ€»ç»“\nprint(\"\\n\" + \"=\"*60)\nprint(\"ğŸ‰ æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å®Œæˆï¼\")\nprint(\"=\"*60)\nprint(f\"ğŸ“Š æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {metrics['accuracy']*100:.2f}%\")\nprint(f\"ğŸ“Š AUC-ROCåˆ†æ•°: {metrics['auc_roc']:.4f}\")\nprint(f\"ğŸ“Š F1åˆ†æ•°: {metrics['f1']:.4f}\")\nprint(f\"âš¡ æ¨ç†é€Ÿåº¦: {len(eval_results['targets'])/eval_results['total_inference_time']:.1f} samples/s\")\nprint(\"\\nğŸ“ æ‰€æœ‰ç»“æœæ–‡ä»¶å·²ä¿å­˜åˆ° ./results/ ç›®å½•\")\nprint(\"ğŸ“ æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ° ./models/best_model.pth\")\nprint(\"\\nâœ¨ å®éªŒæˆåŠŸå®Œæˆï¼å¯ä»¥åœ¨Kaggleä¸­æŸ¥çœ‹æ‰€æœ‰ç”Ÿæˆçš„å›¾è¡¨å’Œç»“æœæ–‡ä»¶ã€‚\")\nprint(\"=\"*60)\n\n# æ˜¾ç¤ºæ–‡ä»¶ç»“æ„\nprint(\"\\nğŸ“‚ ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„:\")\nprint(\"\"\"\n./models/\n  â””â”€â”€ best_model.pth\n./results/\n  â”œâ”€â”€ experiment_results.json\n  â”œâ”€â”€ experiment_report.txt\n  â”œâ”€â”€ training_history.csv\n  â”œâ”€â”€ training_history.png\n  â”œâ”€â”€ test_predictions.csv\n  â””â”€â”€ evaluation/\n      â”œâ”€â”€ confusion_matrix.png\n      â”œâ”€â”€ roc_pr_curves.png\n      â””â”€â”€ score_distribution.png\n\"\"\")\n\nprint(\"\\nğŸš€ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†:\")\nprint(\"\"\"\n# åŠ è½½æ¨¡å‹\nmodel = OptimizedDeepfakeDetector(...)\ncheckpoint = torch.load('./models/best_model.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\n\n# è¿›è¡Œæ¨ç† (æ³¨æ„: æ¨¡å‹è¾“å‡º logitsï¼Œéœ€è¦åº”ç”¨ sigmoid è·å¾—æ¦‚ç‡)\nwith torch.no_grad():\n    logits, attention = model(video_tensor)\n    probs = torch.sigmoid(logits)  # è½¬æ¢ä¸ºæ¦‚ç‡\n    prediction = (probs > 0.5).float()\n    confidence = probs.item()\n\"\"\")\n\nprint(\"\\nğŸ’¡ æç¤º: åœ¨Kaggleä¸­è¿è¡Œæ—¶ï¼Œå»ºè®®æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰cellï¼Œç¡®ä¿æ•°æ®è·¯å¾„æ­£ç¡®è®¾ç½®ã€‚\")\nprint(\"\\nâš ï¸  é‡è¦: æ¨¡å‹è¾“å‡ºçš„æ˜¯ logitsï¼Œä½¿ç”¨æ—¶å¿…é¡»å…ˆåº”ç”¨ sigmoid å‡½æ•°è½¬æ¢ä¸ºæ¦‚ç‡å€¼ï¼\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}