{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3936c6bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:27:45.790240Z",
     "iopub.status.busy": "2025-07-29T10:27:45.789973Z",
     "iopub.status.idle": "2025-07-29T10:27:57.253021Z",
     "shell.execute_reply": "2025-07-29T10:27:57.252179Z"
    },
    "papermill": {
     "duration": 11.473626,
     "end_time": "2025-07-29T10:27:57.254681",
     "exception": false,
     "start_time": "2025-07-29T10:27:45.781055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting av\r\n",
      "  Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\r\n",
      "Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.7 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: av\r\n",
      "Successfully installed av-15.0.0\r\n",
      "Collecting mtcnn\r\n",
      "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn) (1.5.1)\r\n",
      "Collecting lz4>=4.3.3 (from mtcnn)\r\n",
      "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n",
      "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lz4, mtcnn\r\n",
      "Successfully installed lz4-4.4.4 mtcnn-1.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install av\n",
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06535c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:27:57.273811Z",
     "iopub.status.busy": "2025-07-29T10:27:57.273554Z",
     "iopub.status.idle": "2025-07-29T10:28:37.923651Z",
     "shell.execute_reply": "2025-07-29T10:28:37.922758Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 40.661106,
     "end_time": "2025-07-29T10:28:37.925023",
     "exception": false,
     "start_time": "2025-07-29T10:27:57.263917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ CUDAå·²åˆå§‹åŒ–ï¼Œæ£€æµ‹åˆ° 2 ä¸ªGPUè®¾å¤‡\n",
      "   - GPU 0: Tesla T4 (14.7 GB)\n",
      "   - GPU 1: Tesla T4 (14.7 GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753784901.012661      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753784901.121581      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MTCNNå·²å®‰è£…ï¼Œæ”¯æŒé«˜ç²¾åº¦äººè„¸æ£€æµ‹\n",
      "   - äººè„¸æ£€æµ‹ç²¾åº¦: é«˜\n",
      "   - æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼: 0.9\n",
      "   - APIç‰ˆæœ¬: æ–°ç‰ˆæœ¬ (v1.0.0+)\n",
      "   - TensorFlowè­¦å‘Šå·²æŠ‘åˆ¶\n",
      "âœ… PyAVå·²å®‰è£…ï¼Œæ”¯æŒGPUè§†é¢‘å¤„ç†\n",
      "âœ… SciPyå·²å®‰è£…ï¼Œæ”¯æŒé¢‘åŸŸåˆ†æ\n",
      "âœ… æ‰€æœ‰åº“å¯¼å…¥å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: å¯¼å…¥åº“å’Œç¯å¢ƒè®¾ç½®\n",
    "\n",
    "# æŠ‘åˆ¶CUDAå’ŒTensorFlowè­¦å‘Šä¿¡æ¯\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# è®¾ç½®ç¯å¢ƒå˜é‡ - å¿…é¡»åœ¨å¯¼å…¥TensorFlowä¹‹å‰è®¾ç½®\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # æŠ‘åˆ¶æ‰€æœ‰TensorFlowæ—¥å¿— (0=å…¨éƒ¨, 1=INFO, 2=WARNING, 3=ERROR)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # å¼‚æ­¥CUDAæ‰§è¡Œ\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'   # æŠ‘åˆ¶Pythonè­¦å‘Š\n",
    "\n",
    "# æŠ‘åˆ¶CUDAç›¸å…³è­¦å‘Š\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # ç¦ç”¨oneDNNä¼˜åŒ–è­¦å‘Š\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'  # GPUå†…å­˜åŠ¨æ€å¢é•¿\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # æ˜ç¡®æŒ‡å®šå¯è§çš„GPUè®¾å¤‡\n",
    "\n",
    "# æŠ‘åˆ¶cuDNN/cuFFT/cuBLASé‡å¤æ³¨å†Œè­¦å‘Š\n",
    "os.environ['TF_DISABLE_SEGMENT_REDUCTION_OP_DETERMINISM_EXCEPTIONS'] = '1'\n",
    "\n",
    "# æŠ‘åˆ¶æ‰€æœ‰è­¦å‘Š\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# ä¿®å¤CUDAå¤šè¿›ç¨‹é—®é¢˜\n",
    "import multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "except RuntimeError:\n",
    "    pass  # å¦‚æœå·²ç»è®¾ç½®è¿‡ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import warnings\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorchç›¸å…³\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "from torchvision.io import read_video\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# åˆå§‹åŒ–CUDAå¹¶æŠ‘åˆ¶è­¦å‘Š\n",
    "if torch.cuda.is_available():\n",
    "    # åˆå§‹åŒ–CUDAä¸Šä¸‹æ–‡ä»¥é¿å…åç»­è­¦å‘Š\n",
    "    torch.cuda.init()\n",
    "    # è®¾ç½®CUDAè®¾å¤‡\n",
    "    torch.cuda.set_device(0)\n",
    "    # æ¸…ç†CUDAç¼“å­˜\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"ğŸš€ CUDAå·²åˆå§‹åŒ–ï¼Œæ£€æµ‹åˆ° {torch.cuda.device_count()} ä¸ªGPUè®¾å¤‡\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "        print(f\"   - GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "else:\n",
    "    print(\"âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼\")\n",
    "\n",
    "# æœºå™¨å­¦ä¹ æŒ‡æ ‡\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, auc, precision_recall_curve, balanced_accuracy_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ç³»ç»Ÿç›‘æ§å’Œæ€§èƒ½åˆ†æ\n",
    "import psutil\n",
    "import traceback\n",
    "\n",
    "# é«˜ç²¾åº¦äººè„¸æ£€æµ‹ - MTCNN\n",
    "try:\n",
    "    # åœ¨å¯¼å…¥MTCNNä¹‹å‰è¿›ä¸€æ­¥æŠ‘åˆ¶TensorFlowè­¦å‘Š\n",
    "    import logging\n",
    "    logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "    \n",
    "    # æŠ‘åˆ¶abslæ—¥å¿—\n",
    "    try:\n",
    "        import absl.logging\n",
    "        absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    from mtcnn import MTCNN\n",
    "    MTCNN_AVAILABLE = True\n",
    "    print(\"âœ… MTCNNå·²å®‰è£…ï¼Œæ”¯æŒé«˜ç²¾åº¦äººè„¸æ£€æµ‹\")\n",
    "    print(\"   - äººè„¸æ£€æµ‹ç²¾åº¦: é«˜\")\n",
    "    print(\"   - æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼: 0.9\")\n",
    "    print(\"   - APIç‰ˆæœ¬: æ–°ç‰ˆæœ¬ (v1.0.0+)\")\n",
    "    print(\"   - TensorFlowè­¦å‘Šå·²æŠ‘åˆ¶\")\n",
    "except ImportError:\n",
    "    MTCNN_AVAILABLE = False\n",
    "    print(\"âš ï¸ MTCNNæœªå®‰è£…ï¼Œå°†ä½¿ç”¨OpenCVäººè„¸æ£€æµ‹\")\n",
    "    print(\"   - äººè„¸æ£€æµ‹ç²¾åº¦: ä¸­ç­‰\")\n",
    "    print(\"   - å»ºè®®å®‰è£…MTCNNä»¥è·å¾—æ›´é«˜ç²¾åº¦:\")\n",
    "    print(\"   - å®‰è£…å‘½ä»¤: !pip install mtcnn\")\n",
    "    print(\"   - æˆ–è€…: !pip install mtcnn[tensorflow]\")\n",
    "    print(\"   - æ³¨æ„: éœ€è¦TensorFlow >= 2.12\")\n",
    "    print(\"   - å½±å“: äººè„¸æ£€æµ‹ç²¾åº¦ç•¥æœ‰é™ä½ï¼Œä½†ä¸å½±å“æ•´ä½“è®­ç»ƒ\")\n",
    "\n",
    "# è§†é¢‘å¤„ç† (PyAV)\n",
    "try:\n",
    "    import av\n",
    "    PYAV_AVAILABLE = True\n",
    "    print(\"âœ… PyAVå·²å®‰è£…ï¼Œæ”¯æŒGPUè§†é¢‘å¤„ç†\")\n",
    "except ImportError:\n",
    "    PYAV_AVAILABLE = False\n",
    "    print(\"âš ï¸ PyAVæœªå®‰è£…ï¼Œè§†é¢‘å¤„ç†å°†å›é€€åˆ°CPUæ¨¡å¼\")\n",
    "\n",
    "# æ•°æ®å¢å¼º\n",
    "try:\n",
    "    import albumentations as A\n",
    "    from albumentations.pytorch import ToTensorV2\n",
    "    ALBUMENTATIONS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ALBUMENTATIONS_AVAILABLE = False\n",
    "    print(\"è­¦å‘Š: albumentationsæœªå®‰è£…ï¼Œå°†ä½¿ç”¨åŸºç¡€æ•°æ®å¢å¼º\")\n",
    "\n",
    "# é¢‘åŸŸåˆ†ææ”¯æŒ\n",
    "try:\n",
    "    from scipy import fftpack\n",
    "    from scipy.signal import butter, filtfilt\n",
    "    SCIPY_AVAILABLE = True\n",
    "    print(\"âœ… SciPyå·²å®‰è£…ï¼Œæ”¯æŒé¢‘åŸŸåˆ†æ\")\n",
    "except ImportError:\n",
    "    SCIPY_AVAILABLE = False\n",
    "    print(\"âš ï¸ SciPyæœªå®‰è£…ï¼Œé¢‘åŸŸåˆ†æåŠŸèƒ½å—é™\")\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰åº“å¯¼å…¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "988a7827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:37.944094Z",
     "iopub.status.busy": "2025-07-29T10:28:37.943599Z",
     "iopub.status.idle": "2025-07-29T10:28:38.158257Z",
     "shell.execute_reply": "2025-07-29T10:28:38.157555Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.225086,
     "end_time": "2025-07-29T10:28:38.159479",
     "exception": false,
     "start_time": "2025-07-29T10:28:37.934393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½¿ç”¨è®¾å¤‡: cuda\n",
      "ğŸ® GPUæ•°é‡: 2\n",
      "ğŸ® GPUå‹å·: Tesla T4\n",
      "ğŸ’¾ å•GPUå†…å­˜: 14.7 GB\n",
      "ğŸ’¾ æ€»GPUå†…å­˜: 29.5 GB\n",
      "âœ… æ£€æµ‹åˆ° 2 ä¸ªGPUï¼Œå¯ç”¨å¤šGPUå¹¶è¡Œè®­ç»ƒ\n",
      "âœ… Kaggle T4 GPUä¼˜åŒ–é…ç½®å·²å¯ç”¨\n",
      "æ•°æ®ç±»å‹ç­–ç•¥: FP32 (å…¼å®¹æ€§ä¼˜å…ˆ)\n",
      "ç¯å¢ƒ: Kaggle\n",
      "æ•°æ®åŸºç¡€è·¯å¾„: /kaggle/input/ff-c23/FaceForensics++_C23\n",
      "âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: å…¨å±€é…ç½®å’Œå·¥å…·å‡½æ•° - Kaggle T4 ä¼˜åŒ–ç‰ˆæœ¬\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    # Kaggleç¯å¢ƒä¼˜åŒ–ï¼šå¹³è¡¡æ€§èƒ½å’Œå¯é‡å¤æ€§\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Kaggle T4 GPUé…ç½®\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    \n",
    "    print(f\"ğŸ® GPUæ•°é‡: {gpu_count}\")\n",
    "    print(f\"ğŸ® GPUå‹å·: {gpu_name}\")\n",
    "    print(f\"ğŸ’¾ å•GPUå†…å­˜: {gpu_memory:.1f} GB\")\n",
    "    print(f\"ğŸ’¾ æ€»GPUå†…å­˜: {gpu_memory * gpu_count:.1f} GB\")\n",
    "    \n",
    "    # å¤šGPUé…ç½®\n",
    "    USE_MULTI_GPU = gpu_count > 1\n",
    "    if USE_MULTI_GPU:\n",
    "        print(f\"âœ… æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUï¼Œå¯ç”¨å¤šGPUå¹¶è¡Œè®­ç»ƒ\")\n",
    "        # åŒT4 GPUä¼˜åŒ–é…ç½®\n",
    "        torch.cuda.set_per_process_memory_fraction(0.8)  # åŒT4å¯ä»¥ä½¿ç”¨æ›´å¤šå†…å­˜\n",
    "    else:\n",
    "        print(\"ğŸ“ å•GPUæ¨¡å¼\")\n",
    "        torch.cuda.set_per_process_memory_fraction(0.7)  # å•GPUä¿å®ˆé…ç½®\n",
    "    \n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    print(\"âœ… Kaggle T4 GPUä¼˜åŒ–é…ç½®å·²å¯ç”¨\")\n",
    "else:\n",
    "    USE_MULTI_GPU = False\n",
    "\n",
    "# åˆ›å»ºå¿…è¦çš„ç›®å½•\n",
    "for dir_name in ['./data', './models', './logs', './results']:\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "# Kaggleç¯å¢ƒæ£€æµ‹\n",
    "IS_KAGGLE = os.path.exists('/kaggle')\n",
    "BASE_DATA_DIR = '/kaggle/input/ff-c23/FaceForensics++_C23' if IS_KAGGLE else './dataset/FaceForensics++_C23'\n",
    "\n",
    "# ç»Ÿä¸€æ•°æ®ç±»å‹é…ç½® - å…¨éƒ¨ä½¿ç”¨FP32æå‡å…¼å®¹æ€§\n",
    "USE_FP32_ONLY = True  # å¼ºåˆ¶ä½¿ç”¨FP32ï¼Œç¡®ä¿æœ€ä½³å…¼å®¹æ€§\n",
    "print(f\"æ•°æ®ç±»å‹ç­–ç•¥: FP32 (å…¼å®¹æ€§ä¼˜å…ˆ)\")\n",
    "\n",
    "print(f\"ç¯å¢ƒ: {'Kaggle' if IS_KAGGLE else 'æœ¬åœ°'}\")\n",
    "print(f\"æ•°æ®åŸºç¡€è·¯å¾„: {BASE_DATA_DIR}\")\n",
    "print(\"âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f11b1da9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.177555Z",
     "iopub.status.busy": "2025-07-29T10:28:38.177326Z",
     "iopub.status.idle": "2025-07-29T10:28:38.216629Z",
     "shell.execute_reply": "2025-07-29T10:28:38.215926Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.049861,
     "end_time": "2025-07-29T10:28:38.217757",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.167896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•°æ®å¤„ç†å‡½æ•°å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: æ•°æ®å¤„ç†å‡½æ•°\n",
    "def extract_frames_gpu_accelerated(video_path, max_frames=16, target_size=(224, 224),\n",
    "                                  quality_threshold=20, use_gpu=True, use_mtcnn=True):\n",
    "    \"\"\"GPUåŠ é€Ÿçš„å¸§æå–å‡½æ•° - é›†æˆMTCNNäººè„¸æ£€æµ‹\"\"\"\n",
    "    try:\n",
    "        # æ£€æŸ¥PyAVæ˜¯å¦å¯ç”¨\n",
    "        if not globals().get('PYAV_AVAILABLE', False):\n",
    "            print(f\"PyAVä¸å¯ç”¨ï¼Œä½¿ç”¨CPUå›é€€å¤„ç†: {video_path}\")\n",
    "            return extract_frames_cpu_fallback(video_path, max_frames, target_size, quality_threshold, use_mtcnn)\n",
    "            \n",
    "        # è®¾å¤‡é€‰æ‹© - ä¼˜å…ˆä½¿ç”¨GPU\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # ä½¿ç”¨torchvisionçš„GPUåŠ é€Ÿè§†é¢‘è¯»å–\n",
    "        if not use_gpu:\n",
    "            device = torch.device('cpu')\n",
    "            \n",
    "        # è¯»å–è§†é¢‘ï¼ˆtorchvisionè‡ªåŠ¨å¤„ç†è§£ç ï¼‰\n",
    "        try:\n",
    "            video_tensor, audio, info = read_video(video_path, pts_unit='sec')\n",
    "            # video_tensor shape: (T, H, W, C)\n",
    "        except Exception as e:\n",
    "            print(f\"GPUè§†é¢‘è¯»å–å¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}\")\n",
    "            return extract_frames_cpu_fallback(video_path, max_frames, target_size, quality_threshold, use_mtcnn)\n",
    "        \n",
    "        if video_tensor.size(0) == 0:\n",
    "            return []\n",
    "            \n",
    "        # ç§»åŠ¨åˆ°GPUè¿›è¡Œå¤„ç†\n",
    "        video_tensor = video_tensor.to(device, non_blocking=True)\n",
    "        total_frames = video_tensor.size(0)\n",
    "        \n",
    "        # æ™ºèƒ½å¸§é‡‡æ ·ç­–ç•¥\n",
    "        if total_frames <= max_frames:\n",
    "            frame_indices = torch.arange(0, total_frames, device=device)\n",
    "        else:\n",
    "            # å‡åŒ€é‡‡æ ·\n",
    "            step = total_frames / max_frames\n",
    "            frame_indices = torch.arange(0, total_frames, step, device=device).long()[:max_frames]\n",
    "        \n",
    "        # æ‰¹é‡æå–å¸§\n",
    "        selected_frames = video_tensor[frame_indices]  # (max_frames, H, W, C)\n",
    "        \n",
    "        # GPUä¸Šè¿›è¡Œè´¨é‡æ£€æµ‹ï¼ˆä½¿ç”¨Sobelç®—å­ä»£æ›¿Laplacianï¼‰\n",
    "        if quality_threshold > 0:\n",
    "            # è½¬æ¢ä¸ºç°åº¦å›¾è¿›è¡Œè´¨é‡æ£€æµ‹ï¼ˆå…ˆè½¬æ¢ä¸ºfloatç±»å‹ï¼‰\n",
    "            gray_frames = selected_frames.float().mean(dim=-1, keepdim=True)  # (T, H, W, 1)\n",
    "            gray_frames = gray_frames.permute(0, 3, 1, 2)  # (T, 1, H, W)\n",
    "            \n",
    "            # ä½¿ç”¨Sobelç®—å­è®¡ç®—å›¾åƒè´¨é‡\n",
    "            sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], \n",
    "                                 dtype=torch.float32, device=device).view(1, 1, 3, 3)\n",
    "            sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], \n",
    "                                 dtype=torch.float32, device=device).view(1, 1, 3, 3)\n",
    "            \n",
    "            grad_x = F.conv2d(gray_frames, sobel_x, padding=1)\n",
    "            grad_y = F.conv2d(gray_frames, sobel_y, padding=1)\n",
    "            quality_scores = (grad_x.pow(2) + grad_y.pow(2)).mean(dim=[1, 2, 3])\n",
    "            \n",
    "            # è¿‡æ»¤ä½è´¨é‡å¸§\n",
    "            quality_mask = quality_scores > quality_threshold\n",
    "            if quality_mask.sum() > 0:\n",
    "                selected_frames = selected_frames[quality_mask]\n",
    "            \n",
    "        # GPUä¸Šè¿›è¡Œå°ºå¯¸è°ƒæ•´\n",
    "        selected_frames = selected_frames.permute(0, 3, 1, 2).float()  # (T, C, H, W)\n",
    "        if selected_frames.size(-1) != target_size[0] or selected_frames.size(-2) != target_size[1]:\n",
    "            selected_frames = F.interpolate(selected_frames, size=target_size, \n",
    "                                          mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # ç¡®ä¿å¸§æ•°è¶³å¤Ÿ\n",
    "        current_frames = selected_frames.size(0)\n",
    "        if current_frames < max_frames:\n",
    "            # é‡å¤æœ€åä¸€å¸§\n",
    "            if current_frames > 0:\n",
    "                last_frame = selected_frames[-1:].repeat(max_frames - current_frames, 1, 1, 1)\n",
    "                selected_frames = torch.cat([selected_frames, last_frame], dim=0)\n",
    "            else:\n",
    "                # åˆ›å»ºé»‘è‰²å¸§\n",
    "                selected_frames = torch.zeros(max_frames, 3, target_size[0], target_size[1], \n",
    "                                            device=device, dtype=torch.float32)\n",
    "        \n",
    "        # é™åˆ¶åˆ°æœ€å¤§å¸§æ•°\n",
    "        selected_frames = selected_frames[:max_frames]\n",
    "        \n",
    "        # è½¬æ¢å›CPU numpyæ ¼å¼ï¼ˆä¸ºäº†å…¼å®¹ç°æœ‰ä»£ç ï¼‰\n",
    "        frames_cpu = selected_frames.permute(0, 2, 3, 1).cpu().numpy().astype(np.uint8)\n",
    "        frames_list = [frame for frame in frames_cpu]\n",
    "        \n",
    "        # åº”ç”¨MTCNNäººè„¸æ£€æµ‹å’Œè£å‰ª\n",
    "        if use_mtcnn and globals().get('MTCNN_AVAILABLE', False):\n",
    "            frames_list = apply_mtcnn_face_detection(frames_list, target_size)\n",
    "        \n",
    "        return frames_list\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"GPUå¸§æå–å¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}\")\n",
    "        return extract_frames_cpu_fallback(video_path, max_frames, target_size, quality_threshold, use_mtcnn)\n",
    "\n",
    "def apply_mtcnn_face_detection(frames, target_size=(224, 224)):\n",
    "    \"\"\"ä½¿ç”¨MTCNNè¿›è¡Œäººè„¸æ£€æµ‹å’Œè£å‰ª - å…¼å®¹æ–°ç‰ˆæœ¬API\"\"\"\n",
    "    try:\n",
    "        # æ–°ç‰ˆæœ¬MTCNNæ„é€ å‡½æ•°ä¸éœ€è¦å‚æ•°\n",
    "        detector = MTCNN()\n",
    "        processed_frames = []\n",
    "        \n",
    "        for frame in frames:\n",
    "            # MTCNNéœ€è¦RGBæ ¼å¼\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if len(frame.shape) == 3 else frame\n",
    "            \n",
    "            # æ£€æµ‹äººè„¸ - æ–°ç‰ˆæœ¬APIåœ¨detect_facesæ–¹æ³•ä¸­ä¼ é€’å‚æ•°\n",
    "            results = detector.detect_faces(\n",
    "                frame_rgb,\n",
    "                min_face_size=40,  # æœ€å°äººè„¸å°ºå¯¸\n",
    "                threshold_pnet=0.6,  # PNeté˜ˆå€¼\n",
    "                threshold_rnet=0.7,  # RNeté˜ˆå€¼  \n",
    "                threshold_onet=0.8   # ONeté˜ˆå€¼\n",
    "            )\n",
    "            \n",
    "            if results and len(results) > 0:\n",
    "                # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„äººè„¸\n",
    "                best_face = max(results, key=lambda x: x['confidence'])\n",
    "                \n",
    "                if best_face['confidence'] > 0.9:  # é«˜ç½®ä¿¡åº¦é˜ˆå€¼\n",
    "                    # æå–äººè„¸åŒºåŸŸ\n",
    "                    x, y, w, h = best_face['box']\n",
    "                    \n",
    "                    # æ‰©å±•è¾¹ç•Œæ¡†ä»¥åŒ…å«æ›´å¤šä¸Šä¸‹æ–‡\n",
    "                    margin = 0.2\n",
    "                    x_margin = int(w * margin)\n",
    "                    y_margin = int(h * margin)\n",
    "                    \n",
    "                    x1 = max(0, x - x_margin)\n",
    "                    y1 = max(0, y - y_margin)\n",
    "                    x2 = min(frame_rgb.shape[1], x + w + x_margin)\n",
    "                    y2 = min(frame_rgb.shape[0], y + h + y_margin)\n",
    "                    \n",
    "                    # è£å‰ªäººè„¸\n",
    "                    face_crop = frame_rgb[y1:y2, x1:x2]\n",
    "                    \n",
    "                    # ä½¿ç”¨ç»Ÿä¸€çš„å¸§å¤„ç†å‡½æ•°\n",
    "                    processed_frame = resize_and_validate_frame(face_crop, target_size, 0)  # MTCNNä¸éœ€è¦é¢å¤–è´¨é‡æ£€æŸ¥\n",
    "                    if processed_frame is None:\n",
    "                        processed_frames.append(cv2.resize(face_crop, target_size))  # å¦‚æœå¤„ç†å¤±è´¥ï¼Œè¿”å›åŸå¸§\n",
    "                    else:\n",
    "                        processed_frames.append(processed_frame)\n",
    "                else:\n",
    "                    # ç½®ä¿¡åº¦ä¸å¤Ÿï¼Œä½¿ç”¨åŸå§‹å¸§\n",
    "                    processed_frames.append(cv2.resize(frame_rgb, target_size))\n",
    "            else:\n",
    "                # æ²¡æœ‰æ£€æµ‹åˆ°äººè„¸ï¼Œä½¿ç”¨åŸå§‹å¸§\n",
    "                processed_frames.append(cv2.resize(frame_rgb, target_size))\n",
    "        \n",
    "        return processed_frames\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"MTCNNäººè„¸æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å¸§: {e}\")\n",
    "        return [cv2.resize(frame, target_size) for frame in frames]\n",
    "\n",
    "def resize_and_validate_frame(frame, target_size, quality_threshold=20):\n",
    "    \"\"\"ç»Ÿä¸€çš„å¸§å¤„ç†å‡½æ•°ï¼šè°ƒæ•´å¤§å°å¹¶éªŒè¯è´¨é‡\"\"\"\n",
    "    if frame is None:\n",
    "        return None\n",
    "    \n",
    "    # è°ƒæ•´å°ºå¯¸\n",
    "    resized_frame = cv2.resize(frame, target_size)\n",
    "    \n",
    "    # è´¨é‡æ£€æŸ¥\n",
    "    if quality_threshold > 0:\n",
    "        # è®¡ç®—å›¾åƒçš„æ–¹å·®ä½œä¸ºè´¨é‡æŒ‡æ ‡\n",
    "        gray = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2GRAY) if len(resized_frame.shape) == 3 else resized_frame\n",
    "        variance = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        if variance < quality_threshold:\n",
    "            return None\n",
    "    \n",
    "    return resized_frame\n",
    "\n",
    "def extract_frames_cpu_fallback(video_path, max_frames=16, target_size=(224, 224), quality_threshold=20, use_mtcnn=True):\n",
    "    \"\"\"CPUå›é€€çš„å¸§æå–å‡½æ•° - é›†æˆMTCNN\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}\")\n",
    "        return frames\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames == 0:\n",
    "        cap.release()\n",
    "        return frames\n",
    "\n",
    "    # å‡åŒ€é‡‡æ ·ç­–ç•¥\n",
    "    if total_frames <= max_frames:\n",
    "        frame_indices = list(range(0, total_frames, max(1, total_frames // max_frames)))\n",
    "    else:\n",
    "        step = max(1, total_frames // max_frames)\n",
    "        frame_indices = list(range(0, total_frames, step))[:max_frames]\n",
    "\n",
    "    frame_count = 0\n",
    "    for frame_idx in frame_indices:\n",
    "        if frame_count >= max_frames:\n",
    "            break\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # ä½¿ç”¨ç»Ÿä¸€çš„å¸§å¤„ç†å‡½æ•°\n",
    "            processed_frame = resize_and_validate_frame(frame, target_size, quality_threshold)\n",
    "            if processed_frame is None:\n",
    "                continue\n",
    "            frame = processed_frame\n",
    "            frames.append(frame)\n",
    "            frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # å¦‚æœå¸§æ•°ä¸è¶³ï¼Œé‡å¤æœ€åä¸€å¸§\n",
    "    while len(frames) < max_frames and len(frames) > 0:\n",
    "        frames.append(frames[-1].copy())\n",
    "\n",
    "    # åº”ç”¨MTCNNäººè„¸æ£€æµ‹\n",
    "    if use_mtcnn and globals().get('MTCNN_AVAILABLE', False):\n",
    "        frames = apply_mtcnn_face_detection(frames, target_size)\n",
    "\n",
    "    return frames[:max_frames]\n",
    "\n",
    "# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸå‡½æ•°åï¼Œä½†ç§»é™¤å†—ä½™å‚æ•°\n",
    "def extract_frames_memory_efficient(video_path, max_frames=16, target_size=(224, 224),\n",
    "                                   quality_threshold=20, use_mtcnn=True):\n",
    "    \"\"\"å…¼å®¹æ€§åŒ…è£…å‡½æ•°ï¼Œä¼˜å…ˆä½¿ç”¨GPUåŠ é€Ÿï¼Œé›†æˆMTCNN\n",
    "    æ³¨æ„ï¼šskip_frameså‚æ•°å·²ç§»é™¤ï¼Œå› ä¸ºGPUç‰ˆæœ¬ä½¿ç”¨æ›´æ™ºèƒ½çš„é‡‡æ ·ç­–ç•¥\n",
    "    \"\"\"\n",
    "    return extract_frames_gpu_accelerated(video_path, max_frames, target_size, quality_threshold, use_mtcnn=use_mtcnn)\n",
    "\n",
    "def process_videos_simple(base_data_dir, max_videos_per_class=60, max_frames=16, max_real=None, max_fake=None):\n",
    "    \"\"\"ç®€åŒ–çš„è§†é¢‘å¤„ç†å‡½æ•° - ä¼˜åŒ–å‡è§†é¢‘å¹³å‡åˆ†é…\"\"\"\n",
    "    # æ‰“å°è®¾å¤‡ä¿¡æ¯ï¼ˆåªæ‰“å°ä¸€æ¬¡ï¼‰\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"ğŸ“± æ•°æ®å¤„ç†ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "    \n",
    "    # å‘åå…¼å®¹ï¼šå¦‚æœæŒ‡å®šäº†æ–°å‚æ•°ï¼Œä½¿ç”¨æ–°å‚æ•°ï¼›å¦åˆ™ä½¿ç”¨æ—§å‚æ•°\n",
    "    if max_real is None:\n",
    "        max_real = max_videos_per_class\n",
    "    if max_fake is None:\n",
    "        max_fake = max_videos_per_class\n",
    "    \n",
    "    data_list = []\n",
    "    fake_methods = ['Deepfakes', 'Face2Face', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'DeepFakeDetection']\n",
    "\n",
    "    print(\"å¼€å§‹å¤„ç†çœŸå®è§†é¢‘...\")\n",
    "    # å¤„ç†çœŸå®è§†é¢‘\n",
    "    original_dir = os.path.join(base_data_dir, 'original')\n",
    "    if os.path.exists(original_dir):\n",
    "        video_files = [f for f in os.listdir(original_dir)\n",
    "                      if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        \n",
    "        if len(video_files) > max_real:\n",
    "            video_files = random.sample(video_files, max_real)\n",
    "\n",
    "        print(f\"æ‰¾åˆ° {len(video_files)} ä¸ªçœŸå®è§†é¢‘\")\n",
    "\n",
    "        for video_file in tqdm(video_files, desc=\"å¤„ç†çœŸå®è§†é¢‘\"):\n",
    "            try:\n",
    "                video_path = os.path.join(original_dir, video_file)\n",
    "                frames = extract_frames_memory_efficient(video_path, max_frames)\n",
    "                \n",
    "                if len(frames) >= max_frames // 2:  # è‡³å°‘è¦æœ‰ä¸€åŠçš„å¸§\n",
    "                    data_list.append({\n",
    "                        'video_path': video_path,\n",
    "                        'frames': frames,\n",
    "                        'label': 0,  # çœŸå®è§†é¢‘\n",
    "                        'method': 'original'\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"å¤„ç†è§†é¢‘ {video_file} æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "\n",
    "    # å¤„ç†ä¼ªé€ è§†é¢‘ - å¹³å‡åˆ†é…ç­–ç•¥\n",
    "    print(\"å¼€å§‹å¤„ç†ä¼ªé€ è§†é¢‘...\")\n",
    "    \n",
    "    # ç»Ÿè®¡æ¯ç§æ–¹æ³•çš„å¯ç”¨è§†é¢‘æ•°é‡\n",
    "    method_videos = {}\n",
    "    total_available_fake = 0\n",
    "    \n",
    "    for method in fake_methods:\n",
    "        method_dir = os.path.join(base_data_dir, method)\n",
    "        if os.path.exists(method_dir):\n",
    "            videos = [os.path.join(method_dir, f) for f in os.listdir(method_dir) \n",
    "                     if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "            method_videos[method] = videos\n",
    "            total_available_fake += len(videos)\n",
    "            print(f\"  {method}: {len(videos)} ä¸ªè§†é¢‘\")\n",
    "        else:\n",
    "            method_videos[method] = []\n",
    "            print(f\"  {method}: ç›®å½•ä¸å­˜åœ¨\")\n",
    "    \n",
    "    print(f\"æ€»å…±å¯ç”¨å‡è§†é¢‘: {total_available_fake} ä¸ª\")\n",
    "    \n",
    "    # è®¡ç®—æ¯ç§æ–¹æ³•åº”è¯¥é‡‡æ ·çš„è§†é¢‘æ•°é‡ï¼ˆå¹³å‡åˆ†é…ï¼‰\n",
    "    available_methods = [method for method in fake_methods if len(method_videos[method]) > 0]\n",
    "    if not available_methods:\n",
    "        print(\"âŒ æœªæ‰¾åˆ°ä»»ä½•å‡è§†é¢‘æ–¹æ³•\")\n",
    "        return data_list\n",
    "    \n",
    "    videos_per_method = max_fake // len(available_methods)\n",
    "    remaining_videos = max_fake % len(available_methods)\n",
    "    \n",
    "    print(f\"å¹³å‡åˆ†é…ç­–ç•¥: æ¯ç§æ–¹æ³• {videos_per_method} ä¸ªè§†é¢‘\")\n",
    "    if remaining_videos > 0:\n",
    "        print(f\"å‰©ä½™ {remaining_videos} ä¸ªè§†é¢‘å°†åˆ†é…ç»™å‰ {remaining_videos} ç§æ–¹æ³•\")\n",
    "    \n",
    "    # ä¸ºæ¯ç§æ–¹æ³•é‡‡æ ·è§†é¢‘\n",
    "    selected_fake_videos = []\n",
    "    for i, method in enumerate(available_methods):\n",
    "        # è®¡ç®—å½“å‰æ–¹æ³•åº”è¯¥é‡‡æ ·çš„æ•°é‡\n",
    "        current_method_quota = videos_per_method\n",
    "        if i < remaining_videos:  # å‰å‡ ç§æ–¹æ³•å¤šåˆ†é…ä¸€ä¸ª\n",
    "            current_method_quota += 1\n",
    "        \n",
    "        available_videos = method_videos[method]\n",
    "        \n",
    "        # å¦‚æœå¯ç”¨è§†é¢‘æ•°é‡å°‘äºé…é¢ï¼Œå…¨éƒ¨ä½¿ç”¨\n",
    "        if len(available_videos) <= current_method_quota:\n",
    "            method_selected = available_videos\n",
    "            print(f\"  {method}: ä½¿ç”¨å…¨éƒ¨ {len(method_selected)} ä¸ªè§†é¢‘\")\n",
    "        else:\n",
    "            # éšæœºé‡‡æ ·æŒ‡å®šæ•°é‡\n",
    "            method_selected = random.sample(available_videos, current_method_quota)\n",
    "            print(f\"  {method}: é‡‡æ · {len(method_selected)} ä¸ªè§†é¢‘\")\n",
    "        \n",
    "        selected_fake_videos.extend([(v, method) for v in method_selected])\n",
    "    \n",
    "    print(f\"æ€»å…±é€‰æ‹© {len(selected_fake_videos)} ä¸ªå‡è§†é¢‘è¿›è¡Œå¤„ç†\")\n",
    "    \n",
    "    # æ‰“ä¹±é€‰æ‹©çš„å‡è§†é¢‘é¡ºåº\n",
    "    random.shuffle(selected_fake_videos)\n",
    "    \n",
    "    # å¤„ç†é€‰æ‹©çš„å‡è§†é¢‘\n",
    "    for video_path, method in tqdm(selected_fake_videos, desc=\"å¤„ç†ä¼ªé€ è§†é¢‘\"):\n",
    "        try:\n",
    "            frames = extract_frames_memory_efficient(video_path, max_frames)\n",
    "            \n",
    "            if len(frames) >= max_frames // 2:\n",
    "                data_list.append({\n",
    "                    'video_path': video_path,\n",
    "                    'frames': frames,\n",
    "                    'label': 1,  # ä¼ªé€ è§†é¢‘\n",
    "                    'method': method\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"å¤„ç†è§†é¢‘ {os.path.basename(video_path)} æ—¶å‡ºé”™: {e}\")\n",
    "            continue\n",
    "\n",
    "    # ç»Ÿè®¡æœ€ç»ˆç»“æœ\n",
    "    method_counts = {}\n",
    "    for item in data_list:\n",
    "        if item['label'] == 1:  # åªç»Ÿè®¡å‡è§†é¢‘\n",
    "            method = item['method']\n",
    "            method_counts[method] = method_counts.get(method, 0) + 1\n",
    "    \n",
    "    print(f\"\\nâœ… æ•°æ®å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(data_list)} ä¸ªè§†é¢‘\")\n",
    "    print(\"å‡è§†é¢‘æ–¹æ³•åˆ†å¸ƒ:\")\n",
    "    for method, count in method_counts.items():\n",
    "        print(f\"  {method}: {count} ä¸ªè§†é¢‘\")\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "def create_dataset_split(data_list, test_size=0.2, val_size=0.1):\n",
    "    \"\"\"åˆ›å»ºæ•°æ®é›†åˆ’åˆ†\"\"\"\n",
    "    # åˆ†ç¦»çœŸå®å’Œä¼ªé€ æ•°æ®\n",
    "    real_data = [item for item in data_list if item['label'] == 0]\n",
    "    fake_data = [item for item in data_list if item['label'] == 1]\n",
    "    \n",
    "    print(f\"çœŸå®è§†é¢‘: {len(real_data)} ä¸ª\")\n",
    "    print(f\"ä¼ªé€ è§†é¢‘: {len(fake_data)} ä¸ª\")\n",
    "    \n",
    "    # åˆ†åˆ«åˆ’åˆ†çœŸå®å’Œä¼ªé€ æ•°æ®\n",
    "    real_train, real_temp = train_test_split(real_data, test_size=test_size+val_size, random_state=42)\n",
    "    real_val, real_test = train_test_split(real_temp, test_size=test_size/(test_size+val_size), random_state=42)\n",
    "    \n",
    "    fake_train, fake_temp = train_test_split(fake_data, test_size=test_size+val_size, random_state=42)\n",
    "    fake_val, fake_test = train_test_split(fake_temp, test_size=test_size/(test_size+val_size), random_state=42)\n",
    "    \n",
    "    # åˆå¹¶æ•°æ®\n",
    "    train_data = real_train + fake_train\n",
    "    val_data = real_val + fake_val\n",
    "    test_data = real_test + fake_test\n",
    "    \n",
    "    # æ‰“ä¹±æ•°æ®\n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(val_data)\n",
    "    random.shuffle(test_data)\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def save_dataset_to_csv(data_list, filename):\n",
    "    \"\"\"å°†æ•°æ®é›†ä¿å­˜ä¸ºCSVæ–‡ä»¶ - æ”¯æŒé¢„æå–å¸§è·¯å¾„\"\"\"\n",
    "    df_data = []\n",
    "    for item in data_list:\n",
    "        # æ£€æŸ¥æ˜¯å¦ä¸ºé¢„æå–çš„å¸§æ•°æ®\n",
    "        if 'frame_path' in item:\n",
    "            df_data.append({\n",
    "                'frame_path': item['frame_path'],\n",
    "                'label': item['label'],\n",
    "                'method': item['method'],\n",
    "                'num_frames': item.get('num_frames', 16)\n",
    "            })\n",
    "        else:\n",
    "            # å‘åå…¼å®¹ï¼šåŸå§‹è§†é¢‘è·¯å¾„æ ¼å¼\n",
    "            df_data.append({\n",
    "                'video_path': item['video_path'],\n",
    "                'label': item['label'],\n",
    "                'method': item['method'],\n",
    "                'num_frames': len(item['frames'])\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"æ•°æ®é›†å·²ä¿å­˜åˆ°: {filename}\")\n",
    "    return df\n",
    "\n",
    "print(\"âœ… æ•°æ®å¤„ç†å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db687c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.235659Z",
     "iopub.status.busy": "2025-07-29T10:28:38.235459Z",
     "iopub.status.idle": "2025-07-29T10:28:38.266965Z",
     "shell.execute_reply": "2025-07-29T10:28:38.266157Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.042035,
     "end_time": "2025-07-29T10:28:38.268076",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.226041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•°æ®é›†ç±»å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: æ•°æ®é›†ç±»å®šä¹‰\n",
    "\n",
    "# å¿…è¦çš„å¯¼å…¥\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class DeepfakeVideoDataset(Dataset):\n",
    "    \"\"\"æ·±åº¦ä¼ªé€ è§†é¢‘æ•°æ®é›†ç±» - æ”¯æŒé¢„æå–å¸§å’Œå¤šæ¨¡æ€ç‰¹å¾\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file, max_frames=16, gpu_preprocessing=True, \n",
    "                 extract_fourier=True, extract_compression=True, transform=None):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–æ•°æ®é›† - ä¸“ç”¨äºé¢„æå–å¸§çš„GPUé¢„å¤„ç†\n",
    "        \n",
    "        Args:\n",
    "            csv_file: CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¿…é¡»åŒ…å«frame_pathåˆ—ï¼‰\n",
    "            max_frames: æœ€å¤§å¸§æ•°\n",
    "            gpu_preprocessing: æ˜¯å¦å¯ç”¨GPUé¢„å¤„ç†\n",
    "            extract_fourier: æ˜¯å¦æå–å‚…é‡Œå¶ç‰¹å¾\n",
    "            extract_compression: æ˜¯å¦æå–å‹ç¼©ç‰¹å¾\n",
    "            transform: æ•°æ®å˜æ¢ï¼ˆå¯é€‰ï¼‰\n",
    "        \"\"\"\n",
    "        self.csv_file = csv_file\n",
    "        self.max_frames = max_frames\n",
    "        self.gpu_preprocessing = gpu_preprocessing\n",
    "        self.extract_fourier = extract_fourier\n",
    "        self.extract_compression = extract_compression\n",
    "        self.transform = transform  # æ·»åŠ transformå±æ€§\n",
    "        \n",
    "        # åŠ è½½æ•°æ®\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # éªŒè¯å¿…é¡»åŒ…å«frame_pathåˆ—\n",
    "        if 'frame_path' not in self.df.columns:\n",
    "            raise ValueError(f\"CSVæ–‡ä»¶ {csv_file} å¿…é¡»åŒ…å« 'frame_path' åˆ—ã€‚è¯·å…ˆè¿è¡Œé¢„æå–æµç¨‹ã€‚\")\n",
    "        \n",
    "        print(f\"âœ… é¢„æå–å¸§æ¨¡å¼ï¼Œå…± {len(self.df)} ä¸ªæ ·æœ¬\")\n",
    "        \n",
    "        # GPUè®¾å¤‡\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and gpu_preprocessing else 'cpu')\n",
    "        \n",
    "        # é¢„è®¡ç®—çš„æ ‡å‡†åŒ–å‚æ•°ï¼ˆImageNetæ ‡å‡†ï¼‰\n",
    "        self.mean_tensor = torch.tensor([0.485, 0.456, 0.406], device=self.device).view(1, 3, 1, 1)\n",
    "        self.std_tensor = torch.tensor([0.229, 0.224, 0.225], device=self.device).view(1, 3, 1, 1)\n",
    "        \n",
    "        # é¢„è®¡ç®—æ•°æ®ç»Ÿè®¡ä¿¡æ¯\n",
    "        self._compute_dataset_stats()\n",
    "        \n",
    "        print(f\"âœ… æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ: {len(self)} ä¸ªæ ·æœ¬\")\n",
    "        print(f\"ğŸš€ GPUé¢„å¤„ç†: {self.gpu_preprocessing} (è®¾å¤‡: {self.device})\")\n",
    "        if self.extract_fourier:\n",
    "            print(\"ğŸ“Š å¯ç”¨é¢‘åŸŸç‰¹å¾æå–\")\n",
    "        if self.extract_compression:\n",
    "            print(\"ğŸ” å¯ç”¨å‹ç¼©ä¼ªå½±åˆ†æ\")\n",
    "\n",
    "    def _compute_dataset_stats(self):\n",
    "        \"\"\"é¢„è®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        try:\n",
    "            self.real_count = len(self.df[self.df['label'] == 0])\n",
    "            self.fake_count = len(self.df[self.df['label'] == 1])\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ è®¡ç®—æ•°æ®ç»Ÿè®¡æ—¶å‡ºé”™: {e}\")\n",
    "            self.real_count = 0\n",
    "            self.fake_count = 0\n",
    "        \n",
    "        print(f\"ğŸ“Š æ•°æ®åˆ†å¸ƒ: çœŸå®={self.real_count}, ä¼ªé€ ={self.fake_count}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"è·å–æ•°æ®é¡¹ - ä¸“ç”¨äºé¢„æå–å¸§çš„GPUé¢„å¤„ç†\"\"\"\n",
    "        try:\n",
    "            row = self.df.iloc[idx]\n",
    "            label = row['label']\n",
    "            frame_path = row['frame_path']\n",
    "\n",
    "            # ä»é¢„æå–çš„å¸§æ–‡ä»¶åŠ è½½\n",
    "            video_tensor = self._load_preextracted_frames(frame_path)\n",
    "            \n",
    "            # ç¡®ä¿å¸§æ•°ä¸€è‡´\n",
    "            video_tensor = self._ensure_frame_count(video_tensor)\n",
    "            \n",
    "            # GPUé¢„å¤„ç†\n",
    "            if self.gpu_preprocessing and video_tensor.device != self.device:\n",
    "                video_tensor = video_tensor.to(self.device, non_blocking=True)\n",
    "            \n",
    "            # æ ‡å‡†åŒ–\n",
    "            video_tensor = self._normalize_frames(video_tensor)\n",
    "            \n",
    "            # åº”ç”¨å˜æ¢ï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "            if self.transform:\n",
    "                video_tensor = self._apply_transforms(video_tensor)\n",
    "\n",
    "            # æå–å¤šæ¨¡æ€ç‰¹å¾\n",
    "            additional_features = self._extract_additional_features(video_tensor)\n",
    "\n",
    "            label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "            \n",
    "            # æ¸…ç†GPUå†…å­˜\n",
    "            if self.gpu_preprocessing:\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # è¿”å›æ•°æ®å’Œé¢å¤–ç‰¹å¾\n",
    "            if additional_features:\n",
    "                return video_tensor, label_tensor, additional_features\n",
    "            else:\n",
    "                return video_tensor, label_tensor\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ è·å–æ•°æ®é¡¹ {idx} æ—¶å‡ºé”™: {e}\")\n",
    "            # è¿”å›é»˜è®¤æ•°æ®\n",
    "            return self._get_default_item()\n",
    "\n",
    "    def _extract_additional_features(self, frames_tensor):\n",
    "        \"\"\"æå–é¢å¤–çš„å¤šæ¨¡æ€ç‰¹å¾\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        try:\n",
    "            # å°†tensorè½¬æ¢ä¸ºnumpyè¿›è¡Œç‰¹å¾æå–\n",
    "            if frames_tensor.device != torch.device('cpu'):\n",
    "                frames_np = frames_tensor.cpu().numpy()\n",
    "            else:\n",
    "                frames_np = frames_tensor.numpy()\n",
    "            \n",
    "            # åæ ‡å‡†åŒ–ä»¥è·å¾—åŸå§‹åƒç´ å€¼\n",
    "            mean_np = self.mean_tensor.cpu().numpy().reshape(1, 3, 1, 1)\n",
    "            std_np = self.std_tensor.cpu().numpy().reshape(1, 3, 1, 1)\n",
    "            frames_np = frames_np * std_np + mean_np\n",
    "            frames_np = np.clip(frames_np * 255.0, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            if self.extract_fourier:\n",
    "                # æå–é¢‘åŸŸç‰¹å¾ï¼ˆä½¿ç”¨ä¸­é—´å¸§ï¼‰\n",
    "                mid_frame_idx = len(frames_np) // 2\n",
    "                mid_frame = frames_np[mid_frame_idx].transpose(1, 2, 0)  # CHW -> HWC\n",
    "                \n",
    "                try:\n",
    "                    # æ£€æŸ¥å‡½æ•°æ˜¯å¦å­˜åœ¨\n",
    "                    if 'extract_fourier_features' in globals():\n",
    "                        fourier_features = extract_fourier_features(mid_frame)\n",
    "                        if fourier_features:\n",
    "                            features['fourier'] = fourier_features\n",
    "                    else:\n",
    "                        # å¦‚æœå‡½æ•°ä¸å­˜åœ¨ï¼Œåˆ›å»ºç®€å•çš„é¢‘åŸŸç‰¹å¾æ›¿ä»£\n",
    "                        gray_frame = np.mean(mid_frame, axis=2)\n",
    "                        fft = np.fft.fft2(gray_frame)\n",
    "                        fft_magnitude = np.abs(fft)\n",
    "                        features['fourier'] = {\n",
    "                            'mean_magnitude': float(np.mean(fft_magnitude)),\n",
    "                            'std_magnitude': float(np.std(fft_magnitude)),\n",
    "                            'max_magnitude': float(np.max(fft_magnitude))\n",
    "                        }\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ é¢‘åŸŸç‰¹å¾æå–å¤±è´¥: {e}\")\n",
    "            \n",
    "            if self.extract_compression:\n",
    "                # æå–å‹ç¼©ä¼ªå½±ç‰¹å¾\n",
    "                compression_features = []\n",
    "                for i in range(0, len(frames_np), 4):  # æ¯4å¸§é‡‡æ ·ä¸€æ¬¡\n",
    "                    frame = frames_np[i].transpose(1, 2, 0)  # CHW -> HWC\n",
    "                    try:\n",
    "                        # æ£€æŸ¥å‡½æ•°æ˜¯å¦å­˜åœ¨\n",
    "                        if 'analyze_compression_artifacts' in globals():\n",
    "                            comp_feat = analyze_compression_artifacts(frame)\n",
    "                            if comp_feat:\n",
    "                                compression_features.append(comp_feat)\n",
    "                        else:\n",
    "                            # å¦‚æœå‡½æ•°ä¸å­˜åœ¨ï¼Œåˆ›å»ºç®€å•çš„å‹ç¼©ç‰¹å¾æ›¿ä»£\n",
    "                            gray_frame = np.mean(frame, axis=2)\n",
    "                            # ç®€å•çš„DCTèƒ½é‡è®¡ç®—\n",
    "                            dct_energy = float(np.var(gray_frame))\n",
    "                            # ç®€å•çš„è¾¹ç¼˜å¯†åº¦è®¡ç®—\n",
    "                            edges = np.abs(np.gradient(gray_frame.astype(float)))\n",
    "                            edge_density = float(np.mean(edges[0]**2 + edges[1]**2))\n",
    "                            \n",
    "                            comp_feat = {\n",
    "                                'dct_energy': dct_energy,\n",
    "                                'edge_density': edge_density,\n",
    "                                'dct_mean': dct_energy,\n",
    "                                'high_freq_energy': dct_energy * 0.1\n",
    "                            }\n",
    "                            compression_features.append(comp_feat)\n",
    "                    except Exception as e:\n",
    "                        print(f\"âš ï¸ å‹ç¼©ç‰¹å¾æå–å¤±è´¥: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                if compression_features:\n",
    "                    # èšåˆå‹ç¼©ç‰¹å¾\n",
    "                    features['compression'] = {\n",
    "                        'dct_mean': np.mean([f.get('dct_mean', f.get('dct_energy', 0)) for f in compression_features]),\n",
    "                        'dct_std': np.std([f.get('dct_mean', f.get('dct_energy', 0)) for f in compression_features]),\n",
    "                        'dct_energy': np.mean([f.get('dct_energy', 0) for f in compression_features]),\n",
    "                        'high_freq_energy': np.mean([f.get('high_freq_energy', f.get('dct_energy', 0) * 0.1) for f in compression_features]),\n",
    "                        'edge_density': np.mean([f.get('edge_density', 0) for f in compression_features])\n",
    "                    }\n",
    "            \n",
    "            # è®¡ç®—æ—¶åºä¸€è‡´æ€§ç‰¹å¾\n",
    "            if len(frames_np) > 1:\n",
    "                temporal_features = self._compute_temporal_consistency_tensor(frames_np)\n",
    "                if temporal_features:\n",
    "                    features['temporal'] = temporal_features\n",
    "            \n",
    "            return features if features else None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ æå–é¢å¤–ç‰¹å¾å¤±è´¥: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _compute_temporal_consistency(self, frames):\n",
    "        \"\"\"è®¡ç®—æ—¶åºä¸€è‡´æ€§ç‰¹å¾ï¼ˆå‘åå…¼å®¹ï¼‰\"\"\"\n",
    "        try:\n",
    "            # è®¡ç®—ç›¸é‚»å¸§ä¹‹é—´çš„å·®å¼‚\n",
    "            frame_diffs = []\n",
    "            for i in range(len(frames) - 1):\n",
    "                diff = np.mean(np.abs(frames[i+1].astype(float) - frames[i].astype(float)))\n",
    "                frame_diffs.append(diff)\n",
    "            \n",
    "            if frame_diffs:\n",
    "                return {\n",
    "                    'mean_frame_diff': np.mean(frame_diffs),\n",
    "                    'std_frame_diff': np.std(frame_diffs),\n",
    "                    'max_frame_diff': np.max(frame_diffs),\n",
    "                    'temporal_smoothness': 1.0 / (1.0 + np.std(frame_diffs))\n",
    "                }\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ è®¡ç®—æ—¶åºç‰¹å¾å¤±è´¥: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _compute_temporal_consistency_tensor(self, frames_np):\n",
    "        \"\"\"è®¡ç®—æ—¶åºä¸€è‡´æ€§ç‰¹å¾ï¼ˆtensorç‰ˆæœ¬ï¼‰\"\"\"\n",
    "        try:\n",
    "            # è®¡ç®—ç›¸é‚»å¸§ä¹‹é—´çš„å·®å¼‚\n",
    "            frame_diffs = []\n",
    "            for i in range(len(frames_np) - 1):\n",
    "                diff = np.mean(np.abs(frames_np[i+1].astype(float) - frames_np[i].astype(float)))\n",
    "                frame_diffs.append(diff)\n",
    "            \n",
    "            if frame_diffs:\n",
    "                return {\n",
    "                    'mean_frame_diff': np.mean(frame_diffs),\n",
    "                    'std_frame_diff': np.std(frame_diffs),\n",
    "                    'max_frame_diff': np.max(frame_diffs),\n",
    "                    'temporal_smoothness': 1.0 / (1.0 + np.std(frame_diffs))\n",
    "                }\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ è®¡ç®—æ—¶åºç‰¹å¾å¤±è´¥: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _load_preextracted_frames(self, frame_path):\n",
    "        \"\"\"ä»é¢„æå–çš„å¸§æ–‡ä»¶åŠ è½½æ•°æ®\"\"\"\n",
    "        try:\n",
    "            # ç›´æ¥åŠ è½½tensorï¼ˆæ•°æ®å‡†å¤‡é˜¶æ®µä¿å­˜çš„æ ¼å¼ï¼‰\n",
    "            frames_tensor = torch.load(frame_path, map_location='cpu')\n",
    "            \n",
    "            # å¦‚æœåŠ è½½çš„æ˜¯å­—å…¸æ ¼å¼ï¼Œæå–frames\n",
    "            if isinstance(frames_tensor, dict):\n",
    "                frames_tensor = frames_tensor['frames']\n",
    "            \n",
    "            # ç¡®ä¿æ•°æ®ç±»å‹å’ŒèŒƒå›´æ­£ç¡®\n",
    "            if frames_tensor.dtype != torch.float32:\n",
    "                frames_tensor = frames_tensor.float()\n",
    "            \n",
    "            # æ•°æ®å‡†å¤‡é˜¶æ®µå·²ç»å°†åƒç´ å€¼æ ‡å‡†åŒ–åˆ°[0,1]ï¼Œè¿™é‡Œéœ€è¦æ¢å¤åˆ°[0,255]\n",
    "            if frames_tensor.max() <= 1.0:\n",
    "                frames_tensor = frames_tensor * 255.0\n",
    "            \n",
    "            return frames_tensor\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"åŠ è½½é¢„æå–å¸§å¤±è´¥ {frame_path}: {e}\")\n",
    "            return self._create_default_frames_tensor()\n",
    "    \n",
    "\n",
    "    \n",
    "    def _create_default_frames_tensor(self):\n",
    "        \"\"\"åˆ›å»ºé»˜è®¤å¸§å¼ é‡\"\"\"\n",
    "        # åˆ›å»ºéšæœºå™ªå£°å¸§è€Œä¸æ˜¯å…¨é›¶å¸§ï¼Œä½¿è®­ç»ƒæ›´æœ‰æ„ä¹‰\n",
    "        frames_tensor = torch.randint(0, 50, (self.max_frames, 3, 224, 224), dtype=torch.float32)\n",
    "        return frames_tensor\n",
    "    \n",
    "    def _ensure_frame_count(self, frames_tensor):\n",
    "        \"\"\"ç¡®ä¿å¸§æ•°ä¸€è‡´\"\"\"\n",
    "        current_frames = frames_tensor.shape[0]\n",
    "        \n",
    "        if current_frames < self.max_frames:\n",
    "            # é‡å¤æœ€åä¸€å¸§\n",
    "            last_frame = frames_tensor[-1:]\n",
    "            repeat_count = self.max_frames - current_frames\n",
    "            repeated_frames = last_frame.repeat(repeat_count, 1, 1, 1)\n",
    "            frames_tensor = torch.cat([frames_tensor, repeated_frames], dim=0)\n",
    "        elif current_frames > self.max_frames:\n",
    "            # æˆªå–å‰max_frameså¸§\n",
    "            frames_tensor = frames_tensor[:self.max_frames]\n",
    "        \n",
    "        return frames_tensor\n",
    "    \n",
    "    def _normalize_frames(self, frames_tensor):\n",
    "        \"\"\"æ ‡å‡†åŒ–å¸§æ•°æ®\"\"\"\n",
    "        # ç¡®ä¿åƒç´ å€¼åœ¨[0, 1]èŒƒå›´å†…\n",
    "        if frames_tensor.max() > 1.0:\n",
    "            frames_tensor = frames_tensor / 255.0\n",
    "        \n",
    "        # ç§»åŠ¨æ ‡å‡†åŒ–å‚æ•°åˆ°æ­£ç¡®è®¾å¤‡\n",
    "        if self.mean_tensor.device != frames_tensor.device:\n",
    "            self.mean_tensor = self.mean_tensor.to(frames_tensor.device)\n",
    "            self.std_tensor = self.std_tensor.to(frames_tensor.device)\n",
    "        \n",
    "        # ImageNetæ ‡å‡†åŒ–\n",
    "        frames_tensor = (frames_tensor - self.mean_tensor) / self.std_tensor\n",
    "        \n",
    "        # é™åˆ¶æ•°å€¼èŒƒå›´é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸\n",
    "        frames_tensor = torch.clamp(frames_tensor, -10, 10)\n",
    "        \n",
    "        return frames_tensor\n",
    "    \n",
    "    def _apply_transforms(self, frames_tensor):\n",
    "        \"\"\"åº”ç”¨æ•°æ®å˜æ¢\"\"\"\n",
    "        try:\n",
    "            # å°†tensorè½¬æ¢å›PILæ ¼å¼è¿›è¡Œå˜æ¢\n",
    "            transformed_frames = []\n",
    "            \n",
    "            # åæ ‡å‡†åŒ–ä»¥è·å¾—åŸå§‹åƒç´ å€¼\n",
    "            denorm_tensor = frames_tensor * self.std_tensor + self.mean_tensor\n",
    "            denorm_tensor = torch.clamp(denorm_tensor * 255.0, 0, 255)\n",
    "            \n",
    "            for i in range(frames_tensor.shape[0]):\n",
    "                frame = denorm_tensor[i].permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "                frame_pil = Image.fromarray(frame)\n",
    "                transformed_frame = self.transform(frame_pil)\n",
    "                \n",
    "                # æ£€æŸ¥å˜æ¢åæ˜¯å¦æœ‰NaNæˆ–æ— ç©·å€¼\n",
    "                if torch.isnan(transformed_frame).any() or torch.isinf(transformed_frame).any():\n",
    "                    print(f\"âš ï¸ æ£€æµ‹åˆ°NaN/Infå€¼ï¼Œè·³è¿‡å˜æ¢\")\n",
    "                    return frames_tensor\n",
    "                \n",
    "                transformed_frames.append(transformed_frame)\n",
    "            \n",
    "            return torch.stack(transformed_frames)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ æ•°æ®å˜æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {e}\")\n",
    "            return frames_tensor\n",
    "    \n",
    "\n",
    "\n",
    "    def _get_default_item(self):\n",
    "        \"\"\"è·å–é»˜è®¤æ•°æ®é¡¹ï¼ˆç”¨äºé”™è¯¯æ¢å¤ï¼‰\"\"\"\n",
    "        frames = self._create_default_frames()\n",
    "        video_tensor = torch.stack([\n",
    "            torch.from_numpy(frame).permute(2, 0, 1) for frame in frames\n",
    "        ]).float() / 255.0\n",
    "        \n",
    "        # æ ‡å‡†åŒ–\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "        video_tensor = (video_tensor - mean) / std\n",
    "        \n",
    "        label_tensor = torch.tensor(0.0, dtype=torch.float32)\n",
    "        return video_tensor, label_tensor\n",
    "\n",
    "    def _create_default_frames(self):\n",
    "        \"\"\"åˆ›å»ºé»˜è®¤å¸§æ•°æ®ï¼ˆnumpyæ ¼å¼ï¼‰\"\"\"\n",
    "        # åˆ›å»ºéšæœºå™ªå£°å¸§è€Œä¸æ˜¯å…¨é›¶å¸§ï¼Œä½¿è®­ç»ƒæ›´æœ‰æ„ä¹‰\n",
    "        frames = []\n",
    "        for _ in range(self.max_frames):\n",
    "            # åˆ›å»º224x224x3çš„éšæœºå¸§ï¼Œå€¼åœ¨[0, 50]èŒƒå›´å†…ï¼ˆä½å™ªå£°ï¼‰\n",
    "            frame = np.random.randint(0, 50, (224, 224, 3), dtype=np.uint8)\n",
    "            frames.append(frame)\n",
    "        return frames\n",
    "\n",
    "\n",
    "\n",
    "    def enable_ensemble_mode(self):\n",
    "        \"\"\"å¯ç”¨é›†æˆæ¨¡å¼ï¼Œæå–æ‰€æœ‰å¯ç”¨ç‰¹å¾\"\"\"\n",
    "        self.extract_fourier = True\n",
    "        self.extract_compression = True\n",
    "        print(\"ğŸ¯ å¯ç”¨é›†æˆæ¨¡å¼ï¼šæ‰€æœ‰ç‰¹å¾æå–å·²æ¿€æ´»\")\n",
    "\n",
    "print(\"âœ… æ•°æ®é›†ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb6855e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.286035Z",
     "iopub.status.busy": "2025-07-29T10:28:38.285825Z",
     "iopub.status.idle": "2025-07-29T10:28:38.328817Z",
     "shell.execute_reply": "2025-07-29T10:28:38.328167Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.053578,
     "end_time": "2025-07-29T10:28:38.329803",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.276225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä¼˜åŒ–æ¨¡å‹å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: æ¨¡å‹å®šä¹‰ - é›†æˆå¤šæ¨¡æ€ç‰¹å¾å’ŒEnsembleç­–ç•¥\n",
    "class OptimizedDeepfakeDetector(nn.Module):\n",
    "    \"\"\"ä¼˜åŒ–çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨ - é›†æˆå¤šæ¨¡æ€ç‰¹å¾å’ŒEnsembleç­–ç•¥\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=1, dropout_rate=0.3, use_attention=True, \n",
    "                 use_multimodal=False, ensemble_mode=False):\n",
    "        super(OptimizedDeepfakeDetector, self).__init__()\n",
    "        \n",
    "        self.use_attention = use_attention\n",
    "        self.use_multimodal = use_multimodal\n",
    "        self.ensemble_mode = ensemble_mode\n",
    "        \n",
    "        # ä¸»å¹²ç½‘ç»œ - ResNet50\n",
    "        self.backbone = models.resnet50(pretrained=True)\n",
    "        backbone_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()  # ç§»é™¤æœ€åçš„åˆ†ç±»å±‚\n",
    "        \n",
    "        # æ—¶åºç‰¹å¾æå–\n",
    "        self.temporal_conv = nn.Sequential(\n",
    "            nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool3d((1, 7, 7))\n",
    "        )\n",
    "        \n",
    "        # æ³¨æ„åŠ›æœºåˆ¶\n",
    "        if use_attention:\n",
    "            self.attention = nn.MultiheadAttention(\n",
    "                embed_dim=backbone_features, \n",
    "                num_heads=8, \n",
    "                dropout=dropout_rate,\n",
    "                batch_first=True\n",
    "            )\n",
    "            self.attention_norm = nn.LayerNorm(backbone_features)\n",
    "        \n",
    "        # å¤šæ¨¡æ€ç‰¹å¾èåˆ\n",
    "        if use_multimodal:\n",
    "            # é¢‘åŸŸç‰¹å¾å¤„ç† - ä¿®æ­£è¾“å…¥ç»´åº¦\n",
    "            self.fourier_fc = nn.Sequential(\n",
    "                nn.Linear(5, 256),  # é¢‘åŸŸç‰¹å¾å®é™…ç»´åº¦ä¸º5 (mean, std, max, energy, entropy)\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(256, 128)\n",
    "            )\n",
    "            \n",
    "            # å‹ç¼©ä¼ªå½±ç‰¹å¾å¤„ç† - ä¿®æ­£è¾“å…¥ç»´åº¦\n",
    "            self.compression_fc = nn.Sequential(\n",
    "                nn.Linear(32, 64),  # å‹ç¼©ç‰¹å¾æ‰©å±•ä¸º32ç»´\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(64, 32)\n",
    "            )\n",
    "            \n",
    "            # æ—¶åºä¸€è‡´æ€§ç‰¹å¾å¤„ç†\n",
    "            self.temporal_fc = nn.Sequential(\n",
    "                nn.Linear(4, 64),  # æ—¶åºç‰¹å¾ç»´åº¦ä¸º4\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(64, 32)\n",
    "            )\n",
    "            \n",
    "            # ç‰¹å¾èåˆå±‚ - åŠ¨æ€è®¡ç®—è¾“å…¥ç»´åº¦\n",
    "            # åŸºç¡€ç‰¹å¾: backbone_features (2048)\n",
    "            # é¢‘åŸŸç‰¹å¾: 128 (fourier_fcè¾“å‡º)\n",
    "            # å‹ç¼©ç‰¹å¾: 32 (compression_fcè¾“å‡º)  \n",
    "            # æ—¶åºç‰¹å¾: 32 (temporal_fcè¾“å‡º)\n",
    "            fusion_dim = backbone_features + 128 + 32 + 32  # 2048 + 128 + 32 + 32 = 2240\n",
    "            self.fusion_layer = nn.Sequential(\n",
    "                nn.Linear(fusion_dim, 512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(512, 256)\n",
    "            )\n",
    "            final_features = 256\n",
    "        else:\n",
    "            final_features = backbone_features\n",
    "        \n",
    "        # é›†æˆæ¨¡å¼çš„å¤šä¸ªåˆ†ç±»å¤´\n",
    "        if ensemble_mode:\n",
    "            # ä¸»åˆ†ç±»å™¨\n",
    "            self.main_classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(final_features, 128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(128, num_classes)\n",
    "            )\n",
    "            \n",
    "            # è¾…åŠ©åˆ†ç±»å™¨1 - ä¸“æ³¨äºç©ºé—´ç‰¹å¾\n",
    "            self.spatial_classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(final_features, 64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(64, num_classes)\n",
    "            )\n",
    "            \n",
    "            # è¾…åŠ©åˆ†ç±»å™¨2 - ä¸“æ³¨äºæ—¶åºç‰¹å¾\n",
    "            self.temporal_classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(final_features, 64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(64, num_classes)\n",
    "            )\n",
    "            \n",
    "            # é›†æˆæƒé‡ï¼ˆå¯å­¦ä¹ ï¼‰\n",
    "            self.ensemble_weights = nn.Parameter(torch.ones(3) / 3)\n",
    "            \n",
    "        else:\n",
    "            # å•ä¸€åˆ†ç±»å™¨\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(final_features, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(128, num_classes)\n",
    "            )\n",
    "            \n",
    "            # æ·»åŠ å•ä¸€åˆ†ç±»å™¨ç”¨äºå¤„ç†åŸºç¡€ç‰¹å¾ï¼ˆå½“å¤šæ¨¡æ€ç‰¹å¾å¤„ç†å¤±è´¥æ—¶ï¼‰\n",
    "            self.single_classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(backbone_features, 128),  # ç›´æ¥å¤„ç†backboneç‰¹å¾\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(128, num_classes)\n",
    "            )\n",
    "        \n",
    "        # åˆå§‹åŒ–æƒé‡\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        print(f\"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\")\n",
    "        print(f\"   - æ³¨æ„åŠ›æœºåˆ¶: {'å¯ç”¨' if use_attention else 'ç¦ç”¨'}\")\n",
    "        print(f\"   - å¤šæ¨¡æ€èåˆ: {'å¯ç”¨' if use_multimodal else 'ç¦ç”¨'}\")\n",
    "        print(f\"   - é›†æˆæ¨¡å¼: {'å¯ç”¨' if ensemble_mode else 'ç¦ç”¨'}\")\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"åˆå§‹åŒ–æƒé‡\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x, additional_features=None):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        Args:\n",
    "            x: è§†é¢‘å¼ é‡ (B, T, C, H, W)\n",
    "            additional_features: é¢å¤–ç‰¹å¾å­—å…¸\n",
    "        \"\"\"\n",
    "        batch_size, num_frames, channels, height, width = x.shape\n",
    "        \n",
    "        # æå–æ¯å¸§çš„ç©ºé—´ç‰¹å¾\n",
    "        x_reshaped = x.view(batch_size * num_frames, channels, height, width)\n",
    "        spatial_features = self.backbone(x_reshaped)  # (B*T, features)\n",
    "        spatial_features = spatial_features.view(batch_size, num_frames, -1)  # (B, T, features)\n",
    "        \n",
    "        # æ—¶åºç‰¹å¾èšåˆ\n",
    "        if self.use_attention:\n",
    "            # ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶èšåˆæ—¶åºç‰¹å¾\n",
    "            attended_features, attention_weights = self.attention(\n",
    "                spatial_features, spatial_features, spatial_features\n",
    "            )\n",
    "            attended_features = self.attention_norm(attended_features + spatial_features)\n",
    "            # å…¨å±€å¹³å‡æ± åŒ–\n",
    "            temporal_features = torch.mean(attended_features, dim=1)  # (B, features)\n",
    "        else:\n",
    "            # ç®€å•å¹³å‡æ± åŒ–\n",
    "            temporal_features = torch.mean(spatial_features, dim=1)  # (B, features)\n",
    "        \n",
    "        # å¤šæ¨¡æ€ç‰¹å¾èåˆ\n",
    "        if self.use_multimodal and additional_features is not None:\n",
    "            fusion_features = [temporal_features]\n",
    "            \n",
    "            # å¤„ç†é¢‘åŸŸç‰¹å¾\n",
    "            if 'fourier' in additional_features:\n",
    "                try:\n",
    "                    fourier_feat = additional_features['fourier']\n",
    "                    if isinstance(fourier_feat, dict):\n",
    "                        # å®‰å…¨åœ°æå–æ•°å€¼ç‰¹å¾\n",
    "                        fourier_values = []\n",
    "                        for value in fourier_feat.values():\n",
    "                            if isinstance(value, (int, float)):\n",
    "                                fourier_values.append(float(value))\n",
    "                            elif isinstance(value, torch.Tensor):\n",
    "                                if value.numel() == 1:\n",
    "                                    fourier_values.append(float(value.item()))\n",
    "                                else:\n",
    "                                    fourier_values.append(float(value.mean().item()))\n",
    "                            elif isinstance(value, np.ndarray):\n",
    "                                if value.size == 1:\n",
    "                                    fourier_values.append(float(value.item()))\n",
    "                                else:\n",
    "                                    fourier_values.append(float(value.mean()))\n",
    "                            else:\n",
    "                                fourier_values.append(0.0)  # é»˜è®¤å€¼\n",
    "                        \n",
    "                        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç‰¹å¾ç»´åº¦\n",
    "                        if len(fourier_values) < 5:  # fourier_fcæœŸæœ›5ç»´è¾“å…¥\n",
    "                            fourier_values.extend([0.0] * (5 - len(fourier_values)))\n",
    "                        elif len(fourier_values) > 5:\n",
    "                            fourier_values = fourier_values[:5]\n",
    "                        \n",
    "                        fourier_tensor = torch.tensor([fourier_values] * batch_size, \n",
    "                                                    dtype=torch.float32, \n",
    "                                                    device=temporal_features.device)\n",
    "                    else:\n",
    "                        # å¦‚æœå·²ç»æ˜¯å¼ é‡ï¼Œç¡®ä¿æ­£ç¡®çš„å½¢çŠ¶\n",
    "                        if isinstance(fourier_feat, torch.Tensor):\n",
    "                            fourier_tensor = fourier_feat.to(temporal_features.device)\n",
    "                            if fourier_tensor.dim() == 1:\n",
    "                                fourier_tensor = fourier_tensor.unsqueeze(0).repeat(batch_size, 1)\n",
    "                        else:\n",
    "                            # åˆ›å»ºé»˜è®¤å¼ é‡\n",
    "                            fourier_tensor = torch.zeros(batch_size, 5, \n",
    "                                                        dtype=torch.float32, \n",
    "                                                        device=temporal_features.device)\n",
    "                    \n",
    "                    fourier_processed = self.fourier_fc(fourier_tensor)\n",
    "                    fusion_features.append(fourier_processed)\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ é¢‘åŸŸç‰¹å¾å¤„ç†å¤±è´¥: {e}\")\n",
    "                    # ä½¿ç”¨é»˜è®¤ç‰¹å¾\n",
    "                    fourier_tensor = torch.zeros(batch_size, 5, \n",
    "                                                dtype=torch.float32, \n",
    "                                                device=temporal_features.device)\n",
    "                    fourier_processed = self.fourier_fc(fourier_tensor)\n",
    "                    fusion_features.append(fourier_processed)\n",
    "            \n",
    "            # å¤„ç†å‹ç¼©ä¼ªå½±ç‰¹å¾\n",
    "            if 'compression' in additional_features:\n",
    "                try:\n",
    "                    comp_feat = additional_features['compression']\n",
    "                    if isinstance(comp_feat, dict):\n",
    "                        # å®‰å…¨åœ°æå–å‹ç¼©ç‰¹å¾ - ä¿®æ­£ä¸º5ä¸ªç‰¹å¾\n",
    "                        comp_values = []\n",
    "                        for key in ['dct_mean', 'dct_std', 'dct_energy', 'high_freq_energy', 'edge_density']:\n",
    "                            if key in comp_feat:\n",
    "                                value = comp_feat[key]\n",
    "                                if isinstance(value, (int, float)):\n",
    "                                    comp_values.append(float(value))\n",
    "                                elif isinstance(value, torch.Tensor):\n",
    "                                    comp_values.append(float(value.item() if value.numel() == 1 else value.mean().item()))\n",
    "                                elif isinstance(value, np.ndarray):\n",
    "                                    comp_values.append(float(value.item() if value.size == 1 else value.mean()))\n",
    "                                else:\n",
    "                                    comp_values.append(0.0)\n",
    "                            else:\n",
    "                                comp_values.append(0.0)\n",
    "                        \n",
    "                        # æ‰©å±•åˆ°32ç»´ï¼šé‡å¤åŸºç¡€ç‰¹å¾å¹¶æ·»åŠ æ´¾ç”Ÿç‰¹å¾\n",
    "                        extended_values = comp_values.copy()\n",
    "                        # æ·»åŠ æ´¾ç”Ÿç‰¹å¾\n",
    "                        extended_values.extend([\n",
    "                            comp_values[0] * comp_values[1],  # mean * std\n",
    "                            comp_values[2] / (comp_values[3] + 1e-8),  # energy ratio\n",
    "                            comp_values[4] * comp_values[0],  # edge * mean\n",
    "                            np.sqrt(abs(comp_values[2])),  # sqrt energy\n",
    "                            comp_values[1] / (comp_values[0] + 1e-8),  # std/mean ratio\n",
    "                        ])\n",
    "                        # é‡å¤å¡«å……åˆ°32ç»´\n",
    "                        while len(extended_values) < 32:\n",
    "                            extended_values.extend(comp_values[:min(5, 32 - len(extended_values))])\n",
    "                        \n",
    "                        comp_tensor = torch.tensor([extended_values[:32]] * batch_size, \n",
    "                                                 dtype=torch.float32, \n",
    "                                                 device=temporal_features.device)\n",
    "                    else:\n",
    "                        if isinstance(comp_feat, torch.Tensor):\n",
    "                            comp_tensor = comp_feat.to(temporal_features.device)\n",
    "                            if comp_tensor.dim() == 1:\n",
    "                                comp_tensor = comp_tensor.unsqueeze(0).repeat(batch_size, 1)\n",
    "                            # ç¡®ä¿æ˜¯32ç»´\n",
    "                            if comp_tensor.size(-1) < 32:\n",
    "                                padding = torch.zeros(batch_size, 32 - comp_tensor.size(-1), \n",
    "                                                    dtype=torch.float32, \n",
    "                                                    device=temporal_features.device)\n",
    "                                comp_tensor = torch.cat([comp_tensor, padding], dim=-1)\n",
    "                            elif comp_tensor.size(-1) > 32:\n",
    "                                comp_tensor = comp_tensor[:, :32]\n",
    "                        else:\n",
    "                            comp_tensor = torch.zeros(batch_size, 32, \n",
    "                                                    dtype=torch.float32, \n",
    "                                                    device=temporal_features.device)\n",
    "                    \n",
    "                    comp_processed = self.compression_fc(comp_tensor)\n",
    "                    fusion_features.append(comp_processed)\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ å‹ç¼©ç‰¹å¾å¤„ç†å¤±è´¥: {e}\")\n",
    "                    comp_tensor = torch.zeros(batch_size, 32, \n",
    "                                            dtype=torch.float32, \n",
    "                                            device=temporal_features.device)\n",
    "                    comp_processed = self.compression_fc(comp_tensor)\n",
    "                    fusion_features.append(comp_processed)\n",
    "            \n",
    "            # å¤„ç†æ—¶åºä¸€è‡´æ€§ç‰¹å¾\n",
    "            if 'temporal' in additional_features:\n",
    "                try:\n",
    "                    temp_feat = additional_features['temporal']\n",
    "                    if isinstance(temp_feat, dict):\n",
    "                        # å®‰å…¨åœ°æå–æ—¶åºç‰¹å¾\n",
    "                        temp_values = []\n",
    "                        for key in ['mean_frame_diff', 'std_frame_diff', 'max_frame_diff', 'temporal_smoothness']:\n",
    "                            if key in temp_feat:\n",
    "                                value = temp_feat[key]\n",
    "                                if isinstance(value, (int, float)):\n",
    "                                    temp_values.append(float(value))\n",
    "                                elif isinstance(value, torch.Tensor):\n",
    "                                    temp_values.append(float(value.item() if value.numel() == 1 else value.mean().item()))\n",
    "                                elif isinstance(value, np.ndarray):\n",
    "                                    temp_values.append(float(value.item() if value.size == 1 else value.mean()))\n",
    "                                else:\n",
    "                                    temp_values.append(0.0)\n",
    "                            else:\n",
    "                                temp_values.append(0.0)\n",
    "                        \n",
    "                        temp_tensor = torch.tensor([temp_values] * batch_size, \n",
    "                                                 dtype=torch.float32, \n",
    "                                                 device=temporal_features.device)\n",
    "                    else:\n",
    "                        if isinstance(temp_feat, torch.Tensor):\n",
    "                            temp_tensor = temp_feat.to(temporal_features.device)\n",
    "                            if temp_tensor.dim() == 1:\n",
    "                                temp_tensor = temp_tensor.unsqueeze(0).repeat(batch_size, 1)\n",
    "                        else:\n",
    "                            temp_tensor = torch.zeros(batch_size, 4, \n",
    "                                                    dtype=torch.float32, \n",
    "                                                    device=temporal_features.device)\n",
    "                    \n",
    "                    temp_processed = self.temporal_fc(temp_tensor)\n",
    "                    fusion_features.append(temp_processed)\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ æ—¶åºç‰¹å¾å¤„ç†å¤±è´¥: {e}\")\n",
    "                    temp_tensor = torch.zeros(batch_size, 4, \n",
    "                                            dtype=torch.float32, \n",
    "                                            device=temporal_features.device)\n",
    "                    temp_processed = self.temporal_fc(temp_tensor)\n",
    "                    fusion_features.append(temp_processed)\n",
    "            \n",
    "            # ç‰¹å¾èåˆ - ç¡®ä¿ç»´åº¦ä¸€è‡´æ€§\n",
    "            if len(fusion_features) > 1:\n",
    "                try:\n",
    "                    # æ£€æŸ¥æ¯ä¸ªç‰¹å¾çš„ç»´åº¦\n",
    "                    feature_dims = [f.shape[1] for f in fusion_features]\n",
    "                    total_dim = sum(feature_dims)\n",
    "                    expected_dim = self.fusion_layer[0].in_features\n",
    "                    \n",
    "                    if total_dim == expected_dim:\n",
    "                        # ç»´åº¦åŒ¹é…ï¼Œç›´æ¥èåˆ\n",
    "                        fused_features = torch.cat(fusion_features, dim=1)\n",
    "                        final_features = self.fusion_layer(fused_features)\n",
    "                    else:\n",
    "                        # ç»´åº¦ä¸åŒ¹é…æ—¶è¿›è¡Œè°ƒæ•´ï¼ˆè¿™æ˜¯æ­£å¸¸çš„å¤šæ¨¡æ€ç‰¹å¾å¤„ç†ï¼‰\n",
    "                        if total_dim < expected_dim:\n",
    "                            # ç»´åº¦ä¸è¶³ï¼Œç”¨é›¶å¡«å……\n",
    "                            padding_dim = expected_dim - total_dim\n",
    "                            fused_features = torch.cat(fusion_features, dim=1)\n",
    "                            padding = torch.zeros(batch_size, padding_dim, \n",
    "                                                dtype=fused_features.dtype, \n",
    "                                                device=fused_features.device)\n",
    "                            fused_features = torch.cat([fused_features, padding], dim=1)\n",
    "                            final_features = self.fusion_layer(fused_features)\n",
    "                            # åªåœ¨è°ƒè¯•æ¨¡å¼ä¸‹è¾“å‡ºè¯¦ç»†ä¿¡æ¯\n",
    "                            if hasattr(self, 'debug_mode') and self.debug_mode:\n",
    "                                print(f\"ğŸ”§ ç‰¹å¾å¡«å……: {total_dim} -> {expected_dim}\")\n",
    "                        elif total_dim > expected_dim:\n",
    "                            # ç»´åº¦è¿‡å¤šï¼Œæˆªæ–­åˆ°æœŸæœ›ç»´åº¦\n",
    "                            fused_features = torch.cat(fusion_features, dim=1)\n",
    "                            fused_features = fused_features[:, :expected_dim]\n",
    "                            final_features = self.fusion_layer(fused_features)\n",
    "                            # åªåœ¨è°ƒè¯•æ¨¡å¼ä¸‹è¾“å‡ºè¯¦ç»†ä¿¡æ¯\n",
    "                            if hasattr(self, 'debug_mode') and self.debug_mode:\n",
    "                                print(f\"ğŸ”§ ç‰¹å¾æˆªæ–­: {total_dim} -> {expected_dim}\")\n",
    "                        else:\n",
    "                            # ç†è®ºä¸Šä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œ\n",
    "                            print(f\"âš ï¸ ç‰¹å¾èåˆå¼‚å¸¸ï¼Œä½¿ç”¨åŸºç¡€ç‰¹å¾\")\n",
    "                            final_features = temporal_features\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ ç‰¹å¾èåˆå¤±è´¥: {e}\")\n",
    "                    final_features = temporal_features\n",
    "            else:\n",
    "                final_features = temporal_features\n",
    "        else:\n",
    "            final_features = temporal_features\n",
    "        \n",
    "        # åˆ†ç±»é¢„æµ‹ - æ ¹æ®ç‰¹å¾ç»´åº¦é€‰æ‹©åˆé€‚çš„åˆ†ç±»å™¨\n",
    "        if self.ensemble_mode:\n",
    "            # é›†æˆé¢„æµ‹\n",
    "            main_pred = self.main_classifier(final_features)\n",
    "            spatial_pred = self.spatial_classifier(final_features)\n",
    "            temporal_pred = self.temporal_classifier(final_features)\n",
    "            \n",
    "            # åŠ æƒèåˆ\n",
    "            weights = F.softmax(self.ensemble_weights, dim=0)\n",
    "            ensemble_pred = (weights[0] * main_pred + \n",
    "                           weights[1] * spatial_pred + \n",
    "                           weights[2] * temporal_pred)\n",
    "            \n",
    "            if self.training:\n",
    "                # è®­ç»ƒæ—¶è¿”å›æ‰€æœ‰é¢„æµ‹ç”¨äºå¤šä»»åŠ¡å­¦ä¹ \n",
    "                return {\n",
    "                    'main': main_pred,\n",
    "                    'spatial': spatial_pred,\n",
    "                    'temporal': temporal_pred,\n",
    "                    'ensemble': ensemble_pred\n",
    "                }\n",
    "            else:\n",
    "                # æ¨ç†æ—¶åªè¿”å›é›†æˆç»“æœ\n",
    "                return ensemble_pred\n",
    "        else:\n",
    "            # æ£€æŸ¥ç‰¹å¾ç»´åº¦å¹¶é€‰æ‹©åˆé€‚çš„åˆ†ç±»å™¨\n",
    "            feature_dim = final_features.shape[1]\n",
    "            \n",
    "            # è·å–åˆ†ç±»å™¨çš„è¾“å…¥ç»´åº¦\n",
    "            classifier_input_dim = None\n",
    "            single_classifier_input_dim = None\n",
    "            \n",
    "            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªLinearå±‚æ¥è·å–è¾“å…¥ç»´åº¦\n",
    "            for layer in self.classifier:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    classifier_input_dim = layer.in_features\n",
    "                    break\n",
    "            \n",
    "            for layer in self.single_classifier:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    single_classifier_input_dim = layer.in_features\n",
    "                    break\n",
    "            \n",
    "            # æ ¹æ®ç‰¹å¾ç»´åº¦é€‰æ‹©åˆé€‚çš„åˆ†ç±»å™¨\n",
    "            if classifier_input_dim and feature_dim == classifier_input_dim:\n",
    "                logits = self.classifier(final_features)\n",
    "            elif single_classifier_input_dim and feature_dim == single_classifier_input_dim:\n",
    "                logits = self.single_classifier(final_features)\n",
    "            else:\n",
    "                # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œå°è¯•ä½¿ç”¨å•ä¸€åˆ†ç±»å™¨ï¼ˆé€šå¸¸å¤„ç†åŸºç¡€ç‰¹å¾ï¼‰\n",
    "                print(f\"âš ï¸ ç‰¹å¾ç»´åº¦ {feature_dim} ä¸åŒ¹é…ä»»ä½•åˆ†ç±»å™¨ï¼Œä½¿ç”¨å•ä¸€åˆ†ç±»å™¨\")\n",
    "                logits = self.single_classifier(final_features)\n",
    "            \n",
    "            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åŒ…å«NaNæˆ–æ— ç©·å€¼\n",
    "            if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
    "                print(\"âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\")\n",
    "                # è¿”å›å®‰å…¨çš„é»˜è®¤è¾“å‡ºï¼ˆä¸­æ€§é¢„æµ‹ï¼‰\n",
    "                batch_size = logits.shape[0]\n",
    "                device = logits.device\n",
    "                logits = torch.zeros(batch_size, 1, device=device, dtype=torch.float32)\n",
    "            \n",
    "            # é™åˆ¶logitsçš„æ•°å€¼èŒƒå›´ï¼Œé¿å…æç«¯å€¼\n",
    "            logits = torch.clamp(logits, -10, 10)\n",
    "            \n",
    "            return logits\n",
    "\n",
    "    def get_attention_weights(self, x):\n",
    "        \"\"\"è·å–æ³¨æ„åŠ›æƒé‡ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰\"\"\"\n",
    "        if not self.use_attention:\n",
    "            return None\n",
    "        \n",
    "        batch_size, num_frames, channels, height, width = x.shape\n",
    "        x_reshaped = x.view(batch_size * num_frames, channels, height, width)\n",
    "        spatial_features = self.backbone(x_reshaped)\n",
    "        spatial_features = spatial_features.view(batch_size, num_frames, -1)\n",
    "        \n",
    "        _, attention_weights = self.attention(\n",
    "            spatial_features, spatial_features, spatial_features\n",
    "        )\n",
    "        \n",
    "        return attention_weights\n",
    "\n",
    "    def enable_ensemble_mode(self):\n",
    "        \"\"\"å¯ç”¨é›†æˆæ¨¡å¼\"\"\"\n",
    "        self.ensemble_mode = True\n",
    "        print(\"ğŸ¯ é›†æˆæ¨¡å¼å·²å¯ç”¨\")\n",
    "\n",
    "    def disable_ensemble_mode(self):\n",
    "        \"\"\"ç¦ç”¨é›†æˆæ¨¡å¼\"\"\"\n",
    "        self.ensemble_mode = False\n",
    "        print(\"ğŸ¯ é›†æˆæ¨¡å¼å·²ç¦ç”¨\")\n",
    "\n",
    "    def get_model_info(self):\n",
    "        \"\"\"è·å–æ¨¡å‹ä¿¡æ¯\"\"\"\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        \n",
    "        return {\n",
    "            'total_parameters': total_params,\n",
    "            'trainable_parameters': trainable_params,\n",
    "            'use_attention': self.use_attention,\n",
    "            'use_multimodal': self.use_multimodal,\n",
    "            'ensemble_mode': self.ensemble_mode\n",
    "        }\n",
    "\n",
    "def create_ensemble_models(num_models=3, **kwargs):\n",
    "    \"\"\"åˆ›å»ºå¤šä¸ªæ¨¡å‹ç”¨äºé›†æˆå­¦ä¹ \"\"\"\n",
    "    models = []\n",
    "    for i in range(num_models):\n",
    "        # ä¸ºæ¯ä¸ªæ¨¡å‹ä½¿ç”¨ä¸åŒçš„é…ç½®\n",
    "        model_kwargs = kwargs.copy()\n",
    "        if i == 0:\n",
    "            model_kwargs.update({'use_attention': True, 'dropout_rate': 0.3})\n",
    "        elif i == 1:\n",
    "            model_kwargs.update({'use_attention': False, 'dropout_rate': 0.4})\n",
    "        else:\n",
    "            model_kwargs.update({'use_attention': True, 'dropout_rate': 0.2})\n",
    "        \n",
    "        model = OptimizedDeepfakeDetector(**model_kwargs)\n",
    "        models.append(model)\n",
    "    \n",
    "    print(f\"âœ… åˆ›å»ºäº† {num_models} ä¸ªé›†æˆæ¨¡å‹\")\n",
    "    return models\n",
    "\n",
    "print(\"âœ… ä¼˜åŒ–æ¨¡å‹å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45178020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.347510Z",
     "iopub.status.busy": "2025-07-29T10:28:38.347301Z",
     "iopub.status.idle": "2025-07-29T10:28:38.363856Z",
     "shell.execute_reply": "2025-07-29T10:28:38.362999Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.027378,
     "end_time": "2025-07-29T10:28:38.365352",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.337974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æŸå¤±å‡½æ•°å’Œå·¥å…·ç±»å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: æŸå¤±å‡½æ•°å’Œå·¥å…·ç±»\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"ç„¦ç‚¹æŸå¤±å‡½æ•° - è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥\n",
    "        inputs = torch.clamp(inputs, min=-10, max=10)  # é˜²æ­¢æå€¼å¯¼è‡´NaN\n",
    "        \n",
    "        # ä½¿ç”¨ BCEWithLogitsLoss ä»¥å…¼å®¹ autocastï¼Œæ”¯æŒpos_weight\n",
    "        ce_loss = nn.BCEWithLogitsLoss(pos_weight=self.pos_weight, reduction='none')(inputs, targets)\n",
    "        \n",
    "        # æ·»åŠ æ•°å€¼ç¨³å®šæ€§\n",
    "        ce_loss = torch.clamp(ce_loss, min=1e-8, max=100)\n",
    "        \n",
    "        # è®¡ç®—æ¦‚ç‡ç”¨äºfocal weight\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        pt = torch.clamp(pt, min=1e-8, max=1-1e-8)  # é˜²æ­¢æå€¼\n",
    "        \n",
    "        # åŠ¨æ€alphaï¼šå¯¹äºæ­£æ ·æœ¬ä½¿ç”¨alphaï¼Œè´Ÿæ ·æœ¬ä½¿ç”¨(1-alpha)\n",
    "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "        focal_loss = alpha_t * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        # æ£€æŸ¥NaNå¹¶æ›¿æ¢\n",
    "        focal_loss = torch.where(torch.isnan(focal_loss), torch.zeros_like(focal_loss), focal_loss)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    \"\"\"æ ‡ç­¾å¹³æ»‘æŸå¤±å‡½æ•°\"\"\"\n",
    "    \n",
    "    def __init__(self, smoothing=0.1, pos_weight=None):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.pos_weight = pos_weight\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        # æ ‡ç­¾å¹³æ»‘\n",
    "        targets_smooth = targets * (1 - self.smoothing) + 0.5 * self.smoothing\n",
    "        \n",
    "        # ä½¿ç”¨BCEWithLogitsLoss\n",
    "        loss = nn.BCEWithLogitsLoss(pos_weight=self.pos_weight, reduction='mean')(inputs, targets_smooth)\n",
    "        return loss\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"ç»„åˆæŸå¤±å‡½æ•°ï¼šFocal Loss + Label Smoothing\"\"\"\n",
    "    \n",
    "    def __init__(self, focal_weight=0.7, smooth_weight=0.3, alpha=0.25, gamma=2.0, \n",
    "                 smoothing=0.1, pos_weight=None):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.focal_weight = focal_weight\n",
    "        self.smooth_weight = smooth_weight\n",
    "        self.focal_loss = FocalLoss(alpha=alpha, gamma=gamma, pos_weight=pos_weight)\n",
    "        self.smooth_loss = LabelSmoothingLoss(smoothing=smoothing, pos_weight=pos_weight)\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        focal = self.focal_loss(inputs, targets)\n",
    "        smooth = self.smooth_loss(inputs, targets)\n",
    "        return self.focal_weight * focal + self.smooth_weight * smooth\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"æ—©åœæœºåˆ¶\"\"\"\n",
    "    \n",
    "    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "        if self.counter >= self.patience:\n",
    "            if self.restore_best_weights:\n",
    "                model.load_state_dict(self.best_weights)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        self.best_weights = model.state_dict().copy()\n",
    "\n",
    "def get_transforms(mode='train', image_size=224):\n",
    "    \"\"\"è·å–ä¼˜åŒ–çš„æ•°æ®å˜æ¢ \"\"\"\n",
    "    if mode == 'train':\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((int(image_size * 1.1), int(image_size * 1.1))),\n",
    "            transforms.RandomCrop((image_size, image_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.RandomRotation(degrees=10),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # æ·»åŠ å¹³ç§»\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "def compute_class_weights(dataset):\n",
    "    \"\"\"è®¡ç®—ç±»åˆ«æƒé‡\"\"\"\n",
    "    if hasattr(dataset, 'real_count') and hasattr(dataset, 'fake_count'):\n",
    "        real_count = dataset.real_count\n",
    "        fake_count = dataset.fake_count\n",
    "    else:\n",
    "        # å›é€€æ–¹æ¡ˆ\n",
    "        real_count = 1\n",
    "        fake_count = 1\n",
    "    \n",
    "    total = real_count + fake_count\n",
    "    weight_real = total / (2 * real_count) if real_count > 0 else 1.0\n",
    "    weight_fake = total / (2 * fake_count) if fake_count > 0 else 1.0\n",
    "    \n",
    "    return torch.tensor([weight_fake / weight_real])  # pos_weight for BCEWithLogitsLoss\n",
    "\n",
    "print(\"âœ… æŸå¤±å‡½æ•°å’Œå·¥å…·ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9bd4281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.383695Z",
     "iopub.status.busy": "2025-07-29T10:28:38.383471Z",
     "iopub.status.idle": "2025-07-29T10:28:38.426520Z",
     "shell.execute_reply": "2025-07-29T10:28:38.425502Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.053309,
     "end_time": "2025-07-29T10:28:38.427660",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.374351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä¼˜åŒ–è®­ç»ƒå‡½æ•°å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: è®­ç»ƒå‡½æ•° - é›†æˆå¤šä»»åŠ¡å­¦ä¹ å’Œé«˜çº§ä¼˜åŒ–ç­–ç•¥\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, scheduler=None, \n",
    "                use_amp=False, gradient_clip=1.0, ensemble_mode=False):\n",
    "    \"\"\"\n",
    "    è®­ç»ƒä¸€ä¸ªepoch - æ”¯æŒé›†æˆå­¦ä¹ å’Œå¤šä»»åŠ¡å­¦ä¹ \n",
    "    \n",
    "    Args:\n",
    "        model: æ¨¡å‹\n",
    "        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨\n",
    "        criterion: æŸå¤±å‡½æ•°\n",
    "        optimizer: ä¼˜åŒ–å™¨\n",
    "        device: è®¾å¤‡\n",
    "        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "        use_amp: æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "        gradient_clip: æ¢¯åº¦è£å‰ªé˜ˆå€¼\n",
    "        ensemble_mode: æ˜¯å¦ä¸ºé›†æˆæ¨¡å¼\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    # é›†æˆæ¨¡å¼çš„æŸå¤±ç»Ÿè®¡\n",
    "    if ensemble_mode:\n",
    "        ensemble_losses = {\n",
    "            'main': 0.0,\n",
    "            'spatial': 0.0,\n",
    "            'temporal': 0.0,\n",
    "            'ensemble': 0.0\n",
    "        }\n",
    "    \n",
    "    # æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "    if use_amp:\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"è®­ç»ƒä¸­\", leave=False)\n",
    "    \n",
    "    # æ·»åŠ è®­ç»ƒå¼€å§‹çš„è°ƒè¯•ä¿¡æ¯\n",
    "    print(f\"ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\")\n",
    "    print(f\"   - æ•°æ®åŠ è½½å™¨é•¿åº¦: {len(train_loader)}\")\n",
    "    print(f\"   - å½“å‰å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    print(f\"   - è®¾å¤‡: {device}\")\n",
    "    print(f\"   - æ··åˆç²¾åº¦: {'å¯ç”¨' if use_amp else 'ç¦ç”¨'}\")\n",
    "    \n",
    "    for batch_idx, batch_data in enumerate(progress_bar):\n",
    "        # å®šæœŸæ¸…ç†GPUå†…å­˜\n",
    "        if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        # å†…å­˜ç›‘æ§\n",
    "        if batch_idx % 20 == 0 and torch.cuda.is_available():\n",
    "            memory_allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "            memory_reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "            print(f\"ğŸ“Š æ‰¹æ¬¡ {batch_idx}: GPUå†…å­˜ {memory_allocated:.1f}GB / {memory_reserved:.1f}GB\")\n",
    "        \n",
    "        # å¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼\n",
    "        if len(batch_data) == 3:\n",
    "            # åŒ…å«é¢å¤–ç‰¹å¾\n",
    "            videos, labels, additional_features = batch_data\n",
    "            videos = videos.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # å¤„ç†é¢å¤–ç‰¹å¾\n",
    "            if additional_features and isinstance(additional_features, dict):\n",
    "                for key, value in additional_features.items():\n",
    "                    if isinstance(value, torch.Tensor):\n",
    "                        additional_features[key] = value.to(device)\n",
    "        else:\n",
    "            # æ ‡å‡†æ ¼å¼\n",
    "            videos, labels = batch_data\n",
    "            videos = videos.to(device)\n",
    "            labels = labels.to(device)\n",
    "            additional_features = None\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        try:\n",
    "            if use_amp:\n",
    "                # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    if additional_features is not None:\n",
    "                        outputs = model(videos, additional_features)\n",
    "                    else:\n",
    "                        outputs = model(videos)\n",
    "                    \n",
    "                    # æ£€æŸ¥æ¨¡å‹è¾“å‡ºæ˜¯å¦åŒ…å«NaN\n",
    "                    if isinstance(outputs, dict):\n",
    "                        for key, output in outputs.items():\n",
    "                            if torch.isnan(output).any() or torch.isinf(output).any():\n",
    "                                print(f\"âš ï¸ æ‰¹æ¬¡ {batch_idx}: æ¨¡å‹è¾“å‡º {key} åŒ…å«NaN/Inf\")\n",
    "                                raise ValueError(f\"Model output {key} contains NaN/Inf\")\n",
    "                    else:\n",
    "                        if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "                            print(f\"âš ï¸ æ‰¹æ¬¡ {batch_idx}: æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Inf\")\n",
    "                            raise ValueError(\"Model output contains NaN/Inf\")\n",
    "                    \n",
    "                    # è®¡ç®—æŸå¤±\n",
    "                    if ensemble_mode and isinstance(outputs, dict):\n",
    "                        # é›†æˆæ¨¡å¼çš„å¤šä»»åŠ¡æŸå¤±\n",
    "                        losses = {}\n",
    "                        total_ensemble_loss = 0\n",
    "                        \n",
    "                        for key, pred in outputs.items():\n",
    "                            if pred.dim() > 1:\n",
    "                                pred = pred.squeeze(-1)\n",
    "                            loss = criterion(pred, labels)\n",
    "                            losses[key] = loss\n",
    "                            \n",
    "                            # ä¸åŒä»»åŠ¡çš„æƒé‡\n",
    "                            if key == 'ensemble':\n",
    "                                weight = 0.5  # é›†æˆé¢„æµ‹æƒé‡æœ€é«˜\n",
    "                            elif key == 'main':\n",
    "                                weight = 0.3\n",
    "                            else:\n",
    "                                weight = 0.1  # è¾…åŠ©ä»»åŠ¡æƒé‡è¾ƒä½\n",
    "                            \n",
    "                            total_ensemble_loss += weight * loss\n",
    "                        \n",
    "                        loss = total_ensemble_loss\n",
    "                        pred_probs = torch.sigmoid(outputs['ensemble'])\n",
    "                        \n",
    "                        # æ›´æ–°é›†æˆæŸå¤±ç»Ÿè®¡\n",
    "                        for key, l in losses.items():\n",
    "                            ensemble_losses[key] += l.item()\n",
    "                    else:\n",
    "                        # æ ‡å‡†æ¨¡å¼\n",
    "                        if outputs.dim() > 1:\n",
    "                            outputs = outputs.squeeze(-1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        pred_probs = torch.sigmoid(outputs)\n",
    "                    \n",
    "                    # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸ºNaN\n",
    "                    if torch.isnan(loss) or torch.isinf(loss):\n",
    "                        print(f\"âš ï¸ æ‰¹æ¬¡ {batch_idx}: æŸå¤±ä¸ºNaN/Infï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡\")\n",
    "                        raise ValueError(\"Loss is NaN/Inf\")\n",
    "                \n",
    "                # æ··åˆç²¾åº¦åå‘ä¼ æ’­\n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                # æ¢¯åº¦è£å‰ª\n",
    "                if gradient_clip > 0:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n",
    "                \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # æ ‡å‡†ç²¾åº¦è®­ç»ƒ\n",
    "                if additional_features is not None:\n",
    "                    outputs = model(videos, additional_features)\n",
    "                else:\n",
    "                    outputs = model(videos)\n",
    "                \n",
    "                # æ£€æŸ¥æ¨¡å‹è¾“å‡ºæ˜¯å¦åŒ…å«NaN\n",
    "                if isinstance(outputs, dict):\n",
    "                    for key, output in outputs.items():\n",
    "                        if torch.isnan(output).any() or torch.isinf(output).any():\n",
    "                            print(f\"âš ï¸ æ‰¹æ¬¡ {batch_idx}: æ¨¡å‹è¾“å‡º {key} åŒ…å«NaN/Inf\")\n",
    "                            raise ValueError(f\"Model output {key} contains NaN/Inf\")\n",
    "                else:\n",
    "                    if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "                        print(f\"âš ï¸ æ‰¹æ¬¡ {batch_idx}: æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Inf\")\n",
    "                        raise ValueError(\"Model output contains NaN/Inf\")\n",
    "                \n",
    "                # è®¡ç®—æŸå¤±\n",
    "                if ensemble_mode and isinstance(outputs, dict):\n",
    "                    # é›†æˆæ¨¡å¼çš„å¤šä»»åŠ¡æŸå¤±\n",
    "                    losses = {}\n",
    "                    total_ensemble_loss = 0\n",
    "                    \n",
    "                    for key, pred in outputs.items():\n",
    "                        if pred.dim() > 1:\n",
    "                            pred = pred.squeeze(-1)\n",
    "                        loss_item = criterion(pred, labels)\n",
    "                        losses[key] = loss_item\n",
    "                        \n",
    "                        # ä¸åŒä»»åŠ¡çš„æƒé‡\n",
    "                        if key == 'ensemble':\n",
    "                            weight = 0.5\n",
    "                        elif key == 'main':\n",
    "                            weight = 0.3\n",
    "                        else:\n",
    "                            weight = 0.1\n",
    "                        \n",
    "                        total_ensemble_loss += weight * loss_item\n",
    "                    \n",
    "                    loss = total_ensemble_loss\n",
    "                    pred_probs = torch.sigmoid(outputs['ensemble'])\n",
    "                    \n",
    "                    # æ›´æ–°é›†æˆæŸå¤±ç»Ÿè®¡\n",
    "                    for key, l in losses.items():\n",
    "                        ensemble_losses[key] += l.item()\n",
    "                else:\n",
    "                    # æ ‡å‡†æ¨¡å¼\n",
    "                    if outputs.dim() > 1:\n",
    "                        outputs = outputs.squeeze(-1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    pred_probs = torch.sigmoid(outputs)\n",
    "                \n",
    "                # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸ºNaN\n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(f\"âš ï¸ æ‰¹æ¬¡ {batch_idx}: æŸå¤±ä¸ºNaN/Infï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡\")\n",
    "                    raise ValueError(\"Loss is NaN/Inf\")\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                # æ¢¯åº¦è£å‰ª\n",
    "                if gradient_clip > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n",
    "                \n",
    "                optimizer.step()\n",
    "            \n",
    "            # ç¡®ä¿pred_probsæ˜¯æ­£ç¡®çš„å¼ é‡æ ¼å¼\n",
    "            if pred_probs.dim() > 1:\n",
    "                pred_probs = pred_probs.squeeze(-1)\n",
    "            \n",
    "            # è®¡ç®—å‡†ç¡®ç‡\n",
    "            predictions = (pred_probs > 0.5).float()\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            \n",
    "            # æ›´æ–°ç»Ÿè®¡\n",
    "            total_loss += loss.item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            # æ·»åŠ æˆåŠŸæ‰¹æ¬¡çš„è°ƒè¯•ä¿¡æ¯ï¼ˆä»…å‰3ä¸ªæ‰¹æ¬¡ï¼‰\n",
    "            if batch_idx < 3:\n",
    "                print(f\"ğŸ” æ‰¹æ¬¡ {batch_idx} æˆåŠŸ:\")\n",
    "                print(f\"   - æŸå¤±å€¼: {loss.item():.6f}\")\n",
    "                print(f\"   - æ ·æœ¬æ•°: {labels.size(0)}\")\n",
    "                print(f\"   - é¢„æµ‹æ¦‚ç‡èŒƒå›´: [{pred_probs.min().item():.4f}, {pred_probs.max().item():.4f}]\")\n",
    "                print(f\"   - æ ‡ç­¾åˆ†å¸ƒ: {labels.sum().item()}/{labels.size(0)}\")\n",
    "            \n",
    "            # æ›´æ–°è¿›åº¦æ¡\n",
    "            avg_loss = total_loss / (batch_idx + 1)\n",
    "            accuracy = correct_predictions / total_samples\n",
    "            \n",
    "            if ensemble_mode:\n",
    "                progress_bar.set_postfix({\n",
    "                    'Loss': f'{avg_loss:.4f}',\n",
    "                    'Acc': f'{accuracy:.4f}',\n",
    "                    'Ensemble': f'{ensemble_losses[\"ensemble\"]/(batch_idx+1):.4f}'\n",
    "                })\n",
    "            else:\n",
    "                progress_bar.set_postfix({\n",
    "                    'Loss': f'{avg_loss:.4f}',\n",
    "                    'Acc': f'{accuracy:.4f}'\n",
    "                })\n",
    "            \n",
    "            # æ¯ä¸ªæ‰¹æ¬¡åæ¸…ç†å˜é‡\n",
    "            del videos, labels\n",
    "            if additional_features is not None:\n",
    "                del additional_features\n",
    "            if 'outputs' in locals():\n",
    "                del outputs\n",
    "            if 'pred_probs' in locals():\n",
    "                del pred_probs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ è®­ç»ƒæ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}\")\n",
    "            import traceback\n",
    "            print(f\"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}\")\n",
    "            # æ·»åŠ è°ƒè¯•ä¿¡æ¯\n",
    "            print(f\"ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: {batch_idx}, æ€»æ ·æœ¬æ•°: {total_samples}, æ€»æŸå¤±: {total_loss}\")\n",
    "            # æ¸…ç†GPUå†…å­˜\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            continue\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®\n",
    "    if total_samples == 0:\n",
    "        print(\"âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\")\n",
    "        return {\n",
    "            'loss': float('inf'),\n",
    "            'accuracy': 0.0,\n",
    "            'learning_rate': optimizer.param_groups[0]['lr']\n",
    "        }\n",
    "    \n",
    "    # å­¦ä¹ ç‡è°ƒåº¦\n",
    "    if scheduler is not None:\n",
    "        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(total_loss / max(len(train_loader), 1))\n",
    "        else:\n",
    "            scheduler.step()\n",
    "    \n",
    "    # è¿”å›è®­ç»ƒç»“æœ\n",
    "    avg_loss = total_loss / max(len(train_loader), 1)\n",
    "    accuracy = correct_predictions / max(total_samples, 1)\n",
    "    \n",
    "    # æ·»åŠ è¯¦ç»†è°ƒè¯•ä¿¡æ¯\n",
    "    print(f\"ğŸ” è®­ç»ƒç»“æœè°ƒè¯•:\")\n",
    "    print(f\"   - æ€»æŸå¤±: {total_loss}\")\n",
    "    print(f\"   - æ•°æ®åŠ è½½å™¨é•¿åº¦: {len(train_loader)}\")\n",
    "    print(f\"   - å¹³å‡æŸå¤±: {avg_loss}\")\n",
    "    print(f\"   - æ­£ç¡®é¢„æµ‹æ•°: {correct_predictions}\")\n",
    "    print(f\"   - æ€»æ ·æœ¬æ•°: {total_samples}\")\n",
    "    print(f\"   - å‡†ç¡®ç‡: {accuracy}\")\n",
    "    \n",
    "    results = {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'learning_rate': optimizer.param_groups[0]['lr']\n",
    "    }\n",
    "    \n",
    "    if ensemble_mode:\n",
    "        # æ·»åŠ é›†æˆæŸå¤±ç»Ÿè®¡\n",
    "        for key in ensemble_losses:\n",
    "            results[f'{key}_loss'] = ensemble_losses[key] / len(train_loader)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device, ensemble_mode=False):\n",
    "    \"\"\"\n",
    "    éªŒè¯ä¸€ä¸ªepoch - æ”¯æŒé›†æˆå­¦ä¹ è¯„ä¼°\n",
    "    \n",
    "    Args:\n",
    "        model: æ¨¡å‹\n",
    "        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨\n",
    "        criterion: æŸå¤±å‡½æ•°\n",
    "        device: è®¾å¤‡\n",
    "        ensemble_mode: æ˜¯å¦ä¸ºé›†æˆæ¨¡å¼\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # é›†æˆæ¨¡å¼çš„æŸå¤±ç»Ÿè®¡\n",
    "    if ensemble_mode:\n",
    "        ensemble_losses = {\n",
    "            'main': 0.0,\n",
    "            'spatial': 0.0,\n",
    "            'temporal': 0.0,\n",
    "            'ensemble': 0.0\n",
    "        }\n",
    "        ensemble_predictions = {\n",
    "            'main': [],\n",
    "            'spatial': [],\n",
    "            'temporal': [],\n",
    "            'ensemble': []\n",
    "        }\n",
    "    \n",
    "    progress_bar = tqdm(val_loader, desc=\"éªŒè¯ä¸­\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(progress_bar):\n",
    "            try:\n",
    "                # å¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼\n",
    "                if len(batch_data) == 3:\n",
    "                    videos, labels, additional_features = batch_data\n",
    "                    videos = videos.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                    # å¤„ç†é¢å¤–ç‰¹å¾\n",
    "                    if additional_features and isinstance(additional_features, dict):\n",
    "                        for key, value in additional_features.items():\n",
    "                            if isinstance(value, torch.Tensor):\n",
    "                                additional_features[key] = value.to(device)\n",
    "                else:\n",
    "                    videos, labels = batch_data\n",
    "                    videos = videos.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    additional_features = None\n",
    "                \n",
    "                # å‰å‘ä¼ æ’­\n",
    "                if additional_features is not None:\n",
    "                    outputs = model(videos, additional_features)\n",
    "                else:\n",
    "                    outputs = model(videos)\n",
    "                \n",
    "                # è®¡ç®—æŸå¤±å’Œé¢„æµ‹\n",
    "                if ensemble_mode and isinstance(outputs, dict):\n",
    "                    # é›†æˆæ¨¡å¼\n",
    "                    losses = {}\n",
    "                    total_ensemble_loss = 0\n",
    "                    \n",
    "                    for key, pred in outputs.items():\n",
    "                        if pred.dim() > 1:\n",
    "                            pred = pred.squeeze(-1)\n",
    "                        loss_item = criterion(pred, labels)\n",
    "                        losses[key] = loss_item\n",
    "                        \n",
    "                        # æƒé‡ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´\n",
    "                        if key == 'ensemble':\n",
    "                            weight = 0.5\n",
    "                        elif key == 'main':\n",
    "                            weight = 0.3\n",
    "                        else:\n",
    "                            weight = 0.1\n",
    "                        \n",
    "                        total_ensemble_loss += weight * loss_item\n",
    "                        \n",
    "                        # ä¿å­˜é¢„æµ‹ç»“æœ\n",
    "                        pred_probs_item = torch.sigmoid(pred)\n",
    "                        ensemble_predictions[key].extend(pred_probs_item.cpu().numpy())\n",
    "                        ensemble_losses[key] += loss_item.item()\n",
    "                    \n",
    "                    loss = total_ensemble_loss\n",
    "                    pred_probs = torch.sigmoid(outputs['ensemble'])\n",
    "                else:\n",
    "                    # æ ‡å‡†æ¨¡å¼\n",
    "                    if outputs.dim() > 1:\n",
    "                        outputs = outputs.squeeze(-1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    pred_probs = torch.sigmoid(outputs)\n",
    "                \n",
    "                # ç¡®ä¿pred_probsæ˜¯æ­£ç¡®çš„å¼ é‡æ ¼å¼\n",
    "                if pred_probs.dim() > 1:\n",
    "                    pred_probs = pred_probs.squeeze(-1)\n",
    "                \n",
    "                # è®¡ç®—å‡†ç¡®ç‡\n",
    "                predictions = (pred_probs > 0.5).float()\n",
    "                correct_predictions += (predictions == labels).sum().item()\n",
    "                \n",
    "                # ä¿å­˜é¢„æµ‹å’Œæ ‡ç­¾ç”¨äºè¯¦ç»†è¯„ä¼°\n",
    "                all_predictions.extend(pred_probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # æ›´æ–°ç»Ÿè®¡\n",
    "                total_loss += loss.item()\n",
    "                total_samples += labels.size(0)\n",
    "                \n",
    "                # æ›´æ–°è¿›åº¦æ¡\n",
    "                avg_loss = total_loss / (batch_idx + 1)\n",
    "                accuracy = correct_predictions / total_samples\n",
    "                progress_bar.set_postfix({\n",
    "                    'Val Loss': f'{avg_loss:.4f}',\n",
    "                    'Val Acc': f'{accuracy:.4f}'\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ éªŒè¯æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}\")\n",
    "                import traceback\n",
    "                print(f\"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}\")\n",
    "                continue\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„éªŒè¯æ•°æ®\n",
    "    if total_samples == 0:\n",
    "        print(\"âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•éªŒè¯æ‰¹æ¬¡!\")\n",
    "        return {\n",
    "            'loss': float('inf'),\n",
    "            'accuracy': 0.0,\n",
    "            'auc': 0.0,\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0,\n",
    "            'predictions': [],\n",
    "            'labels': []\n",
    "        }\n",
    "    \n",
    "    # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡\n",
    "    avg_loss = total_loss / max(len(val_loader), 1)\n",
    "    accuracy = correct_predictions / max(total_samples, 1)\n",
    "    \n",
    "    # è®¡ç®—AUCç­‰é«˜çº§æŒ‡æ ‡\n",
    "    try:\n",
    "        from sklearn.metrics import roc_auc_score, precision_recall_fscore_support\n",
    "        auc_score = roc_auc_score(all_labels, all_predictions)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, \n",
    "            np.array(all_predictions) > 0.5, \n",
    "            average='binary'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è®¡ç®—é«˜çº§æŒ‡æ ‡å¤±è´¥: {e}\")\n",
    "        auc_score = 0.0\n",
    "        precision = recall = f1 = 0.0\n",
    "    \n",
    "    results = {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc_score,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "    \n",
    "    if ensemble_mode:\n",
    "        # æ·»åŠ é›†æˆè¯„ä¼°ç»“æœ\n",
    "        for key in ensemble_losses:\n",
    "            results[f'{key}_loss'] = ensemble_losses[key] / len(val_loader)\n",
    "            results[f'{key}_predictions'] = ensemble_predictions[key]\n",
    "        \n",
    "        # è®¡ç®—é›†æˆæ¨¡å‹çš„AUC\n",
    "        try:\n",
    "            ensemble_auc = roc_auc_score(all_labels, ensemble_predictions['ensemble'])\n",
    "            results['ensemble_auc'] = ensemble_auc\n",
    "        except:\n",
    "            results['ensemble_auc'] = 0.0\n",
    "    \n",
    "    return results\n",
    "\n",
    "def train_ensemble_models(models, train_loader, val_loader, criterion, optimizers, \n",
    "                         device, num_epochs=10, schedulers=None, use_amp=False):\n",
    "    \"\"\"\n",
    "    è®­ç»ƒå¤šä¸ªæ¨¡å‹è¿›è¡Œé›†æˆå­¦ä¹ \n",
    "    \n",
    "    Args:\n",
    "        models: æ¨¡å‹åˆ—è¡¨\n",
    "        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨\n",
    "        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨\n",
    "        criterion: æŸå¤±å‡½æ•°\n",
    "        optimizers: ä¼˜åŒ–å™¨åˆ—è¡¨\n",
    "        device: è®¾å¤‡\n",
    "        num_epochs: è®­ç»ƒè½®æ•°\n",
    "        schedulers: å­¦ä¹ ç‡è°ƒåº¦å™¨åˆ—è¡¨\n",
    "        use_amp: æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "    \"\"\"\n",
    "    ensemble_results = []\n",
    "    \n",
    "    for i, (model, optimizer) in enumerate(zip(models, optimizers)):\n",
    "        print(f\"\\nğŸš€ è®­ç»ƒé›†æˆæ¨¡å‹ {i+1}/{len(models)}\")\n",
    "        \n",
    "        scheduler = schedulers[i] if schedulers else None\n",
    "        model_results = {'train_history': [], 'val_history': []}\n",
    "        \n",
    "        best_val_auc = 0.0\n",
    "        best_model_state = None\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "            \n",
    "            # è®­ç»ƒ\n",
    "            train_results = train_epoch(\n",
    "                model, train_loader, criterion, optimizer, device,\n",
    "                scheduler=scheduler, use_amp=use_amp\n",
    "            )\n",
    "            \n",
    "            # éªŒè¯\n",
    "            val_results = validate_epoch(model, val_loader, criterion, device)\n",
    "            \n",
    "            # ä¿å­˜å†å²\n",
    "            model_results['train_history'].append(train_results)\n",
    "            model_results['val_history'].append(val_results)\n",
    "            \n",
    "            # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "            if val_results['auc'] > best_val_auc:\n",
    "                best_val_auc = val_results['auc']\n",
    "                best_model_state = model.state_dict().copy()\n",
    "            \n",
    "            print(f\"è®­ç»ƒ - Loss: {train_results['loss']:.4f}, Acc: {train_results['accuracy']:.4f}\")\n",
    "            print(f\"éªŒè¯ - Loss: {val_results['loss']:.4f}, Acc: {val_results['accuracy']:.4f}, AUC: {val_results['auc']:.4f}\")\n",
    "        \n",
    "        # åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡\n",
    "        if best_model_state is not None:\n",
    "            model.load_state_dict(best_model_state)\n",
    "        \n",
    "        model_results['best_val_auc'] = best_val_auc\n",
    "        ensemble_results.append(model_results)\n",
    "        \n",
    "        print(f\"âœ… æ¨¡å‹ {i+1} è®­ç»ƒå®Œæˆï¼Œæœ€ä½³éªŒè¯AUC: {best_val_auc:.4f}\")\n",
    "    \n",
    "    return ensemble_results\n",
    "\n",
    "def ensemble_predict(models, data_loader, device, weights=None):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨å¤šä¸ªæ¨¡å‹è¿›è¡Œé›†æˆé¢„æµ‹\n",
    "    \n",
    "    Args:\n",
    "        models: æ¨¡å‹åˆ—è¡¨\n",
    "        data_loader: æ•°æ®åŠ è½½å™¨\n",
    "        device: è®¾å¤‡\n",
    "        weights: æ¨¡å‹æƒé‡ï¼ˆå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å¹³å‡æƒé‡ï¼‰\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = [1.0 / len(models)] * len(models)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # è®¾ç½®æ‰€æœ‰æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(data_loader, desc=\"é›†æˆé¢„æµ‹ä¸­\"):\n",
    "            if len(batch_data) == 3:\n",
    "                videos, labels, additional_features = batch_data\n",
    "                videos = videos.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                if additional_features and isinstance(additional_features, dict):\n",
    "                    for key, value in additional_features.items():\n",
    "                        if isinstance(value, torch.Tensor):\n",
    "                            additional_features[key] = value.to(device)\n",
    "            else:\n",
    "                videos, labels = batch_data\n",
    "                videos = videos.to(device)\n",
    "                labels = labels.to(device)\n",
    "                additional_features = None\n",
    "            \n",
    "            # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹\n",
    "            batch_predictions = []\n",
    "            for model in models:\n",
    "                if additional_features is not None:\n",
    "                    outputs = model(videos, additional_features)\n",
    "                else:\n",
    "                    outputs = model(videos)\n",
    "                \n",
    "                if isinstance(outputs, dict):\n",
    "                    # é›†æˆæ¨¡å¼ï¼Œä½¿ç”¨ensembleè¾“å‡º\n",
    "                    pred = outputs['ensemble']\n",
    "                else:\n",
    "                    pred = outputs\n",
    "                \n",
    "                if pred.dim() > 1:\n",
    "                    pred = pred.squeeze(-1)\n",
    "                \n",
    "                pred_probs = torch.sigmoid(pred)\n",
    "                batch_predictions.append(pred_probs.cpu().numpy())\n",
    "            \n",
    "            # åŠ æƒå¹³å‡\n",
    "            ensemble_pred = np.average(batch_predictions, axis=0, weights=weights)\n",
    "            all_predictions.extend(ensemble_pred)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_labels)\n",
    "\n",
    "print(\"âœ… ä¼˜åŒ–è®­ç»ƒå‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6e89300",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.444419Z",
     "iopub.status.busy": "2025-07-29T10:28:38.444181Z",
     "iopub.status.idle": "2025-07-29T10:28:38.470727Z",
     "shell.execute_reply": "2025-07-29T10:28:38.470033Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.036108,
     "end_time": "2025-07-29T10:28:38.471740",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.435632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è¯„ä¼°å‡½æ•°å’Œå¯è§†åŒ–å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: è¯„ä¼°å‡½æ•°å’Œå¯è§†åŒ–\n",
    "\n",
    "def evaluate_model_optimized(model, test_loader, criterion, device):\n",
    "    \"\"\"ä¼˜åŒ–çš„æ¨¡å‹è¯„ä¼°å‡½æ•°\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_scores = []\n",
    "    \n",
    "    inference_times = []\n",
    "    \n",
    "    print(\"ğŸš€ å¼€å§‹æ¨¡å‹è¯„ä¼°...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(tqdm(test_loader, desc=\"è¯„ä¼°è¿›åº¦\")):\n",
    "            # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼ï¼š(data, target) æˆ– (data, target, additional_features)\n",
    "            if len(batch_data) == 2:\n",
    "                data, target = batch_data\n",
    "                additional_features = None\n",
    "            elif len(batch_data) == 3:\n",
    "                data, target, additional_features = batch_data\n",
    "            else:\n",
    "                raise ValueError(f\"æ•°æ®åŠ è½½å™¨è¿”å›äº†æ„å¤–çš„æ•°æ®æ ¼å¼ï¼Œé•¿åº¦ä¸º {len(batch_data)}\")\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # å¤„ç†é¢å¤–ç‰¹å¾çš„è®¾å¤‡è½¬ç§»\n",
    "            if additional_features is not None:\n",
    "                if isinstance(additional_features, dict):\n",
    "                    for key, value in additional_features.items():\n",
    "                        if isinstance(value, torch.Tensor):\n",
    "                            additional_features[key] = value.to(device)\n",
    "            \n",
    "            # è®°å½•æ¨ç†æ—¶é—´\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # å¤„ç†æ¨¡å‹è¾“å‡º - æ¨¡å‹å¯èƒ½è¿”å›å•ä¸ªå¼ é‡æˆ–å­—å…¸\n",
    "            if additional_features is not None:\n",
    "                model_output = model(data, additional_features)\n",
    "            else:\n",
    "                model_output = model(data)\n",
    "            \n",
    "            inference_time = time.time() - start_time\n",
    "            inference_times.append(inference_time)\n",
    "            \n",
    "            # å¤„ç†ä¸åŒçš„è¾“å‡ºæ ¼å¼\n",
    "            if isinstance(model_output, dict):\n",
    "                # é›†æˆæ¨¡å¼ï¼Œä½¿ç”¨ensembleè¾“å‡º\n",
    "                output = model_output.get('ensemble', model_output.get('main', list(model_output.values())[0]))\n",
    "            else:\n",
    "                # æ ‡å‡†æ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨è¾“å‡º\n",
    "                output = model_output\n",
    "            \n",
    "            # ç¡®ä¿è¾“å‡ºå’Œç›®æ ‡çš„ç»´åº¦åŒ¹é…\n",
    "            if output.dim() > 1:\n",
    "                output = output.squeeze(-1)  # å°† [batch, 1] å‹ç¼©ä¸º [batch]\n",
    "            \n",
    "            # ç¡®ä¿ç›®æ ‡æ ‡ç­¾æ˜¯æ­£ç¡®çš„æ•°æ®ç±»å‹å’Œç»´åº¦\n",
    "            if target.dim() > 1:\n",
    "                target = target.squeeze(-1)  # å°† [batch, 1] å‹ç¼©ä¸º [batch]\n",
    "            target = target.float()  # ç¡®ä¿æ˜¯floatç±»å‹\n",
    "            \n",
    "            # è®¡ç®—æŸå¤±\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # æ”¶é›†é¢„æµ‹ç»“æœ (åº”ç”¨ sigmoid è·å¾—æ¦‚ç‡)\n",
    "            probs = torch.sigmoid(output)\n",
    "            predictions = (probs > 0.5).float()\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_scores.extend(probs.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    total_inference_time = np.sum(inference_times)\n",
    "    \n",
    "    print(f\"âœ… è¯„ä¼°å®Œæˆ\")\n",
    "    print(f\"å¹³å‡æŸå¤±: {avg_loss:.4f}\")\n",
    "    print(f\"å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time*1000:.2f} ms/batch\")\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'predictions': np.array(all_predictions),\n",
    "        'targets': np.array(all_targets),\n",
    "        'scores': np.array(all_scores),\n",
    "        'avg_inference_time': avg_inference_time,\n",
    "        'total_inference_time': total_inference_time\n",
    "    }\n",
    "\n",
    "def calculate_comprehensive_metrics(predictions, targets, scores):\n",
    "    \"\"\"è®¡ç®—å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…å«ç±»åˆ«ä¸å¹³è¡¡åˆ†æ\"\"\"\n",
    "    # åŸºç¡€æŒ‡æ ‡\n",
    "    accuracy = accuracy_score(targets, predictions)\n",
    "    balanced_acc = balanced_accuracy_score(targets, predictions)\n",
    "    precision = precision_score(targets, predictions, zero_division=0)\n",
    "    recall = recall_score(targets, predictions, zero_division=0)\n",
    "    f1 = f1_score(targets, predictions, zero_division=0)\n",
    "    \n",
    "    # æ··æ·†çŸ©é˜µ\n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n",
    "    \n",
    "    # ç‰¹å¼‚æ€§å’Œè´Ÿé¢„æµ‹å€¼\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    \n",
    "    # ç±»åˆ«ç‰¹å®šæŒ‡æ ‡\n",
    "    real_total = np.sum(targets == 0)\n",
    "    fake_total = np.sum(targets == 1)\n",
    "    real_correct = tn  # çœŸå®è§†é¢‘æ­£ç¡®é¢„æµ‹ä¸ºçœŸå®\n",
    "    fake_correct = tp  # ä¼ªé€ è§†é¢‘æ­£ç¡®é¢„æµ‹ä¸ºä¼ªé€ \n",
    "    \n",
    "    real_accuracy = real_correct / real_total if real_total > 0 else 0\n",
    "    fake_accuracy = fake_correct / fake_total if fake_total > 0 else 0\n",
    "    \n",
    "    # ç±»åˆ«ä¸å¹³è¡¡åˆ†æ\n",
    "    class_distribution = {\n",
    "        'real_samples': int(real_total),\n",
    "        'fake_samples': int(fake_total),\n",
    "        'imbalance_ratio': fake_total / real_total if real_total > 0 else float('inf')\n",
    "    }\n",
    "    \n",
    "    # AUCæŒ‡æ ‡\n",
    "    try:\n",
    "        auc_roc = roc_auc_score(targets, scores)\n",
    "    except:\n",
    "        auc_roc = 0.0\n",
    "    \n",
    "    try:\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)\n",
    "        auc_pr = auc(recall_curve, precision_curve)\n",
    "    except:\n",
    "        auc_pr = 0.0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'balanced_accuracy': balanced_acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        'f1': f1,\n",
    "        'auc_roc': auc_roc,\n",
    "        'auc_pr': auc_pr,\n",
    "        'npv': npv,\n",
    "        'confusion_matrix': cm,\n",
    "        'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp,\n",
    "        'real_accuracy': real_accuracy,\n",
    "        'fake_accuracy': fake_accuracy,\n",
    "        'class_distribution': class_distribution\n",
    "    }\n",
    "\n",
    "def plot_enhanced_confusion_matrix(cm, save_path):\n",
    "    \"\"\"ç»˜åˆ¶å¢å¼ºçš„æ··æ·†çŸ©é˜µ\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # è®¡ç®—ç™¾åˆ†æ¯”\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # åˆ›å»ºæ ‡ç­¾\n",
    "    labels = np.array([[\n",
    "        f'{cm[i,j]}\\n({cm_percent[i,j]:.1f}%)' \n",
    "        for j in range(cm.shape[1])\n",
    "    ] for i in range(cm.shape[0])])\n",
    "    \n",
    "    # ç»˜åˆ¶çƒ­å›¾\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', \n",
    "                xticklabels=['çœŸå®', 'ä¼ªé€ '],\n",
    "                yticklabels=['çœŸå®', 'ä¼ªé€ '],\n",
    "                cbar_kws={'label': 'æ ·æœ¬æ•°é‡'})\n",
    "    \n",
    "    plt.title('å¢å¼ºæ··æ·†çŸ©é˜µ', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)\n",
    "    plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=12)\n",
    "    \n",
    "    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    stats_text = f'å‡†ç¡®ç‡: {accuracy:.3f}\\nç²¾ç¡®ç‡: {precision:.3f}\\nå¬å›ç‡: {recall:.3f}\\nF1åˆ†æ•°: {f1:.3f}'\n",
    "    plt.text(2.1, 0.5, stats_text, fontsize=10, \n",
    "             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {save_path}\")\n",
    "\n",
    "def plot_roc_pr_curves(targets, scores, save_path):\n",
    "    \"\"\"ç»˜åˆ¶ROCå’ŒPRæ›²çº¿\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # ROCæ›²çº¿\n",
    "    fpr, tpr, _ = roc_curve(targets, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    ax1.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f'ROCæ›²çº¿ (AUC = {roc_auc:.4f})')\n",
    "    ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    ax1.set_xlim([0.0, 1.0])\n",
    "    ax1.set_ylim([0.0, 1.05])\n",
    "    ax1.set_xlabel('å‡æ­£ç‡')\n",
    "    ax1.set_ylabel('çœŸæ­£ç‡')\n",
    "    ax1.set_title('ROCæ›²çº¿')\n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # PRæ›²çº¿\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)\n",
    "    pr_auc = auc(recall_curve, precision_curve)\n",
    "    \n",
    "    ax2.plot(recall_curve, precision_curve, color='darkgreen', lw=2,\n",
    "             label=f'PRæ›²çº¿ (AUC = {pr_auc:.4f})')\n",
    "    ax2.set_xlim([0.0, 1.0])\n",
    "    ax2.set_ylim([0.0, 1.05])\n",
    "    ax2.set_xlabel('å¬å›ç‡')\n",
    "    ax2.set_ylabel('ç²¾ç¡®ç‡')\n",
    "    ax2.set_title('ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿')\n",
    "    ax2.legend(loc='lower left')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"ROC/PRæ›²çº¿å·²ä¿å­˜åˆ°: {save_path}\")\n",
    "\n",
    "def generate_class_imbalance_report(metrics):\n",
    "    \"\"\"ç”Ÿæˆè¯¦ç»†çš„ç±»åˆ«ä¸å¹³è¡¡åˆ†ææŠ¥å‘Š\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š ç±»åˆ«ä¸å¹³è¡¡åˆ†ææŠ¥å‘Š\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # æ•°æ®åˆ†å¸ƒ\n",
    "    dist = metrics['class_distribution']\n",
    "    print(f\"\\nğŸ“ˆ æ•°æ®åˆ†å¸ƒ:\")\n",
    "    print(f\"  çœŸå®è§†é¢‘æ ·æœ¬: {dist['real_samples']}\")\n",
    "    print(f\"  ä¼ªé€ è§†é¢‘æ ·æœ¬: {dist['fake_samples']}\")\n",
    "    print(f\"  ä¸å¹³è¡¡æ¯”ä¾‹: {dist['imbalance_ratio']:.2f}:1 (ä¼ªé€ :çœŸå®)\")\n",
    "    \n",
    "    # ç±»åˆ«ç‰¹å®šæ€§èƒ½\n",
    "    print(f\"\\nğŸ¯ ç±»åˆ«ç‰¹å®šå‡†ç¡®ç‡:\")\n",
    "    print(f\"  çœŸå®è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: {metrics['real_accuracy']*100:.2f}%\")\n",
    "    print(f\"  ä¼ªé€ è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: {metrics['fake_accuracy']*100:.2f}%\")\n",
    "    \n",
    "    # æ··æ·†çŸ©é˜µåˆ†æ\n",
    "    tn, fp, fn, tp = metrics['tn'], metrics['fp'], metrics['fn'], metrics['tp']\n",
    "    print(f\"\\nğŸ“‹ æ··æ·†çŸ©é˜µåˆ†æ:\")\n",
    "    print(f\"  çœŸè´Ÿä¾‹ (TN): {tn} - æ­£ç¡®è¯†åˆ«çš„çœŸå®è§†é¢‘\")\n",
    "    print(f\"  å‡æ­£ä¾‹ (FP): {fp} - è¯¯åˆ¤ä¸ºä¼ªé€ çš„çœŸå®è§†é¢‘\")\n",
    "    print(f\"  å‡è´Ÿä¾‹ (FN): {fn} - è¯¯åˆ¤ä¸ºçœŸå®çš„ä¼ªé€ è§†é¢‘\")\n",
    "    print(f\"  çœŸæ­£ä¾‹ (TP): {tp} - æ­£ç¡®è¯†åˆ«çš„ä¼ªé€ è§†é¢‘\")\n",
    "    \n",
    "    # åå‘æ€§åˆ†æ\n",
    "    total_predictions = tn + fp + fn + tp\n",
    "    predicted_real = tn + fn\n",
    "    predicted_fake = fp + tp\n",
    "    \n",
    "    print(f\"\\nâš–ï¸ æ¨¡å‹åå‘æ€§åˆ†æ:\")\n",
    "    print(f\"  é¢„æµ‹ä¸ºçœŸå®çš„æ ·æœ¬: {predicted_real} ({predicted_real/total_predictions*100:.1f}%)\")\n",
    "    print(f\"  é¢„æµ‹ä¸ºä¼ªé€ çš„æ ·æœ¬: {predicted_fake} ({predicted_fake/total_predictions*100:.1f}%)\")\n",
    "    \n",
    "    # é—®é¢˜è¯Šæ–­\n",
    "    print(f\"\\nğŸ” é—®é¢˜è¯Šæ–­:\")\n",
    "    if metrics['real_accuracy'] < 0.1:\n",
    "        print(\"  âŒ ä¸¥é‡é—®é¢˜: æ¨¡å‹å‡ ä¹æ— æ³•è¯†åˆ«çœŸå®è§†é¢‘\")\n",
    "    elif metrics['real_accuracy'] < 0.5:\n",
    "        print(\"  âš ï¸  é—®é¢˜: çœŸå®è§†é¢‘è¯†åˆ«èƒ½åŠ›è¾ƒå·®\")\n",
    "    else:\n",
    "        print(\"  âœ… çœŸå®è§†é¢‘è¯†åˆ«èƒ½åŠ›æ­£å¸¸\")\n",
    "        \n",
    "    if metrics['fake_accuracy'] > 0.9 and metrics['real_accuracy'] < 0.1:\n",
    "        print(\"  âŒ ä¸¥é‡åå‘: æ¨¡å‹è¿‡åº¦åå‘é¢„æµ‹ä¼ªé€ è§†é¢‘\")\n",
    "    \n",
    "    if metrics['auc_roc'] < 0.6:\n",
    "        print(\"  âŒ AUC-ROCè¿‡ä½: æ¨¡å‹åˆ¤åˆ«èƒ½åŠ›æ¥è¿‘éšæœºçŒœæµ‹\")\n",
    "    \n",
    "    # æ”¹è¿›å»ºè®®\n",
    "    print(f\"\\nğŸ’¡ æ”¹è¿›å»ºè®®:\")\n",
    "    if dist['imbalance_ratio'] > 3.0:\n",
    "        print(\"  1. å¢åŠ çœŸå®è§†é¢‘æ ·æœ¬æˆ–å‡å°‘ä¼ªé€ è§†é¢‘æ ·æœ¬\")\n",
    "        print(\"  2. ä½¿ç”¨æ›´å¼ºçš„ç±»åˆ«æƒé‡ (pos_weight > 3.0)\")\n",
    "        print(\"  3. è°ƒæ•´Focal Losså‚æ•° (é™ä½alpha, å¢åŠ gamma)\")\n",
    "    \n",
    "    if metrics['real_accuracy'] < 0.3:\n",
    "        print(\"  4. æ£€æŸ¥æ•°æ®è´¨é‡ï¼Œç¡®ä¿çœŸå®è§†é¢‘æ ‡ç­¾æ­£ç¡®\")\n",
    "        print(\"  5. ä½¿ç”¨æˆæœ¬æ•æ„Ÿå­¦ä¹ æ–¹æ³•\")\n",
    "        print(\"  6. è€ƒè™‘ä½¿ç”¨SMOTEç­‰è¿‡é‡‡æ ·æŠ€æœ¯\")\n",
    "    \n",
    "    if metrics['auc_roc'] < 0.6:\n",
    "        print(\"  7. é‡æ–°è®¾è®¡æ¨¡å‹æ¶æ„\")\n",
    "        print(\"  8. å¢åŠ æ¨¡å‹å¤æ‚åº¦æˆ–ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹\")\n",
    "        print(\"  9. æ£€æŸ¥ç‰¹å¾æå–æ˜¯å¦æœ‰æ•ˆ\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "print(\"âœ… è¯„ä¼°å‡½æ•°å’Œå¯è§†åŒ–å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6dae556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.488781Z",
     "iopub.status.busy": "2025-07-29T10:28:38.488574Z",
     "iopub.status.idle": "2025-07-29T11:31:08.831827Z",
     "shell.execute_reply": "2025-07-29T11:31:08.830943Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3750.353734,
     "end_time": "2025-07-29T11:31:08.833276",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.479542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ é…ç½®å‚æ•°:\n",
      "   çœŸå®è§†é¢‘æ•°é‡: 200\n",
      "   å‡è§†é¢‘æ•°é‡: 400\n",
      "   æ¯è§†é¢‘å¸§æ•°: 16\n",
      "   çœŸå‡æ¯”ä¾‹: 1:2\n",
      "   é¢„è®¡æ€»æ ·æœ¬: 600\n",
      "ğŸ¬ å¼€å§‹ç›´æ¥é¢„æå–è§†é¢‘å¸§åˆ° ./data/frames...\n",
      "ğŸ“± æ•°æ®å¤„ç†ä½¿ç”¨è®¾å¤‡: cuda\n",
      "ğŸ¯ å¼€å§‹å¤„ç†çœŸå®è§†é¢‘...\n",
      "æ‰¾åˆ° 200 ä¸ªçœŸå®è§†é¢‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å¤„ç†çœŸå®è§†é¢‘:   0%|          | 0/200 [00:00<?, ?it/s]I0000 00:00:1753784922.694664      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13318 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1753784922.695324      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "å¤„ç†çœŸå®è§†é¢‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [21:10<00:00,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ­ å¼€å§‹å¤„ç†å‡è§†é¢‘...\n",
      "  Deepfakes: 1000 ä¸ªè§†é¢‘\n",
      "  Face2Face: 1000 ä¸ªè§†é¢‘\n",
      "  FaceShifter: 1000 ä¸ªè§†é¢‘\n",
      "  FaceSwap: 1000 ä¸ªè§†é¢‘\n",
      "  NeuralTextures: 1000 ä¸ªè§†é¢‘\n",
      "  DeepFakeDetection: 1000 ä¸ªè§†é¢‘\n",
      "æ€»å…±å¯ç”¨å‡è§†é¢‘: 6000 ä¸ª\n",
      "å¹³å‡åˆ†é…ç­–ç•¥: æ¯ç§æ–¹æ³• 66 ä¸ªè§†é¢‘\n",
      "å‰©ä½™ 4 ä¸ªè§†é¢‘å°†åˆ†é…ç»™å‰ 4 ç§æ–¹æ³•\n",
      "  Deepfakes: é‡‡æ · 67 ä¸ªè§†é¢‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å¤„ç†Deepfakes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [07:11<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Face2Face: é‡‡æ · 67 ä¸ªè§†é¢‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å¤„ç†Face2Face: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [06:56<00:00,  6.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FaceShifter: é‡‡æ · 67 ä¸ªè§†é¢‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å¤„ç†FaceShifter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [06:18<00:00,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FaceSwap: é‡‡æ · 67 ä¸ªè§†é¢‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å¤„ç†FaceSwap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [05:05<00:00,  4.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NeuralTextures: é‡‡æ · 66 ä¸ªè§†é¢‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å¤„ç†NeuralTextures: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [05:08<00:00,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DeepFakeDetection: é‡‡æ · 66 ä¸ªè§†é¢‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å¤„ç†DeepFakeDetection: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [10:39<00:00,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ç›´æ¥é¢„æå–å®Œæˆ: 600 ä¸ªè§†é¢‘\n",
      "   çœŸå®è§†é¢‘: 200 ä¸ª\n",
      "   å‡è§†é¢‘: 400 ä¸ª\n",
      "å‡è§†é¢‘æ–¹æ³•åˆ†å¸ƒ:\n",
      "  Deepfakes: 67 ä¸ªè§†é¢‘\n",
      "  Face2Face: 67 ä¸ªè§†é¢‘\n",
      "  FaceShifter: 67 ä¸ªè§†é¢‘\n",
      "  FaceSwap: 67 ä¸ªè§†é¢‘\n",
      "  NeuralTextures: 66 ä¸ªè§†é¢‘\n",
      "  DeepFakeDetection: 66 ä¸ªè§†é¢‘\n",
      "\n",
      "ğŸ“Š æ€»ä½“æ•°æ®ç»Ÿè®¡: 600 ä¸ªæ ·æœ¬\n",
      "   çœŸå®è§†é¢‘: 200 ä¸ª\n",
      "   å‡è§†é¢‘: 400 ä¸ª\n",
      "\n",
      "ğŸ“Š åˆ†å‰²æ•°æ®é›†...\n",
      "çœŸå®è§†é¢‘: 200 ä¸ª\n",
      "ä¼ªé€ è§†é¢‘: 400 ä¸ª\n",
      "è®­ç»ƒé›†: 420 æ ·æœ¬\n",
      "éªŒè¯é›†: 90 æ ·æœ¬\n",
      "æµ‹è¯•é›†: 90 æ ·æœ¬\n",
      "\n",
      "ğŸ’¾ ä¿å­˜æ•°æ®é›†...\n",
      "æ•°æ®é›†å·²ä¿å­˜åˆ°: ./data/train.csv\n",
      "æ•°æ®é›†å·²ä¿å­˜åˆ°: ./data/val.csv\n",
      "æ•°æ®é›†å·²ä¿å­˜åˆ°: ./data/test.csv\n",
      "\n",
      "ğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:\n",
      "è®­ç»ƒé›†: çœŸå®=140, ä¼ªé€ =280, æ€»è®¡=420\n",
      "éªŒè¯é›†: çœŸå®=30, ä¼ªé€ =60, æ€»è®¡=90\n",
      "æµ‹è¯•é›†: çœŸå®=30, ä¼ªé€ =60, æ€»è®¡=90\n",
      "\n",
      "âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼\n",
      "   ğŸ“Š æ•°æ®åˆ†å¸ƒ: çœŸå®è§†é¢‘ 200 | å‡è§†é¢‘ 400\n",
      "   ğŸ“ˆ å½“å‰æ¯”ä¾‹: 1:2\n",
      "   ğŸ¯ æ•°æ®é›†è§„æ¨¡: 600 ä¸ªæ ·æœ¬\n",
      "   ğŸš€ å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: æ•°æ®å‡†å¤‡ - ç›´æ¥é¢„æå–ä¼˜åŒ–ç‰ˆæœ¬\n",
    "\n",
    "# ==================== é…ç½®å‚æ•° ====================\n",
    "# æ•°æ®é›†è·¯å¾„é…ç½®\n",
    "DATA_BASE_DIR = '/kaggle/input/ff-c23/FaceForensics++_C23'\n",
    "\n",
    "# å¯è‡ªå®šä¹‰é¢„å¤„ç†è§†é¢‘æ•°é‡\n",
    "MAX_REAL_VIDEOS = 200      # çœŸå®è§†é¢‘æ•°é‡\n",
    "MAX_FAKE_VIDEOS = 400      # å‡è§†é¢‘æ•°é‡\n",
    "MAX_FRAMES_PER_VIDEO = 16  # æ¯ä¸ªè§†é¢‘æå–çš„å¸§æ•°\n",
    "\n",
    "# çœŸå‡è§†é¢‘æ¯”ä¾‹å»ºè®®\n",
    "# 1:1 - å¹³è¡¡æ•°æ®é›†ï¼Œé€‚åˆå¤§å¤šæ•°æƒ…å†µ\n",
    "# 1:2 - è½»å¾®åå‘å‡è§†é¢‘ï¼Œæé«˜å‡è§†é¢‘æ£€æµ‹èƒ½åŠ›\n",
    "# 1:3 - ä¸­ç­‰åå‘å‡è§†é¢‘ï¼Œé€‚åˆå®é™…åº”ç”¨åœºæ™¯\n",
    "# 1:6 - å¼ºçƒˆåå‘å‡è§†é¢‘ï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œåˆ†å¸ƒ\n",
    "REAL_FAKE_RATIO = \"1:2\"  # å½“å‰æ¯”ä¾‹\n",
    "\n",
    "def direct_extract_frames_from_videos(base_data_dir, max_real=MAX_REAL_VIDEOS, max_fake=MAX_FAKE_VIDEOS, max_frames=MAX_FRAMES_PER_VIDEO, frames_dir='./data/frames'):\n",
    "    \"\"\"\n",
    "    ç›´æ¥ä»è§†é¢‘ç›®å½•é¢„æå–å¸§åˆ°ç¡¬ç›˜ - ä¸€æ­¥åˆ°ä½çš„ä¼˜åŒ–æ–¹æ¡ˆ\n",
    "    \n",
    "    Args:\n",
    "        base_data_dir: æ•°æ®é›†æ ¹ç›®å½•\n",
    "        max_real: æœ€å¤§çœŸå®è§†é¢‘æ•°é‡\n",
    "        max_fake: æœ€å¤§å‡è§†é¢‘æ•°é‡\n",
    "        max_frames: æ¯ä¸ªè§†é¢‘æå–çš„å¸§æ•°\n",
    "        frames_dir: å¸§å­˜å‚¨ç›®å½•\n",
    "    \n",
    "    Returns:\n",
    "        extracted_data: åŒ…å«é¢„æå–å¸§è·¯å¾„çš„æ•°æ®åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ¬ å¼€å§‹ç›´æ¥é¢„æå–è§†é¢‘å¸§åˆ° {frames_dir}...\")\n",
    "    \n",
    "    # åˆ›å»ºå¿…è¦çš„ç›®å½•\n",
    "    os.makedirs('./data', exist_ok=True)\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "    \n",
    "    # æ‰“å°è®¾å¤‡ä¿¡æ¯\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"ğŸ“± æ•°æ®å¤„ç†ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "    \n",
    "    extracted_data = []\n",
    "    fake_methods = ['Deepfakes', 'Face2Face', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'DeepFakeDetection']\n",
    "    \n",
    "    # ==================== å¤„ç†çœŸå®è§†é¢‘ ====================\n",
    "    print(\"ğŸ¯ å¼€å§‹å¤„ç†çœŸå®è§†é¢‘...\")\n",
    "    original_dir = os.path.join(base_data_dir, 'original')\n",
    "    if os.path.exists(original_dir):\n",
    "        video_files = [f for f in os.listdir(original_dir)\n",
    "                      if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        \n",
    "        if len(video_files) > max_real:\n",
    "            video_files = random.sample(video_files, max_real)\n",
    "        \n",
    "        print(f\"æ‰¾åˆ° {len(video_files)} ä¸ªçœŸå®è§†é¢‘\")\n",
    "        \n",
    "        for video_file in tqdm(video_files, desc=\"å¤„ç†çœŸå®è§†é¢‘\"):\n",
    "            try:\n",
    "                video_path = os.path.join(original_dir, video_file)\n",
    "                \n",
    "                # ç”Ÿæˆå¸§æ–‡ä»¶è·¯å¾„\n",
    "                video_name = os.path.splitext(video_file)[0]\n",
    "                frame_file = os.path.join(frames_dir, f\"{video_name}_frames.pt\")\n",
    "                \n",
    "                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨\n",
    "                if os.path.exists(frame_file):\n",
    "                    # å¯¹äºå·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œæˆ‘ä»¬éœ€è¦åŠ è½½å®ƒæ¥è·å–å¸§æ•°\n",
    "                    try:\n",
    "                        existing_frames = torch.load(frame_file)\n",
    "                        num_frames = len(existing_frames)\n",
    "                    except:\n",
    "                        num_frames = max_frames  # é»˜è®¤å€¼\n",
    "                    \n",
    "                    extracted_data.append({\n",
    "                        'frame_path': frame_file,\n",
    "                        'label': 0,\n",
    "                        'method': 'original',\n",
    "                        'original_video': video_path,\n",
    "                        'num_frames': num_frames\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # ç›´æ¥æå–å¸§å¹¶ä¿å­˜\n",
    "                frames = extract_frames_memory_efficient(video_path, max_frames)\n",
    "                \n",
    "                if len(frames) >= max_frames // 2:  # è‡³å°‘è¦æœ‰ä¸€åŠçš„å¸§\n",
    "                    # è½¬æ¢ä¸ºtensorå¹¶ä¿å­˜\n",
    "                    frames_tensor = torch.stack([\n",
    "                        torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0\n",
    "                        for frame in frames\n",
    "                    ])\n",
    "                    \n",
    "                    torch.save(frames_tensor, frame_file)\n",
    "                    \n",
    "                    extracted_data.append({\n",
    "                        'frame_path': frame_file,\n",
    "                        'label': 0,  # çœŸå®è§†é¢‘\n",
    "                        'method': 'original',\n",
    "                        'original_video': video_path,\n",
    "                        'num_frames': len(frames)\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"âš ï¸ è·³è¿‡å¸§æ•°ä¸è¶³çš„è§†é¢‘: {video_file}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ å¤„ç†çœŸå®è§†é¢‘å¤±è´¥ {video_file}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # ==================== å¤„ç†å‡è§†é¢‘ - å¹³å‡åˆ†é…ç­–ç•¥ ====================\n",
    "    print(\"ğŸ­ å¼€å§‹å¤„ç†å‡è§†é¢‘...\")\n",
    "    \n",
    "    # ç»Ÿè®¡æ¯ç§æ–¹æ³•çš„å¯ç”¨è§†é¢‘æ•°é‡\n",
    "    method_videos = {}\n",
    "    total_available_fake = 0\n",
    "    \n",
    "    for method in fake_methods:\n",
    "        method_dir = os.path.join(base_data_dir, method)\n",
    "        if os.path.exists(method_dir):\n",
    "            videos = [os.path.join(method_dir, f) for f in os.listdir(method_dir) \n",
    "                     if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "            method_videos[method] = videos\n",
    "            total_available_fake += len(videos)\n",
    "            print(f\"  {method}: {len(videos)} ä¸ªè§†é¢‘\")\n",
    "        else:\n",
    "            method_videos[method] = []\n",
    "            print(f\"  {method}: ç›®å½•ä¸å­˜åœ¨\")\n",
    "    \n",
    "    print(f\"æ€»å…±å¯ç”¨å‡è§†é¢‘: {total_available_fake} ä¸ª\")\n",
    "    \n",
    "    # è®¡ç®—æ¯ç§æ–¹æ³•åº”è¯¥é‡‡æ ·çš„è§†é¢‘æ•°é‡ï¼ˆå¹³å‡åˆ†é…ï¼‰\n",
    "    available_methods = [method for method in fake_methods if len(method_videos[method]) > 0]\n",
    "    if not available_methods:\n",
    "        print(\"âŒ æœªæ‰¾åˆ°ä»»ä½•å‡è§†é¢‘æ–¹æ³•\")\n",
    "        return extracted_data\n",
    "    \n",
    "    videos_per_method = max_fake // len(available_methods)\n",
    "    remaining_videos = max_fake % len(available_methods)\n",
    "    \n",
    "    print(f\"å¹³å‡åˆ†é…ç­–ç•¥: æ¯ç§æ–¹æ³• {videos_per_method} ä¸ªè§†é¢‘\")\n",
    "    if remaining_videos > 0:\n",
    "        print(f\"å‰©ä½™ {remaining_videos} ä¸ªè§†é¢‘å°†åˆ†é…ç»™å‰ {remaining_videos} ç§æ–¹æ³•\")\n",
    "    \n",
    "    # ä¸ºæ¯ç§æ–¹æ³•é‡‡æ ·å¹¶ç›´æ¥å¤„ç†è§†é¢‘\n",
    "    for i, method in enumerate(available_methods):\n",
    "        # è®¡ç®—å½“å‰æ–¹æ³•åº”è¯¥é‡‡æ ·çš„æ•°é‡\n",
    "        current_method_quota = videos_per_method\n",
    "        if i < remaining_videos:  # å‰å‡ ç§æ–¹æ³•å¤šåˆ†é…ä¸€ä¸ª\n",
    "            current_method_quota += 1\n",
    "        \n",
    "        available_videos = method_videos[method]\n",
    "        \n",
    "        # å¦‚æœå¯ç”¨è§†é¢‘æ•°é‡å°‘äºé…é¢ï¼Œå…¨éƒ¨ä½¿ç”¨\n",
    "        if len(available_videos) <= current_method_quota:\n",
    "            method_selected = available_videos\n",
    "            print(f\"  {method}: ä½¿ç”¨å…¨éƒ¨ {len(method_selected)} ä¸ªè§†é¢‘\")\n",
    "        else:\n",
    "            # éšæœºé‡‡æ ·æŒ‡å®šæ•°é‡\n",
    "            method_selected = random.sample(available_videos, current_method_quota)\n",
    "            print(f\"  {method}: é‡‡æ · {len(method_selected)} ä¸ªè§†é¢‘\")\n",
    "        \n",
    "        # ç›´æ¥å¤„ç†é€‰æ‹©çš„è§†é¢‘\n",
    "        for video_path in tqdm(method_selected, desc=f\"å¤„ç†{method}\"):\n",
    "            try:\n",
    "                # ç”Ÿæˆå¸§æ–‡ä»¶è·¯å¾„\n",
    "                video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "                frame_file = os.path.join(frames_dir, f\"{video_name}_frames.pt\")\n",
    "                \n",
    "                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨\n",
    "                if os.path.exists(frame_file):\n",
    "                    # å¯¹äºå·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œæˆ‘ä»¬éœ€è¦åŠ è½½å®ƒæ¥è·å–å¸§æ•°\n",
    "                    try:\n",
    "                        existing_frames = torch.load(frame_file)\n",
    "                        num_frames = len(existing_frames)\n",
    "                    except:\n",
    "                        num_frames = max_frames  # é»˜è®¤å€¼\n",
    "                    \n",
    "                    extracted_data.append({\n",
    "                        'frame_path': frame_file,\n",
    "                        'label': 1,\n",
    "                        'method': method,\n",
    "                        'original_video': video_path,\n",
    "                        'num_frames': num_frames\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # ç›´æ¥æå–å¸§å¹¶ä¿å­˜\n",
    "                frames = extract_frames_memory_efficient(video_path, max_frames)\n",
    "                \n",
    "                if len(frames) >= max_frames // 2:\n",
    "                    # è½¬æ¢ä¸ºtensorå¹¶ä¿å­˜\n",
    "                    frames_tensor = torch.stack([\n",
    "                        torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0\n",
    "                        for frame in frames\n",
    "                    ])\n",
    "                    \n",
    "                    torch.save(frames_tensor, frame_file)\n",
    "                    \n",
    "                    extracted_data.append({\n",
    "                        'frame_path': frame_file,\n",
    "                        'label': 1,  # å‡è§†é¢‘\n",
    "                        'method': method,\n",
    "                        'original_video': video_path,\n",
    "                        'num_frames': len(frames)\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"âš ï¸ è·³è¿‡å¸§æ•°ä¸è¶³çš„è§†é¢‘: {os.path.basename(video_path)}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ å¤„ç†å‡è§†é¢‘å¤±è´¥ {os.path.basename(video_path)}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # ç»Ÿè®¡æœ€ç»ˆç»“æœ\n",
    "    real_count = sum(1 for item in extracted_data if item['label'] == 0)\n",
    "    fake_count = sum(1 for item in extracted_data if item['label'] == 1)\n",
    "    \n",
    "    method_counts = {}\n",
    "    for item in extracted_data:\n",
    "        if item['label'] == 1:  # åªç»Ÿè®¡å‡è§†é¢‘\n",
    "            method = item['method']\n",
    "            method_counts[method] = method_counts.get(method, 0) + 1\n",
    "    \n",
    "    print(f\"\\nâœ… ç›´æ¥é¢„æå–å®Œæˆ: {len(extracted_data)} ä¸ªè§†é¢‘\")\n",
    "    print(f\"   çœŸå®è§†é¢‘: {real_count} ä¸ª\")\n",
    "    print(f\"   å‡è§†é¢‘: {fake_count} ä¸ª\")\n",
    "    print(\"å‡è§†é¢‘æ–¹æ³•åˆ†å¸ƒ:\")\n",
    "    for method, count in method_counts.items():\n",
    "        print(f\"  {method}: {count} ä¸ªè§†é¢‘\")\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "print(f\"ğŸ“‹ é…ç½®å‚æ•°:\")\n",
    "print(f\"   çœŸå®è§†é¢‘æ•°é‡: {MAX_REAL_VIDEOS}\")\n",
    "print(f\"   å‡è§†é¢‘æ•°é‡: {MAX_FAKE_VIDEOS}\")\n",
    "print(f\"   æ¯è§†é¢‘å¸§æ•°: {MAX_FRAMES_PER_VIDEO}\")\n",
    "print(f\"   çœŸå‡æ¯”ä¾‹: {REAL_FAKE_RATIO}\")\n",
    "print(f\"   é¢„è®¡æ€»æ ·æœ¬: {MAX_REAL_VIDEOS + MAX_FAKE_VIDEOS}\")\n",
    "\n",
    "# ç›´æ¥é¢„æå–å¸§ - ä¸€æ­¥åˆ°ä½çš„ä¼˜åŒ–æ–¹æ¡ˆ\n",
    "extracted_data = direct_extract_frames_from_videos(\n",
    "    base_data_dir=DATA_BASE_DIR,\n",
    "    max_real=MAX_REAL_VIDEOS,\n",
    "    max_fake=MAX_FAKE_VIDEOS,\n",
    "    max_frames=MAX_FRAMES_PER_VIDEO\n",
    ")\n",
    "\n",
    "if len(extracted_data) == 0:\n",
    "    raise ValueError(\"âŒ é¢„æå–å¸§å¤±è´¥ï¼Œæ— æ³•ç»§ç»­ã€‚è¯·æ£€æŸ¥è§†é¢‘è·¯å¾„å’Œæ ¼å¼ã€‚\")\n",
    "\n",
    "# ç»Ÿè®¡æ€»ä½“æ•°æ®åˆ†å¸ƒ\n",
    "total_real = sum(1 for item in extracted_data if item['label'] == 0)\n",
    "total_fake = sum(1 for item in extracted_data if item['label'] == 1)\n",
    "print(f\"\\nğŸ“Š æ€»ä½“æ•°æ®ç»Ÿè®¡: {len(extracted_data)} ä¸ªæ ·æœ¬\")\n",
    "print(f\"   çœŸå®è§†é¢‘: {total_real} ä¸ª\")\n",
    "print(f\"   å‡è§†é¢‘: {total_fake} ä¸ª\")\n",
    "\n",
    "# æ•°æ®é›†åˆ†å‰²\n",
    "print(\"\\nğŸ“Š åˆ†å‰²æ•°æ®é›†...\")\n",
    "train_data, val_data, test_data = create_dataset_split(\n",
    "    extracted_data,  # ä½¿ç”¨é¢„æå–çš„æ•°æ®\n",
    "    test_size=0.15,  # æµ‹è¯•é›†æ¯”ä¾‹\n",
    "    val_size=0.15    # éªŒè¯é›†æ¯”ä¾‹\n",
    ")\n",
    "\n",
    "print(f\"è®­ç»ƒé›†: {len(train_data)} æ ·æœ¬\")\n",
    "print(f\"éªŒè¯é›†: {len(val_data)} æ ·æœ¬\")\n",
    "print(f\"æµ‹è¯•é›†: {len(test_data)} æ ·æœ¬\")\n",
    "\n",
    "# ä¿å­˜æ•°æ®é›†\n",
    "print(\"\\nğŸ’¾ ä¿å­˜æ•°æ®é›†...\")\n",
    "save_dataset_to_csv(train_data, './data/train.csv')\n",
    "save_dataset_to_csv(val_data, './data/val.csv')\n",
    "save_dataset_to_csv(test_data, './data/test.csv')\n",
    "\n",
    "# æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡\n",
    "print(\"\\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:\")\n",
    "for name, data in [(\"è®­ç»ƒ\", train_data), (\"éªŒè¯\", val_data), (\"æµ‹è¯•\", test_data)]:\n",
    "    real_count = sum(1 for item in data if item['label'] == 0)\n",
    "    fake_count = sum(1 for item in data if item['label'] == 1)\n",
    "    print(f\"{name}é›†: çœŸå®={real_count}, ä¼ªé€ ={fake_count}, æ€»è®¡={len(data)}\")\n",
    "\n",
    "print(f\"\\nâœ… æ•°æ®å‡†å¤‡å®Œæˆï¼\")\n",
    "print(f\"   ğŸ“Š æ•°æ®åˆ†å¸ƒ: çœŸå®è§†é¢‘ {total_real} | å‡è§†é¢‘ {total_fake}\")\n",
    "print(f\"   ğŸ“ˆ å½“å‰æ¯”ä¾‹: {REAL_FAKE_RATIO}\")\n",
    "print(f\"   ğŸ¯ æ•°æ®é›†è§„æ¨¡: {len(extracted_data)} ä¸ªæ ·æœ¬\")\n",
    "print(f\"   ğŸš€ å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b0dc70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T11:31:08.902515Z",
     "iopub.status.busy": "2025-07-29T11:31:08.902272Z",
     "iopub.status.idle": "2025-07-29T11:31:10.358803Z",
     "shell.execute_reply": "2025-07-29T11:31:10.357672Z"
    },
    "papermill": {
     "duration": 1.4921,
     "end_time": "2025-07-29T11:31:10.360210",
     "exception": false,
     "start_time": "2025-07-29T11:31:08.868110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– åˆ›å»ºå’Œé…ç½®æ¨¡å‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 166MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\n",
      "   - æ³¨æ„åŠ›æœºåˆ¶: å¯ç”¨\n",
      "   - å¤šæ¨¡æ€èåˆ: å¯ç”¨\n",
      "   - é›†æˆæ¨¡å¼: ç¦ç”¨\n",
      "ğŸš€ å¯ç”¨å¤šGPUå¹¶è¡Œè®­ç»ƒï¼Œä½¿ç”¨ 2 ä¸ªGPU\n",
      "ğŸ“¦ æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: 8 (å•GPU: 4)\n",
      "âœ… æ¨¡å‹å·²åˆ›å»ºå¹¶ç§»åŠ¨åˆ° cuda\n",
      "ğŸ“Š æ¨¡å‹å‚æ•°æ•°é‡: 41,983,874\n",
      "ğŸ® GPU: Tesla T4\n",
      "ğŸ’¾ GPUå†…å­˜: 14.7GB\n",
      "ğŸ”§ å†…å­˜ä½¿ç”¨é™åˆ¶: 60%\n",
      "âš ï¸ train_loaderæœªå®šä¹‰ï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«æƒé‡\n",
      "ğŸ“Š ç±»åˆ«åˆ†å¸ƒ - çœŸå®: 1, ä¼ªé€ : 1\n",
      "âš–ï¸ æ­£æ ·æœ¬æƒé‡: 1.00\n",
      "ğŸ“ ä½¿ç”¨FP32è®­ç»ƒ (è§£å†³NaNé—®é¢˜)\n",
      "ğŸ¯ è®­ç»ƒé…ç½®:\n",
      "  - è®­ç»ƒè½®æ•°: 30\n",
      "  - åˆå§‹å­¦ä¹ ç‡: 1.00e-04\n",
      "  - æƒé‡è¡°å‡: 1.00e-02\n",
      "  - æ—©åœè€å¿ƒå€¼: 15\n",
      "  - æ··åˆç²¾åº¦: ç¦ç”¨\n",
      "âœ… æ¨¡å‹å’Œè®­ç»ƒé…ç½®å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: æ¨¡å‹åˆå§‹åŒ–å’Œè®­ç»ƒé…ç½®\n",
    "print(\"ğŸ¤– åˆ›å»ºå’Œé…ç½®æ¨¡å‹...\")\n",
    "\n",
    "# è®­ç»ƒé…ç½®å‚æ•° \n",
    "batch_size = 4  \n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹ - é’ˆå¯¹Kaggle T4 GPUä¼˜åŒ–ï¼ˆç®€åŒ–é…ç½®è§£å†³NaNé—®é¢˜ï¼‰\n",
    "model = OptimizedDeepfakeDetector(\n",
    "    num_classes=1,\n",
    "    dropout_rate=0.2,  # é™ä½dropoutç‡\n",
    "    use_attention=True,\n",
    "    use_multimodal=True,\n",
    "    ensemble_mode=False   # å•æ¨¡å‹æ¨¡å¼\n",
    ").to(device)\n",
    "\n",
    "# å¤šGPUå¹¶è¡Œæ”¯æŒ\n",
    "if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "    print(f\"ğŸš€ å¯ç”¨å¤šGPUå¹¶è¡Œè®­ç»ƒï¼Œä½¿ç”¨ {torch.cuda.device_count()} ä¸ªGPU\")\n",
    "    model = nn.DataParallel(model)\n",
    "    # è°ƒæ•´æ‰¹æ¬¡å¤§å°ä»¥å……åˆ†åˆ©ç”¨å¤šGPU\n",
    "    effective_batch_size = batch_size * torch.cuda.device_count()\n",
    "    print(f\"ğŸ“¦ æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {effective_batch_size} (å•GPU: {batch_size})\")\n",
    "else:\n",
    "    print(\"ğŸ“ å•GPUè®­ç»ƒæ¨¡å¼\")\n",
    "\n",
    "print(f\"âœ… æ¨¡å‹å·²åˆ›å»ºå¹¶ç§»åŠ¨åˆ° {device}\")\n",
    "print(f\"ğŸ“Š æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ä¼˜åŒ–GPUå†…å­˜é…ç½® - æ›´ä¿å®ˆçš„å†…å­˜ä½¿ç”¨é¿å…OOM\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_per_process_memory_fraction(0.6)  # é™ä½åˆ°60%é¿å…å†…å­˜æº¢å‡º\n",
    "    torch.cuda.empty_cache()  # æ¸…ç†ç¼“å­˜\n",
    "    print(f\"ğŸ® GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
    "    print(f\"ğŸ”§ å†…å­˜ä½¿ç”¨é™åˆ¶: 60%\")\n",
    "\n",
    "# æŸå¤±å‡½æ•° - ä½¿ç”¨ç±»åˆ«æƒé‡å¹³è¡¡\n",
    "# è®¡ç®—ç±»åˆ«æƒé‡ - ä¿®å¤ç‰ˆæœ¬\n",
    "if 'train_loader' in globals() and train_loader is not None:\n",
    "    # ä»train_loaderè·å–æ•°æ®é›†\n",
    "    train_dataset = train_loader.dataset\n",
    "    \n",
    "    if hasattr(train_dataset, 'real_count') and hasattr(train_dataset, 'fake_count'):\n",
    "        # ä½¿ç”¨é¢„è®¡ç®—çš„ç»Ÿè®¡ä¿¡æ¯\n",
    "        real_count = train_dataset.real_count\n",
    "        fake_count = train_dataset.fake_count\n",
    "    else:\n",
    "        # å›é€€æ–¹æ¡ˆï¼šæ‰‹åŠ¨è®¡ç®—\n",
    "        if hasattr(train_dataset, 'data_list') and train_dataset.data_list is not None:\n",
    "            real_count = sum(1 for item in train_dataset.data_list if item['label'] == 0)\n",
    "            fake_count = sum(1 for item in train_dataset.data_list if item['label'] == 1)\n",
    "        elif hasattr(train_dataset, 'df') and train_dataset.df is not None:\n",
    "            real_count = len(train_dataset.df[train_dataset.df['label'] == 0])\n",
    "            fake_count = len(train_dataset.df[train_dataset.df['label'] == 1])\n",
    "        else:\n",
    "            # é»˜è®¤å€¼\n",
    "            real_count = 1\n",
    "            fake_count = 1\n",
    "            print(\"âš ï¸ æ— æ³•è·å–ç±»åˆ«åˆ†å¸ƒï¼Œä½¿ç”¨é»˜è®¤æƒé‡\")\n",
    "else:\n",
    "    # å¦‚æœæ²¡æœ‰train_loaderï¼Œä½¿ç”¨é»˜è®¤å€¼\n",
    "    real_count = 1\n",
    "    fake_count = 1\n",
    "    print(\"âš ï¸ train_loaderæœªå®šä¹‰ï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«æƒé‡\")\n",
    "\n",
    "# ç¡®ä¿è®¡æ•°ä¸ä¸ºé›¶\n",
    "real_count = max(real_count, 1)\n",
    "fake_count = max(fake_count, 1)\n",
    "\n",
    "pos_weight = torch.tensor([real_count / fake_count], device=device)\n",
    "\n",
    "print(f\"ğŸ“Š ç±»åˆ«åˆ†å¸ƒ - çœŸå®: {real_count}, ä¼ªé€ : {fake_count}\")\n",
    "print(f\"âš–ï¸ æ­£æ ·æœ¬æƒé‡: {pos_weight.item():.2f}\")\n",
    "\n",
    "# ä½¿ç”¨FocalLosså¤„ç†ç±»åˆ«ä¸å¹³è¡¡\n",
    "criterion = FocalLoss(\n",
    "    alpha=0.25,\n",
    "    gamma=2.0,  # é™ä½gammaå€¼ï¼Œå‡å°‘å¯¹å›°éš¾æ ·æœ¬çš„è¿‡åº¦å…³æ³¨\n",
    "    pos_weight=pos_weight,\n",
    "    reduction='mean'\n",
    ")\n",
    "\n",
    "# ä¼˜åŒ–å™¨é…ç½® - ä½¿ç”¨æ›´å®‰å…¨çš„å­¦ä¹ ç‡é¿å…NaN\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,  # é™ä½å­¦ä¹ ç‡åˆ°æ›´å®‰å…¨çš„èŒƒå›´ï¼Œé¿å…æ¢¯åº¦çˆ†ç‚¸\n",
    "    weight_decay=0.01,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# å­¦ä¹ ç‡è°ƒåº¦å™¨ - è°ƒæ•´ä¸ºæ›´åˆç†çš„å‚æ•°\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=3,  # å‡å°‘é‡å¯å‘¨æœŸï¼Œè®©å­¦ä¹ ç‡å˜åŒ–æ›´é¢‘ç¹\n",
    "    T_mult=2,  # å¢åŠ å‘¨æœŸå€å¢å› å­\n",
    "    eta_min=2e-4  # æé«˜æœ€å°å­¦ä¹ ç‡ï¼Œä»1e-7æé«˜åˆ°1e-6\n",
    ")\n",
    "\n",
    "# æ—©åœæœºåˆ¶ - æ›´ä¸¥æ ¼çš„ç›‘æ§\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=15,  # å‡å°‘è€å¿ƒå€¼\n",
    "    min_delta=0.001,  # å¢åŠ æœ€å°æ”¹è¿›é˜ˆå€¼\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# æ··åˆç²¾åº¦è®­ç»ƒ - æš‚æ—¶ç¦ç”¨ä»¥è§£å†³NaNé—®é¢˜\n",
    "use_amp = False  # å¼ºåˆ¶ç¦ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼Œé¿å…æ•°å€¼ä¸ç¨³å®š\n",
    "scaler = None\n",
    "print(\"ğŸ“ ä½¿ç”¨FP32è®­ç»ƒ (è§£å†³NaNé—®é¢˜)\")\n",
    "\n",
    "# è®­ç»ƒé…ç½® - åŒT4 GPUä¼˜åŒ–\n",
    "num_epochs = 30  # é€‚ä¸­çš„è®­ç»ƒè½®æ•°ï¼Œé€‚åˆåŒT4é…ç½®\n",
    "print(f\"ğŸ¯ è®­ç»ƒé…ç½®:\")\n",
    "print(f\"  - è®­ç»ƒè½®æ•°: {num_epochs}\")\n",
    "print(f\"  - åˆå§‹å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "print(f\"  - æƒé‡è¡°å‡: {optimizer.param_groups[0]['weight_decay']:.2e}\")\n",
    "print(f\"  - æ—©åœè€å¿ƒå€¼: {early_stopping.patience}\")\n",
    "print(f\"  - æ··åˆç²¾åº¦: {'å¯ç”¨' if use_amp else 'ç¦ç”¨'}\")\n",
    "\n",
    "print(\"âœ… æ¨¡å‹å’Œè®­ç»ƒé…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf424ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T11:31:10.430751Z",
     "iopub.status.busy": "2025-07-29T11:31:10.429942Z",
     "iopub.status.idle": "2025-07-29T11:31:10.562348Z",
     "shell.execute_reply": "2025-07-29T11:31:10.561377Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.168516,
     "end_time": "2025-07-29T11:31:10.563667",
     "exception": false,
     "start_time": "2025-07-29T11:31:10.395151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•°æ®åŠ è½½å™¨å‡½æ•°å®šä¹‰å®Œæˆï¼ˆä¸‰æ­¥ä¼˜åŒ–ä¸“ç”¨ï¼‰\n",
      "\n",
      "ğŸš€ åˆ›å»ºæ•°æ®åŠ è½½å™¨å®ä¾‹...\n",
      "ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆä¸‰æ­¥ä¼˜åŒ–æ¨¡å¼ï¼‰...\n",
      "ğŸ”§ æ£€æµ‹åˆ°GPUé¢„å¤„ç†ï¼Œè‡ªåŠ¨ç¦ç”¨pin_memoryä»¥é¿å…å†²çª\n",
      "âœ… é¢„æå–å¸§æ¨¡å¼ï¼Œå…± 420 ä¸ªæ ·æœ¬\n",
      "ğŸ“Š æ•°æ®åˆ†å¸ƒ: çœŸå®=140, ä¼ªé€ =280\n",
      "âœ… æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ: 420 ä¸ªæ ·æœ¬\n",
      "ğŸš€ GPUé¢„å¤„ç†: True (è®¾å¤‡: cuda)\n",
      "ğŸ“Š å¯ç”¨é¢‘åŸŸç‰¹å¾æå–\n",
      "ğŸ” å¯ç”¨å‹ç¼©ä¼ªå½±åˆ†æ\n",
      "âœ… é¢„æå–å¸§æ¨¡å¼ï¼Œå…± 90 ä¸ªæ ·æœ¬\n",
      "ğŸ“Š æ•°æ®åˆ†å¸ƒ: çœŸå®=30, ä¼ªé€ =60\n",
      "âœ… æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ: 90 ä¸ªæ ·æœ¬\n",
      "ğŸš€ GPUé¢„å¤„ç†: True (è®¾å¤‡: cuda)\n",
      "ğŸ“Š å¯ç”¨é¢‘åŸŸç‰¹å¾æå–\n",
      "ğŸ” å¯ç”¨å‹ç¼©ä¼ªå½±åˆ†æ\n",
      "âœ… é¢„æå–å¸§æ¨¡å¼ï¼Œå…± 90 ä¸ªæ ·æœ¬\n",
      "ğŸ“Š æ•°æ®åˆ†å¸ƒ: çœŸå®=30, ä¼ªé€ =60\n",
      "âœ… æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ: 90 ä¸ªæ ·æœ¬\n",
      "ğŸš€ GPUé¢„å¤„ç†: True (è®¾å¤‡: cuda)\n",
      "ğŸ“Š å¯ç”¨é¢‘åŸŸç‰¹å¾æå–\n",
      "ğŸ” å¯ç”¨å‹ç¼©ä¼ªå½±åˆ†æ\n",
      "è®­ç»ƒé›†å¤§å°: 420\n",
      "éªŒè¯é›†å¤§å°: 90\n",
      "æµ‹è¯•é›†å¤§å°: 90\n",
      "ç±»åˆ«åˆ†å¸ƒ: {0: 140, 1: 280}\n",
      "âœ… ä½¿ç”¨åŠ æƒéšæœºé‡‡æ ·å™¨è¿›è¡Œç±»åˆ«å¹³è¡¡\n",
      "ğŸ”§ ä½¿ç”¨ 0 ä¸ªå·¥ä½œè¿›ç¨‹ï¼ˆKaggleä¼˜åŒ–ï¼‰\n",
      "âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ\n",
      "ğŸ“ˆ ä¸‰æ­¥ä¼˜åŒ–æ€§èƒ½æå‡:\n",
      "  - é¢„æå–å¸§: æ¶ˆé™¤é‡å¤I/O\n",
      "  - GPUé¢„å¤„ç†: åŠ é€Ÿç‰¹å¾æå–\n",
      "  - æ€»ä½“è®­ç»ƒé€Ÿåº¦æå‡: 3-4å€\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: æ•°æ®åŠ è½½å™¨\n",
    "\n",
    "# å¿…è¦çš„å¯¼å…¥\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# æ³¨æ„ï¼šéœ€è¦å…ˆæ‰§è¡Œ cell_04_dataset_class.py æ¥å®šä¹‰ DeepfakeVideoDataset\n",
    "# å¦‚æœåœ¨Jupyterä¸­ï¼ŒDeepfakeVideoDataset åº”è¯¥å·²ç»åœ¨ä¹‹å‰çš„cellä¸­å®šä¹‰\n",
    "\n",
    "def create_data_loaders(batch_size=1, num_workers=0, pin_memory=True):\n",
    "    \"\"\"åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä¸“ç”¨äºé¢„æå–å¸§çš„GPUé¢„å¤„ç†\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆä¸‰æ­¥ä¼˜åŒ–æ¨¡å¼ï¼‰...\")\n",
    "    \n",
    "    # GPUé¢„å¤„ç†é…ç½®\n",
    "    gpu_preprocessing = True\n",
    "    \n",
    "    # é‡è¦ï¼šå½“å¯ç”¨GPUé¢„å¤„ç†æ—¶ï¼Œå¿…é¡»ç¦ç”¨pin_memory\n",
    "    # å› ä¸ºæ•°æ®å·²ç»åœ¨GPUä¸Šï¼Œpin_memoryåªé€‚ç”¨äºCPU tensor\n",
    "    if gpu_preprocessing:\n",
    "        pin_memory = False\n",
    "        print(\"ğŸ”§ æ£€æµ‹åˆ°GPUé¢„å¤„ç†ï¼Œè‡ªåŠ¨ç¦ç”¨pin_memoryä»¥é¿å…å†²çª\")\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®é›†å®ä¾‹ - ä¸“ç”¨äºé¢„æå–å¸§\n",
    "    train_dataset = DeepfakeVideoDataset(\n",
    "        csv_file='./data/train.csv',\n",
    "        max_frames=16,\n",
    "        gpu_preprocessing=gpu_preprocessing,  # å¯ç”¨GPUé¢„å¤„ç†\n",
    "        extract_fourier=True,   # å¯ç”¨å¤šæ¨¡æ€ç‰¹å¾\n",
    "        extract_compression=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = DeepfakeVideoDataset(\n",
    "        csv_file='./data/val.csv',\n",
    "        max_frames=16,\n",
    "        gpu_preprocessing=gpu_preprocessing,  # å¯ç”¨GPUé¢„å¤„ç†\n",
    "        extract_fourier=True,   # å¯ç”¨å¤šæ¨¡æ€ç‰¹å¾\n",
    "        extract_compression=True\n",
    "    )\n",
    "    \n",
    "    test_dataset = DeepfakeVideoDataset(\n",
    "        csv_file='./data/test.csv',\n",
    "        max_frames=16,\n",
    "        gpu_preprocessing=gpu_preprocessing,  # å¯ç”¨GPUé¢„å¤„ç†\n",
    "        extract_fourier=True,   # å¯ç”¨å¤šæ¨¡æ€ç‰¹å¾\n",
    "        extract_compression=True\n",
    "    )\n",
    "    \n",
    "    print(f\"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}\")\n",
    "    print(f\"éªŒè¯é›†å¤§å°: {len(val_dataset)}\")\n",
    "    print(f\"æµ‹è¯•é›†å¤§å°: {len(test_dataset)}\")\n",
    "    \n",
    "    # è®¡ç®—ç±»åˆ«æƒé‡ç”¨äºå¹³è¡¡é‡‡æ ·\n",
    "    train_df = pd.read_csv('./data/train.csv')\n",
    "    class_counts = train_df['label'].value_counts().sort_index()\n",
    "    total_samples = len(train_df)\n",
    "    \n",
    "    print(f\"ç±»åˆ«åˆ†å¸ƒ: {class_counts.to_dict()}\")\n",
    "    \n",
    "    # åˆ›å»ºå¹³è¡¡é‡‡æ ·å™¨\n",
    "    if len(class_counts) > 1:\n",
    "        # è®¡ç®—ç±»åˆ«æƒé‡\n",
    "        class_weights = total_samples / (len(class_counts) * class_counts.values)\n",
    "        sample_weights = [class_weights[int(label)] for label in train_df['label']]\n",
    "        \n",
    "        # åˆ›å»ºåŠ æƒéšæœºé‡‡æ ·å™¨\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… ä½¿ç”¨åŠ æƒéšæœºé‡‡æ ·å™¨è¿›è¡Œç±»åˆ«å¹³è¡¡\")\n",
    "        shuffle_train = False  # ä½¿ç”¨é‡‡æ ·å™¨æ—¶ä¸èƒ½shuffle\n",
    "    else:\n",
    "        sampler = None\n",
    "        shuffle_train = True\n",
    "        print(\"âš ï¸ åªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œè·³è¿‡ç±»åˆ«å¹³è¡¡\")\n",
    "    \n",
    "    # Kaggleä¼˜åŒ–é…ç½®\n",
    "    safe_num_workers = 0  # å•è¿›ç¨‹æ¨¡å¼é¿å…åºåˆ—åŒ–é—®é¢˜\n",
    "    print(f\"ğŸ”§ ä½¿ç”¨ {safe_num_workers} ä¸ªå·¥ä½œè¿›ç¨‹ï¼ˆKaggleä¼˜åŒ–ï¼‰\")\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä¸‰æ­¥ä¼˜åŒ–é…ç½®\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle_train,\n",
    "        sampler=sampler,\n",
    "        num_workers=safe_num_workers,\n",
    "        pin_memory=pin_memory,  # å·²æ ¹æ®GPUé¢„å¤„ç†è‡ªåŠ¨è°ƒæ•´\n",
    "        drop_last=True,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=2 if safe_num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=safe_num_workers,\n",
    "        pin_memory=pin_memory,  # å·²æ ¹æ®GPUé¢„å¤„ç†è‡ªåŠ¨è°ƒæ•´\n",
    "        drop_last=False,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=2 if safe_num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=safe_num_workers,\n",
    "        pin_memory=pin_memory,  # å·²æ ¹æ®GPUé¢„å¤„ç†è‡ªåŠ¨è°ƒæ•´\n",
    "        drop_last=False,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=2 if safe_num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ\")\n",
    "    print(f\"ğŸ“ˆ ä¸‰æ­¥ä¼˜åŒ–æ€§èƒ½æå‡:\")\n",
    "    print(f\"  - é¢„æå–å¸§: æ¶ˆé™¤é‡å¤I/O\")\n",
    "    print(f\"  - GPUé¢„å¤„ç†: åŠ é€Ÿç‰¹å¾æå–\")\n",
    "    print(f\"  - æ€»ä½“è®­ç»ƒé€Ÿåº¦æå‡: 3-4å€\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "print(\"âœ… æ•°æ®åŠ è½½å™¨å‡½æ•°å®šä¹‰å®Œæˆï¼ˆä¸‰æ­¥ä¼˜åŒ–ä¸“ç”¨ï¼‰\")\n",
    "\n",
    "# åˆ›å»ºæ•°æ®åŠ è½½å™¨å®ä¾‹\n",
    "print(\"\\nğŸš€ åˆ›å»ºæ•°æ®åŠ è½½å™¨å®ä¾‹...\")\n",
    "train_loader, val_loader, test_loader = create_data_loaders(\n",
    "    batch_size=batch_size,  # ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„batch_size\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41811f63",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-29T11:31:10.635813Z",
     "iopub.status.busy": "2025-07-29T11:31:10.635564Z",
     "iopub.status.idle": "2025-07-29T12:03:45.542368Z",
     "shell.execute_reply": "2025-07-29T12:03:45.541643Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "papermill": {
     "duration": 1954.943986,
     "end_time": "2025-07-29T12:03:45.543820",
     "exception": false,
     "start_time": "2025-07-29T11:31:10.599834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹è®­ç»ƒ...\n",
      "ğŸ“Š è®­ç»ƒé…ç½®: 105 ä¸ªè®­ç»ƒæ‰¹æ¬¡, 23 ä¸ªéªŒè¯æ‰¹æ¬¡\n",
      "ğŸ¯ æ¨¡å‹å‚æ•°æ•°é‡: 41,983,874\n",
      "ğŸ’¾ è®¾å¤‡: cuda\n",
      "ğŸ“¦ æ‰¹æ¬¡å¤§å°: 4\n",
      "ğŸ® GPUæ•°é‡: 2\n",
      "ğŸ® GPUå‹å·: Tesla T4\n",
      "ğŸš€ å¤šGPUå¹¶è¡Œè®­ç»ƒæ¨¡å¼\n",
      "ğŸ“¦ æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: 8\n",
      "\n",
      "ğŸ”„ å¼€å§‹è®­ç»ƒå¾ªç¯...\n",
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.00e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:05<08:55,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:06<04:44,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:07<03:20,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:08<02:42,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:09<02:23,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:10<02:08,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:11<02:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:12<01:51,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:13<01:47,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:14<01:43,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:15<01:38,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:16<01:36,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:17<01:35,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:18<01:35,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:19<01:35,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:20<01:31,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:21<01:31,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:22<01:29,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:23<01:28,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:24<01:27,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:25<01:25,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:26<01:25,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:27<01:25,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:28<01:21,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:29<01:20,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:30<01:20,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:31<01:17,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:32<01:14,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:33<01:12,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:34<01:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:35<01:11,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:36<01:11,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:37<01:11,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:38<01:10,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:39<01:07,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:40<01:08,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:41<01:07,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:42<01:06,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:43<01:03,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:44<01:03,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:45<01:03,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:46<01:01,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:47<01:01,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:48<01:01,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:49<00:59,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:50<00:56,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:51<00:54,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:52<00:53,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:53<00:50,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:54<00:50,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:54<00:48,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:55<00:47,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:56<00:47,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:57<00:46,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:58<00:44,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:59<00:44,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [01:00<00:45,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [01:01<00:42,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [01:02<00:40,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [01:02<00:39,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [01:03<00:40,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [01:04<00:38,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [01:05<00:36,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [01:06<00:35,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [01:07<00:34,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [01:08<00:34,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [01:09<00:33,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [01:10<00:32,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [01:10<00:31,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [01:11<00:30,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [01:12<00:30,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [01:13<00:30,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [01:14<00:28,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [01:15<00:27,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [01:16<00:27,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:17<00:26,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:18<00:25,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:18<00:23,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:19<00:22,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:20<00:21,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:21<00:21,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:22<00:20,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:23<00:19,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:24<00:18,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:25<00:17,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:25<00:16,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:26<00:15,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:27<00:14,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:28<00:13,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:29<00:12,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:30<00:12,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:31<00:11,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:32<00:10,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:32<00:09,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:33<00:08,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:34<00:07,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:35<00:06,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:36<00:06,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:37<00:05,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:38<00:04,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:38<00:03,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:39<00:02,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:40<00:01,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:41<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.25e-04, ç”¨æ—¶: 143.9s\n",
      "ğŸ¯ æ–°çš„æœ€ä½³æ¨¡å‹! Acc: 66.67%, AUC: 0.5000\n",
      "ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.25e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:30,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:27,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:24,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:24,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:04<01:22,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:20,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:22,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:21,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:20,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:08<01:18,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:09<01:19,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:10<01:22,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:11<01:24,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:19,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:12<01:17,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:13<01:16,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:14<01:15,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:15<01:14,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:16<01:11,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:16<01:09,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:17<01:09,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:18<01:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:19<01:08,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:20<01:08,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:21<01:07,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:22<01:06,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:22<01:06,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:23<01:09,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:24<01:07,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:25<01:05,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:26<01:05,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:27<01:02,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:28<01:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:28<01:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:29<01:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:30<00:59,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:31<00:58,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:32<00:56,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:33<00:55,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:34<00:54,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:34<00:53,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:35<00:51,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:36<00:52,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:37<00:50,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:38<00:56,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:39<00:54,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:40<00:53,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:41<00:51,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:42<00:49,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:42<00:49,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:43<00:46,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:44<00:45,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:45<00:44,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:46<00:42,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:47<00:42,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:47<00:41,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:48<00:40,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:49<00:39,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:50<00:38,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:51<00:37,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:52<00:36,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:53<00:37,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:53<00:35,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:54<00:34,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:55<00:33,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:56<00:32,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:57<00:31,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:58<00:31,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:58<00:30,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:59<00:29,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [01:00<00:27,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [01:01<00:27,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [01:02<00:26,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [01:02<00:25,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [01:03<00:24,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:04<00:24,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:05<00:23,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:06<00:22,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:06<00:21,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:07<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:08<00:19,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:09<00:18,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:10<00:18,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:11<00:17,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:11<00:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:12<00:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:13<00:14,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:14<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:15<00:12,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:15<00:12,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:16<00:11,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:17<00:11,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:18<00:10,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:19<00:09,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:20<00:08,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:20<00:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:21<00:06,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:22<00:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:23<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:24<00:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:24<00:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:25<00:02,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:26<00:01,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:27<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.75e-04, ç”¨æ—¶: 125.0s\n",
      "\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.75e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:28,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:24,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:23,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:04<01:23,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:05<01:23,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:23,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:20,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:19,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:08<01:19,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:09<01:19,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:10<01:16,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:15,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:12<01:13,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:13<01:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:14<01:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:11,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:10,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:16<01:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:17<01:09,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:18<01:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:06,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:19<01:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:20<01:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:21<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:22<01:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:03,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:23<01:01,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:24<01:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:25<01:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:26<01:02,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:27<00:59,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:27<00:58,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:28<00:56,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:29<00:55,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:30<00:55,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:31<00:55,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:31<00:53,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:32<00:52,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:33<00:52,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:34<00:51,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:35<00:49,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:36<00:50,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:36<00:48,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:37<00:47,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:38<00:46,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:39<00:45,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:40<00:44,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:40<00:43,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:41<00:42,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:42<00:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:43<00:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:43<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:44<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:45<00:39,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:46<00:38,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:47<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:47<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:48<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:49<00:35,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:50<00:34,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:51<00:34,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:52<00:33,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:52<00:33,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:53<00:31,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:54<00:30,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:55<00:29,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:56<00:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:56<00:28,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:57<00:28,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:58<00:27,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:59<00:26,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [01:00<00:25,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [01:01<00:24,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:01<00:24,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:02<00:22,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:03<00:21,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:04<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:05<00:20,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:05<00:19,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:06<00:19,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:07<00:18,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:08<00:17,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:09<00:16,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:10<00:15,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:10<00:14,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:11<00:13,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:12<00:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:13<00:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:14<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:14<00:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:15<00:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:16<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:17<00:08,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:18<00:07,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:18<00:06,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:19<00:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:20<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:21<00:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:22<00:03,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:22<00:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:23<00:01,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:24<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.00e-04, ç”¨æ—¶: 122.0s\n",
      "\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.00e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:18,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:17,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:07<01:16,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:13,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:11<01:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:12<01:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:19<01:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:19<01:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:20<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:02,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:23<01:01,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:23<01:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<00:59,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:58,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:27<00:57,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:28<00:56,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:55,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:56,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:56,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:31<00:54,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:32<00:52,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:51,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:50,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:49,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:35<00:49,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:36<00:48,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:47,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:46,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:38<00:45,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:39<00:44,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:40<00:43,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:42,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:42<00:41,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:43<00:40,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:44<00:40,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:39,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:46<00:38,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:47<00:37,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:48<00:36,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:35,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:50<00:33,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:51<00:32,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:52<00:31,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:54<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:55<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:56<00:27,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:26,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:58<00:25,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:59<00:24,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:23,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:01<00:23,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:02<00:22,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:03<00:21,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:04<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:05<00:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:06<00:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:07<00:16,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:09<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:10<00:13,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:11<00:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:12<00:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:13<00:10,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:14<00:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:15<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:16<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:17<00:06,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:18<00:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:19<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:20<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:20<00:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:21<00:02,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:22<00:01,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:23<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.07e-04, ç”¨æ—¶: 120.5s\n",
      "\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.07e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:24,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:04<01:22,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:22,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:20,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:21,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:19,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:08<01:17,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:14,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:13,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:12<01:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:12<01:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:09,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:16<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:16<01:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:06,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:19<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:20<01:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:20<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:24<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:57,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:27<00:56,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:27<00:55,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:31<00:53,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:31<00:52,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:50,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:49,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:35<00:48,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:36<00:48,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:48,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:47,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:38<00:46,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:39<00:44,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:40<00:43,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:42,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:42,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:42<00:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:43<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:44<00:40,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:39,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:46<00:37,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:47<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:34,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:50<00:33,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:51<00:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:51<00:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:53<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:54<00:29,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:55<00:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:55<00:27,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:58<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:59<00:24,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:01<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:02<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:03<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:03<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:19,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:05<00:18,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:06<00:17,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:07<00:17,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:08<00:16,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:15,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:09<00:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:10<00:14,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:11<00:13,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:12<00:12,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:13<00:10,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:14<00:09,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:15<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:16<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:17<00:06,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:18<00:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:19<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:20<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:20<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:21<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:22<00:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:23<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.25e-04, ç”¨æ—¶: 120.7s\n",
      "\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.25e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:03<01:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:15,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:14,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:15,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:15,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:12<01:13,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:12<01:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:16<01:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:16<01:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:19<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:20<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:23<00:58,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<00:57,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:27<00:56,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:30<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:35<00:47,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:46,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:38<00:45,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:42<00:41,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:42<00:41,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:43<00:40,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:39,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:38,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:46<00:37,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:46<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:50<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:50<00:32,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:51<00:31,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:53<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:54<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:55<00:27,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:26,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:57<00:26,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:57<00:25,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:58<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:01<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:01<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:02<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:03<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:05<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:05<00:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:07<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:09<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:09<00:13,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:10<00:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:11<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:12<00:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:13<00:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:14<00:08,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:15<00:08,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:17<00:06,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:17<00:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:18<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:19<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:20<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:21<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:22<00:01,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:22<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.50e-04, ç”¨æ—¶: 120.3s\n",
      "\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.50e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:21,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:11<01:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:12<01:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:16<01:07,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:07,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:06,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:19<01:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:19<01:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:20<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:26<00:56,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:54,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:54,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:53,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:35<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:41<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:43<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:39,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:38,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:45<00:37,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:46<00:36,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:35,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:35,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:50<00:34,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:50<00:33,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:51<00:32,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:53<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:54<00:29,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:54<00:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:55<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:57<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:58<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:01<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:01<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:02<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:03<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:05<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:05<00:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:07<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:15,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:09<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:09<00:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:10<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:12<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:13<00:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:14<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:15<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:16<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:17<00:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:18<00:04,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:19<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:20<00:03,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:20<00:02,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:21<00:01,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:22<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.75e-04, ç”¨æ—¶: 119.8s\n",
      "\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.75e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:26,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:23,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:20,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:04<01:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:12<01:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:19<01:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:19<01:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:20<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:23<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:23<01:01,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<01:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:59,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:58,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:27<00:57,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:27<00:55,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:54,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:53,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:53,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:31<00:52,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:31<00:51,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:35<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:35<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:42,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:42<00:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:42<00:40,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:43<00:39,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:46<00:37,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:46<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:50<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:50<00:32,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:51<00:31,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:53<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:54<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:54<00:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:55<00:28,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:27,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:57<00:26,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:58<00:25,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:58<00:24,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:01<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:02<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:02<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:03<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:05<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:06<00:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:07<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:09<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:09<00:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:10<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:13<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:13<00:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:14<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:15<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:17<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:17<00:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:18<00:04,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:19<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:20<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:21<00:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:21<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:22<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.93e-04, ç”¨æ—¶: 120.0s\n",
      "\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.93e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:25,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:24,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:22,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:20,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:04<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:11<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:12<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:04,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:18<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:20<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:22<00:59,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:23<00:58,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<00:57,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:56,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:26<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:53,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:30<00:53,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:31<00:52,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:50,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:49,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:34<00:48,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:35<00:47,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:46,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:37<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:41<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:43<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:37,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:45<00:37,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:46<00:36,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:47<00:35,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:34,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:50<00:32,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:51<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:52<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:54<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:55<00:27,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:57<00:25,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:58<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:01<00:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:02<00:21,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:03<00:20,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:19,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:04<00:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:05<00:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:06<00:16,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:07<00:16,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:08<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:09<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:10<00:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:12<00:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:13<00:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:14<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:15<00:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:16<00:06,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:17<00:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:18<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:19<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:19<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:20<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:21<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:22<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.00e-04, ç”¨æ—¶: 119.8s\n",
      "\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.00e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:25,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:21,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:18,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:19,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:18,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:08<01:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:14,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:13,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:21,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:12<01:17,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:13<01:14,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:12,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:10,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:16<01:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:17<01:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:19<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:20<01:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:21<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:23<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:24<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:56,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:27<00:56,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:28<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:31<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:32<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:48,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:35<00:47,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:35<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:46,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:38<00:46,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:39<00:45,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:40<00:44,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:43,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:42,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:42<00:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:43<00:40,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:43<00:39,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:46<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:47<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:50<00:33,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:51<00:32,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:51<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:54<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:55<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:55<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:58<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:59<00:24,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:01<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:02<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:02<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:03<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:05<00:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:06<00:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:07<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:09<00:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:10<00:13,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:11<00:13,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:11<00:12,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:13<00:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:14<00:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:14<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:15<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:17<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:18<00:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:18<00:04,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:19<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:20<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:21<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:22<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:22<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.02e-04, ç”¨æ—¶: 120.2s\n",
      "\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.02e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:04<01:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:11<01:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:12<01:12,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:11,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:10,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:15<01:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:19<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:20<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:23<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:56,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:35<00:47,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:43<00:40,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:39,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:39,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:46<00:38,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:46<00:37,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:47<00:36,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:34,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:50<00:33,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:50<00:32,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:51<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:54<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:55<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:57<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:58<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:01<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:01<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:02<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:03<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:05<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:05<00:17,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:07<00:15,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:08<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:09<00:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:10<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:12<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:13<00:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:14<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:15<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:17<00:06,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:17<00:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:18<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:19<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:20<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:20<00:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:21<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:22<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.07e-04, ç”¨æ—¶: 119.8s\n",
      "\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.07e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:25,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:03<01:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:15,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:07<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:12,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:11<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:12<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:14<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:04,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:18<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:19<01:05,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:20<01:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:01,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:22<01:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:23<00:59,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<00:58,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:26<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:30<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:34<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:35<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:37<00:45,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:38<00:44,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:41<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:43<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:37,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:45<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:46<00:36,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:50<00:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:51<00:32,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:31,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:53<00:30,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:53<00:30,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:54<00:29,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:55<00:28,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:27,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:57<00:26,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:57<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:58<00:24,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:01<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:01<00:21,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:02<00:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:03<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:05<00:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:05<00:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:07<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:09<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:09<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:10<00:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:12<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:13<00:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:14<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:15<00:08,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:17<00:06,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:18<00:05,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:18<00:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:19<00:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:20<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:21<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:21<00:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:22<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.15e-04, ç”¨æ—¶: 120.3s\n",
      "\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.15e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:24,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:20,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:11<01:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:12<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:16<01:06,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:04,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:18<01:03,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:19<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:20<01:01,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:22<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:23<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:58,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:26<00:58,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:27<00:56,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:55,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:54,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:53,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:35<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:37<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:41<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:43<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:45<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:46<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:47<00:35,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:50<00:32,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:51<00:31,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:53<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:54<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:55<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:57<00:25,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:58<00:25,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:23,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:01<00:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:01<00:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:02<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:03<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:19,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:05<00:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:05<00:17,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:06<00:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:07<00:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:09<00:14,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:09<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:10<00:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:11<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:13<00:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:13<00:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:14<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:15<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:17<00:06,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:17<00:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:18<00:04,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:19<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:20<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:20<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:21<00:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:22<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.25e-04, ç”¨æ—¶: 119.8s\n",
      "\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.25e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:25,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:26,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:26,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:22,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:04<01:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:11<01:10,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:12<01:09,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:08,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:15<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:04,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:19<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:20<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:22<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:23<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<00:57,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:56,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:26<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:27<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:54,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:30<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:51,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:50,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:34<00:49,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:35<00:48,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:47,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:46,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:38<00:45,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:38<00:44,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:39<00:43,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:43<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:37,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:46<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:46<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:34,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:50<00:32,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:51<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:53<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:54<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:55<00:27,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:57<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:58<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:01<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:01<00:21,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:02<00:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:03<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:05<00:18,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:05<00:17,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:06<00:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:07<00:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:09<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:09<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:10<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:12<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:13<00:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:14<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:15<00:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:16<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:17<00:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:18<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:19<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:20<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:20<00:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:21<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:22<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.37e-04, ç”¨æ—¶: 119.8s\n",
      "\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.37e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:26,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:08<01:17,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:16,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:15,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:13,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:12<01:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:12<01:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:20<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:27<00:56,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:27<00:55,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:30<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:31<00:51,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:50,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:35<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:38<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:39<00:44,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:43,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:43,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:42<00:47,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:43<00:44,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:44<00:42,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:40,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:39,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:46<00:38,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:47<00:36,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:48<00:35,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:50<00:33,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:51<00:32,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:51<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:54<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:55<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:55<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:58<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:59<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:01<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:02<00:21,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:03<00:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:03<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:05<00:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:06<00:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:07<00:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:09<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:10<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:10<00:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:11<00:12,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:13<00:10,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:14<00:09,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:15<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:15<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:17<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:18<00:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:19<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:19<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:20<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:21<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:22<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:22<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.50e-04, ç”¨æ—¶: 120.4s\n",
      "\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” è®­ç»ƒå¼€å§‹è°ƒè¯•ä¿¡æ¯:\n",
      "   - æ•°æ®åŠ è½½å™¨é•¿åº¦: 105\n",
      "   - å½“å‰å­¦ä¹ ç‡: 1.50e-04\n",
      "   - è®¾å¤‡: cuda\n",
      "   - æ··åˆç²¾åº¦: å¯ç”¨\n",
      "ğŸ“Š æ‰¹æ¬¡ 0: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   1%|          | 1/105 [00:00<01:24,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 0 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 0, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   2%|â–         | 2/105 [00:01<01:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 1 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 1, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   3%|â–         | 3/105 [00:02<01:22,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 2 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 2, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   4%|â–         | 4/105 [00:03<01:21,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 3 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 3, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   5%|â–         | 5/105 [00:04<01:20,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 4 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 4, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   6%|â–Œ         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 5 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 5, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   7%|â–‹         | 7/105 [00:05<01:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 6 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 6, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   8%|â–Š         | 8/105 [00:06<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 7 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 7, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:   9%|â–Š         | 9/105 [00:07<01:15,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 8 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 8, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–‰         | 10/105 [00:07<01:15,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 9 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 9, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  10%|â–ˆ         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 10 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 10, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  11%|â–ˆâ–        | 12/105 [00:09<01:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 11 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 11, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  12%|â–ˆâ–        | 13/105 [00:10<01:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 12 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 12, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  13%|â–ˆâ–        | 14/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 13 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 13, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  14%|â–ˆâ–        | 15/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 14 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 14, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  15%|â–ˆâ–Œ        | 16/105 [00:12<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 15 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 15, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  16%|â–ˆâ–Œ        | 17/105 [00:13<01:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 16 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 16, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  17%|â–ˆâ–‹        | 18/105 [00:14<01:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 17 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 17, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  18%|â–ˆâ–Š        | 19/105 [00:15<01:10,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 18 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 18, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  19%|â–ˆâ–‰        | 20/105 [00:16<01:09,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 19 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 19, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 20: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  20%|â–ˆâ–ˆ        | 21/105 [00:16<01:07,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 20 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 20, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  21%|â–ˆâ–ˆ        | 22/105 [00:17<01:06,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 21 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 21, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  22%|â–ˆâ–ˆâ–       | 23/105 [00:18<01:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 22 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 22, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  23%|â–ˆâ–ˆâ–       | 24/105 [00:19<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 23 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 23, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  24%|â–ˆâ–ˆâ–       | 25/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 24 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 24, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  25%|â–ˆâ–ˆâ–       | 26/105 [00:20<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 25 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 25, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  26%|â–ˆâ–ˆâ–Œ       | 27/105 [00:21<01:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 26 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 26, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  27%|â–ˆâ–ˆâ–‹       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 27 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 27, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  28%|â–ˆâ–ˆâ–Š       | 29/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 28 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 28, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  29%|â–ˆâ–ˆâ–Š       | 30/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 29 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 29, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–‰       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 30 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 30, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  30%|â–ˆâ–ˆâ–ˆ       | 32/105 [00:25<00:58,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 31 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 31, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  31%|â–ˆâ–ˆâ–ˆâ–      | 33/105 [00:26<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 32 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 32, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  32%|â–ˆâ–ˆâ–ˆâ–      | 34/105 [00:27<00:56,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 33 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 33, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  33%|â–ˆâ–ˆâ–ˆâ–      | 35/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 34 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 34, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  34%|â–ˆâ–ˆâ–ˆâ–      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 35 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 35, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 36 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 36, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 37 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 37, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 39/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 38 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 38, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 39 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 39, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 40: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 40 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 40, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/105 [00:33<00:50,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 41 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 41, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 43/105 [00:34<00:49,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 42 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 42, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/105 [00:34<00:48,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 43 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 43, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/105 [00:35<00:47,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 44 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 44, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/105 [00:36<00:46,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 45 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 45, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/105 [00:37<00:45,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 46 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 46, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 48/105 [00:38<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 47 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 47, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 48 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 48, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 49 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 49, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 50 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 50, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 51 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 51, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 53/105 [00:42<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 52 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 52, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 53 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 53, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/105 [00:43<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 54 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 54, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/105 [00:44<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 55 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 55, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/105 [00:45<00:37,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 56 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 56, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 58/105 [00:46<00:37,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 57 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 57, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 59/105 [00:46<00:37,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 58 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 58, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 60/105 [00:47<00:36,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 59 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 59, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 60: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 61/105 [00:48<00:35,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 60 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 60, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 62/105 [00:49<00:34,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 61 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 61, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/105 [00:50<00:33,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 62 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 62, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 64/105 [00:50<00:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 63 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 63, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/105 [00:51<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 64 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 64, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/105 [00:52<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 65 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 65, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 67/105 [00:53<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 66 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 66, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/105 [00:54<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 67 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 67, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 69/105 [00:54<00:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 68 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 68, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 70/105 [00:55<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 69 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 69, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 71/105 [00:56<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 70 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 70, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 71 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 71, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 73/105 [00:58<00:25,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 72 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 72, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74/105 [00:58<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 73 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 73, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 74 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 74, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 75 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 75, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/105 [01:01<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 76 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 76, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 78/105 [01:01<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 77 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 77, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 79/105 [01:02<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 78 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 78, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 80/105 [01:03<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 79 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 79, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 80: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 81/105 [01:04<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 80 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 80, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 82/105 [01:05<00:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 81 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 81, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83/105 [01:05<00:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 82 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 82, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 83 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 83, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 85/105 [01:07<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 84 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 84, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 85 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 85, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/105 [01:09<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 86 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 86, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 88/105 [01:09<00:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 87 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 87, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 89/105 [01:10<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 88 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 88, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 89 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 89, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 91/105 [01:12<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 90 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 90, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 92/105 [01:13<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 91 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 91, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 93/105 [01:13<00:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 92 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 92, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 94/105 [01:14<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 93 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 93, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 95/105 [01:15<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 94 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 94, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/105 [01:16<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 95 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 95, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/105 [01:17<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 96 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 96, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 98/105 [01:17<00:05,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 97 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 97, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 99/105 [01:18<00:04,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 98 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 98, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 100/105 [01:19<00:04,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 99 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 99, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "ğŸ“Š æ‰¹æ¬¡ 100: GPUå†…å­˜ 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 101/105 [01:20<00:03,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 100 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 100, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 102/105 [01:21<00:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 101 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 101, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 103/105 [01:21<00:01,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 102 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 102, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒä¸­:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 104/105 [01:22<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 103 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 103, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/Infï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤è¾“å‡º\n",
      "âš ï¸ è®­ç»ƒæ‰¹æ¬¡ 104 å‡ºé”™: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "è¯¦ç»†é”™è¯¯ä¿¡æ¯: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "ğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰æ‰¹æ¬¡: 104, æ€»æ ·æœ¬æ•°: 0, æ€»æŸå¤±: 0.0\n",
      "âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒ: Loss=inf, Acc=0.00%\n",
      "éªŒè¯: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "å­¦ä¹ ç‡: 1.63e-04, ç”¨æ—¶: 119.9s\n",
      "\n",
      "â¹ï¸ æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ 16 è½®åœæ­¢è®­ç»ƒ\n",
      "\n",
      "âœ… è®­ç»ƒå®Œæˆ!\n",
      "ğŸ† æœ€ç»ˆæœ€ä½³æ€§èƒ½: Loss=2.4454, Acc=66.67%, AUC=0.5000\n",
      "ğŸ’¾ å³°å€¼GPUå†…å­˜ä½¿ç”¨: 2.6GB\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š è®­ç»ƒå†å²å›¾è¡¨å·²ä¿å­˜åˆ° ./models/training_history.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: è®­ç»ƒå¾ªç¯\n",
    "\n",
    "# ç¡®ä¿æ¨¡å‹ä¿å­˜ç›®å½•å­˜åœ¨\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "print(\"ğŸš€ å¼€å§‹è®­ç»ƒ...\")\n",
    "print(f\"ğŸ“Š è®­ç»ƒé…ç½®: {len(train_loader)} ä¸ªè®­ç»ƒæ‰¹æ¬¡, {len(val_loader)} ä¸ªéªŒè¯æ‰¹æ¬¡\")\n",
    "print(f\"ğŸ¯ æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"ğŸ’¾ è®¾å¤‡: {device}\")\n",
    "print(f\"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {batch_size}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"ğŸ® GPUæ•°é‡: {gpu_count}\")\n",
    "    print(f\"ğŸ® GPUå‹å·: {torch.cuda.get_device_name(0)}\")\n",
    "    if gpu_count > 1:\n",
    "        print(f\"ğŸš€ å¤šGPUå¹¶è¡Œè®­ç»ƒæ¨¡å¼\")\n",
    "        print(f\"ğŸ“¦ æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {batch_size * gpu_count}\")\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# è®­ç»ƒå†å²è®°å½•\n",
    "train_history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "    'val_auc': [],\n",
    "    'val_precision': [],\n",
    "    'val_recall': [],\n",
    "    'val_f1': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0.0\n",
    "best_val_auc = 0.0\n",
    "\n",
    "# è®­ç»ƒå¾ªç¯\n",
    "print(\"\\nğŸ”„ å¼€å§‹è®­ç»ƒå¾ªç¯...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # è®­ç»ƒé˜¶æ®µ\n",
    "    train_results = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, \n",
    "        scheduler=scheduler, use_amp=True, gradient_clip=1.0\n",
    "    )\n",
    "    \n",
    "    # éªŒè¯é˜¶æ®µ\n",
    "    val_results = validate_epoch(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # æå–ç»“æœ\n",
    "    train_loss = train_results['loss']\n",
    "    train_acc = train_results['accuracy'] * 100\n",
    "    \n",
    "    val_loss = val_results['loss']\n",
    "    val_acc = val_results['accuracy'] * 100\n",
    "    val_auc = val_results['auc']\n",
    "    val_precision = val_results['precision']\n",
    "    val_recall = val_results['recall']\n",
    "    val_f1 = val_results['f1']\n",
    "    \n",
    "    # è®°å½•å†å²\n",
    "    train_history['train_loss'].append(train_loss)\n",
    "    train_history['train_acc'].append(train_acc)\n",
    "    train_history['val_loss'].append(val_loss)\n",
    "    train_history['val_acc'].append(val_acc)\n",
    "    train_history['val_auc'].append(val_auc)\n",
    "    train_history['val_precision'].append(val_precision)\n",
    "    train_history['val_recall'].append(val_recall)\n",
    "    train_history['val_f1'].append(val_f1)\n",
    "    \n",
    "    # å­¦ä¹ ç‡è°ƒåº¦\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # è®¡ç®—epochæ—¶é—´\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    # æ‰“å°ç»“æœ\n",
    "    print(f\"è®­ç»ƒ: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
    "    print(f\"éªŒè¯: Loss={val_loss:.4f}, Acc={val_acc:.2f}%, AUC={val_auc:.4f}, F1={val_f1:.4f}\")\n",
    "    print(f\"å­¦ä¹ ç‡: {current_lr:.2e}, ç”¨æ—¶: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        best_val_auc = val_auc\n",
    "        \n",
    "        print(f\"ğŸ¯ æ–°çš„æœ€ä½³æ¨¡å‹! Acc: {best_val_acc:.2f}%, AUC: {best_val_auc:.4f}\")\n",
    "        \n",
    "        # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'best_val_auc': best_val_auc,\n",
    "            'train_history': train_history\n",
    "        }, './models/best_model.pth')\n",
    "        print(\"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜\")\n",
    "    \n",
    "    # æ—©åœæ£€æŸ¥\n",
    "    if early_stopping(val_loss, model):\n",
    "        print(f\"\\nâ¹ï¸ æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ\")\n",
    "        break\n",
    "    \n",
    "    # æ¸…ç†GPUç¼“å­˜ - å¤šGPUå†…å­˜ç®¡ç†\n",
    "    if torch.cuda.is_available():\n",
    "        current_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        \n",
    "        # å¤šGPUç¯å¢ƒä¸‹çš„å†…å­˜é˜ˆå€¼è°ƒæ•´\n",
    "        memory_threshold = 20 if gpu_count > 1 else 10\n",
    "        \n",
    "        if current_memory > memory_threshold:\n",
    "            print(f\"ğŸ§¹ GPUå†…å­˜æ¸…ç†: {current_memory:.1f}GB > {memory_threshold}GB\")\n",
    "            torch.cuda.empty_cache()\n",
    "            if gpu_count > 1:\n",
    "                # å¤šGPUç¯å¢ƒä¸‹æ¸…ç†æ‰€æœ‰GPU\n",
    "                for i in range(gpu_count):\n",
    "                    with torch.cuda.device(i):\n",
    "                        torch.cuda.empty_cache()\n",
    "        \n",
    "        # æ£€æŸ¥è®­ç»ƒæ—¶é—´\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        max_epoch_time = 2 * 3600 if gpu_count > 1 else 1 * 3600  # å¤šGPUå…è®¸æ›´é•¿æ—¶é—´\n",
    "        \n",
    "        if epoch_time > max_epoch_time:\n",
    "            print(f\"â° å•è½®è®­ç»ƒæ—¶é—´è¿‡é•¿ ({epoch_time/3600:.1f}å°æ—¶)ï¼Œåœæ­¢è®­ç»ƒ\")\n",
    "            break\n",
    "\n",
    "print(\"\\nâœ… è®­ç»ƒå®Œæˆ!\")\n",
    "print(f\"ğŸ† æœ€ç»ˆæœ€ä½³æ€§èƒ½: Loss={best_val_loss:.4f}, Acc={best_val_acc:.2f}%, AUC={best_val_auc:.4f}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸ’¾ å³°å€¼GPUå†…å­˜ä½¿ç”¨: {torch.cuda.max_memory_allocated() / 1024**3:.1f}GB\")\n",
    "\n",
    "# ç»˜åˆ¶è®­ç»ƒå†å²\n",
    "def plot_training_history():\n",
    "    \"\"\"ç»˜åˆ¶è®­ç»ƒå†å²å›¾è¡¨\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('è®­ç»ƒå†å²', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(train_history['train_loss'], label='è®­ç»ƒLoss', color='blue')\n",
    "    axes[0, 0].plot(train_history['val_loss'], label='éªŒè¯Loss', color='red')\n",
    "    axes[0, 0].set_title('Losså˜åŒ–')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(train_history['train_acc'], label='è®­ç»ƒAcc', color='blue')\n",
    "    axes[0, 1].plot(train_history['val_acc'], label='éªŒè¯Acc', color='red')\n",
    "    axes[0, 1].set_title('å‡†ç¡®ç‡å˜åŒ–')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # AUC\n",
    "    axes[1, 0].plot(train_history['val_auc'], label='éªŒè¯AUC', color='red')\n",
    "    axes[1, 0].set_title('AUCå˜åŒ–')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('AUC')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # F1 Score\n",
    "    axes[1, 1].plot(train_history['val_f1'], label='éªŒè¯F1', color='red')\n",
    "    axes[1, 1].set_title('F1åˆ†æ•°å˜åŒ–')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('F1 Score')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./models/training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# ç»˜åˆ¶è®­ç»ƒå†å²\n",
    "plot_training_history()\n",
    "\n",
    "print(\"ğŸ“Š è®­ç»ƒå†å²å›¾è¡¨å·²ä¿å­˜åˆ° ./models/training_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "936f18fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T12:03:46.045769Z",
     "iopub.status.busy": "2025-07-29T12:03:46.045445Z",
     "iopub.status.idle": "2025-07-29T12:04:29.607022Z",
     "shell.execute_reply": "2025-07-29T12:04:29.606142Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 43.812213,
     "end_time": "2025-07-29T12:04:29.608420",
     "exception": false,
     "start_time": "2025-07-29T12:03:45.796207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š å¼€å§‹æ¨¡å‹è¯„ä¼°...\n",
      "============================================================\n",
      "ğŸ”„ åŠ è½½æœ€ä½³æ¨¡å‹...\n",
      "âœ… æˆåŠŸåŠ è½½ç¬¬ 1 è½®çš„æœ€ä½³æ¨¡å‹\n",
      "æœ€ä½³éªŒè¯å‡†ç¡®ç‡: 66.67%\n",
      "æœ€ä½³éªŒè¯AUC: 0.5000\n",
      "\n",
      "ğŸ” åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹...\n",
      "ğŸš€ å¼€å§‹æ¨¡å‹è¯„ä¼°...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "è¯„ä¼°è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:40<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è¯„ä¼°å®Œæˆ\n",
      "å¹³å‡æŸå¤±: 2.5270\n",
      "å¹³å‡æ¨ç†æ—¶é—´: 1426.83 ms/batch\n",
      "\n",
      "ğŸ“ˆ è®¡ç®—è¯„ä¼°æŒ‡æ ‡...\n",
      "\n",
      "ğŸ“Š è¯¦ç»†è¯„ä¼°ç»“æœ:\n",
      "==================================================\n",
      "æµ‹è¯•æŸå¤±: 2.5270\n",
      "å‡†ç¡®ç‡: 0.6667 (66.67%)\n",
      "å¹³è¡¡å‡†ç¡®ç‡: 0.5000 (50.00%)\n",
      "ç²¾ç¡®ç‡: 0.6667\n",
      "å¬å›ç‡: 1.0000\n",
      "ç‰¹å¼‚æ€§: 0.0000\n",
      "F1åˆ†æ•°: 0.8000\n",
      "AUC-ROC: 0.5000\n",
      "AUC-PR: 0.8333\n",
      "è´Ÿé¢„æµ‹å€¼: 0.0000\n",
      "\n",
      "ğŸ” æ··æ·†çŸ©é˜µåˆ†æ:\n",
      "çœŸè´Ÿä¾‹ (TN): 0\n",
      "å‡æ­£ä¾‹ (FP): 30\n",
      "å‡è´Ÿä¾‹ (FN): 0\n",
      "çœŸæ­£ä¾‹ (TP): 60\n",
      "\n",
      "âš¡ æ€§èƒ½åˆ†æ:\n",
      "å¹³å‡æ¨ç†æ—¶é—´: 1426.83 ms/batch\n",
      "æ€»æ¨ç†æ—¶é—´: 32.82 ç§’\n",
      "æ¯ä¸ªæ ·æœ¬æ¨ç†æ—¶é—´: 356.71 ms\n",
      "\n",
      "ğŸ“‹ ç±»åˆ«ç‰¹å®šåˆ†æ:\n",
      "æ€»æ ·æœ¬æ•°: 90\n",
      "çœŸå®è§†é¢‘æ ·æœ¬: 30 (33.3%)\n",
      "ä¼ªé€ è§†é¢‘æ ·æœ¬: 60 (66.7%)\n",
      "çœŸå®è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: 0.0000 (0.00%)\n",
      "ä¼ªé€ è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: 1.0000 (100.00%)\n",
      "\n",
      "ğŸ“Š ç”Ÿæˆè¯„ä¼°å›¾è¡¨...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: ./results/evaluation/confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC/PRæ›²çº¿å·²ä¿å­˜åˆ°: ./results/evaluation/roc_pr_curves.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è¯„ä¼°å›¾è¡¨ç”Ÿæˆå®Œæˆ\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š ç±»åˆ«ä¸å¹³è¡¡åˆ†ææŠ¥å‘Š\n",
      "============================================================\n",
      "\n",
      "ğŸ“ˆ æ•°æ®åˆ†å¸ƒ:\n",
      "  çœŸå®è§†é¢‘æ ·æœ¬: 30\n",
      "  ä¼ªé€ è§†é¢‘æ ·æœ¬: 60\n",
      "  ä¸å¹³è¡¡æ¯”ä¾‹: 2.00:1 (ä¼ªé€ :çœŸå®)\n",
      "\n",
      "ğŸ¯ ç±»åˆ«ç‰¹å®šå‡†ç¡®ç‡:\n",
      "  çœŸå®è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: 0.00%\n",
      "  ä¼ªé€ è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: 100.00%\n",
      "\n",
      "ğŸ“‹ æ··æ·†çŸ©é˜µåˆ†æ:\n",
      "  çœŸè´Ÿä¾‹ (TN): 0 - æ­£ç¡®è¯†åˆ«çš„çœŸå®è§†é¢‘\n",
      "  å‡æ­£ä¾‹ (FP): 30 - è¯¯åˆ¤ä¸ºä¼ªé€ çš„çœŸå®è§†é¢‘\n",
      "  å‡è´Ÿä¾‹ (FN): 0 - è¯¯åˆ¤ä¸ºçœŸå®çš„ä¼ªé€ è§†é¢‘\n",
      "  çœŸæ­£ä¾‹ (TP): 60 - æ­£ç¡®è¯†åˆ«çš„ä¼ªé€ è§†é¢‘\n",
      "\n",
      "âš–ï¸ æ¨¡å‹åå‘æ€§åˆ†æ:\n",
      "  é¢„æµ‹ä¸ºçœŸå®çš„æ ·æœ¬: 0 (0.0%)\n",
      "  é¢„æµ‹ä¸ºä¼ªé€ çš„æ ·æœ¬: 90 (100.0%)\n",
      "\n",
      "ğŸ” é—®é¢˜è¯Šæ–­:\n",
      "  âŒ ä¸¥é‡é—®é¢˜: æ¨¡å‹å‡ ä¹æ— æ³•è¯†åˆ«çœŸå®è§†é¢‘\n",
      "  âŒ ä¸¥é‡åå‘: æ¨¡å‹è¿‡åº¦åå‘é¢„æµ‹ä¼ªé€ è§†é¢‘\n",
      "  âŒ AUC-ROCè¿‡ä½: æ¨¡å‹åˆ¤åˆ«èƒ½åŠ›æ¥è¿‘éšæœºçŒœæµ‹\n",
      "\n",
      "ğŸ’¡ æ”¹è¿›å»ºè®®:\n",
      "  4. æ£€æŸ¥æ•°æ®è´¨é‡ï¼Œç¡®ä¿çœŸå®è§†é¢‘æ ‡ç­¾æ­£ç¡®\n",
      "  5. ä½¿ç”¨æˆæœ¬æ•æ„Ÿå­¦ä¹ æ–¹æ³•\n",
      "  6. è€ƒè™‘ä½¿ç”¨SMOTEç­‰è¿‡é‡‡æ ·æŠ€æœ¯\n",
      "  7. é‡æ–°è®¾è®¡æ¨¡å‹æ¶æ„\n",
      "  8. å¢åŠ æ¨¡å‹å¤æ‚åº¦æˆ–ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹\n",
      "  9. æ£€æŸ¥ç‰¹å¾æå–æ˜¯å¦æœ‰æ•ˆ\n",
      "============================================================\n",
      "============================================================\n",
      "ğŸ‰ æ¨¡å‹è¯„ä¼°å®Œæˆï¼\n",
      "ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° ./results/evaluation/ ç›®å½•\n",
      "\n",
      "ğŸ’¡ å¦‚æœå‘ç°ä¸¥é‡çš„ç±»åˆ«åå‘é—®é¢˜ï¼Œè¯·å‚è€ƒä¸Šè¿°æ”¹è¿›å»ºè®®è¿›è¡Œä¼˜åŒ–\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æ\n",
    "\n",
    "print(\"ğŸ“Š å¼€å§‹æ¨¡å‹è¯„ä¼°...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# åŠ è½½æœ€ä½³æ¨¡å‹\n",
    "print(\"ğŸ”„ åŠ è½½æœ€ä½³æ¨¡å‹...\")\n",
    "try:\n",
    "    # ä½¿ç”¨weights_only=Falseæ¥å…¼å®¹æ—§ç‰ˆæœ¬çš„æ¨¡å‹æ–‡ä»¶\n",
    "    checkpoint = torch.load('./models/best_model.pth', map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    best_epoch = checkpoint['epoch']\n",
    "    best_val_acc = checkpoint['best_val_acc']\n",
    "    best_val_auc = checkpoint['best_val_auc']\n",
    "    \n",
    "    print(f\"âœ… æˆåŠŸåŠ è½½ç¬¬ {best_epoch+1} è½®çš„æœ€ä½³æ¨¡å‹\")\n",
    "    print(f\"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\n",
    "    print(f\"æœ€ä½³éªŒè¯AUC: {best_val_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}\")\n",
    "    print(\"ä½¿ç”¨å½“å‰æ¨¡å‹è¿›è¡Œè¯„ä¼°\")\n",
    "\n",
    "# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹\n",
    "print(\"\\nğŸ” åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹...\")\n",
    "eval_results = evaluate_model_optimized(model, test_loader, criterion, device)\n",
    "\n",
    "# è®¡ç®—å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡\n",
    "print(\"\\nğŸ“ˆ è®¡ç®—è¯„ä¼°æŒ‡æ ‡...\")\n",
    "metrics = calculate_comprehensive_metrics(\n",
    "    eval_results['predictions'], \n",
    "    eval_results['targets'], \n",
    "    eval_results['scores']\n",
    ")\n",
    "\n",
    "# æ‰“å°è¯¦ç»†ç»“æœ\n",
    "print(\"\\nğŸ“Š è¯¦ç»†è¯„ä¼°ç»“æœ:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"æµ‹è¯•æŸå¤±: {eval_results['loss']:.4f}\")\n",
    "print(f\"å‡†ç¡®ç‡: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\n",
    "print(f\"å¹³è¡¡å‡†ç¡®ç‡: {metrics['balanced_accuracy']:.4f} ({metrics['balanced_accuracy']*100:.2f}%)\")\n",
    "print(f\"ç²¾ç¡®ç‡: {metrics['precision']:.4f}\")\n",
    "print(f\"å¬å›ç‡: {metrics['recall']:.4f}\")\n",
    "print(f\"ç‰¹å¼‚æ€§: {metrics['specificity']:.4f}\")\n",
    "print(f\"F1åˆ†æ•°: {metrics['f1']:.4f}\")\n",
    "print(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
    "print(f\"AUC-PR: {metrics['auc_pr']:.4f}\")\n",
    "print(f\"è´Ÿé¢„æµ‹å€¼: {metrics['npv']:.4f}\")\n",
    "\n",
    "# æ··æ·†çŸ©é˜µè¯¦ç»†ä¿¡æ¯\n",
    "print(\"\\nğŸ” æ··æ·†çŸ©é˜µåˆ†æ:\")\n",
    "print(f\"çœŸè´Ÿä¾‹ (TN): {metrics['tn']}\")\n",
    "print(f\"å‡æ­£ä¾‹ (FP): {metrics['fp']}\")\n",
    "print(f\"å‡è´Ÿä¾‹ (FN): {metrics['fn']}\")\n",
    "print(f\"çœŸæ­£ä¾‹ (TP): {metrics['tp']}\")\n",
    "\n",
    "# æ€§èƒ½åˆ†æ\n",
    "print(\"\\nâš¡ æ€§èƒ½åˆ†æ:\")\n",
    "print(f\"å¹³å‡æ¨ç†æ—¶é—´: {eval_results['avg_inference_time']*1000:.2f} ms/batch\")\n",
    "print(f\"æ€»æ¨ç†æ—¶é—´: {eval_results['total_inference_time']:.2f} ç§’\")\n",
    "print(f\"æ¯ä¸ªæ ·æœ¬æ¨ç†æ—¶é—´: {eval_results['avg_inference_time']*1000/batch_size:.2f} ms\")\n",
    "\n",
    "# è®¡ç®—é¢å¤–æŒ‡æ ‡\n",
    "total_samples = len(eval_results['targets'])\n",
    "real_samples = np.sum(eval_results['targets'] == 0)\n",
    "fake_samples = np.sum(eval_results['targets'] == 1)\n",
    "real_accuracy = np.sum((eval_results['predictions'] == 0) & (eval_results['targets'] == 0)) / real_samples if real_samples > 0 else 0\n",
    "fake_accuracy = np.sum((eval_results['predictions'] == 1) & (eval_results['targets'] == 1)) / fake_samples if fake_samples > 0 else 0\n",
    "\n",
    "print(\"\\nğŸ“‹ ç±»åˆ«ç‰¹å®šåˆ†æ:\")\n",
    "print(f\"æ€»æ ·æœ¬æ•°: {total_samples}\")\n",
    "print(f\"çœŸå®è§†é¢‘æ ·æœ¬: {real_samples} ({real_samples/total_samples*100:.1f}%)\")\n",
    "print(f\"ä¼ªé€ è§†é¢‘æ ·æœ¬: {fake_samples} ({fake_samples/total_samples*100:.1f}%)\")\n",
    "print(f\"çœŸå®è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: {real_accuracy:.4f} ({real_accuracy*100:.2f}%)\")\n",
    "print(f\"ä¼ªé€ è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: {fake_accuracy:.4f} ({fake_accuracy*100:.2f}%)\")\n",
    "\n",
    "# ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨\n",
    "print(\"\\nğŸ“Š ç”Ÿæˆè¯„ä¼°å›¾è¡¨...\")\n",
    "\n",
    "# ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨\n",
    "os.makedirs('./results/evaluation', exist_ok=True)\n",
    "\n",
    "# ç»˜åˆ¶å¢å¼ºæ··æ·†çŸ©é˜µ\n",
    "plot_enhanced_confusion_matrix(\n",
    "    metrics['confusion_matrix'], \n",
    "    './results/evaluation/confusion_matrix.png'\n",
    ")\n",
    "\n",
    "# ç»˜åˆ¶ROCå’ŒPRæ›²çº¿\n",
    "plot_roc_pr_curves(\n",
    "    eval_results['targets'], \n",
    "    eval_results['scores'], \n",
    "    './results/evaluation/roc_pr_curves.png'\n",
    ")\n",
    "\n",
    "# é¢„æµ‹åˆ†æ•°åˆ†å¸ƒå›¾\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# çœŸå®è§†é¢‘çš„é¢„æµ‹åˆ†æ•°åˆ†å¸ƒ\n",
    "plt.subplot(1, 2, 1)\n",
    "real_scores = eval_results['scores'][eval_results['targets'] == 0]\n",
    "fake_scores = eval_results['scores'][eval_results['targets'] == 1]\n",
    "\n",
    "plt.hist(real_scores, bins=30, alpha=0.7, label='çœŸå®è§†é¢‘', color='blue', density=True)\n",
    "plt.hist(fake_scores, bins=30, alpha=0.7, label='ä¼ªé€ è§†é¢‘', color='red', density=True)\n",
    "plt.xlabel('é¢„æµ‹åˆ†æ•°')\n",
    "plt.ylabel('å¯†åº¦')\n",
    "plt.title('é¢„æµ‹åˆ†æ•°åˆ†å¸ƒ')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# é¢„æµ‹åˆ†æ•°ç®±çº¿å›¾\n",
    "plt.subplot(1, 2, 2)\n",
    "scores_data = [real_scores, fake_scores]\n",
    "labels = ['çœŸå®è§†é¢‘', 'ä¼ªé€ è§†é¢‘']\n",
    "plt.boxplot(scores_data, labels=labels)\n",
    "plt.ylabel('é¢„æµ‹åˆ†æ•°')\n",
    "plt.title('é¢„æµ‹åˆ†æ•°ç®±çº¿å›¾')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./results/evaluation/score_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… è¯„ä¼°å›¾è¡¨ç”Ÿæˆå®Œæˆ\")\n",
    "\n",
    "# ç”Ÿæˆè¯¦ç»†çš„ç±»åˆ«ä¸å¹³è¡¡åˆ†ææŠ¥å‘Š\n",
    "generate_class_imbalance_report(metrics)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ‰ æ¨¡å‹è¯„ä¼°å®Œæˆï¼\")\n",
    "print(\"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° ./results/evaluation/ ç›®å½•\")\n",
    "print(\"\\nğŸ’¡ å¦‚æœå‘ç°ä¸¥é‡çš„ç±»åˆ«åå‘é—®é¢˜ï¼Œè¯·å‚è€ƒä¸Šè¿°æ”¹è¿›å»ºè®®è¿›è¡Œä¼˜åŒ–\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0958c562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T12:04:30.108666Z",
     "iopub.status.busy": "2025-07-29T12:04:30.108355Z",
     "iopub.status.idle": "2025-07-29T12:04:30.127972Z",
     "shell.execute_reply": "2025-07-29T12:04:30.127152Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.266197,
     "end_time": "2025-07-29T12:04:30.129209",
     "exception": false,
     "start_time": "2025-07-29T12:04:29.863012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ ä¿å­˜å®éªŒç»“æœ...\n",
      "============================================================\n",
      "âœ… å®éªŒç»“æœå·²ä¿å­˜åˆ°: ./results/experiment_results.json\n",
      "âœ… è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: ./results/training_history.csv\n",
      "âœ… æµ‹è¯•é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: ./results/test_predictions.csv\n",
      "\n",
      "ğŸ“‹ ç”Ÿæˆå®éªŒæŠ¥å‘Š...\n",
      "âœ… å®éªŒæŠ¥å‘Šå·²ä¿å­˜åˆ°: ./results/experiment_report.txt\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å®Œæˆï¼\n",
      "============================================================\n",
      "ğŸ“Š æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: 66.67%\n",
      "ğŸ“Š AUC-ROCåˆ†æ•°: 0.5000\n",
      "ğŸ“Š F1åˆ†æ•°: 0.8000\n",
      "\n",
      "ğŸ“ æ‰€æœ‰ç»“æœæ–‡ä»¶å·²ä¿å­˜åˆ° ./results/ ç›®å½•\n",
      "ğŸ“ æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ° ./models/best_model.pth\n",
      "\n",
      "âœ¨ å®éªŒæˆåŠŸå®Œæˆï¼\n",
      "============================================================\n",
      "\n",
      "ğŸ“‚ ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„:\n",
      "\n",
      "./models/\n",
      "  â””â”€â”€ best_model.pth\n",
      "./results/\n",
      "  â”œâ”€â”€ experiment_results.json\n",
      "  â”œâ”€â”€ experiment_report.txt\n",
      "  â”œâ”€â”€ training_history.csv\n",
      "  â””â”€â”€ test_predictions.csv\n",
      "\n",
      "\n",
      "ğŸš€ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†:\n",
      "\n",
      "# åŠ è½½æ¨¡å‹\n",
      "model = OptimizedDeepfakeDetector(...)\n",
      "checkpoint = torch.load('./models/best_model.pth', weights_only=False)\n",
      "model.load_state_dict(checkpoint['model_state_dict'])\n",
      "model.eval()\n",
      "\n",
      "\n",
      "âœ… è®­ç»ƒå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: ç»“æœä¿å­˜å’Œæ€»ç»“\n",
    "\n",
    "print(\"ğŸ’¾ ä¿å­˜å®éªŒç»“æœ...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# å‡†å¤‡ä¿å­˜çš„ç»“æœæ•°æ®\n",
    "results_summary = {\n",
    "    'experiment_info': {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'model_architecture': 'OptimizedDeepfakeDetector',\n",
    "        'backbone': 'resnet50',\n",
    "        'total_epochs': len(train_history['train_loss']),\n",
    "        'early_stopping': True\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'train_samples': len(train_loader.dataset) if train_loader else 0,\n",
    "        'val_samples': len(val_loader.dataset) if val_loader else 0,\n",
    "        'test_samples': len(test_loader.dataset) if test_loader else 0,\n",
    "        'batch_size': batch_size\n",
    "    },\n",
    "    'training_config': {\n",
    "        'optimizer': 'AdamW',\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-4,\n",
    "        'loss_function': 'FocalLoss',\n",
    "        'scheduler': 'OneCycleLR',\n",
    "        'early_stopping_patience': 7\n",
    "    },\n",
    "    'final_metrics': {\n",
    "        'test_loss': float(eval_results['loss']),\n",
    "        'accuracy': float(metrics['accuracy']),\n",
    "        'precision': float(metrics['precision']),\n",
    "        'recall': float(metrics['recall']),\n",
    "        'f1_score': float(metrics['f1']),\n",
    "        'auc_roc': float(metrics['auc_roc'])\n",
    "    },\n",
    "    'confusion_matrix': {\n",
    "        'tn': int(metrics['tn']),\n",
    "        'fp': int(metrics['fp']),\n",
    "        'fn': int(metrics['fn']),\n",
    "        'tp': int(metrics['tp'])\n",
    "    },\n",
    "    'training_history': {\n",
    "        'train_loss': [float(x) for x in train_history['train_loss']],\n",
    "        'train_acc': [float(x) for x in train_history['train_acc']],\n",
    "        'val_loss': [float(x) for x in train_history['val_loss']],\n",
    "        'val_acc': [float(x) for x in train_history['val_acc']],\n",
    "        'val_auc': [float(x) for x in train_history['val_auc']],\n",
    "        'val_precision': [float(x) for x in train_history.get('val_precision', [])],\n",
    "        'val_recall': [float(x) for x in train_history.get('val_recall', [])],\n",
    "        'val_f1': [float(x) for x in train_history.get('val_f1', [])]\n",
    "    },\n",
    "    'class_specific_metrics': {\n",
    "        'real_video_accuracy': float(real_accuracy),\n",
    "        'fake_video_accuracy': float(fake_accuracy),\n",
    "        'real_samples_count': int(real_samples),\n",
    "        'fake_samples_count': int(fake_samples)\n",
    "    }\n",
    "}\n",
    "\n",
    "# ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶\n",
    "results_file = './results/experiment_results.json'\n",
    "with open(results_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… å®éªŒç»“æœå·²ä¿å­˜åˆ°: {results_file}\")\n",
    "\n",
    "# ä¿å­˜è®­ç»ƒå†å²åˆ°CSV\n",
    "history_df = pd.DataFrame(train_history)\n",
    "history_df.to_csv('./results/training_history.csv', index=False)\n",
    "print(\"âœ… è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: ./results/training_history.csv\")\n",
    "\n",
    "# ä¿å­˜é¢„æµ‹ç»“æœ\n",
    "predictions_df = pd.DataFrame({\n",
    "    'true_label': eval_results['targets'],\n",
    "    'predicted_label': eval_results['predictions'],\n",
    "    'prediction_score': eval_results['scores']\n",
    "})\n",
    "predictions_df.to_csv('./results/test_predictions.csv', index=False)\n",
    "print(\"âœ… æµ‹è¯•é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: ./results/test_predictions.csv\")\n",
    "\n",
    "# ç”Ÿæˆå®éªŒæŠ¥å‘Š\n",
    "print(\"\\nğŸ“‹ ç”Ÿæˆå®éªŒæŠ¥å‘Š...\")\n",
    "report = f\"\"\"\n",
    "æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹å®éªŒæŠ¥å‘Š\n",
    "{'='*50}\n",
    "\n",
    "å®éªŒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "æ¨¡å‹æ¶æ„: OptimizedDeepfakeDetector (ResNet50 + LSTM + Attention)\n",
    "\n",
    "æ•°æ®é›†ä¿¡æ¯:\n",
    "- è®­ç»ƒæ ·æœ¬: {len(train_loader.dataset) if train_loader else 0:,}\n",
    "- éªŒè¯æ ·æœ¬: {len(val_loader.dataset) if val_loader else 0:,}\n",
    "- æµ‹è¯•æ ·æœ¬: {len(test_loader.dataset) if test_loader else 0:,}\n",
    "- æ‰¹æ¬¡å¤§å°: {batch_size}\n",
    "\n",
    "è®­ç»ƒé…ç½®:\n",
    "- ä¼˜åŒ–å™¨: AdamW (lr=1e-4, weight_decay=1e-4)\n",
    "- æŸå¤±å‡½æ•°: Focal Loss\n",
    "- å­¦ä¹ ç‡è°ƒåº¦: OneCycleLR\n",
    "- æ—©åœæœºåˆ¶: patience=7\n",
    "\n",
    "æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡:\n",
    "- å‡†ç¡®ç‡: {metrics['accuracy']*100:.2f}%\n",
    "- ç²¾ç¡®ç‡: {metrics['precision']:.4f}\n",
    "- å¬å›ç‡: {metrics['recall']:.4f}\n",
    "- F1åˆ†æ•°: {metrics['f1']:.4f}\n",
    "- AUC-ROC: {metrics['auc_roc']:.4f}\n",
    "\n",
    "æ··æ·†çŸ©é˜µ:\n",
    "- çœŸè´Ÿä¾‹ (TN): {metrics['tn']}\n",
    "- å‡æ­£ä¾‹ (FP): {metrics['fp']}\n",
    "- å‡è´Ÿä¾‹ (FN): {metrics['fn']}\n",
    "- çœŸæ­£ä¾‹ (TP): {metrics['tp']}\n",
    "\n",
    "ç±»åˆ«ç‰¹å®šæ€§èƒ½:\n",
    "- çœŸå®è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: {real_accuracy*100:.2f}%\n",
    "- ä¼ªé€ è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: {fake_accuracy*100:.2f}%\n",
    "\n",
    "è®­ç»ƒæ€»ç»“:\n",
    "- è®­ç»ƒè½®æ•°: {len(train_history['train_loss'])}\n",
    "- æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {max(train_history['val_acc']):.2f}%\n",
    "- æœ€ä½³éªŒè¯AUC: {max(train_history['val_auc']):.4f}\n",
    "\n",
    "æ–‡ä»¶è¾“å‡º:\n",
    "- æ¨¡å‹æƒé‡: ./models/best_model.pth\n",
    "- å®éªŒç»“æœ: ./results/experiment_results.json\n",
    "- è®­ç»ƒå†å²: ./results/training_history.csv\n",
    "- é¢„æµ‹ç»“æœ: ./results/test_predictions.csv\n",
    "\n",
    "{'='*50}\n",
    "å®éªŒå®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "# ä¿å­˜æŠ¥å‘Š\n",
    "with open('./results/experiment_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"âœ… å®éªŒæŠ¥å‘Šå·²ä¿å­˜åˆ°: ./results/experiment_report.txt\")\n",
    "\n",
    "# æ‰“å°æœ€ç»ˆæ€»ç»“\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å®Œæˆï¼\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ“Š æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {metrics['accuracy']*100:.2f}%\")\n",
    "print(f\"ğŸ“Š AUC-ROCåˆ†æ•°: {metrics['auc_roc']:.4f}\")\n",
    "print(f\"ğŸ“Š F1åˆ†æ•°: {metrics['f1']:.4f}\")\n",
    "print(\"\\nğŸ“ æ‰€æœ‰ç»“æœæ–‡ä»¶å·²ä¿å­˜åˆ° ./results/ ç›®å½•\")\n",
    "print(\"ğŸ“ æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ° ./models/best_model.pth\")\n",
    "print(\"\\nâœ¨ å®éªŒæˆåŠŸå®Œæˆï¼\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# æ˜¾ç¤ºæ–‡ä»¶ç»“æ„\n",
    "print(\"\\nğŸ“‚ ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„:\")\n",
    "print(\"\"\"\n",
    "./models/\n",
    "  â””â”€â”€ best_model.pth\n",
    "./results/\n",
    "  â”œâ”€â”€ experiment_results.json\n",
    "  â”œâ”€â”€ experiment_report.txt\n",
    "  â”œâ”€â”€ training_history.csv\n",
    "  â””â”€â”€ test_predictions.csv\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nğŸš€ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†:\")\n",
    "print(\"\"\"\n",
    "# åŠ è½½æ¨¡å‹\n",
    "model = OptimizedDeepfakeDetector(...)\n",
    "checkpoint = torch.load('./models/best_model.pth', weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nâœ… è®­ç»ƒå®Œæˆï¼\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6248577,
     "sourceId": 10125851,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5814.74922,
   "end_time": "2025-07-29T12:04:34.402591",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-29T10:27:39.653371",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
