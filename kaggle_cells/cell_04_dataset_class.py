# Cell 4: æ•°æ®é›†ç±»å®šä¹‰

import os
import numpy as np

class DeepfakeVideoDataset(Dataset):
    """æ·±åº¦ä¼ªé€ è§†é¢‘æ•°æ®é›†ç±» - Kaggle T4 ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, csv_file=None, data_list=None, transform=None, max_frames=16, 
                 gpu_preprocessing=True, cache_frames=False):
        if csv_file is not None:
            self.df = pd.read_csv(csv_file)
            self.data_list = None
        elif data_list is not None:
            self.data_list = data_list
            self.df = None
        else:
            raise ValueError("å¿…é¡»æä¾›csv_fileæˆ–data_list")
            
        self.transform = transform
        self.max_frames = max_frames
        self.gpu_preprocessing = gpu_preprocessing and torch.cuda.is_available()
        self.cache_frames = cache_frames
        
        # ç®€åŒ–ç¼“å­˜ç³»ç»Ÿ - ä»…CPUç¼“å­˜ï¼Œé¿å…GPUå†…å­˜å‹åŠ›
        self.frame_cache = {} if cache_frames else None
        self.cache_hits = 0
        self.cache_misses = 0
        
        # GPUé¢„å¤„ç†çš„æ ‡å‡†åŒ–å‚æ•° - ç»Ÿä¸€ä½¿ç”¨FP32
        if self.gpu_preprocessing:
            self.mean = torch.tensor([0.485, 0.456, 0.406], device='cuda', dtype=torch.float32)
            self.std = torch.tensor([0.229, 0.224, 0.225], device='cuda', dtype=torch.float32)
            
        print(f"ğŸš€ æ•°æ®é›†åˆå§‹åŒ–: GPUé¢„å¤„ç†={'å¯ç”¨' if self.gpu_preprocessing else 'ç¦ç”¨'}, "
              f"ç¼“å­˜={'å¯ç”¨' if self.cache_frames else 'ç¦ç”¨'}, æ•°æ®ç±»å‹=FP32")
        self.frame_dir = './frames'
        os.makedirs(self.frame_dir, exist_ok=True)
    
    def __len__(self):
        if self.df is not None:
            return len(self.df)
        return len(self.data_list)
    
    def __getitem__(self, idx):
        if self.data_list is not None:
            item = self.data_list[idx]
            video_path = item['video_path']
            frames = item['frames']
            label = item['label']
        else:
            row = self.df.iloc[idx]
            video_path = row['video_path']
            label = row['label']
            frames = None
        
        # ç®€åŒ–çš„æ•°æ®å¤„ç†æµç¨‹
        npy_path = os.path.join(self.frame_dir, os.path.basename(video_path) + '.npy')
        if os.path.exists(npy_path):
            loaded_frames = np.load(npy_path)
            frames = [loaded_frames[i] for i in range(loaded_frames.shape[0])]
        else:
            if frames is None:
                # æ£€æŸ¥CPUç¼“å­˜
                if self.cache_frames and video_path in self.frame_cache:
                    frames = self.frame_cache[video_path]
                    self.cache_hits += 1
                else:
                    frames = extract_frames_gpu_accelerated(video_path, self.max_frames, target_size=(224, 224))
                    self.cache_misses += 1
                    # ç¼“å­˜å¸§æ•°æ®
                    if self.cache_frames and len(frames) > 0:
                        self.frame_cache[video_path] = frames
            # ä¿å­˜é¢„å¤„ç†å¸§
            if len(frames) > 0:
                np.save(npy_path, np.stack(frames))
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å¸§
        if len(frames) == 0:
            frames = [np.zeros((224, 224, 3), dtype=np.uint8) for _ in range(self.max_frames)]
        
        while len(frames) < self.max_frames:
            frames.append(frames[-1].copy() if frames else np.zeros((224, 224, 3), dtype=np.uint8))
        
        frames = frames[:self.max_frames]
        
        # ç»Ÿä¸€çš„æ•°æ®é¢„å¤„ç† - å…¨éƒ¨ä½¿ç”¨FP32
        if self.transform:
            frames = [self.transform(frame) for frame in frames]
            video_tensor = torch.stack(frames)
        elif self.gpu_preprocessing:
            # GPUé¢„å¤„ç†ï¼šå‡å°‘CPU-GPUä¼ è¾“æ¬¡æ•°
            frames_array = np.stack(frames)  # (T, H, W, C)
            video_tensor = torch.from_numpy(frames_array).permute(0, 3, 1, 2).float()  # (T, C, H, W)
            
            # ç§»åŠ¨åˆ°GPUå¹¶è¿›è¡Œé¢„å¤„ç† - ç»Ÿä¸€ä½¿ç”¨FP32
            video_tensor = video_tensor.to('cuda', non_blocking=True, dtype=torch.float32) / 255.0
            
            # æ ‡å‡†åŒ–
            video_tensor = (video_tensor - self.mean.view(1, 3, 1, 1)) / self.std.view(1, 3, 1, 1)
        else:
            # CPUé¢„å¤„ç†
            frames = [torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0 for frame in frames]
            video_tensor = torch.stack(frames)
        
        # æ ‡ç­¾å¤„ç† - ç»Ÿä¸€ä½¿ç”¨FP32
        label_tensor = torch.tensor(label, dtype=torch.float32)
        if self.gpu_preprocessing:
            label_tensor = label_tensor.to('cuda', non_blocking=True)
        
        return video_tensor, label_tensor
    
    def get_cache_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self.cache_hits + self.cache_misses
        hit_rate = self.cache_hits / total_requests if total_requests > 0 else 0
        return {
            'cache_hits': self.cache_hits,
            'cache_misses': self.cache_misses,
            'hit_rate': hit_rate,
            'cpu_cache_size': len(self.frame_cache) if self.frame_cache else 0
        }

print("âœ… æ•°æ®é›†ç±»å®šä¹‰å®Œæˆ")