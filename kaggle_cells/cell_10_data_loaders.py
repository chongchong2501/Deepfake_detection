# Cell 10: åˆ›å»ºæ•°æ®åŠ è½½å™¨

# ä¿®å¤CUDAå¤šè¿›ç¨‹é—®é¢˜
import multiprocessing as mp
if torch.cuda.is_available():
    try:
        mp.set_start_method('spawn', force=True)
    except RuntimeError:
        pass  # å¦‚æœå·²ç»è®¾ç½®è¿‡ï¼Œå¿½ç•¥é”™è¯¯

print("ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")

# è·å–æ•°æ®å˜æ¢ - ç®€åŒ–å˜æ¢ä»¥å‡å°‘CPUè´Ÿæ‹…
train_transform = None  # ä½¿ç”¨GPUé¢„å¤„ç†æ›¿ä»£CPUå˜æ¢
val_transform = None

# åˆ›å»ºæ•°æ®é›† - å¯ç”¨GPUé¢„å¤„ç†å’Œå¸§ç¼“å­˜
print("ğŸ”§ åˆ›å»ºæ•°æ®é›†ï¼ˆå¯ç”¨GPUé¢„å¤„ç†å’Œå¸§ç¼“å­˜ï¼‰...")
train_dataset = DeepfakeVideoDataset('./data/train.csv', transform=train_transform, max_frames=16, gpu_preprocessing=True, cache_frames=True)
val_dataset = DeepfakeVideoDataset('./data/val.csv', transform=val_transform, max_frames=16, gpu_preprocessing=True, cache_frames=True)
test_dataset = DeepfakeVideoDataset('./data/test.csv', transform=val_transform, max_frames=16, gpu_preprocessing=True, cache_frames=True)
print("âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆï¼Œå·²å¯ç”¨å¸§ç¼“å­˜ä»¥æå‡æ€§èƒ½")

# ä¼˜åŒ–æ‰¹æ¬¡å¤§å°å’Œæ•°æ®åŠ è½½æ€§èƒ½
if torch.cuda.is_available():
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    gpu_count = torch.cuda.device_count()
    print(f"æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUï¼Œæ¯ä¸ªGPUå†…å­˜: {gpu_memory:.1f} GB")
    
    # æ ¹æ®GPUå†…å­˜åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
    if gpu_memory >= 15:  # T4æˆ–æ›´å¥½çš„GPU
        batch_size = 8
    elif gpu_memory >= 8:
        batch_size = 6
    else:
        batch_size = 4
else:
    batch_size = 2

print(f"ä½¿ç”¨æ‰¹æ¬¡å¤§å°: {batch_size} (æ ¹æ®GPUå†…å­˜ä¼˜åŒ–)")

# ä¿®å¤å¤šè¿›ç¨‹åºåˆ—åŒ–é—®é¢˜
# åœ¨Jupyter notebookç¯å¢ƒä¸­ï¼Œè‡ªå®šä¹‰ç±»æ— æ³•è¢«pickleåºåˆ—åŒ–åˆ°workerè¿›ç¨‹
# å› æ­¤æš‚æ—¶ç¦ç”¨å¤šè¿›ç¨‹ï¼Œä½¿ç”¨å•è¿›ç¨‹åŠ è½½
print("âš ï¸ æ£€æµ‹åˆ°Jupyterç¯å¢ƒï¼Œä¸ºé¿å…åºåˆ—åŒ–é—®é¢˜ï¼Œä½¿ç”¨å•è¿›ç¨‹æ•°æ®åŠ è½½")
num_workers = 0  # ç¦ç”¨å¤šè¿›ç¨‹ä»¥é¿å…åºåˆ—åŒ–é—®é¢˜
prefetch_factor = None  # å•è¿›ç¨‹æ—¶ä¸éœ€è¦é¢„å–
pin_memory = True if torch.cuda.is_available() else False
persistent_workers = False  # å•è¿›ç¨‹æ—¶ä¸éœ€è¦æŒä¹…åŒ–worker
print(f"ä½¿ç”¨ {num_workers} ä¸ªæ•°æ®åŠ è½½worker (å•è¿›ç¨‹æ¨¡å¼)")

# åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆå•è¿›ç¨‹æ¨¡å¼ï¼‰
train_loader = DataLoader(
    train_dataset, 
    batch_size=batch_size, 
    shuffle=True, 
    num_workers=num_workers,
    pin_memory=False,  # ç¦ç”¨pin_memoryï¼Œå› ä¸ºæ•°æ®å·²åœ¨GPUä¸Š
    drop_last=True
)

val_loader = DataLoader(
    val_dataset, 
    batch_size=batch_size, 
    shuffle=False, 
    num_workers=num_workers,
    pin_memory=False  # ç¦ç”¨pin_memoryï¼Œå› ä¸ºæ•°æ®å·²åœ¨GPUä¸Š
)

test_loader = DataLoader(
    test_dataset, 
    batch_size=batch_size, 
    shuffle=False, 
    num_workers=num_workers,
    pin_memory=False  # ç¦ç”¨pin_memoryï¼Œå› ä¸ºæ•°æ®å·²åœ¨GPUä¸Š
)

print(f"\nğŸ“Š æ•°æ®åŠ è½½å™¨ç»Ÿè®¡:")
print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
print(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
print(f"æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}")
print(f"æ•°æ®åŠ è½½workeræ•°: {num_workers} (å•è¿›ç¨‹æ¨¡å¼)")
print(f"å†…å­˜å›ºå®š: å·²ç¦ç”¨ (æ•°æ®å·²åœ¨GPUä¸Š)")
print(f"å¸§ç¼“å­˜: {'å¯ç”¨' if train_dataset.cache_frames else 'ç¦ç”¨'}")

# æµ‹è¯•æ•°æ®åŠ è½½å™¨
print("\nğŸ” æµ‹è¯•æ•°æ®åŠ è½½å™¨...")
import time
try:
    sample_batch = next(iter(train_loader))
    videos, labels = sample_batch
    print(f"è§†é¢‘å¼ é‡å½¢çŠ¶: {videos.shape}")
    print(f"æ ‡ç­¾å¼ é‡å½¢çŠ¶: {labels.shape}")
    print(f"è§†é¢‘æ•°æ®ç±»å‹: {videos.dtype}")
    print(f"æ ‡ç­¾æ•°æ®ç±»å‹: {labels.dtype}")
    print(f"è§†é¢‘æ•°æ®èŒƒå›´: [{videos.min():.3f}, {videos.max():.3f}]")
    print(f"æ ‡ç­¾åˆ†å¸ƒ: {labels.unique(return_counts=True)}")
    print("âœ… æ•°æ®åŠ è½½å™¨æµ‹è¯•æˆåŠŸ")
except Exception as e:
    print(f"âŒ æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}")
    raise e

print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")