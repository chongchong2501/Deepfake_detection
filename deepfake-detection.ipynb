{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##  1.ç¯å¢ƒè®¾ç½®å’Œæ•°æ®ä¸‹è½½","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# ç¬¬1æ®µï¼šç¯å¢ƒè®¾ç½®å’Œå¯¼å…¥\n# =============================================================================\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# PyTorchç›¸å…³\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\n# æœºå™¨å­¦ä¹ æŒ‡æ ‡\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    roc_auc_score, confusion_matrix, classification_report,\n    roc_curve, auc\n)\n\n# è®¾ç½®éšæœºç§å­\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n# æ£€æŸ¥GPUå¯ç”¨æ€§\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPUå‹å·: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n\n# åˆ›å»ºå¿…è¦çš„ç›®å½•\nos.makedirs('./data', exist_ok=True)\nos.makedirs('./models', exist_ok=True)\nos.makedirs('./logs', exist_ok=True)\nos.makedirs('./results', exist_ok=True)\n\nprint(\"âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ\")","metadata":{"_uuid":"f6ebcf0d-d34a-4e53-b9c4-c85254661e41","_cell_guid":"4883bd2d-9463-4607-9e61-df4d76492a78","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-04T06:55:55.360300Z","iopub.execute_input":"2025-07-04T06:55:55.360596Z","iopub.status.idle":"2025-07-04T06:56:08.341271Z","shell.execute_reply.started":"2025-07-04T06:55:55.360571Z","shell.execute_reply":"2025-07-04T06:56:08.340282Z"}},"outputs":[{"name":"stdout","text":"ä½¿ç”¨è®¾å¤‡: cuda\nGPUå‹å·: Tesla T4\nGPUå†…å­˜: 14.7 GB\nâœ… ç¯å¢ƒè®¾ç½®å®Œæˆ\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"##  2.æ•°æ®ä¸‹è½½ä¸é¢„å¤„ç†\n","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# ç¬¬2æ®µï¼šæ•°æ®ä¸‹è½½å’Œé¢„å¤„ç†\n# =============================================================================\n\n# æ£€æŸ¥æ˜¯å¦åœ¨Kaggleç¯å¢ƒä¸­\nIS_KAGGLE = os.path.exists('/kaggle')\n\nif IS_KAGGLE:\n    # Kaggleç¯å¢ƒä¸­çš„æ•°æ®è·¯å¾„\n    DATA_DIR = '/kaggle/input/ff-c23'\n    print(\"æ£€æµ‹åˆ°Kaggleç¯å¢ƒ\")\nelse:\n    # æœ¬åœ°ç¯å¢ƒ\n    DATA_DIR = './ff-c23'\n    print(\"æœ¬åœ°ç¯å¢ƒ\")\n\n# è§†é¢‘å¸§æå–å‡½æ•°\ndef extract_frames_from_video(video_path, max_frames=30, target_size=(128, 128)):\n    \"\"\"\n    ä»è§†é¢‘ä¸­æå–å¸§\n    \"\"\"\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    \n    if not cap.isOpened():\n        print(f\"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}\")\n        return frames\n    \n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    if total_frames == 0:\n        cap.release()\n        return frames\n    \n    # è®¡ç®—é‡‡æ ·é—´éš”\n    if total_frames <= max_frames:\n        frame_indices = list(range(total_frames))\n    else:\n        frame_indices = np.linspace(0, total_frames-1, max_frames, dtype=int)\n    \n    for frame_idx in frame_indices:\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n        ret, frame = cap.read()\n        \n        if ret:\n            # è½¬æ¢é¢œè‰²ç©ºé—´\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            # è°ƒæ•´å¤§å°\n            frame = cv2.resize(frame, target_size)\n            frames.append(frame)\n    \n    cap.release()\n    return frames\n\n# å¤„ç†æ‰€æœ‰è§†é¢‘\ndef process_videos(data_dir, max_videos_per_class=100, max_frames=30):\n    \"\"\"\n    å¤„ç†æ‰€æœ‰è§†é¢‘å¹¶åˆ›å»ºæ•°æ®é›†\n    \"\"\"\n    data_list = []\n    \n    # å®šä¹‰ç±»åˆ«å’Œå¯¹åº”çš„æ ‡ç­¾\n    categories = {\n        'real': 0,      # çœŸå®è§†é¢‘\n        'fake': 1       # ä¼ªé€ è§†é¢‘\n    }\n    \n    for category, label in categories.items():\n        category_dir = os.path.join(data_dir, category)\n        \n        if not os.path.exists(category_dir):\n            print(f\"ç›®å½•ä¸å­˜åœ¨: {category_dir}\")\n            continue\n        \n        video_files = [f for f in os.listdir(category_dir) if f.endswith(('.mp4', '.avi', '.mov'))]\n        \n        # é™åˆ¶è§†é¢‘æ•°é‡\n        if len(video_files) > max_videos_per_class:\n            video_files = random.sample(video_files, max_videos_per_class)\n        \n        print(f\"å¤„ç† {category} ç±»åˆ«çš„ {len(video_files)} ä¸ªè§†é¢‘...\")\n        \n        for video_file in tqdm(video_files, desc=f\"å¤„ç†{category}è§†é¢‘\"):\n            video_path = os.path.join(category_dir, video_file)\n            \n            # æå–å¸§\n            frames = extract_frames_from_video(video_path, max_frames)\n            \n            if len(frames) > 0:\n                # ä¿å­˜å¸§æ•°æ®è·¯å¾„\n                frame_save_dir = os.path.join('./data', 'frames', category)\n                os.makedirs(frame_save_dir, exist_ok=True)\n                \n                video_name = os.path.splitext(video_file)[0]\n                frame_save_path = os.path.join(frame_save_dir, f\"{video_name}.npy\")\n                \n                # ä¿å­˜å¸§æ•°æ®\n                np.save(frame_save_path, np.array(frames))\n                \n                data_list.append({\n                    'video_path': video_path,\n                    'frame_path': frame_save_path,\n                    'label': label,\n                    'category': category,\n                    'num_frames': len(frames)\n                })\n    \n    return data_list\n\n# æ£€æŸ¥æ˜¯å¦å·²æœ‰é¢„å¤„ç†æ•°æ®\nif os.path.exists('./data/train.csv') and os.path.exists('./data/val.csv'):\n    print(\"âœ… å‘ç°å·²æœ‰é¢„å¤„ç†æ•°æ®\")\n    train_df = pd.read_csv('./data/train.csv')\n    val_df = pd.read_csv('./data/val.csv')\n    print(f\"è®­ç»ƒé›†: {len(train_df)} ä¸ªæ ·æœ¬\")\n    print(f\"éªŒè¯é›†: {len(val_df)} ä¸ªæ ·æœ¬\")\nelse:\n    print(\"å¼€å§‹å¤„ç†è§†é¢‘æ•°æ®...\")\n    # å¤„ç†è§†é¢‘\n    data_list = process_videos(DATA_DIR, max_videos_per_class=50, max_frames=30)\n    \n    if len(data_list) == 0:\n        print(\"âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ•°æ®\")\n    else:\n        # åˆ›å»ºDataFrame\n        df = pd.DataFrame(data_list)\n        \n        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†\n        from sklearn.model_selection import train_test_split\n        \n        train_df, val_df = train_test_split(\n            df, test_size=0.2, random_state=42, stratify=df['label']\n        )\n        \n        # ä¿å­˜CSVæ–‡ä»¶\n        train_df.to_csv('./data/train.csv', index=False)\n        val_df.to_csv('./data/val.csv', index=False)\n        \n        print(f\"âœ… æ•°æ®å¤„ç†å®Œæˆ\")\n        print(f\"è®­ç»ƒé›†: {len(train_df)} ä¸ªæ ·æœ¬\")\n        print(f\"éªŒè¯é›†: {len(val_df)} ä¸ªæ ·æœ¬\")\n        print(f\"çœŸå®è§†é¢‘: {len(df[df['label']==0])} ä¸ª\")\n        print(f\"ä¼ªé€ è§†é¢‘: {len(df[df['label']==1])} ä¸ª\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:57:27.225220Z","iopub.execute_input":"2025-07-04T06:57:27.225786Z","iopub.status.idle":"2025-07-04T06:57:27.252417Z","shell.execute_reply.started":"2025-07-04T06:57:27.225760Z","shell.execute_reply":"2025-07-04T06:57:27.251725Z"}},"outputs":[{"name":"stdout","text":"æ£€æµ‹åˆ°Kaggleç¯å¢ƒ\nå¼€å§‹å¤„ç†è§†é¢‘æ•°æ®...\nç›®å½•ä¸å­˜åœ¨: /kaggle/input/ff-c23/real\nç›®å½•ä¸å­˜åœ¨: /kaggle/input/ff-c23/fake\nâŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ•°æ®\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 3.æ•°æ®é›†ç±»å®šä¹‰ ","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# ç¬¬3æ®µï¼šæ•°æ®é›†ç±»å®šä¹‰\n# =============================================================================\n\nclass DeepfakeVideoDataset(Dataset):\n    def __init__(self, csv_file, transform=None, max_frames=30):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        self.max_frames = max_frames\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        \n        # åŠ è½½å¸§æ•°æ®\n        frames = np.load(row['frame_path'])\n        label = row['label']\n        \n        # ç¡®ä¿å¸§æ•°é‡\n        if len(frames) < self.max_frames:\n            # å¦‚æœå¸§æ•°ä¸è¶³ï¼Œé‡å¤æœ€åä¸€å¸§\n            last_frame = frames[-1]\n            padding = np.repeat(last_frame[np.newaxis, :], self.max_frames - len(frames), axis=0)\n            frames = np.concatenate([frames, padding], axis=0)\n        elif len(frames) > self.max_frames:\n            # å¦‚æœå¸§æ•°è¿‡å¤šï¼Œå‡åŒ€é‡‡æ ·\n            indices = np.linspace(0, len(frames)-1, self.max_frames, dtype=int)\n            frames = frames[indices]\n        \n        # åº”ç”¨å˜æ¢\n        if self.transform:\n            transformed_frames = []\n            for frame in frames:\n                transformed_frame = self.transform(frame)\n                transformed_frames.append(transformed_frame)\n            frames = torch.stack(transformed_frames)\n        else:\n            frames = torch.tensor(frames, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n        \n        return frames, torch.tensor(label, dtype=torch.float32)\n\n# æ•°æ®è½¬æ¢\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nprint(\"âœ… æ•°æ®é›†ç±»å®šä¹‰å®Œæˆ\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.æ¨¡å‹å®šä¹‰","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# ç¬¬4æ®µï¼šæ¨¡å‹å®šä¹‰\n# =============================================================================\n\n# CNNç‰¹å¾æå–å™¨\nclass CNNFeatureExtractor(nn.Module):\n    def __init__(self, pretrained=True):\n        super(CNNFeatureExtractor, self).__init__()\n        # ä½¿ç”¨ResNet18ä½œä¸ºç‰¹å¾æå–å™¨\n        self.backbone = models.resnet18(pretrained=pretrained)\n        # ç§»é™¤æœ€åçš„åˆ†ç±»å±‚\n        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])\n        self.feature_dim = 512\n    \n    def forward(self, x):\n        # x shape: (batch_size, channels, height, width)\n        features = self.backbone(x)\n        features = features.view(features.size(0), -1)  # å±•å¹³\n        return features\n\n# æ³¨æ„åŠ›å±‚\nclass AttentionLayer(nn.Module):\n    def __init__(self, hidden_dim):\n        super(AttentionLayer, self).__init__()\n        self.attention = nn.Linear(hidden_dim, 1)\n    \n    def forward(self, x):\n        # x shape: (batch_size, seq_len, hidden_dim)\n        attention_weights = torch.softmax(self.attention(x), dim=1)\n        # åŠ æƒæ±‚å’Œ\n        attended = torch.sum(attention_weights * x, dim=1)\n        return attended, attention_weights\n\n# æ ‡å‡†æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹\nclass DeepfakeDetector(nn.Module):\n    def __init__(self, num_classes=1, hidden_dim=256, num_layers=2, dropout=0.3):\n        super(DeepfakeDetector, self).__init__()\n        \n        # CNNç‰¹å¾æå–å™¨\n        self.cnn = CNNFeatureExtractor(pretrained=True)\n        \n        # LSTMå±‚\n        self.lstm = nn.LSTM(\n            input_size=self.cnn.feature_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0,\n            bidirectional=True\n        )\n        \n        # æ³¨æ„åŠ›å±‚\n        self.attention = AttentionLayer(hidden_dim * 2)  # åŒå‘LSTM\n        \n        # åˆ†ç±»å™¨\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, num_classes),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        batch_size, seq_len, channels, height, width = x.size()\n        \n        # é‡å¡‘ä¸º(batch_size * seq_len, channels, height, width)\n        x = x.view(batch_size * seq_len, channels, height, width)\n        \n        # CNNç‰¹å¾æå–\n        features = self.cnn(x)  # (batch_size * seq_len, feature_dim)\n        \n        # é‡å¡‘ä¸º(batch_size, seq_len, feature_dim)\n        features = features.view(batch_size, seq_len, -1)\n        \n        # LSTMå¤„ç†\n        lstm_out, _ = self.lstm(features)  # (batch_size, seq_len, hidden_dim * 2)\n        \n        # æ³¨æ„åŠ›æœºåˆ¶\n        attended, attention_weights = self.attention(lstm_out)\n        \n        # åˆ†ç±»\n        output = self.classifier(attended)\n        \n        return output.squeeze(), attention_weights\n\n# è½»é‡çº§æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹\nclass LightweightDeepfakeDetector(nn.Module):\n    def __init__(self, num_classes=1, hidden_dim=128, dropout=0.3):\n        super(LightweightDeepfakeDetector, self).__init__()\n        \n        # ä½¿ç”¨MobileNetV2ä½œä¸ºç‰¹å¾æå–å™¨\n        self.backbone = models.mobilenet_v2(pretrained=True)\n        self.backbone.classifier = nn.Identity()  # ç§»é™¤åˆ†ç±»å±‚\n        self.feature_dim = 1280\n        \n        # GRUå±‚ï¼ˆæ¯”LSTMæ›´è½»é‡ï¼‰\n        self.gru = nn.GRU(\n            input_size=self.feature_dim,\n            hidden_size=hidden_dim,\n            num_layers=1,\n            batch_first=True,\n            bidirectional=True\n        )\n        \n        # æ³¨æ„åŠ›å±‚\n        self.attention = AttentionLayer(hidden_dim * 2)\n        \n        # åˆ†ç±»å™¨\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, num_classes),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        batch_size, seq_len, channels, height, width = x.size()\n        \n        # é‡å¡‘ä¸º(batch_size * seq_len, channels, height, width)\n        x = x.view(batch_size * seq_len, channels, height, width)\n        \n        # CNNç‰¹å¾æå–\n        features = self.backbone(x)  # (batch_size * seq_len, feature_dim)\n        \n        # é‡å¡‘ä¸º(batch_size, seq_len, feature_dim)\n        features = features.view(batch_size, seq_len, -1)\n        \n        # GRUå¤„ç†\n        gru_out, _ = self.gru(features)  # (batch_size, seq_len, hidden_dim * 2)\n        \n        # æ³¨æ„åŠ›æœºåˆ¶\n        attended, attention_weights = self.attention(gru_out)\n        \n        # åˆ†ç±»\n        output = self.classifier(attended)\n        \n        return output.squeeze(), attention_weights\n\n# æ¨¡å‹åˆ›å»ºå‡½æ•°\ndef create_model(model_type='standard', device='cpu'):\n    if model_type == 'standard':\n        model = DeepfakeDetector()\n    elif model_type == 'lightweight':\n        model = LightweightDeepfakeDetector()\n    else:\n        raise ValueError(f\"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}\")\n    \n    return model.to(device)\n\nprint(\"âœ… æ¨¡å‹å®šä¹‰å®Œæˆ\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.è®­ç»ƒå’ŒéªŒè¯å‡½æ•°","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# ç¬¬5æ®µï¼šè®­ç»ƒå’ŒéªŒè¯å‡½æ•°\n# =============================================================================\n\n# è®­ç»ƒå‡½æ•°\ndef train(model, train_loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    \n    progress_bar = tqdm(train_loader, desc='è®­ç»ƒ')\n    \n    for inputs, labels in progress_bar:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        # æ¢¯åº¦æ¸…é›¶\n        optimizer.zero_grad()\n        \n        # å‰å‘ä¼ æ’­\n        if isinstance(model.forward(inputs), tuple):\n            outputs, _ = model(inputs)\n        else:\n            outputs = model(inputs)\n        \n        outputs = outputs.squeeze()\n        \n        # è®¡ç®—æŸå¤±\n        loss = criterion(outputs, labels)\n        \n        # åå‘ä¼ æ’­\n        loss.backward()\n        \n        # æ¢¯åº¦è£å‰ª\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        # ä¼˜åŒ–\n        optimizer.step()\n        \n        # ç»Ÿè®¡\n        running_loss += loss.item() * inputs.size(0)\n        \n        # æ”¶é›†é¢„æµ‹å’Œç›®æ ‡\n        preds = (outputs > 0.5).float().cpu().numpy()\n        all_predictions.extend(preds)\n        all_targets.extend(labels.cpu().numpy())\n        \n        # æ›´æ–°è¿›åº¦æ¡\n        progress_bar.set_postfix({'loss': loss.item()})\n    \n    # è®¡ç®—å¹³å‡æŸå¤±å’ŒæŒ‡æ ‡\n    epoch_loss = running_loss / len(train_loader.dataset)\n    accuracy = accuracy_score(all_targets, all_predictions)\n    precision = precision_score(all_targets, all_predictions, zero_division=0)\n    recall = recall_score(all_targets, all_predictions, zero_division=0)\n    f1 = f1_score(all_targets, all_predictions, zero_division=0)\n    \n    return epoch_loss, accuracy, precision, recall, f1\n\n# éªŒè¯å‡½æ•°\ndef validate(model, val_loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    all_scores = []\n    \n    with torch.no_grad():\n        progress_bar = tqdm(val_loader, desc='éªŒè¯')\n        \n        for inputs, labels in progress_bar:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            # å‰å‘ä¼ æ’­\n            if isinstance(model.forward(inputs), tuple):\n                outputs, _ = model(inputs)\n            else:\n                outputs = model(inputs)\n            \n            outputs = outputs.squeeze()\n            \n            # è®¡ç®—æŸå¤±\n            loss = criterion(outputs, labels)\n            \n            # ç»Ÿè®¡\n            running_loss += loss.item() * inputs.size(0)\n            \n            # æ”¶é›†é¢„æµ‹å’Œç›®æ ‡\n            preds = (outputs > 0.5).float().cpu().numpy()\n            all_predictions.extend(preds)\n            all_targets.extend(labels.cpu().numpy())\n            all_scores.extend(outputs.cpu().numpy())\n            \n            # æ›´æ–°è¿›åº¦æ¡\n            progress_bar.set_postfix({'loss': loss.item()})\n    \n    # è®¡ç®—å¹³å‡æŸå¤±å’ŒæŒ‡æ ‡\n    epoch_loss = running_loss / len(val_loader.dataset)\n    accuracy = accuracy_score(all_targets, all_predictions)\n    precision = precision_score(all_targets, all_predictions, zero_division=0)\n    recall = recall_score(all_targets, all_predictions, zero_division=0)\n    f1 = f1_score(all_targets, all_predictions, zero_division=0)\n    auc_score = roc_auc_score(all_targets, all_scores) if len(set(all_targets)) > 1 else 0.0\n    \n    return epoch_loss, accuracy, precision, recall, f1, auc_score\n\n# ä¿å­˜æ£€æŸ¥ç‚¹å‡½æ•°\ndef save_checkpoint(model, optimizer, epoch, metrics, save_dir, model_type, is_best=False):\n    checkpoint = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'metrics': metrics\n    }\n    \n    # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹\n    latest_path = os.path.join(save_dir, f'{model_type}_model_latest.pth')\n    torch.save(checkpoint, latest_path)\n    \n    # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹\n    if is_best:\n        best_path = os.path.join(save_dir, f'{model_type}_model_best.pth')\n        torch.save(checkpoint, best_path)\n\n# ç»˜åˆ¶è®­ç»ƒæ›²çº¿å‡½æ•°\ndef plot_training_curves(train_losses, val_losses, train_metrics, val_metrics, save_dir):\n    epochs = range(1, len(train_losses) + 1)\n    \n    # åˆ›å»ºå­å›¾\n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n    \n    # æŸå¤±æ›²çº¿\n    axes[0, 0].plot(epochs, train_losses, 'b-', label='è®­ç»ƒæŸå¤±')\n    axes[0, 0].plot(epochs, val_losses, 'r-', label='éªŒè¯æŸå¤±')\n    axes[0, 0].set_title('æŸå¤±æ›²çº¿')\n    axes[0, 0].set_xlabel('Epoch')\n    axes[0, 0].set_ylabel('æŸå¤±')\n    axes[0, 0].legend()\n    axes[0, 0].grid(True)\n    \n    # å‡†ç¡®ç‡æ›²çº¿\n    train_acc = [m['accuracy'] for m in train_metrics]\n    val_acc = [m['accuracy'] for m in val_metrics]\n    axes[0, 1].plot(epochs, train_acc, 'b-', label='è®­ç»ƒå‡†ç¡®ç‡')\n    axes[0, 1].plot(epochs, val_acc, 'r-', label='éªŒè¯å‡†ç¡®ç‡')\n    axes[0, 1].set_title('å‡†ç¡®ç‡æ›²çº¿')\n    axes[0, 1].set_xlabel('Epoch')\n    axes[0, 1].set_ylabel('å‡†ç¡®ç‡')\n    axes[0, 1].legend()\n    axes[0, 1].grid(True)\n    \n    # F1åˆ†æ•°æ›²çº¿\n    train_f1 = [m['f1'] for m in train_metrics]\n    val_f1 = [m['f1'] for m in val_metrics]\n    axes[1, 0].plot(epochs, train_f1, 'b-', label='è®­ç»ƒF1')\n    axes[1, 0].plot(epochs, val_f1, 'r-', label='éªŒè¯F1')\n    axes[1, 0].set_title('F1åˆ†æ•°æ›²çº¿')\n    axes[1, 0].set_xlabel('Epoch')\n    axes[1, 0].set_ylabel('F1åˆ†æ•°')\n    axes[1, 0].legend()\n    axes[1, 0].grid(True)\n    \n    # AUCæ›²çº¿\n    val_auc = [m.get('auc', 0) for m in val_metrics]\n    axes[1, 1].plot(epochs, val_auc, 'r-', label='éªŒè¯AUC')\n    axes[1, 1].set_title('AUCæ›²çº¿')\n    axes[1, 1].set_xlabel('Epoch')\n    axes[1, 1].set_ylabel('AUC')\n    axes[1, 1].legend()\n    axes[1, 1].grid(True)\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(save_dir, 'training_curves.png'), dpi=300, bbox_inches='tight')\n    plt.close()\n\nprint(\"âœ… è®­ç»ƒå’ŒéªŒè¯å‡½æ•°å®šä¹‰å®Œæˆ\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  6.æ¨¡å‹è®­ç»ƒ","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# ç¬¬6æ®µï¼šæ¨¡å‹è®­ç»ƒ\n# =============================================================================\n\n# è®­ç»ƒå‚æ•°\nMODEL_TYPE = 'lightweight'  # 'standard' æˆ– 'lightweight'\nNUM_EPOCHS = 10\nBATCH_SIZE = 8\nLEARNING_RATE = 0.0001\nWEIGHT_DECAY = 1e-5\nNUM_FRAMES = 30\n\nprint(f\"è®­ç»ƒå‚æ•°:\")\nprint(f\"- æ¨¡å‹ç±»å‹: {MODEL_TYPE}\")\nprint(f\"- è®­ç»ƒè½®æ•°: {NUM_EPOCHS}\")\nprint(f\"- æ‰¹é‡å¤§å°: {BATCH_SIZE}\")\nprint(f\"- å­¦ä¹ ç‡: {LEARNING_RATE}\")\nprint(f\"- æƒé‡è¡°å‡: {WEIGHT_DECAY}\")\nprint(f\"- å¸§æ•°: {NUM_FRAMES}\")\n\n# åˆ›å»ºæ•°æ®é›†\ntrain_dataset = DeepfakeVideoDataset(\n    csv_file='./data/train.csv',\n    transform=transform,\n    max_frames=NUM_FRAMES\n)\n\nval_dataset = DeepfakeVideoDataset(\n    csv_file='./data/val.csv',\n    transform=transform,\n    max_frames=NUM_FRAMES\n)\n\n# åˆ›å»ºæ•°æ®åŠ è½½å™¨\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\nprint(f\"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}\")\nprint(f\"éªŒè¯é›†å¤§å°: {len(val_dataset)}\")\n\n# åˆ›å»ºæ¨¡å‹\nmodel = create_model(model_type=MODEL_TYPE, device=device)\nprint(f\"æ¨¡å‹ç±»å‹: {MODEL_TYPE}\")\n\n# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n# å­¦ä¹ ç‡è°ƒåº¦å™¨\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n)\n\n# åˆå§‹åŒ–å˜é‡\nstart_epoch = 0\nbest_val_loss = float('inf')\ntrain_losses = []\nval_losses = []\ntrain_metrics = []\nval_metrics = []\n\nprint(\"âœ… è®­ç»ƒå‡†å¤‡å®Œæˆ\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.æ‰§è¡Œè®­ç»ƒå¾ªç¯","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# ç¬¬7æ®µï¼šæ‰§è¡Œè®­ç»ƒå¾ªç¯\n# =============================================================================\n\n# è®­ç»ƒå¾ªç¯\nprint(\"å¼€å§‹è®­ç»ƒ...\")\nfor epoch in range(start_epoch, NUM_EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n    \n    # è®­ç»ƒ\n    train_loss, train_acc, train_prec, train_rec, train_f1 = train(\n        model, train_loader, criterion, optimizer, device\n    )\n    \n    # éªŒè¯\n    val_loss, val_acc, val_prec, val_rec, val_f1, val_auc = validate(\n        model, val_loader, criterion, device\n    )\n    \n    # æ›´æ–°å­¦ä¹ ç‡\n    scheduler.step(val_loss)\n    \n    # è®°å½•æŒ‡æ ‡\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    \n    train_metrics.append({\n        'accuracy': train_acc,\n        'precision': train_prec,\n        'recall': train_rec,\n        'f1': train_f1\n    })\n    \n    val_metrics.append({\n        'accuracy': val_acc,\n        'precision': val_prec,\n        'recall': val_rec,\n        'f1': val_f1,\n        'auc': val_auc\n    })\n    \n    # æ‰“å°æŒ‡æ ‡\n    print(f\"è®­ç»ƒæŸå¤±: {train_loss:.4f}, å‡†ç¡®ç‡: {train_acc:.4f}, F1: {train_f1:.4f}\")\n    print(f\"éªŒè¯æŸå¤±: {val_loss:.4f}, å‡†ç¡®ç‡: {val_acc:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}\")\n    \n    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹\n    is_best = val_loss < best_val_loss\n    if is_best:\n        best_val_loss = val_loss\n        print(\"ğŸ‰ å‘ç°æ›´å¥½çš„æ¨¡å‹ï¼\")\n    \n    # ä¿å­˜æ£€æŸ¥ç‚¹\n    metrics = {\n        'train_loss': train_loss,\n        'val_loss': val_loss,\n        'train_acc': train_acc,\n        'val_acc': val_acc,\n        'train_f1': train_f1,\n        'val_f1': val_f1,\n        'val_auc': val_auc\n    }\n    save_checkpoint(model, optimizer, epoch, metrics, './models', MODEL_TYPE, is_best)\n    \n    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n    plot_training_curves(train_losses, val_losses, train_metrics, val_metrics, './logs')\n\nprint(\"âœ… è®­ç»ƒå®Œæˆï¼\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8.æ¨¡å‹è¯„ä¼°","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# ç¬¬8æ®µï¼šæ¨¡å‹è¯„ä¼°\n# =============================================================================\n\n# è¯„ä¼°å‡½æ•°\ndef evaluate_model(model, test_loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    all_scores = []\n    \n    with torch.no_grad():\n        progress_bar = tqdm(test_loader, desc='è¯„ä¼°')\n        \n        for inputs, labels in progress_bar:\n            inputs = inputs.to(device)\n            labels = labels.float().to(device)\n            \n            # å‰å‘ä¼ æ’­\n            if isinstance(model.forward(inputs), tuple):\n                outputs, _ = model(inputs)\n            else:\n                outputs = model(inputs)\n            \n            outputs = outputs.squeeze()\n            \n            # è®¡ç®—æŸå¤±\n            loss = criterion(outputs, labels)\n            \n            # ç»Ÿè®¡\n            running_loss += loss.item() * inputs.size(0)\n            \n            # æ”¶é›†é¢„æµ‹å’Œç›®æ ‡\n            preds = (outputs > 0.5).float().cpu().numpy()\n            all_predictions.extend(preds)\n            all_targets.extend(labels.cpu().numpy())\n            all_scores.extend(outputs.cpu().numpy())\n            \n            # æ›´æ–°è¿›åº¦æ¡\n            progress_bar.set_postfix({'loss': loss.item()})\n    \n    # è®¡ç®—å¹³å‡æŸå¤±\n    test_loss = running_loss / len(test_loader.dataset)\n    \n    return test_loss, all_predictions, all_targets, all_scores\n\n# è®¡ç®—å¹¶æ‰“å°æŒ‡æ ‡\ndef calculate_metrics(predictions, targets, scores):\n    accuracy = accuracy_score(targets, predictions)\n    precision = precision_score(targets, predictions, zero_division=0)\n    recall = recall_score(targets, predictions, zero_division=0)\n    f1 = f1_score(targets, predictions, zero_division=0)\n    auc_score = roc_auc_score(targets, scores) if len(set(targets)) > 1 else 0.0\n    \n    print(f\"å‡†ç¡®ç‡: {accuracy:.4f}\")\n    print(f\"ç²¾ç¡®ç‡: {precision:.4f}\")\n    print(f\"å¬å›ç‡: {recall:.4f}\")\n    print(f\"F1åˆ†æ•°: {f1:.4f}\")\n    print(f\"AUC-ROC: {auc_score:.4f}\")\n    \n    # æ‰“å°åˆ†ç±»æŠ¥å‘Š\n    print(\"\\nåˆ†ç±»æŠ¥å‘Š:\")\n    print(classification_report(targets, predictions, target_names=['çœŸå®', 'ä¼ªé€ ']))\n    \n    # è®¡ç®—æ··æ·†çŸ©é˜µ\n    cm = confusion_matrix(targets, predictions)\n    \n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'auc': auc_score,\n        'confusion_matrix': cm\n    }\n\n# ç»˜åˆ¶æ··æ·†çŸ©é˜µ\ndef plot_confusion_matrix(cm, save_path):\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n                xticklabels=['çœŸå®', 'ä¼ªé€ '], yticklabels=['çœŸå®', 'ä¼ªé€ '])\n    plt.xlabel('é¢„æµ‹æ ‡ç­¾')\n    plt.ylabel('çœŸå®æ ‡ç­¾')\n    plt.title('æ··æ·†çŸ©é˜µ')\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.show()\n    plt.close()\n\n# ç»˜åˆ¶ROCæ›²çº¿\ndef plot_roc_curve(targets, scores, save_path):\n    fpr, tpr, _ = roc_curve(targets, scores)\n    roc_auc = auc(fpr, tpr)\n    \n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROCæ›²çº¿ (AUC = {roc_auc:.4f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('å‡é˜³æ€§ç‡')\n    plt.ylabel('çœŸé˜³æ€§ç‡')\n    plt.title('æ¥æ”¶è€…æ“ä½œç‰¹å¾æ›²çº¿')\n    plt.legend(loc='lower right')\n    plt.grid(True, linestyle='--', alpha=0.7)\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.show()\n    plt.close()\n\nprint(\"âœ… è¯„ä¼°å‡½æ•°å®šä¹‰å®Œæˆ\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9.æ‰§è¡Œæ¨¡å‹è¯„ä¼°","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# ç¬¬9æ®µï¼šæ‰§è¡Œæ¨¡å‹è¯„ä¼°\n# =============================================================================\n\n# åŠ è½½æœ€ä½³æ¨¡å‹\nbest_model_path = os.path.join('./models', f'{MODEL_TYPE}_model_best.pth')\nif os.path.exists(best_model_path):\n    checkpoint = torch.load(best_model_path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    print(f\"âœ… åŠ è½½æœ€ä½³æ¨¡å‹: {best_model_path}\")\nelse:\n    print(\"âš ï¸ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼Œä½¿ç”¨å½“å‰æ¨¡å‹\")\n\n# åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆä½¿ç”¨éªŒè¯é›†ä½œä¸ºæµ‹è¯•é›†ï¼‰\ntest_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\nprint(f\"æµ‹è¯•é›†å¤§å°: {len(val_dataset)}\")\n\n# è¯„ä¼°æ¨¡å‹\nprint(\"å¼€å§‹è¯„ä¼°...\")\ntest_loss, predictions, targets, scores = evaluate_model(model, test_loader, criterion, device)\nprint(f\"æµ‹è¯•æŸå¤±: {test_loss:.4f}\")\n\n# è®¡ç®—æŒ‡æ ‡\nmetrics = calculate_metrics(predictions, targets, scores)\n\n# ç»˜åˆ¶æ··æ·†çŸ©é˜µ\ncm_path = os.path.join('./results', 'confusion_matrix.png')\nplot_confusion_matrix(metrics['confusion_matrix'], cm_path)\nprint(f\"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ° {cm_path}\")\n\n# ç»˜åˆ¶ROCæ›²çº¿\nroc_path = os.path.join('./results', 'roc_curve.png')\nplot_roc_curve(targets, scores, roc_path)\nprint(f\"âœ… ROCæ›²çº¿å·²ä¿å­˜åˆ° {roc_path}\")\n\n# ä¿å­˜è¯„ä¼°ç»“æœ\nresults = {\n    'test_loss': test_loss,\n    'accuracy': metrics['accuracy'],\n    'precision': metrics['precision'],\n    'recall': metrics['recall'],\n    'f1': metrics['f1'],\n    'auc': metrics['auc']\n}\n\nresults_df = pd.DataFrame([results])\nresults_df.to_csv(os.path.join('./results', 'evaluation_results.csv'), index=False)\nprint(f\"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ° ./results/evaluation_results.csv\")\n\nprint(\"\\nğŸ‰ è¯„ä¼°å®Œæˆï¼\")\nprint(f\"æœ€ç»ˆç»“æœ: å‡†ç¡®ç‡={metrics['accuracy']:.4f}, F1={metrics['f1']:.4f}, AUC={metrics['auc']:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}