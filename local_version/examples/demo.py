#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ·±åº¦ä¼ªé€ æ£€æµ‹ç³»ç»Ÿæ¼”ç¤ºè„šæœ¬ - æœ¬åœ°RTX4070ç‰ˆæœ¬

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹ç³»ç»Ÿçš„ä¸»è¦åŠŸèƒ½ï¼š
1. æ•°æ®å‡†å¤‡å’Œé¢„å¤„ç†
2. æ¨¡å‹è®­ç»ƒï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰
3. æ¨¡å‹è¯„ä¼°
4. è§†é¢‘æ¨ç†

ä½¿ç”¨æ–¹æ³•:
    python demo.py [--data-dir DATA_DIR] [--quick]
"""

import os
import sys
import argparse
from pathlib import Path
import torch
import time

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent / 'src'))

from config import config
from data_processing import prepare_data
from dataset import create_data_loaders
from model import create_model
from utils import FocalLoss, EarlyStopping, set_random_seed, count_parameters
from training import Trainer, Evaluator

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='æ·±åº¦ä¼ªé€ æ£€æµ‹ç³»ç»Ÿæ¼”ç¤º')
    parser.add_argument('--data-dir', type=str, 
                       default="e:\\program\\Deepfake\\dataset\\FaceForensics++_C23",
                       help='æ•°æ®é›†ç›®å½•è·¯å¾„')
    parser.add_argument('--quick', action='store_true', 
                       help='å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼ï¼ˆä½¿ç”¨æ›´å°‘çš„æ•°æ®å’Œepochï¼‰')
    parser.add_argument('--skip-training', action='store_true',
                       help='è·³è¿‡è®­ç»ƒï¼Œä»…æ¼”ç¤ºæ•°æ®å¤„ç†å’Œæ¨¡å‹åˆ›å»º')
    parser.add_argument('--output-dir', type=str, default='./demo_outputs',
                       help='è¾“å‡ºç›®å½•')
    
    return parser.parse_args()

def print_section_header(title):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print("\n" + "="*60)
    print(f"ğŸ¯ {title}")
    print("="*60)

def print_step(step_num, title):
    """æ‰“å°æ­¥éª¤æ ‡é¢˜"""
    print(f"\nğŸ“‹ æ­¥éª¤ {step_num}: {title}")
    print("-" * 40)

def demo_data_preparation(data_dir, quick_mode=False):
    """æ¼”ç¤ºæ•°æ®å‡†å¤‡è¿‡ç¨‹"""
    print_section_header("æ•°æ®å‡†å¤‡å’Œé¢„å¤„ç†æ¼”ç¤º")
    
    print_step(1, "æ£€æŸ¥æ•°æ®é›†")
    data_path = Path(data_dir)
    if not data_path.exists():
        print(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {data_path}")
        print("è¯·ç¡®ä¿FaceForensics++æ•°æ®é›†å·²ä¸‹è½½åˆ°æŒ‡å®šç›®å½•")
        return None, None, None
    
    # æ£€æŸ¥FaceForensics++æ•°æ®é›†ç»“æ„
    original_dir = data_path / 'original'
    fake_methods = ['Deepfakes', 'Face2Face', 'FaceShifter', 'FaceSwap', 'NeuralTextures']
    
    if original_dir.exists():
        real_videos = list(original_dir.glob('*.mp4'))
        print(f"âœ… æ‰¾åˆ° {len(real_videos)} ä¸ªçœŸå®è§†é¢‘")
    else:
        print("âŒ æœªæ‰¾åˆ°çœŸå®è§†é¢‘ç›®å½• (original)")
        return None, None, None
    
    # æ£€æŸ¥ä¼ªé€ è§†é¢‘ç›®å½•
    total_fake_videos = 0
    found_fake_methods = []
    for method in fake_methods:
        method_dir = data_path / method
        if method_dir.exists():
            method_videos = list(method_dir.glob('*.mp4'))
            total_fake_videos += len(method_videos)
            found_fake_methods.append(f"{method}({len(method_videos)})")
    
    if total_fake_videos > 0:
        print(f"âœ… æ‰¾åˆ° {total_fake_videos} ä¸ªä¼ªé€ è§†é¢‘")
        print(f"   ä¼ªé€ æ–¹æ³•: {', '.join(found_fake_methods)}")
    else:
        print("âŒ æœªæ‰¾åˆ°ä¼ªé€ è§†é¢‘ç›®å½•")
        return None, None, None
    
    print_step(2, "æ•°æ®é¢„å¤„ç†")
    print("å¼€å§‹æå–è§†é¢‘å¸§å’Œé¢„å¤„ç†...")
    
    # åœ¨å¿«é€Ÿæ¨¡å¼ä¸‹é™åˆ¶è§†é¢‘æ•°é‡
    max_videos = 20 if quick_mode else None
    
    try:
        train_data, val_data, test_data = prepare_data(
            data_dir=data_path,
            max_videos_per_class=max_videos,
            force_reprocess=False
        )
        
        print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
        print(f"   è®­ç»ƒé›†: {len(train_data)} ä¸ªæ ·æœ¬")
        print(f"   éªŒè¯é›†: {len(val_data)} ä¸ªæ ·æœ¬")
        print(f"   æµ‹è¯•é›†: {len(test_data)} ä¸ªæ ·æœ¬")
        
        return train_data, val_data, test_data
        
    except Exception as e:
        print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
        return None, None, None

def demo_model_creation():
    """æ¼”ç¤ºæ¨¡å‹åˆ›å»º"""
    print_section_header("æ¨¡å‹åˆ›å»ºæ¼”ç¤º")
    
    print_step(1, "åˆ›å»ºæ¨¡å‹")
    print(f"ä½¿ç”¨é…ç½®: {config.BACKBONE} + LSTM + æ³¨æ„åŠ›æœºåˆ¶")
    
    try:
        model = create_model()
        device = config.get_device()
        model = model.to(device)
        
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"   è®¾å¤‡: {device}")
        
        # ç»Ÿè®¡å‚æ•°
        params = count_parameters(model)
        print(f"   æ€»å‚æ•°: {params['total']:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {params['trainable']:,}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        print_step(2, "æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­")
        model.eval()
        
        # åˆ›å»ºéšæœºè¾“å…¥
        batch_size = 2
        num_frames = config.MAX_FRAMES
        height, width = config.FRAME_SIZE
        
        dummy_input = torch.randn(batch_size, num_frames, 3, height, width).to(device)
        
        with torch.no_grad():
            start_time = time.time()
            output, attention = model(dummy_input)
            inference_time = time.time() - start_time
        
        print(f"âœ… å‰å‘ä¼ æ’­æµ‹è¯•æˆåŠŸ")
        print(f"   è¾“å…¥å½¢çŠ¶: {dummy_input.shape}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"   æ¨ç†æ—¶é—´: {inference_time*1000:.2f} ms")
        
        if attention is not None:
            print(f"   æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {attention.shape}")
        
        return model
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def demo_training(model, train_data, val_data, quick_mode=False, output_dir='./demo_outputs'):
    """æ¼”ç¤ºè®­ç»ƒè¿‡ç¨‹"""
    print_section_header("æ¨¡å‹è®­ç»ƒæ¼”ç¤º")
    
    print_step(1, "åˆ›å»ºæ•°æ®åŠ è½½å™¨")
    try:
        train_loader, val_loader, _ = create_data_loaders(train_data, val_data, val_data, quick_mode=quick_mode)
        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        print(f"   è®­ç»ƒæ‰¹æ¬¡: {len(train_loader)}")
        print(f"   éªŒè¯æ‰¹æ¬¡: {len(val_loader)}")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥: {e}")
        return None
    
    print_step(2, "è®¾ç½®è®­ç»ƒç»„ä»¶")
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    criterion = FocalLoss()
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.LEARNING_RATE,
        weight_decay=config.WEIGHT_DECAY
    )
    
    # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=5 if quick_mode else config.NUM_EPOCHS
    )
    
    # åˆ›å»ºæ—©åœæœºåˆ¶
    early_stopping = EarlyStopping(patience=3 if quick_mode else config.EARLY_STOPPING_PATIENCE)
    
    print("âœ… è®­ç»ƒç»„ä»¶è®¾ç½®å®Œæˆ")
    
    print_step(3, "å¼€å§‹è®­ç»ƒ")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    try:
        trainer = Trainer(
            model=model,
            train_loader=train_loader,
            val_loader=val_loader,
            criterion=criterion,
            optimizer=optimizer,
            scheduler=scheduler,
            early_stopping=early_stopping
        )
        
        # åœ¨å¿«é€Ÿæ¨¡å¼ä¸‹åªè®­ç»ƒå‡ ä¸ªepoch
        num_epochs = 3 if quick_mode else 10
        print(f"è®­ç»ƒ {num_epochs} ä¸ªepochï¼ˆ{'å¿«é€Ÿæ¨¡å¼' if quick_mode else 'æ¼”ç¤ºæ¨¡å¼'}ï¼‰")
        
        history = trainer.train(num_epochs=num_epochs, save_dir=output_path)
        
        print("âœ… è®­ç»ƒå®Œæˆ")
        print(f"   æœ€ç»ˆè®­ç»ƒæŸå¤±: {history['train_loss'][-1]:.4f}")
        print(f"   æœ€ç»ˆéªŒè¯æŸå¤±: {history['val_loss'][-1]:.4f}")
        print(f"   æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {history['train_acc'][-1]:.2f}%")
        print(f"   æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {history['val_acc'][-1]:.2f}%")
        
        return model, history
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def demo_evaluation(model, test_data):
    """æ¼”ç¤ºæ¨¡å‹è¯„ä¼°"""
    print_section_header("æ¨¡å‹è¯„ä¼°æ¼”ç¤º")
    
    print_step(1, "å‡†å¤‡æµ‹è¯•æ•°æ®")
    try:
        _, _, test_loader = create_data_loaders(test_data, test_data, test_data, quick_mode=True)
        print(f"âœ… æµ‹è¯•æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        print(f"   æµ‹è¯•æ‰¹æ¬¡: {len(test_loader)}")
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
        return
    
    print_step(2, "æ¨¡å‹è¯„ä¼°")
    try:
        criterion = FocalLoss()
        evaluator = Evaluator(model, test_loader, criterion)
        
        results = evaluator.evaluate()
        metrics = evaluator.calculate_metrics(
            results['predictions'],
            results['targets'],
            results['scores']
        )
        
        print("âœ… è¯„ä¼°å®Œæˆ")
        print(f"   å‡†ç¡®ç‡: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)")
        print(f"   ç²¾ç¡®ç‡: {metrics['precision']:.4f}")
        print(f"   å¬å›ç‡: {metrics['recall']:.4f}")
        print(f"   F1åˆ†æ•°: {metrics['f1']:.4f}")
        print(f"   AUC-ROC: {metrics['auc_roc']:.4f}")
        print(f"   å¹³å‡æ¨ç†æ—¶é—´: {results['avg_inference_time']*1000:.2f} ms/batch")
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    args = parse_args()
    
    # è®¾ç½®éšæœºç§å­
    set_random_seed()
    
    # æ›´æ–°é…ç½®
    config.DATA_DIR = Path(args.data_dir)
    config.OUTPUT_DIR = Path(args.output_dir)
    
    if args.quick:
        config.BATCH_SIZE = min(config.BATCH_SIZE, 4)
        print("ğŸš€ å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼å·²å¯ç”¨")
    
    # è®¾ç½®ç¯å¢ƒ
    config.setup_environment()
    
    print("="*60)
    print("ğŸ¬ æ·±åº¦ä¼ªé€ æ£€æµ‹ç³»ç»Ÿæ¼”ç¤º")
    print("="*60)
    print(f"æ•°æ®ç›®å½•: {config.DATA_DIR}")
    print(f"è¾“å‡ºç›®å½•: {config.OUTPUT_DIR}")
    print(f"è®¾å¤‡: {config.get_device()}")
    print(f"æ¨¡å¼: {'å¿«é€Ÿæ¼”ç¤º' if args.quick else 'å®Œæ•´æ¼”ç¤º'}")
    print("="*60)
    
    try:
        # 1. æ•°æ®å‡†å¤‡æ¼”ç¤º
        train_data, val_data, test_data = demo_data_preparation(
            args.data_dir, quick_mode=args.quick
        )
        
        if train_data is None:
            print("âŒ æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œæ¼”ç¤ºç»ˆæ­¢")
            return 1
        
        # 2. æ¨¡å‹åˆ›å»ºæ¼”ç¤º
        model = demo_model_creation()
        
        if model is None:
            print("âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥ï¼Œæ¼”ç¤ºç»ˆæ­¢")
            return 1
        
        # 3. è®­ç»ƒæ¼”ç¤ºï¼ˆå¯é€‰ï¼‰
        if not args.skip_training:
            model, history = demo_training(
                model, train_data, val_data, 
                quick_mode=args.quick, 
                output_dir=args.output_dir
            )
            
            if model is None:
                print("âŒ è®­ç»ƒå¤±è´¥ï¼Œè·³è¿‡è¯„ä¼°")
                return 1
        else:
            print_section_header("è·³è¿‡è®­ç»ƒæ¼”ç¤º")
            print("ä½¿ç”¨æœªè®­ç»ƒçš„æ¨¡å‹è¿›è¡Œè¯„ä¼°æ¼”ç¤º")
        
        # 4. è¯„ä¼°æ¼”ç¤º
        demo_evaluation(model, test_data)
        
        print_section_header("æ¼”ç¤ºå®Œæˆ")
        print("ğŸ‰ æ·±åº¦ä¼ªé€ æ£€æµ‹ç³»ç»Ÿæ¼”ç¤ºæˆåŠŸå®Œæˆï¼")
        print("\nğŸ“š æ¥ä¸‹æ¥ä½ å¯ä»¥ï¼š")
        print("   1. ä½¿ç”¨ train.py è¿›è¡Œå®Œæ•´è®­ç»ƒ")
        print("   2. ä½¿ç”¨ evaluate.py è¿›è¡Œè¯¦ç»†è¯„ä¼°")
        print("   3. ä½¿ç”¨ inference.py è¿›è¡Œè§†é¢‘æ¨ç†")
        print("   4. æŸ¥çœ‹ README.md äº†è§£æ›´å¤šä½¿ç”¨æ–¹æ³•")
        
        return 0
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)