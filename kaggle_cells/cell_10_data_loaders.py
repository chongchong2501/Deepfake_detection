# Cell 10: åˆ›å»ºæ•°æ®åŠ è½½å™¨ - Kaggle T4 ä¼˜åŒ–ç‰ˆæœ¬

import multiprocessing as mp

print("ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")

# ç®€åŒ–æ•°æ®å˜æ¢ - ä½¿ç”¨GPUé¢„å¤„ç†æ›¿ä»£CPUå˜æ¢
train_transform = None
val_transform = None

# å¤šGPUä¼˜åŒ–é…ç½®
gpu_count = torch.cuda.device_count() if torch.cuda.is_available() else 1
is_multi_gpu = gpu_count > 1

print(f"ğŸ”§ åˆ›å»ºæ•°æ®é›†ï¼ˆKaggle T4ä¼˜åŒ–é…ç½®ï¼‰...")
print(f"ğŸ“Š æ•°æ®ç±»å‹: FP32 (å…¼å®¹æ€§ä¼˜å…ˆ)")

# åˆ›å»ºæ•°æ®é›† - åŒT4 GPUä¼˜åŒ–é…ç½®
train_dataset = DeepfakeVideoDataset(
    csv_file='./data/train.csv',
    transform=train_transform,
    max_frames=12,  # é€‚ä¸­çš„å¸§æ•°ï¼Œå¹³è¡¡æ€§èƒ½å’Œå†…å­˜
    gpu_preprocessing=False,  # åœ¨å¤šè¿›ç¨‹ç¯å¢ƒä¸­ç¦ç”¨GPUé¢„å¤„ç†
    cache_frames=False,  # é¿å…å†…å­˜å‹åŠ›
    extract_fourier=True,  # é‡æ–°å¯ç”¨é¢‘åŸŸç‰¹å¾æå–
    extract_compression=True  # é‡æ–°å¯ç”¨å‹ç¼©ç‰¹å¾æå–
)

val_dataset = DeepfakeVideoDataset(
    csv_file='./data/val.csv',
    transform=val_transform,
    max_frames=12,  # é€‚ä¸­çš„å¸§æ•°ï¼Œå¹³è¡¡æ€§èƒ½å’Œå†…å­˜
    gpu_preprocessing=False,
    cache_frames=False,
    extract_fourier=True,  # é‡æ–°å¯ç”¨é¢‘åŸŸç‰¹å¾æå–
    extract_compression=True  # é‡æ–°å¯ç”¨å‹ç¼©ç‰¹å¾æå–
)

test_dataset = DeepfakeVideoDataset(
    csv_file='./data/test.csv',
    transform=val_transform,
    max_frames=12,  # é€‚ä¸­çš„å¸§æ•°ï¼Œå¹³è¡¡æ€§èƒ½å’Œå†…å­˜
    gpu_preprocessing=False,
    cache_frames=False,
    extract_fourier=True,  # é‡æ–°å¯ç”¨é¢‘åŸŸç‰¹å¾æå–
    extract_compression=True  # é‡æ–°å¯ç”¨å‹ç¼©ç‰¹å¾æå–
)

print(f"ğŸ“Š æ•°æ®é›†å¤§å°: è®­ç»ƒ={len(train_dataset)}, éªŒè¯={len(val_dataset)}, æµ‹è¯•={len(test_dataset)}")

# æ‰¹æ¬¡å¤§å°é…ç½® - æ ¹æ®GPUæ•°é‡è°ƒæ•´
batch_size = 2  # åŸºç¡€æ‰¹æ¬¡å¤§å°
if is_multi_gpu:
    print(f"ğŸš€ å¤šGPUæ¨¡å¼: {gpu_count} ä¸ªGPU")
    print(f"ğŸ“¦ å•GPUæ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"ğŸ“¦ æ€»æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {batch_size * gpu_count}")
else:
    print(f"ğŸ“ å•GPUæ¨¡å¼")
    print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {batch_size}")

# å·¥ä½œè¿›ç¨‹æ•°ä¼˜åŒ–
num_workers = 0  # Kaggleç¯å¢ƒä½¿ç”¨å•è¿›ç¨‹æ¨¡å¼ç¡®ä¿ç¨³å®šæ€§

# ä¼˜åŒ–æ•°æ®åŠ è½½å™¨é…ç½® - å‡å°‘workeræ•°é‡ä»¥é¿å…å´©æºƒ
if IS_KAGGLE:
    prefetch_factor = None
    persistent_workers = False
else:
    prefetch_factor = None
    persistent_workers = False

print(f"ğŸ”¥ æ•°æ®åŠ è½½é…ç½®: {num_workers} workers (å•è¿›ç¨‹æ¨¡å¼ç¡®ä¿ç¨³å®šæ€§)")

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
train_loader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=num_workers,
    pin_memory=False,  # åœ¨å•è¿›ç¨‹æ¨¡å¼ä¸‹ç¦ç”¨pin_memory
    drop_last=True,  # ç¡®ä¿æ‰¹æ¬¡å¤§å°ä¸€è‡´
    prefetch_factor=prefetch_factor,
    persistent_workers=persistent_workers
)

val_loader = DataLoader(
    val_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=num_workers,
    pin_memory=False,
    prefetch_factor=prefetch_factor,
    persistent_workers=persistent_workers
)

test_loader = DataLoader(
    test_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=num_workers,
    pin_memory=False,
    prefetch_factor=prefetch_factor,
    persistent_workers=persistent_workers
)

print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")
print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)} (æ‰¹æ¬¡å¤§å°: {batch_size})")
print(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
print(f"æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}")
print(f"æ•°æ®åŠ è½½workeræ•°: {num_workers}")
print("âš ï¸ ä½¿ç”¨å•è¿›ç¨‹æ¨¡å¼ç¡®ä¿ç¨³å®šæ€§ï¼Œå¦‚éœ€å¤šè¿›ç¨‹è¯·ç¡®ä¿æ•°æ®è·¯å¾„æ­£ç¡®ä¸”å¸§æå–å‡½æ•°å¯ç”¨")