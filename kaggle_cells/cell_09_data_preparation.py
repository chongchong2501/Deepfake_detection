# Cell 9: æ•°æ®å‡†å¤‡ - ç›´æ¥é¢„æå–ä¼˜åŒ–ç‰ˆæœ¬

# ==================== é…ç½®å‚æ•° ====================
# æ•°æ®é›†è·¯å¾„é…ç½®
DATA_BASE_DIR = '/kaggle/input/ff-c23/FaceForensics++_C23'

# å¯è‡ªå®šä¹‰é¢„å¤„ç†è§†é¢‘æ•°é‡
MAX_REAL_VIDEOS = 600      # çœŸå®è§†é¢‘æ•°é‡
MAX_FAKE_VIDEOS = 600      # å‡è§†é¢‘æ•°é‡
MAX_FRAMES_PER_VIDEO = 16  # æ¯ä¸ªè§†é¢‘æå–çš„å¸§æ•°

# çœŸå‡è§†é¢‘æ¯”ä¾‹å»ºè®®
# 1:1 - å¹³è¡¡æ•°æ®é›†ï¼Œé€‚åˆå¤§å¤šæ•°æƒ…å†µ
# 1:2 - è½»å¾®åå‘å‡è§†é¢‘ï¼Œæé«˜å‡è§†é¢‘æ£€æµ‹èƒ½åŠ›
# 1:3 - ä¸­ç­‰åå‘å‡è§†é¢‘ï¼Œé€‚åˆå®é™…åº”ç”¨åœºæ™¯
# 1:6 - å¼ºçƒˆåå‘å‡è§†é¢‘ï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œåˆ†å¸ƒ
REAL_FAKE_RATIO = "1:1"  # å½“å‰æ¯”ä¾‹

def direct_extract_frames_from_videos(base_data_dir, max_real=MAX_REAL_VIDEOS, max_fake=MAX_FAKE_VIDEOS, max_frames=MAX_FRAMES_PER_VIDEO, frames_dir='./data/frames'):
    """
    ç›´æ¥ä»è§†é¢‘ç›®å½•é¢„æå–å¸§åˆ°ç¡¬ç›˜ - ä¸€æ­¥åˆ°ä½çš„ä¼˜åŒ–æ–¹æ¡ˆ
    
    Args:
        base_data_dir: æ•°æ®é›†æ ¹ç›®å½•
        max_real: æœ€å¤§çœŸå®è§†é¢‘æ•°é‡
        max_fake: æœ€å¤§å‡è§†é¢‘æ•°é‡
        max_frames: æ¯ä¸ªè§†é¢‘æå–çš„å¸§æ•°
        frames_dir: å¸§å­˜å‚¨ç›®å½•
    
    Returns:
        extracted_data: åŒ…å«é¢„æå–å¸§è·¯å¾„çš„æ•°æ®åˆ—è¡¨
    """
    print(f"ğŸ¬ å¼€å§‹ç›´æ¥é¢„æå–è§†é¢‘å¸§åˆ° {frames_dir}...")
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs('./data', exist_ok=True)
    os.makedirs(frames_dir, exist_ok=True)
    
    # æ‰“å°è®¾å¤‡ä¿¡æ¯
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± æ•°æ®å¤„ç†ä½¿ç”¨è®¾å¤‡: {device}")
    
    extracted_data = []
    fake_methods = ['Deepfakes', 'Face2Face', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'DeepFakeDetection']
    
    # ==================== å¤„ç†çœŸå®è§†é¢‘ ====================
    print("ğŸ¯ å¼€å§‹å¤„ç†çœŸå®è§†é¢‘...")
    original_dir = os.path.join(base_data_dir, 'original')
    if os.path.exists(original_dir):
        video_files = [f for f in os.listdir(original_dir)
                      if f.endswith(('.mp4', '.avi', '.mov'))]
        
        if len(video_files) > max_real:
            video_files = random.sample(video_files, max_real)
        
        print(f"æ‰¾åˆ° {len(video_files)} ä¸ªçœŸå®è§†é¢‘")
        
        for video_file in tqdm(video_files, desc="å¤„ç†çœŸå®è§†é¢‘"):
            try:
                video_path = os.path.join(original_dir, video_file)
                
                # ç”Ÿæˆå¸§æ–‡ä»¶è·¯å¾„
                video_name = os.path.splitext(video_file)[0]
                frame_file = os.path.join(frames_dir, f"{video_name}_frames.pt")
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                if os.path.exists(frame_file):
                    # å¯¹äºå·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œæˆ‘ä»¬éœ€è¦åŠ è½½å®ƒæ¥è·å–å¸§æ•°
                    try:
                        existing_frames = torch.load(frame_file)
                        num_frames = len(existing_frames)
                    except:
                        num_frames = max_frames  # é»˜è®¤å€¼
                    
                    extracted_data.append({
                        'frame_path': frame_file,
                        'label': 0,
                        'method': 'original',
                        'original_video': video_path,
                        'num_frames': num_frames
                    })
                    continue
                
                # ç›´æ¥æå–å¸§å¹¶ä¿å­˜
                frames = extract_frames_memory_efficient(video_path, max_frames)
                
                if len(frames) >= max_frames // 2:  # è‡³å°‘è¦æœ‰ä¸€åŠçš„å¸§
                    # è½¬æ¢ä¸ºtensorå¹¶ä¿å­˜
                    frames_tensor = torch.stack([
                        torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0
                        for frame in frames
                    ])
                    
                    torch.save(frames_tensor, frame_file)
                    
                    extracted_data.append({
                        'frame_path': frame_file,
                        'label': 0,  # çœŸå®è§†é¢‘
                        'method': 'original',
                        'original_video': video_path,
                        'num_frames': len(frames)
                    })
                else:
                    print(f"âš ï¸ è·³è¿‡å¸§æ•°ä¸è¶³çš„è§†é¢‘: {video_file}")
                    
            except Exception as e:
                print(f"âŒ å¤„ç†çœŸå®è§†é¢‘å¤±è´¥ {video_file}: {e}")
                continue
    
    # ==================== å¤„ç†å‡è§†é¢‘ - å¹³å‡åˆ†é…ç­–ç•¥ ====================
    print("ğŸ­ å¼€å§‹å¤„ç†å‡è§†é¢‘...")
    
    # ç»Ÿè®¡æ¯ç§æ–¹æ³•çš„å¯ç”¨è§†é¢‘æ•°é‡
    method_videos = {}
    total_available_fake = 0
    
    for method in fake_methods:
        method_dir = os.path.join(base_data_dir, method)
        if os.path.exists(method_dir):
            videos = [os.path.join(method_dir, f) for f in os.listdir(method_dir) 
                     if f.endswith(('.mp4', '.avi', '.mov'))]
            method_videos[method] = videos
            total_available_fake += len(videos)
            print(f"  {method}: {len(videos)} ä¸ªè§†é¢‘")
        else:
            method_videos[method] = []
            print(f"  {method}: ç›®å½•ä¸å­˜åœ¨")
    
    print(f"æ€»å…±å¯ç”¨å‡è§†é¢‘: {total_available_fake} ä¸ª")
    
    # è®¡ç®—æ¯ç§æ–¹æ³•åº”è¯¥é‡‡æ ·çš„è§†é¢‘æ•°é‡ï¼ˆå¹³å‡åˆ†é…ï¼‰
    available_methods = [method for method in fake_methods if len(method_videos[method]) > 0]
    if not available_methods:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å‡è§†é¢‘æ–¹æ³•")
        return extracted_data
    
    videos_per_method = max_fake // len(available_methods)
    remaining_videos = max_fake % len(available_methods)
    
    print(f"å¹³å‡åˆ†é…ç­–ç•¥: æ¯ç§æ–¹æ³• {videos_per_method} ä¸ªè§†é¢‘")
    if remaining_videos > 0:
        print(f"å‰©ä½™ {remaining_videos} ä¸ªè§†é¢‘å°†åˆ†é…ç»™å‰ {remaining_videos} ç§æ–¹æ³•")
    
    # ä¸ºæ¯ç§æ–¹æ³•é‡‡æ ·å¹¶ç›´æ¥å¤„ç†è§†é¢‘
    for i, method in enumerate(available_methods):
        # è®¡ç®—å½“å‰æ–¹æ³•åº”è¯¥é‡‡æ ·çš„æ•°é‡
        current_method_quota = videos_per_method
        if i < remaining_videos:  # å‰å‡ ç§æ–¹æ³•å¤šåˆ†é…ä¸€ä¸ª
            current_method_quota += 1
        
        available_videos = method_videos[method]
        
        # å¦‚æœå¯ç”¨è§†é¢‘æ•°é‡å°‘äºé…é¢ï¼Œå…¨éƒ¨ä½¿ç”¨
        if len(available_videos) <= current_method_quota:
            method_selected = available_videos
            print(f"  {method}: ä½¿ç”¨å…¨éƒ¨ {len(method_selected)} ä¸ªè§†é¢‘")
        else:
            # éšæœºé‡‡æ ·æŒ‡å®šæ•°é‡
            method_selected = random.sample(available_videos, current_method_quota)
            print(f"  {method}: é‡‡æ · {len(method_selected)} ä¸ªè§†é¢‘")
        
        # ç›´æ¥å¤„ç†é€‰æ‹©çš„è§†é¢‘
        for video_path in tqdm(method_selected, desc=f"å¤„ç†{method}"):
            try:
                # ç”Ÿæˆå¸§æ–‡ä»¶è·¯å¾„
                video_name = os.path.splitext(os.path.basename(video_path))[0]
                frame_file = os.path.join(frames_dir, f"{video_name}_frames.pt")
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                if os.path.exists(frame_file):
                    # å¯¹äºå·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œæˆ‘ä»¬éœ€è¦åŠ è½½å®ƒæ¥è·å–å¸§æ•°
                    try:
                        existing_frames = torch.load(frame_file)
                        num_frames = len(existing_frames)
                    except:
                        num_frames = max_frames  # é»˜è®¤å€¼
                    
                    extracted_data.append({
                        'frame_path': frame_file,
                        'label': 1,
                        'method': method,
                        'original_video': video_path,
                        'num_frames': num_frames
                    })
                    continue
                
                # ç›´æ¥æå–å¸§å¹¶ä¿å­˜
                frames = extract_frames_memory_efficient(video_path, max_frames)
                
                if len(frames) >= max_frames // 2:
                    # è½¬æ¢ä¸ºtensorå¹¶ä¿å­˜
                    frames_tensor = torch.stack([
                        torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0
                        for frame in frames
                    ])
                    
                    torch.save(frames_tensor, frame_file)
                    
                    extracted_data.append({
                        'frame_path': frame_file,
                        'label': 1,  # å‡è§†é¢‘
                        'method': method,
                        'original_video': video_path,
                        'num_frames': len(frames)
                    })
                else:
                    print(f"âš ï¸ è·³è¿‡å¸§æ•°ä¸è¶³çš„è§†é¢‘: {os.path.basename(video_path)}")
                    
            except Exception as e:
                print(f"âŒ å¤„ç†å‡è§†é¢‘å¤±è´¥ {os.path.basename(video_path)}: {e}")
                continue
    
    # ç»Ÿè®¡æœ€ç»ˆç»“æœ
    real_count = sum(1 for item in extracted_data if item['label'] == 0)
    fake_count = sum(1 for item in extracted_data if item['label'] == 1)
    
    method_counts = {}
    for item in extracted_data:
        if item['label'] == 1:  # åªç»Ÿè®¡å‡è§†é¢‘
            method = item['method']
            method_counts[method] = method_counts.get(method, 0) + 1
    
    print(f"\nâœ… ç›´æ¥é¢„æå–å®Œæˆ: {len(extracted_data)} ä¸ªè§†é¢‘")
    print(f"   çœŸå®è§†é¢‘: {real_count} ä¸ª")
    print(f"   å‡è§†é¢‘: {fake_count} ä¸ª")
    print("å‡è§†é¢‘æ–¹æ³•åˆ†å¸ƒ:")
    for method, count in method_counts.items():
        print(f"  {method}: {count} ä¸ªè§†é¢‘")
    
    return extracted_data


print(f"ğŸ“‹ é…ç½®å‚æ•°:")
print(f"   çœŸå®è§†é¢‘æ•°é‡: {MAX_REAL_VIDEOS}")
print(f"   å‡è§†é¢‘æ•°é‡: {MAX_FAKE_VIDEOS}")
print(f"   æ¯è§†é¢‘å¸§æ•°: {MAX_FRAMES_PER_VIDEO}")
print(f"   çœŸå‡æ¯”ä¾‹: {REAL_FAKE_RATIO}")
print(f"   é¢„è®¡æ€»æ ·æœ¬: {MAX_REAL_VIDEOS + MAX_FAKE_VIDEOS}")

# ç›´æ¥é¢„æå–å¸§ - ä¸€æ­¥åˆ°ä½çš„ä¼˜åŒ–æ–¹æ¡ˆ
extracted_data = direct_extract_frames_from_videos(
    base_data_dir=DATA_BASE_DIR,
    max_real=MAX_REAL_VIDEOS,
    max_fake=MAX_FAKE_VIDEOS,
    max_frames=MAX_FRAMES_PER_VIDEO
)

if len(extracted_data) == 0:
    raise ValueError("âŒ é¢„æå–å¸§å¤±è´¥ï¼Œæ— æ³•ç»§ç»­ã€‚è¯·æ£€æŸ¥è§†é¢‘è·¯å¾„å’Œæ ¼å¼ã€‚")

# ç»Ÿè®¡æ€»ä½“æ•°æ®åˆ†å¸ƒ
total_real = sum(1 for item in extracted_data if item['label'] == 0)
total_fake = sum(1 for item in extracted_data if item['label'] == 1)
print(f"\nğŸ“Š æ€»ä½“æ•°æ®ç»Ÿè®¡: {len(extracted_data)} ä¸ªæ ·æœ¬")
print(f"   çœŸå®è§†é¢‘: {total_real} ä¸ª")
print(f"   å‡è§†é¢‘: {total_fake} ä¸ª")

# æ•°æ®é›†åˆ†å‰²
print("\nğŸ“Š åˆ†å‰²æ•°æ®é›†...")
train_data, val_data, test_data = create_dataset_split(
    extracted_data,  # ä½¿ç”¨é¢„æå–çš„æ•°æ®
    test_size=0.15,  # æµ‹è¯•é›†æ¯”ä¾‹
    val_size=0.15    # éªŒè¯é›†æ¯”ä¾‹
)

print(f"è®­ç»ƒé›†: {len(train_data)} æ ·æœ¬")
print(f"éªŒè¯é›†: {len(val_data)} æ ·æœ¬")
print(f"æµ‹è¯•é›†: {len(test_data)} æ ·æœ¬")

# ä¿å­˜æ•°æ®é›†
print("\nğŸ’¾ ä¿å­˜æ•°æ®é›†...")
save_dataset_to_csv(train_data, './data/train.csv')
save_dataset_to_csv(val_data, './data/val.csv')
save_dataset_to_csv(test_data, './data/test.csv')

# æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡
print("\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
for name, data in [("è®­ç»ƒ", train_data), ("éªŒè¯", val_data), ("æµ‹è¯•", test_data)]:
    real_count = sum(1 for item in data if item['label'] == 0)
    fake_count = sum(1 for item in data if item['label'] == 1)
    print(f"{name}é›†: çœŸå®={real_count}, ä¼ªé€ ={fake_count}, æ€»è®¡={len(data)}")

print(f"\nâœ… æ•°æ®å‡†å¤‡å®Œæˆï¼")
print(f"   ğŸ“Š æ•°æ®åˆ†å¸ƒ: çœŸå®è§†é¢‘ {total_real} | å‡è§†é¢‘ {total_fake}")
print(f"   ğŸ“ˆ å½“å‰æ¯”ä¾‹: {REAL_FAKE_RATIO}")
print(f"   ğŸ¯ æ•°æ®é›†è§„æ¨¡: {len(extracted_data)} ä¸ªæ ·æœ¬")
print(f"   ğŸš€ å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼")