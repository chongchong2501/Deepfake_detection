# Cell 11: æ¨¡å‹åˆå§‹åŒ–å’Œè®­ç»ƒé…ç½® - Kaggle T4 GPUä¼˜åŒ–ç‰ˆæœ¬
print("ğŸ¤– åˆ›å»ºå’Œé…ç½®æ¨¡å‹...")

# è®­ç»ƒé…ç½®å‚æ•°
batch_size = 2

# åˆ›å»ºæ¨¡å‹ - é’ˆå¯¹Kaggle T4 GPUä¼˜åŒ–
model = OptimizedDeepfakeDetector(
    num_classes=1,
    dropout_rate=0.3,
    use_attention=True,
    use_multimodal=True,  # å¯ç”¨å¤šæ¨¡æ€ç‰¹å¾èåˆ
    ensemble_mode=False   # å•æ¨¡å‹æ¨¡å¼
).to(device)

# å¤šGPUå¹¶è¡Œæ”¯æŒ
if torch.cuda.is_available() and torch.cuda.device_count() > 1:
    print(f"ğŸš€ å¯ç”¨å¤šGPUå¹¶è¡Œè®­ç»ƒï¼Œä½¿ç”¨ {torch.cuda.device_count()} ä¸ªGPU")
    model = nn.DataParallel(model)
    # è°ƒæ•´æ‰¹æ¬¡å¤§å°ä»¥å……åˆ†åˆ©ç”¨å¤šGPU
    effective_batch_size = batch_size * torch.cuda.device_count()
    print(f"ğŸ“¦ æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {effective_batch_size} (å•GPU: {batch_size})")
else:
    print("ğŸ“ å•GPUè®­ç»ƒæ¨¡å¼")

print(f"âœ… æ¨¡å‹å·²åˆ›å»ºå¹¶ç§»åŠ¨åˆ° {device}")
print(f"ğŸ“Š æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

# ä¼˜åŒ–GPUå†…å­˜é…ç½® - åŒT4 GPUé…ç½®
if torch.cuda.is_available():
    torch.cuda.set_per_process_memory_fraction(0.8)  # åŒT4å¯ä»¥ä½¿ç”¨æ›´å¤šå†…å­˜
    print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
    print(f"ğŸ’¾ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")

# æŸå¤±å‡½æ•° - ä½¿ç”¨ç±»åˆ«æƒé‡å¹³è¡¡
# è®¡ç®—ç±»åˆ«æƒé‡ - ä¿®å¤ç‰ˆæœ¬
if 'train_loader' in globals() and train_loader is not None:
    # ä»train_loaderè·å–æ•°æ®é›†
    train_dataset = train_loader.dataset
    
    if hasattr(train_dataset, 'real_count') and hasattr(train_dataset, 'fake_count'):
        # ä½¿ç”¨é¢„è®¡ç®—çš„ç»Ÿè®¡ä¿¡æ¯
        real_count = train_dataset.real_count
        fake_count = train_dataset.fake_count
    else:
        # å›é€€æ–¹æ¡ˆï¼šæ‰‹åŠ¨è®¡ç®—
        if hasattr(train_dataset, 'data_list') and train_dataset.data_list is not None:
            real_count = sum(1 for item in train_dataset.data_list if item['label'] == 0)
            fake_count = sum(1 for item in train_dataset.data_list if item['label'] == 1)
        elif hasattr(train_dataset, 'df') and train_dataset.df is not None:
            real_count = len(train_dataset.df[train_dataset.df['label'] == 0])
            fake_count = len(train_dataset.df[train_dataset.df['label'] == 1])
        else:
            # é»˜è®¤å€¼
            real_count = 1
            fake_count = 1
            print("âš ï¸ æ— æ³•è·å–ç±»åˆ«åˆ†å¸ƒï¼Œä½¿ç”¨é»˜è®¤æƒé‡")
else:
    # å¦‚æœæ²¡æœ‰train_loaderï¼Œä½¿ç”¨é»˜è®¤å€¼
    real_count = 1
    fake_count = 1
    print("âš ï¸ train_loaderæœªå®šä¹‰ï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«æƒé‡")

# ç¡®ä¿è®¡æ•°ä¸ä¸ºé›¶
real_count = max(real_count, 1)
fake_count = max(fake_count, 1)

pos_weight = torch.tensor([real_count / fake_count], device=device)

print(f"ğŸ“Š ç±»åˆ«åˆ†å¸ƒ - çœŸå®: {real_count}, ä¼ªé€ : {fake_count}")
print(f"âš–ï¸ æ­£æ ·æœ¬æƒé‡: {pos_weight.item():.2f}")

# ä½¿ç”¨FocalLosså¤„ç†ç±»åˆ«ä¸å¹³è¡¡
criterion = FocalLoss(
    alpha=0.25,
    gamma=2.0,  # é™ä½gammaå€¼ï¼Œå‡å°‘å¯¹å›°éš¾æ ·æœ¬çš„è¿‡åº¦å…³æ³¨
    pos_weight=pos_weight,
    reduction='mean'
)

# ä¼˜åŒ–å™¨é…ç½® - é™ä½å­¦ä¹ ç‡é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
optimizer = optim.AdamW(
    model.parameters(),
    lr=1e-5,  # å¤§å¹…é™ä½å­¦ä¹ ç‡ï¼Œä»2e-4é™åˆ°1e-5
    weight_decay=0.01,  # å¢åŠ æƒé‡è¡°å‡
    betas=(0.9, 0.999),
    eps=1e-8
)

# å­¦ä¹ ç‡è°ƒåº¦å™¨ - æ›´ä¿å®ˆçš„ç­–ç•¥
scheduler = CosineAnnealingWarmRestarts(
    optimizer,
    T_0=5,  # å‡å°‘é‡å¯å‘¨æœŸ
    T_mult=1,  # å‘¨æœŸå€å¢å› å­
    eta_min=1e-7  # æ›´ä½çš„æœ€å°å­¦ä¹ ç‡
)

# æ—©åœæœºåˆ¶ - æ›´ä¸¥æ ¼çš„ç›‘æ§
early_stopping = EarlyStopping(
    patience=5,  # å‡å°‘è€å¿ƒå€¼
    min_delta=0.001,  # å¢åŠ æœ€å°æ”¹è¿›é˜ˆå€¼
    restore_best_weights=True
)

# æ··åˆç²¾åº¦è®­ç»ƒ - ä»…åœ¨æ”¯æŒçš„GPUä¸Šå¯ç”¨
use_amp = torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 7
if use_amp:
    scaler = GradScaler()
    print("âœ… å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP)")
else:
    scaler = None
    print("ğŸ“ ä½¿ç”¨FP32è®­ç»ƒ (å…¼å®¹æ€§æ¨¡å¼)")

# è®­ç»ƒé…ç½® - åŒT4 GPUä¼˜åŒ–
num_epochs = 15  # é€‚ä¸­çš„è®­ç»ƒè½®æ•°ï¼Œé€‚åˆåŒT4é…ç½®
print(f"ğŸ¯ è®­ç»ƒé…ç½®:")
print(f"  - è®­ç»ƒè½®æ•°: {num_epochs}")
print(f"  - åˆå§‹å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.2e}")
print(f"  - æƒé‡è¡°å‡: {optimizer.param_groups[0]['weight_decay']:.2e}")
print(f"  - æ—©åœè€å¿ƒå€¼: {early_stopping.patience}")
print(f"  - æ··åˆç²¾åº¦: {'å¯ç”¨' if use_amp else 'ç¦ç”¨'}")

print("âœ… æ¨¡å‹å’Œè®­ç»ƒé…ç½®å®Œæˆ")