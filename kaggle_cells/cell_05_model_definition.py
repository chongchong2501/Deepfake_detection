# Cell 5: æ¨¡å‹å®šä¹‰ - é›†æˆå¤šæ¨¡æ€ç‰¹å¾å’ŒEnsembleç­–ç•¥

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models

class OptimizedDeepfakeDetector(nn.Module):
    """ä¼˜åŒ–çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨ - é›†æˆå¤šæ¨¡æ€ç‰¹å¾å’ŒEnsembleç­–ç•¥"""
    
    def __init__(self, num_classes=1, dropout_rate=0.3, use_attention=True, 
                 use_multimodal=False, ensemble_mode=False):
        super(OptimizedDeepfakeDetector, self).__init__()
        
        self.use_attention = use_attention
        self.use_multimodal = use_multimodal
        self.ensemble_mode = ensemble_mode
        
        # ä¸»å¹²ç½‘ç»œ - ResNet50
        self.backbone = models.resnet50(pretrained=True)
        backbone_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()  # ç§»é™¤æœ€åçš„åˆ†ç±»å±‚
        
        # æ—¶åºç‰¹å¾æå–
        self.temporal_conv = nn.Sequential(
            nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1)),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool3d((1, 7, 7))
        )
        
        # æ³¨æ„åŠ›æœºåˆ¶
        if use_attention:
            self.attention = nn.MultiheadAttention(
                embed_dim=backbone_features, 
                num_heads=8, 
                dropout=dropout_rate,
                batch_first=True
            )
            self.attention_norm = nn.LayerNorm(backbone_features)
        
        # å¤šæ¨¡æ€ç‰¹å¾èåˆ
        if use_multimodal:
            # é¢‘åŸŸç‰¹å¾å¤„ç†
            self.fourier_fc = nn.Sequential(
                nn.Linear(512, 256),  # å‡è®¾é¢‘åŸŸç‰¹å¾ç»´åº¦ä¸º512
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(256, 128)
            )
            
            # å‹ç¼©ä¼ªå½±ç‰¹å¾å¤„ç†
            self.compression_fc = nn.Sequential(
                nn.Linear(3, 64),  # å‹ç¼©ç‰¹å¾ç»´åº¦ä¸º3
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(64, 32)
            )
            
            # æ—¶åºä¸€è‡´æ€§ç‰¹å¾å¤„ç†
            self.temporal_fc = nn.Sequential(
                nn.Linear(4, 64),  # æ—¶åºç‰¹å¾ç»´åº¦ä¸º4
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(64, 32)
            )
            
            # ç‰¹å¾èåˆå±‚
            fusion_dim = backbone_features + 128 + 32 + 32  # ä¸»å¹² + é¢‘åŸŸ + å‹ç¼© + æ—¶åº
            self.fusion_layer = nn.Sequential(
                nn.Linear(fusion_dim, 512),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(512, 256)
            )
            final_features = 256
        else:
            final_features = backbone_features
        
        # é›†æˆæ¨¡å¼çš„å¤šä¸ªåˆ†ç±»å¤´
        if ensemble_mode:
            # ä¸»åˆ†ç±»å™¨
            self.main_classifier = nn.Sequential(
                nn.Dropout(dropout_rate),
                nn.Linear(final_features, 128),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(128, num_classes)
            )
            
            # è¾…åŠ©åˆ†ç±»å™¨1 - ä¸“æ³¨äºç©ºé—´ç‰¹å¾
            self.spatial_classifier = nn.Sequential(
                nn.Dropout(dropout_rate),
                nn.Linear(final_features, 64),
                nn.ReLU(inplace=True),
                nn.Linear(64, num_classes)
            )
            
            # è¾…åŠ©åˆ†ç±»å™¨2 - ä¸“æ³¨äºæ—¶åºç‰¹å¾
            self.temporal_classifier = nn.Sequential(
                nn.Dropout(dropout_rate),
                nn.Linear(final_features, 64),
                nn.ReLU(inplace=True),
                nn.Linear(64, num_classes)
            )
            
            # é›†æˆæƒé‡ï¼ˆå¯å­¦ä¹ ï¼‰
            self.ensemble_weights = nn.Parameter(torch.ones(3) / 3)
            
        else:
            # å•ä¸€åˆ†ç±»å™¨
            self.classifier = nn.Sequential(
                nn.Dropout(dropout_rate),
                nn.Linear(final_features, 256),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(256, 128),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(128, num_classes)
            )
        
        # åˆå§‹åŒ–æƒé‡
        self._initialize_weights()
        
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        print(f"   - æ³¨æ„åŠ›æœºåˆ¶: {'å¯ç”¨' if use_attention else 'ç¦ç”¨'}")
        print(f"   - å¤šæ¨¡æ€èåˆ: {'å¯ç”¨' if use_multimodal else 'ç¦ç”¨'}")
        print(f"   - é›†æˆæ¨¡å¼: {'å¯ç”¨' if ensemble_mode else 'ç¦ç”¨'}")

    def _initialize_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Conv3d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')

    def forward(self, x, additional_features=None):
        """
        å‰å‘ä¼ æ’­
        Args:
            x: è§†é¢‘å¼ é‡ (B, T, C, H, W)
            additional_features: é¢å¤–ç‰¹å¾å­—å…¸
        """
        batch_size, num_frames, channels, height, width = x.shape
        
        # æå–æ¯å¸§çš„ç©ºé—´ç‰¹å¾
        x_reshaped = x.view(batch_size * num_frames, channels, height, width)
        spatial_features = self.backbone(x_reshaped)  # (B*T, features)
        spatial_features = spatial_features.view(batch_size, num_frames, -1)  # (B, T, features)
        
        # æ—¶åºç‰¹å¾èšåˆ
        if self.use_attention:
            # ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶èšåˆæ—¶åºç‰¹å¾
            attended_features, attention_weights = self.attention(
                spatial_features, spatial_features, spatial_features
            )
            attended_features = self.attention_norm(attended_features + spatial_features)
            # å…¨å±€å¹³å‡æ± åŒ–
            temporal_features = torch.mean(attended_features, dim=1)  # (B, features)
        else:
            # ç®€å•å¹³å‡æ± åŒ–
            temporal_features = torch.mean(spatial_features, dim=1)  # (B, features)
        
        # å¤šæ¨¡æ€ç‰¹å¾èåˆ
        if self.use_multimodal and additional_features is not None:
            fusion_features = [temporal_features]
            
            # å¤„ç†é¢‘åŸŸç‰¹å¾
            if 'fourier' in additional_features:
                fourier_feat = additional_features['fourier']
                if isinstance(fourier_feat, dict):
                    # å°†å­—å…¸è½¬æ¢ä¸ºå¼ é‡
                    fourier_tensor = torch.stack([
                        torch.tensor(list(fourier_feat.values()), dtype=torch.float32)
                        for _ in range(batch_size)
                    ]).to(temporal_features.device)
                else:
                    fourier_tensor = fourier_feat.to(temporal_features.device)
                
                fourier_processed = self.fourier_fc(fourier_tensor)
                fusion_features.append(fourier_processed)
            
            # å¤„ç†å‹ç¼©ä¼ªå½±ç‰¹å¾
            if 'compression' in additional_features:
                comp_feat = additional_features['compression']
                if isinstance(comp_feat, dict):
                    comp_tensor = torch.stack([
                        torch.tensor([
                            comp_feat['mean_dct_energy'],
                            comp_feat['mean_edge_density'],
                            comp_feat['std_dct_energy']
                        ], dtype=torch.float32)
                        for _ in range(batch_size)
                    ]).to(temporal_features.device)
                else:
                    comp_tensor = comp_feat.to(temporal_features.device)
                
                comp_processed = self.compression_fc(comp_tensor)
                fusion_features.append(comp_processed)
            
            # å¤„ç†æ—¶åºä¸€è‡´æ€§ç‰¹å¾
            if 'temporal' in additional_features:
                temp_feat = additional_features['temporal']
                if isinstance(temp_feat, dict):
                    temp_tensor = torch.stack([
                        torch.tensor([
                            temp_feat['mean_frame_diff'],
                            temp_feat['std_frame_diff'],
                            temp_feat['max_frame_diff'],
                            temp_feat['temporal_smoothness']
                        ], dtype=torch.float32)
                        for _ in range(batch_size)
                    ]).to(temporal_features.device)
                else:
                    temp_tensor = temp_feat.to(temporal_features.device)
                
                temp_processed = self.temporal_fc(temp_tensor)
                fusion_features.append(temp_processed)
            
            # ç‰¹å¾èåˆ
            if len(fusion_features) > 1:
                fused_features = torch.cat(fusion_features, dim=1)
                final_features = self.fusion_layer(fused_features)
            else:
                final_features = temporal_features
        else:
            final_features = temporal_features
        
        # åˆ†ç±»é¢„æµ‹
        if self.ensemble_mode:
            # é›†æˆé¢„æµ‹
            main_pred = self.main_classifier(final_features)
            spatial_pred = self.spatial_classifier(final_features)
            temporal_pred = self.temporal_classifier(final_features)
            
            # åŠ æƒèåˆ
            weights = F.softmax(self.ensemble_weights, dim=0)
            ensemble_pred = (weights[0] * main_pred + 
                           weights[1] * spatial_pred + 
                           weights[2] * temporal_pred)
            
            if self.training:
                # è®­ç»ƒæ—¶è¿”å›æ‰€æœ‰é¢„æµ‹ç”¨äºå¤šä»»åŠ¡å­¦ä¹ 
                return {
                    'main': main_pred,
                    'spatial': spatial_pred,
                    'temporal': temporal_pred,
                    'ensemble': ensemble_pred
                }
            else:
                # æ¨ç†æ—¶åªè¿”å›é›†æˆç»“æœ
                return ensemble_pred
        else:
            # å•ä¸€é¢„æµ‹
            return self.classifier(final_features)

    def get_attention_weights(self, x):
        """è·å–æ³¨æ„åŠ›æƒé‡ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰"""
        if not self.use_attention:
            return None
        
        batch_size, num_frames, channels, height, width = x.shape
        x_reshaped = x.view(batch_size * num_frames, channels, height, width)
        spatial_features = self.backbone(x_reshaped)
        spatial_features = spatial_features.view(batch_size, num_frames, -1)
        
        _, attention_weights = self.attention(
            spatial_features, spatial_features, spatial_features
        )
        
        return attention_weights

    def enable_ensemble_mode(self):
        """å¯ç”¨é›†æˆæ¨¡å¼"""
        self.ensemble_mode = True
        print("ğŸ¯ é›†æˆæ¨¡å¼å·²å¯ç”¨")

    def disable_ensemble_mode(self):
        """ç¦ç”¨é›†æˆæ¨¡å¼"""
        self.ensemble_mode = False
        print("ğŸ¯ é›†æˆæ¨¡å¼å·²ç¦ç”¨")

    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        return {
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'use_attention': self.use_attention,
            'use_multimodal': self.use_multimodal,
            'ensemble_mode': self.ensemble_mode
        }

def create_ensemble_models(num_models=3, **kwargs):
    """åˆ›å»ºå¤šä¸ªæ¨¡å‹ç”¨äºé›†æˆå­¦ä¹ """
    models = []
    for i in range(num_models):
        # ä¸ºæ¯ä¸ªæ¨¡å‹ä½¿ç”¨ä¸åŒçš„é…ç½®
        model_kwargs = kwargs.copy()
        if i == 0:
            model_kwargs.update({'use_attention': True, 'dropout_rate': 0.3})
        elif i == 1:
            model_kwargs.update({'use_attention': False, 'dropout_rate': 0.4})
        else:
            model_kwargs.update({'use_attention': True, 'dropout_rate': 0.2})
        
        model = OptimizedDeepfakeDetector(**model_kwargs)
        models.append(model)
    
    print(f"âœ… åˆ›å»ºäº† {num_models} ä¸ªé›†æˆæ¨¡å‹")
    return models

print("âœ… ä¼˜åŒ–æ¨¡å‹å®šä¹‰å®Œæˆ")