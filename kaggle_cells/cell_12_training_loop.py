# Cell 12: è®­ç»ƒå¾ªç¯ - Kaggle T4 GPUä¼˜åŒ–ç‰ˆæœ¬

# ç¡®ä¿æ¨¡å‹ä¿å­˜ç›®å½•å­˜åœ¨
os.makedirs('./models', exist_ok=True)

print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
print(f"ğŸ“Š è®­ç»ƒé…ç½®: {len(train_loader)} ä¸ªè®­ç»ƒæ‰¹æ¬¡, {len(val_loader)} ä¸ªéªŒè¯æ‰¹æ¬¡")
print(f"ğŸ¯ æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
print(f"ğŸ’¾ è®¾å¤‡: {device}")
print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {batch_size}")

if torch.cuda.is_available():
    print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
    torch.cuda.reset_peak_memory_stats()

# è®­ç»ƒå†å²è®°å½•
train_history = {
    'train_loss': [],
    'val_loss': [],
    'train_acc': [],
    'val_acc': [],
    'train_auc': [],
    'val_auc': []
}
best_val_loss = float('inf')
best_val_acc = 0.0
best_val_auc = 0.0
best_model_state = None

# è®­ç»ƒå¾ªç¯
print("\nğŸ”„ å¼€å§‹è®­ç»ƒå¾ªç¯...")
for epoch in range(num_epochs):
    epoch_start_time = time.time()
    print(f"\nEpoch {epoch+1}/{num_epochs}")
    
    # è®­ç»ƒé˜¶æ®µ
    train_loss, train_acc, train_auc = train_epoch(model, train_loader, criterion, optimizer, device, scaler)
    
    # éªŒè¯é˜¶æ®µ
    val_loss, val_acc, val_auc = validate_epoch(model, val_loader, criterion, device, scaler)
    
    # è®°å½•å†å²
    train_history['train_loss'].append(train_loss)
    train_history['train_acc'].append(train_acc)
    train_history['train_auc'].append(train_auc)
    train_history['val_loss'].append(val_loss)
    train_history['val_acc'].append(val_acc)
    train_history['val_auc'].append(val_auc)
    
    # å­¦ä¹ ç‡è°ƒåº¦
    scheduler.step()
    current_lr = optimizer.param_groups[0]['lr']
    
    # è®¡ç®—epochæ—¶é—´
    epoch_time = time.time() - epoch_start_time
    
    # æ‰“å°ç»“æœ
    print(f"è®­ç»ƒ: Loss={train_loss:.4f}, Acc={train_acc:.2f}%, AUC={train_auc:.4f}")
    print(f"éªŒè¯: Loss={val_loss:.4f}, Acc={val_acc:.2f}%, AUC={val_auc:.4f}")
    print(f"å­¦ä¹ ç‡: {current_lr:.2e}, ç”¨æ—¶: {epoch_time:.1f}s")
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        best_val_acc = val_acc
        best_val_auc = val_auc
        best_model_state = model.state_dict().copy()
        print(f"ğŸ¯ æ–°çš„æœ€ä½³æ¨¡å‹! Loss: {best_val_loss:.4f}, Acc: {best_val_acc:.2f}%, AUC: {best_val_auc:.4f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°æ–‡ä»¶
        torch.save({
            'epoch': epoch,
            'model_state_dict': best_model_state,
            'optimizer_state_dict': optimizer.state_dict(),
            'best_val_loss': best_val_loss,
            'best_val_acc': best_val_acc,
            'best_val_auc': best_val_auc,
            'train_history': train_history
        }, './models/best_model.pth')
        print("ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜")
    
    # æ—©åœæ£€æŸ¥
    if early_stopping(val_loss, model):
        print(f"\nâ¹ï¸ æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
        break
    
    # æ¸…ç†GPUç¼“å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

print("\nâœ… è®­ç»ƒå®Œæˆ!")
print(f"ğŸ† æœ€ç»ˆæœ€ä½³æ€§èƒ½: Loss={best_val_loss:.4f}, Acc={best_val_acc:.2f}%, AUC={best_val_auc:.4f}")
if torch.cuda.is_available():
    print(f"ğŸ’¾ å³°å€¼GPUå†…å­˜ä½¿ç”¨: {torch.cuda.max_memory_allocated() / 1024**3:.1f}GB")