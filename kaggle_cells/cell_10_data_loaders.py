# Cell 10: åˆ›å»ºæ•°æ®åŠ è½½å™¨ - Kaggle T4 ä¼˜åŒ–ç‰ˆæœ¬

print("ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")

# æ”¹è¿›çš„æ•°æ®å˜æ¢ç­–ç•¥
train_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((256, 256)),  # å…ˆæ”¾å¤§
    transforms.RandomCrop(224),     # éšæœºè£å‰ª
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
    transforms.RandomRotation(degrees=10),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # éšæœºå¹³ç§»
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

print(f"ğŸ”§ åˆ›å»ºæ•°æ®é›†ï¼ˆKaggle T4ä¼˜åŒ–é…ç½®ï¼‰...")
print(f"ğŸ“Š æ•°æ®ç±»å‹: FP32 (å…¼å®¹æ€§ä¼˜å…ˆ)")

# ä¼˜å…ˆä½¿ç”¨é‡é‡‡æ ·åçš„å¹³è¡¡æ•°æ®é›†
balanced_train_file = './data/train_balanced.csv'
original_train_file = './data/train.csv'

if os.path.exists(balanced_train_file):
    train_csv_file = balanced_train_file
    print("ğŸ”„ ä½¿ç”¨é‡é‡‡æ ·åçš„å¹³è¡¡è®­ç»ƒæ•°æ®é›†")
else:
    train_csv_file = original_train_file
    print("ğŸ“Š ä½¿ç”¨åŸå§‹è®­ç»ƒæ•°æ®é›†")

train_dataset = DeepfakeVideoDataset(
    csv_file=train_csv_file,
    transform=train_transform,
    max_frames=16,
    gpu_preprocessing=False,    # ç¦ç”¨GPUé¢„å¤„ç†ï¼Œä½¿ç”¨CPUæ•°æ®å¢å¼º
    cache_frames=False        # ç¦ç”¨ç¼“å­˜ä»¥èŠ‚çœå†…å­˜
)

val_dataset = DeepfakeVideoDataset(
    csv_file='./data/val.csv',
    transform=val_transform,
    max_frames=16,
    gpu_preprocessing=False,    # ç¦ç”¨GPUé¢„å¤„ç†
    cache_frames=False        # ç¦ç”¨ç¼“å­˜ä»¥èŠ‚çœå†…å­˜
)

test_dataset = DeepfakeVideoDataset(
    csv_file='./data/test.csv',
    transform=val_transform,
    max_frames=16,
    gpu_preprocessing=False,    # ç¦ç”¨GPUé¢„å¤„ç†
    cache_frames=False        # ç¦ç”¨ç¼“å­˜ä»¥èŠ‚çœå†…å­˜
)
print("âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆï¼Œå·²ä¼˜åŒ–Kaggle T4ç¯å¢ƒé…ç½®")

# åˆ é™¤åŠ¨æ€ batch_size è®¾ç½®
batch_size = 2
print(f"ä½¿ç”¨æ‰¹æ¬¡å¤§å°: {batch_size} (ç”¨æˆ·æŒ‡å®š)")

# Kaggleç¯å¢ƒå¤šè¿›ç¨‹é…ç½® - ç®€åŒ–ç‰ˆæœ¬
if IS_KAGGLE:
    # Kaggleç¯å¢ƒï¼šä½¿ç”¨å•è¿›ç¨‹é¿å…åºåˆ—åŒ–é—®é¢˜
    num_workers = 0
    prefetch_factor = None
    persistent_workers = False
    print("ğŸ“ Kaggleç¯å¢ƒï¼šä½¿ç”¨å•è¿›ç¨‹æ¨¡å¼")
else:
    # æœ¬åœ°ç¯å¢ƒï¼šä½¿ç”¨å°‘é‡worker
    num_workers = 2
    prefetch_factor = 2
    persistent_workers = False
    print(f"ğŸ”¥ æœ¬åœ°ç¯å¢ƒï¼šä½¿ç”¨ {num_workers} workers")

print(f"æ•°æ®åŠ è½½é…ç½®: {num_workers} workers, é¢„å–å› å­: {prefetch_factor}")

# åˆ›å»ºæ•°æ®åŠ è½½å™¨ - Kaggle T4ä¼˜åŒ–ç‰ˆæœ¬
train_loader = DataLoader(
    train_dataset, 
    batch_size=batch_size, 
    shuffle=True, 
    num_workers=num_workers,
    pin_memory=False,  # GPUé¢„å¤„ç†ï¼Œæ— éœ€pin_memory
    drop_last=True,
    prefetch_factor=prefetch_factor if num_workers > 0 else None,
    persistent_workers=persistent_workers if num_workers > 0 else False
)

val_loader = DataLoader(
    val_dataset, 
    batch_size=batch_size, 
    shuffle=False, 
    num_workers=num_workers,
    pin_memory=False,
    prefetch_factor=prefetch_factor if num_workers > 0 else None,
    persistent_workers=persistent_workers if num_workers > 0 else False
)

test_loader = DataLoader(
    test_dataset, 
    batch_size=batch_size, 
    shuffle=False, 
    num_workers=num_workers,
    pin_memory=False,
    prefetch_factor=prefetch_factor if num_workers > 0 else None,
    persistent_workers=persistent_workers if num_workers > 0 else False
)

print(f"\nğŸ“Š æ•°æ®åŠ è½½å™¨ç»Ÿè®¡:")
print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)} (æ‰¹æ¬¡å¤§å°: {batch_size})")
print(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
print(f"æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}")
print(f"æ•°æ®åŠ è½½workeræ•°: {num_workers}")
print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")