# è®­ç»ƒå’Œè¯„ä¼°æ¨¡å— - æœ¬åœ°RTX4070ä¼˜åŒ–ç‰ˆæœ¬

import torch
import torch.nn as nn
import numpy as np
import time
from tqdm import tqdm
from sklearn.metrics import (
    accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, auc
)
import matplotlib.pyplot as plt
import seaborn as sns
from config import config
from utils import (
    calculate_accuracy, calculate_auc, PerformanceMonitor,
    save_model_checkpoint, print_gpu_memory_info, cleanup_gpu_memory
)
from memory_manager import MemoryManager, auto_memory_management

class Trainer:
    """è®­ç»ƒå™¨ç±» - RTX4070ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, model, train_loader, val_loader, criterion, optimizer, scheduler=None, early_stopping=None):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.early_stopping = early_stopping
        self.device = config.get_device()
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        self.use_amp = config.USE_MIXED_PRECISION
        self.scaler = torch.cuda.amp.GradScaler() if self.use_amp else None
        
        # æ€§èƒ½ç›‘æ§
        self.monitor = PerformanceMonitor()
        
        # å†…å­˜ç®¡ç†å™¨
        self.memory_manager = MemoryManager(
            gpu_memory_threshold=0.85,
            cpu_memory_threshold=0.80,
            auto_cleanup_interval=30.0,
            enable_monitoring=True
        )
        
        # æ³¨å†Œå†…å­˜æ¸…ç†å›è°ƒ
        self.memory_manager.register_cleanup_callback(self._cleanup_training_cache)
        self.memory_manager.register_warning_callback(self._memory_warning_handler)
        
        # è®­ç»ƒå†å²
        self.history = {
            'train_loss': [],
            'train_acc': [],
            'train_auc': [],
            'val_loss': [],
            'val_acc': [],
            'val_auc': [],
            'lr': []
        }
    
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        all_preds = []
        all_targets = []
        
        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch+1} - Training', leave=False)
        
        for batch_idx, (data, target) in enumerate(pbar):
            # æ•°æ®ä¼ è¾“åˆ°GPU
            data = data.to(self.device, non_blocking=True)
            target = target.to(self.device, non_blocking=True)
            
            # æ¢¯åº¦æ¸…é›¶
            self.optimizer.zero_grad(set_to_none=True)
            
            # å‰å‘ä¼ æ’­
            if self.use_amp:
                with torch.cuda.amp.autocast():
                    output, _ = self.model(data)
                    loss = self.criterion(output, target)
                
                # åå‘ä¼ æ’­
                self.scaler.scale(loss).backward()
                self.scaler.unscale_(self.optimizer)
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                output, _ = self.model(data)
                loss = self.criterion(output, target)
                
                # åå‘ä¼ æ’­
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                self.optimizer.step()
            
            total_loss += loss.item()
            
            # è®¡ç®—å‡†ç¡®ç‡
            with torch.no_grad():
                probs = torch.sigmoid(output)
                predicted = (probs > 0.5).float()
                total += target.size(0)
                correct += (predicted == target).sum().item()
                
                # æ”¶é›†é¢„æµ‹ç»“æœ
                all_preds.extend(probs.detach().cpu().numpy())
                all_targets.extend(target.detach().cpu().numpy())
            
            # æ›´æ–°è¿›åº¦æ¡
            current_acc = 100. * correct / total
            pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{current_acc:.2f}%'
            })
            
            # å®šæœŸæ¸…ç†GPUç¼“å­˜å’Œå†…å­˜ç›‘æ§
            if batch_idx % 50 == 0:
                self.memory_manager.smart_cleanup()
                self.monitor.update()
        
        avg_loss = total_loss / len(self.train_loader)
        accuracy = 100. * correct / total
        auc_score = calculate_auc(torch.tensor(all_preds), torch.tensor(all_targets))
        
        return avg_loss, accuracy, auc_score
    
    def validate_epoch(self, epoch):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0.0
        correct = 0
        total = 0
        all_preds = []
        all_targets = []
        
        with torch.no_grad():
            pbar = tqdm(self.val_loader, desc=f'Epoch {epoch+1} - Validation', leave=False)
            
            for batch_idx, (data, target) in enumerate(pbar):
                # æ•°æ®ä¼ è¾“åˆ°GPU
                data = data.to(self.device, non_blocking=True)
                target = target.to(self.device, non_blocking=True)
                
                # å‰å‘ä¼ æ’­
                if self.use_amp:
                    with torch.cuda.amp.autocast():
                        output, _ = self.model(data)
                        loss = self.criterion(output, target)
                else:
                    output, _ = self.model(data)
                    loss = self.criterion(output, target)
                
                total_loss += loss.item()
                
                # è®¡ç®—å‡†ç¡®ç‡
                probs = torch.sigmoid(output)
                predicted = (probs > 0.5).float()
                total += target.size(0)
                correct += (predicted == target).sum().item()
                
                # æ”¶é›†é¢„æµ‹ç»“æœ
                all_preds.extend(probs.cpu().numpy())
                all_targets.extend(target.cpu().numpy())
                
                # æ›´æ–°è¿›åº¦æ¡
                current_acc = 100. * correct / total
                pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{current_acc:.2f}%'
                })
                
                # å®šæœŸæ¸…ç†GPUç¼“å­˜
                if batch_idx % 50 == 0:
                    self.memory_manager.cleanup_gpu_memory()
        
        avg_loss = total_loss / len(self.val_loader)
        accuracy = 100. * correct / total
        auc_score = calculate_auc(torch.tensor(all_preds), torch.tensor(all_targets))
        
        return avg_loss, accuracy, auc_score
    
    def train(self, num_epochs, save_dir=None):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print(f"å¼€å§‹è®­ç»ƒ - {num_epochs} epochs")
        print(f"è®¾å¤‡: {self.device}")
        print(f"æ··åˆç²¾åº¦: {self.use_amp}")
        print_gpu_memory_info()
        
        self.monitor.reset()
        best_val_loss = float('inf')
        
        for epoch in range(num_epochs):
            epoch_start_time = time.time()
            
            # è®­ç»ƒ
            train_loss, train_acc, train_auc = self.train_epoch(epoch)
            
            # éªŒè¯
            val_loss, val_acc, val_auc = self.validate_epoch(epoch)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            if self.scheduler:
                if hasattr(self.scheduler, 'step'):
                    if 'ReduceLROnPlateau' in str(type(self.scheduler)):
                        self.scheduler.step(val_loss)
                    else:
                        self.scheduler.step()
            
            # è®°å½•å†å²
            self.history['train_loss'].append(train_loss)
            self.history['train_acc'].append(train_acc)
            self.history['train_auc'].append(train_auc)
            self.history['val_loss'].append(val_loss)
            self.history['val_acc'].append(val_acc)
            self.history['val_auc'].append(val_auc)
            self.history['lr'].append(self.optimizer.param_groups[0]['lr'])
            
            epoch_time = time.time() - epoch_start_time
            
            # æ‰“å°ç»“æœ
            print(f"\nEpoch {epoch+1}/{num_epochs}:")
            print(f"  è®­ç»ƒ - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%, AUC: {train_auc:.4f}")
            print(f"  éªŒè¯ - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, AUC: {val_auc:.4f}")
            print(f"  å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.6f}")
            print(f"  è€—æ—¶: {epoch_time:.1f}ç§’")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                if save_dir:
                    best_model_path = save_dir / 'best_model.pth'
                    save_model_checkpoint(
                        self.model, self.optimizer, self.scheduler,
                        epoch, val_loss, val_acc, val_auc, best_model_path
                    )
            
            # æ—©åœæ£€æŸ¥
            if self.early_stopping:
                if self.early_stopping(val_loss, self.model, epoch):
                    print(f"\næ—©åœè§¦å‘ï¼Œåœ¨ç¬¬{epoch+1}è½®åœæ­¢è®­ç»ƒ")
                    break
            
            # å†…å­˜ç›‘æ§å’Œä¼˜åŒ–å»ºè®®
            if epoch % 5 == 0:
                self.memory_manager.print_memory_report()
                suggestions = self.memory_manager.get_optimization_suggestions()
                if len(suggestions) > 1 or "å†…å­˜ä½¿ç”¨çŠ¶å†µè‰¯å¥½" not in suggestions[0]:
                    print("ğŸ’¡ å†…å­˜ä¼˜åŒ–å»ºè®®:")
                    for suggestion in suggestions:
                        print(f"   {suggestion}")
        
        # è®­ç»ƒå®Œæˆç»Ÿè®¡
        stats = self.monitor.get_stats()
        print(f"\nè®­ç»ƒå®Œæˆ!")
        print(f"æ€»è€—æ—¶: {stats['elapsed_time']:.1f}ç§’")
        print(f"å¹³å‡CPUä½¿ç”¨ç‡: {stats['avg_cpu_usage']:.1f}%")
        print(f"å³°å€¼GPUå†…å­˜: {stats['peak_gpu_memory_gb']:.2f}GB")
        
        return self.history
    
    def _cleanup_training_cache(self):
        """è®­ç»ƒç¼“å­˜æ¸…ç†å›è°ƒ"""
        try:
            # æ¸…ç†æ¨¡å‹ç¼“å­˜
            if hasattr(self.model, 'clear_cache'):
                self.model.clear_cache()
            
            # æ¸…ç†ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
            if hasattr(self.optimizer, 'zero_grad'):
                self.optimizer.zero_grad(set_to_none=True)
            
            # æ¸…ç†æ•°æ®åŠ è½½å™¨ç¼“å­˜
            if hasattr(self.train_loader.dataset, 'clear_cache'):
                self.train_loader.dataset.clear_cache()
            if hasattr(self.val_loader.dataset, 'clear_cache'):
                self.val_loader.dataset.clear_cache()
            
            print("ğŸ§¹ è®­ç»ƒç¼“å­˜å·²æ¸…ç†")
        except Exception as e:
            print(f"è®­ç»ƒç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
    
    def _memory_warning_handler(self, message: str):
        """å†…å­˜è­¦å‘Šå¤„ç†å›è°ƒ"""
        print(f"âš ï¸ å†…å­˜è­¦å‘Š: {message}")
        
        # è‡ªåŠ¨é™ä½batch sizeï¼ˆå¦‚æœå¯èƒ½ï¼‰
        if "GPUå†…å­˜ä¸¥é‡ä¸è¶³" in message:
            current_batch_size = self.train_loader.batch_size
            if current_batch_size > 1:
                print(f"ğŸ”§ å»ºè®®å°†batch_sizeä»{current_batch_size}é™ä½åˆ°{current_batch_size//2}")
    
    def start_training_with_memory_management(self, num_epochs, save_dir=None):
        """å¸¦å†…å­˜ç®¡ç†çš„è®­ç»ƒæµç¨‹"""
        with self.memory_manager:
            return self.train(num_epochs, save_dir)

class Evaluator:
    """è¯„ä¼°å™¨ç±»"""
    
    def __init__(self, model, test_loader, criterion):
        self.model = model
        self.test_loader = test_loader
        self.criterion = criterion
        self.device = config.get_device()
    
    def evaluate(self):
        """å…¨é¢è¯„ä¼°æ¨¡å‹"""
        print("ğŸš€ å¼€å§‹æ¨¡å‹è¯„ä¼°...")
        
        self.model.eval()
        total_loss = 0.0
        all_predictions = []
        all_targets = []
        all_scores = []
        inference_times = []
        
        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(tqdm(self.test_loader, desc="è¯„ä¼°è¿›åº¦")):
                data, target = data.to(self.device), target.to(self.device)
                
                # è®°å½•æ¨ç†æ—¶é—´
                start_time = time.time()
                output, attention_weights = self.model(data)
                inference_time = time.time() - start_time
                inference_times.append(inference_time)
                
                # è®¡ç®—æŸå¤±
                loss = self.criterion(output, target)
                total_loss += loss.item()
                
                # æ”¶é›†é¢„æµ‹ç»“æœ
                probs = torch.sigmoid(output)
                predictions = (probs > 0.5).float()
                all_predictions.extend(predictions.cpu().numpy())
                all_targets.extend(target.cpu().numpy())
                all_scores.extend(probs.cpu().numpy())
        
        avg_loss = total_loss / len(self.test_loader)
        avg_inference_time = np.mean(inference_times)
        
        print(f"âœ… è¯„ä¼°å®Œæˆ")
        print(f"å¹³å‡æŸå¤±: {avg_loss:.4f}")
        print(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time*1000:.2f} ms/batch")
        
        return {
            'loss': avg_loss,
            'predictions': np.array(all_predictions),
            'targets': np.array(all_targets),
            'scores': np.array(all_scores),
            'avg_inference_time': avg_inference_time,
            'total_inference_time': np.sum(inference_times)
        }
    
    def calculate_metrics(self, predictions, targets, scores):
        """è®¡ç®—å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡"""
        # åŸºç¡€æŒ‡æ ‡
        accuracy = accuracy_score(targets, predictions)
        balanced_acc = balanced_accuracy_score(targets, predictions)
        precision = precision_score(targets, predictions, zero_division=0)
        recall = recall_score(targets, predictions, zero_division=0)
        f1 = f1_score(targets, predictions, zero_division=0)
        
        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(targets, predictions)
        tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)
        
        # ç‰¹å¼‚æ€§å’Œè´Ÿé¢„æµ‹å€¼
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        npv = tn / (tn + fn) if (tn + fn) > 0 else 0
        
        # AUCæŒ‡æ ‡
        try:
            auc_roc = roc_auc_score(targets, scores)
        except:
            auc_roc = 0.0
        
        try:
            precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)
            auc_pr = auc(recall_curve, precision_curve)
        except:
            auc_pr = 0.0
        
        return {
            'accuracy': accuracy,
            'balanced_accuracy': balanced_acc,
            'precision': precision,
            'recall': recall,
            'specificity': specificity,
            'f1': f1,
            'auc_roc': auc_roc,
            'auc_pr': auc_pr,
            'npv': npv,
            'confusion_matrix': cm,
            'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp
        }
    
    def plot_confusion_matrix(self, cm, save_path):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        plt.figure(figsize=(10, 8))
        
        # è®¡ç®—ç™¾åˆ†æ¯”
        cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100
        
        # åˆ›å»ºæ ‡ç­¾
        labels = np.array([[
            f'{cm[i,j]}\n({cm_percent[i,j]:.1f}%)' 
            for j in range(cm.shape[1])
        ] for i in range(cm.shape[0])])
        
        # ç»˜åˆ¶çƒ­å›¾
        sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', 
                    xticklabels=['çœŸå®', 'ä¼ªé€ '],
                    yticklabels=['çœŸå®', 'ä¼ªé€ '],
                    cbar_kws={'label': 'æ ·æœ¬æ•°é‡'})
        
        plt.title('æ··æ·†çŸ©é˜µ', fontsize=16, fontweight='bold')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
        plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        tn, fp, fn, tp = cm.ravel()
        accuracy = (tp + tn) / (tp + tn + fp + fn)
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        stats_text = f'å‡†ç¡®ç‡: {accuracy:.3f}\nç²¾ç¡®ç‡: {precision:.3f}\nå¬å›ç‡: {recall:.3f}\nF1åˆ†æ•°: {f1:.3f}'
        plt.text(2.1, 0.5, stats_text, fontsize=10, 
                 bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {save_path}")
    
    def plot_roc_pr_curves(self, targets, scores, save_path):
        """ç»˜åˆ¶ROCå’ŒPRæ›²çº¿"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # ROCæ›²çº¿
        fpr, tpr, _ = roc_curve(targets, scores)
        roc_auc = auc(fpr, tpr)
        
        ax1.plot(fpr, tpr, color='darkorange', lw=2,
                 label=f'ROCæ›²çº¿ (AUC = {roc_auc:.4f})')
        ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        ax1.set_xlim([0.0, 1.0])
        ax1.set_ylim([0.0, 1.05])
        ax1.set_xlabel('å‡æ­£ç‡')
        ax1.set_ylabel('çœŸæ­£ç‡')
        ax1.set_title('ROCæ›²çº¿')
        ax1.legend(loc='lower right')
        ax1.grid(True, alpha=0.3)
        
        # PRæ›²çº¿
        precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)
        pr_auc = auc(recall_curve, precision_curve)
        
        ax2.plot(recall_curve, precision_curve, color='darkgreen', lw=2,
                 label=f'PRæ›²çº¿ (AUC = {pr_auc:.4f})')
        ax2.set_xlim([0.0, 1.0])
        ax2.set_ylim([0.0, 1.05])
        ax2.set_xlabel('å¬å›ç‡')
        ax2.set_ylabel('ç²¾ç¡®ç‡')
        ax2.set_title('ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿')
        ax2.legend(loc='lower left')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"ROC/PRæ›²çº¿å·²ä¿å­˜åˆ°: {save_path}")