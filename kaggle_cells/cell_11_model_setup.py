# Cell 11: æ¨¡å‹åˆå§‹åŒ–å’Œè®­ç»ƒé…ç½® - GPUä¼˜åŒ–ç‰ˆæœ¬

print("ğŸ¤– åˆ›å»ºå’Œé…ç½®æ¨¡å‹...")

# åˆ›å»ºæ¨¡å‹ - é’ˆå¯¹T4*2 GPUä¼˜åŒ–
model = OptimizedDeepfakeDetector(
    backbone='resnet50',  # ä½¿ç”¨ResNet50ä»¥å……åˆ†åˆ©ç”¨T4*2 GPUæ€§èƒ½
    hidden_dim=512,      # å¢åŠ éšè—å±‚ç»´åº¦
    num_layers=2,        # å¢åŠ LSTMå±‚æ•°
    dropout=0.4,         # é€‚å½“å¢åŠ dropouté˜²æ­¢è¿‡æ‹Ÿåˆ
    use_attention=True
).to(device)

# å¤šGPUæ”¯æŒ - å……åˆ†åˆ©ç”¨T4*2é…ç½®
if torch.cuda.device_count() > 1:
    print(f"ä½¿ç”¨ {torch.cuda.device_count()} ä¸ªGPUè¿›è¡Œå¹¶è¡Œè®­ç»ƒ")
    model = nn.DataParallel(model)
else:
    print("ä½¿ç”¨å•GPUè®­ç»ƒ")

# è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f"æ¨¡å‹æ€»å‚æ•°æ•°é‡: {total_params:,}")
print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}")
print(f"æ¨¡å‹å¤§å°ä¼°è®¡: {total_params * 4 / 1024**2:.1f} MB")

# æŸå¤±å‡½æ•°
criterion = FocalLoss(alpha=1, gamma=2)
print("ä½¿ç”¨ç„¦ç‚¹æŸå¤±å‡½æ•° (Focal Loss)")

# ä¼˜åŒ–å™¨ - é’ˆå¯¹ResNet50ä¼˜åŒ–
optimizer = optim.AdamW(
    model.parameters(), 
    lr=2e-4,  # ç¨å¾®æé«˜å­¦ä¹ ç‡ä»¥é€‚åº”æ›´å¤§æ¨¡å‹
    weight_decay=1e-4,
    betas=(0.9, 0.999)
)
print("ä½¿ç”¨AdamWä¼˜åŒ–å™¨ (lr=2e-4)")

# å­¦ä¹ ç‡è°ƒåº¦å™¨ - æ›´ä¿å®ˆçš„è°ƒåº¦
scheduler = ReduceLROnPlateau(
    optimizer, 
    mode='min', 
    factor=0.6,  # æ›´ä¿å®ˆçš„è¡°å‡å› å­
    patience=4,  # å¢åŠ patience
    verbose=True,
    min_lr=1e-7
)
print("ä½¿ç”¨ReduceLROnPlateauå­¦ä¹ ç‡è°ƒåº¦å™¨ (factor=0.6, patience=4)")

# æ—©åœæœºåˆ¶ - å¢åŠ patienceä»¥é€‚åº”æ›´å¤§æ¨¡å‹
early_stopping = EarlyStopping(patience=8, min_delta=0.001)
print("é…ç½®æ—©åœæœºåˆ¶ (patience=8)")

# æ··åˆç²¾åº¦è®­ç»ƒ
if torch.cuda.is_available():
    scaler = GradScaler()
    print("å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP)")
else:
    scaler = None
    print("CPUæ¨¡å¼ï¼Œä¸ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")

# è®­ç»ƒé…ç½® - é’ˆå¯¹T4*2 GPUå’Œæ›´å¤§æ•°æ®é›†ä¼˜åŒ–
num_epochs = 25  # å¢åŠ è®­ç»ƒè½®æ•°ä»¥å……åˆ†è®­ç»ƒæ›´å¤§çš„æ¨¡å‹
print(f"è®­ç»ƒè½®æ•°: {num_epochs}")

# æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
print("\nğŸ” æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
try:
    model.eval()
    with torch.no_grad():
        sample_batch = next(iter(train_loader))
        videos, labels = sample_batch
        videos, labels = videos.to(device), labels.to(device)
        
        # å‰å‘ä¼ æ’­
        outputs, attention_weights = model(videos)
        loss = criterion(outputs, labels)
        
        print(f"è¾“å…¥å½¢çŠ¶: {videos.shape}")
        print(f"è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
        print(f"æŸå¤±å€¼: {loss.item():.4f}")
        print(f"LogitsèŒƒå›´: [{outputs.min():.3f}, {outputs.max():.3f}]")
        
        # æ˜¾ç¤ºæ¦‚ç‡èŒƒå›´
        probs = torch.sigmoid(outputs)
        print(f"æ¦‚ç‡èŒƒå›´: [{probs.min():.3f}, {probs.max():.3f}]")
        
        if attention_weights is not None:
            print(f"æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {attention_weights.shape}")
        
        print("âœ… æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•æˆåŠŸ")
except Exception as e:
    print(f"âŒ æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
    raise e

print("âœ… æ¨¡å‹é…ç½®å®Œæˆï¼Œå‡†å¤‡å¼€å§‹è®­ç»ƒ")