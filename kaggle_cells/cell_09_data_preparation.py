# Cell 9: æ•°æ®å‡†å¤‡ - ä¸‰æ­¥ä¼˜åŒ–ä¸“ç”¨ç‰ˆæœ¬

DATA_BASE_DIR = '/kaggle/input/ff-c23/FaceForensics++_C23'

print("ğŸ“ åˆ›å»ºæ•°æ®ç›®å½•...")
os.makedirs('./data', exist_ok=True)
os.makedirs('./data/frames', exist_ok=True)  # é¢„æå–å¸§å­˜å‚¨ç›®å½•

def pre_extract_all_frames(video_data, frames_dir='./data/frames'):
    """
    é¢„æå–æ‰€æœ‰è§†é¢‘å¸§åˆ°ç¡¬ç›˜ - ä¸‰æ­¥ä¼˜åŒ–çš„ç¬¬ä¸€æ­¥
    
    Args:
        video_data: è§†é¢‘æ•°æ®åˆ—è¡¨
        frames_dir: å¸§å­˜å‚¨ç›®å½•
    
    Returns:
        extracted_data: åŒ…å«é¢„æå–å¸§è·¯å¾„çš„æ•°æ®åˆ—è¡¨
    """
    print(f"ğŸ¬ å¼€å§‹é¢„æå–æ‰€æœ‰è§†é¢‘å¸§åˆ° {frames_dir}...")
    
    extracted_data = []
    total_videos = len(video_data)
    
    for idx, video_info in enumerate(tqdm(video_data, desc="é¢„æå–å¸§")):
        try:
            video_path = video_info['video_path']
            label = video_info['label']
            
            # ç”Ÿæˆå¸§æ–‡ä»¶è·¯å¾„
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            frame_file = os.path.join(frames_dir, f"{video_name}_frames.pt")
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(frame_file):
                extracted_data.append({
                    'frame_path': frame_file,
                    'label': label,
                    'original_video': video_path
                })
                continue
            
            # ä½¿ç”¨GPUåŠ é€Ÿæå–å¸§
            frames = extract_frames_memory_efficient(video_path, max_frames=MAX_FRAMES_PER_VIDEO)
            
            if len(frames) > 0:
                # è½¬æ¢ä¸ºtensorå¹¶ä¿å­˜
                frames_tensor = torch.stack([
                    torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0
                    for frame in frames
                ])
                
                torch.save(frames_tensor, frame_file)
                
                extracted_data.append({
                    'frame_path': frame_file,
                    'label': label,
                    'original_video': video_path
                })
            else:
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆè§†é¢‘: {video_path}")
                
        except Exception as e:
            print(f"âŒ é¢„æå–å¤±è´¥ {video_path}: {e}")
            continue
    
    print(f"âœ… é¢„æå–å®Œæˆ: {len(extracted_data)}/{total_videos} ä¸ªè§†é¢‘")
    return extracted_data


# ==================== é…ç½®å‚æ•° ====================
# å¯è‡ªå®šä¹‰é¢„å¤„ç†è§†é¢‘æ•°é‡
MAX_REAL_VIDEOS = 500      # çœŸå®è§†é¢‘æ•°é‡
MAX_FAKE_VIDEOS = 500      # å‡è§†é¢‘æ•°é‡
MAX_FRAMES_PER_VIDEO = 16  # æ¯ä¸ªè§†é¢‘æå–çš„å¸§æ•°

# çœŸå‡è§†é¢‘æ¯”ä¾‹å»ºè®®
# 1:1 - å¹³è¡¡æ•°æ®é›†ï¼Œé€‚åˆå¤§å¤šæ•°æƒ…å†µ
# 1:2 - è½»å¾®åå‘å‡è§†é¢‘ï¼Œæé«˜å‡è§†é¢‘æ£€æµ‹èƒ½åŠ›
# 1:3 - ä¸­ç­‰åå‘å‡è§†é¢‘ï¼Œé€‚åˆå®é™…åº”ç”¨åœºæ™¯
# 1:6 - å¼ºçƒˆåå‘å‡è§†é¢‘ï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œåˆ†å¸ƒ
REAL_FAKE_RATIO = "1:1"  # å½“å‰æ¯”ä¾‹

print("ğŸ“ åˆ›å»ºæ•°æ®ç›®å½•...")
os.makedirs('./data', exist_ok=True)
os.makedirs('./data/frames', exist_ok=True)  # é¢„æå–å¸§å­˜å‚¨ç›®å½•

print(f"ğŸ“‹ é…ç½®å‚æ•°:")
print(f"   çœŸå®è§†é¢‘æ•°é‡: {MAX_REAL_VIDEOS}")
print(f"   å‡è§†é¢‘æ•°é‡: {MAX_FAKE_VIDEOS}")
print(f"   æ¯è§†é¢‘å¸§æ•°: {MAX_FRAMES_PER_VIDEO}")
print(f"   çœŸå‡æ¯”ä¾‹: {REAL_FAKE_RATIO}")
print(f"   é¢„è®¡æ€»æ ·æœ¬: {MAX_REAL_VIDEOS + MAX_FAKE_VIDEOS}")

video_data = process_videos_simple(
    base_data_dir=DATA_BASE_DIR,  # ä½¿ç”¨åŠ¨æ€æ£€æµ‹çš„æ•°æ®è·¯å¾„
    max_real=MAX_REAL_VIDEOS,      # ä½¿ç”¨è‡ªå®šä¹‰çœŸè§†é¢‘æ•°é‡
    max_fake=MAX_FAKE_VIDEOS,      # ä½¿ç”¨è‡ªå®šä¹‰å‡è§†é¢‘æ•°é‡
    max_frames=MAX_FRAMES_PER_VIDEO
)

print(f"ğŸ“Š åŸå§‹è§†é¢‘æ•°æ®: {len(video_data)} ä¸ªæ ·æœ¬")

# ç»Ÿè®¡çœŸå‡è§†é¢‘åˆ†å¸ƒ
real_count = sum(1 for item in video_data if item['label'] == 0)
fake_count = sum(1 for item in video_data if item['label'] == 1)
print(f"   çœŸå®è§†é¢‘: {real_count} ä¸ª")
print(f"   å‡è§†é¢‘: {fake_count} ä¸ª")

# æ­¥éª¤1: é¢„æå–æ‰€æœ‰å¸§
extracted_data = pre_extract_all_frames(video_data)

if len(extracted_data) == 0:
    raise ValueError("âŒ é¢„æå–å¸§å¤±è´¥ï¼Œæ— æ³•ç»§ç»­ã€‚è¯·æ£€æŸ¥è§†é¢‘è·¯å¾„å’Œæ ¼å¼ã€‚")

print(f"âœ… é¢„æå–å¸§å®Œæˆ: {len(extracted_data)} ä¸ªæ ·æœ¬")

# æ•°æ®é›†åˆ†å‰²
print("ğŸ“Š åˆ†å‰²æ•°æ®é›†...")
train_data, val_data, test_data = create_dataset_split(
    extracted_data,  # ä½¿ç”¨é¢„æå–çš„æ•°æ®
    train_ratio=0.7,
    val_ratio=0.15,
    test_ratio=0.15,
    random_state=42
)

print(f"è®­ç»ƒé›†: {len(train_data)} æ ·æœ¬")
print(f"éªŒè¯é›†: {len(val_data)} æ ·æœ¬")
print(f"æµ‹è¯•é›†: {len(test_data)} æ ·æœ¬")

# ä¿å­˜æ•°æ®é›†
print("ğŸ’¾ ä¿å­˜æ•°æ®é›†...")
save_dataset_to_csv(train_data, './data/train.csv')
save_dataset_to_csv(val_data, './data/val.csv')
save_dataset_to_csv(test_data, './data/test.csv')

# æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡
print("\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
for name, data in [("è®­ç»ƒ", train_data), ("éªŒè¯", val_data), ("æµ‹è¯•", test_data)]:
    real_count = sum(1 for item in data if item['label'] == 0)
    fake_count = sum(1 for item in data if item['label'] == 1)
    print(f"{name}é›†: çœŸå®={real_count}, ä¼ªé€ ={fake_count}, æ€»è®¡={len(data)}")

# æ˜¾ç¤ºä¼ªé€ è§†é¢‘æ–¹æ³•åˆ†å¸ƒ
print("\nğŸ­ ä¼ªé€ è§†é¢‘æ–¹æ³•åˆ†å¸ƒ:")
fake_methods = {}
for item in extracted_data:
    if item['label'] == 1:  # ä¼ªé€ è§†é¢‘
        original_path = item['original_video']
        if 'Deepfakes' in original_path:
            method = 'Deepfakes'
        elif 'Face2Face' in original_path:
            method = 'Face2Face'
        elif 'FaceSwap' in original_path:
            method = 'FaceSwap'
        elif 'NeuralTextures' in original_path:
            method = 'NeuralTextures'
        else:
            method = 'Unknown'
        
        fake_methods[method] = fake_methods.get(method, 0) + 1

for method, count in fake_methods.items():
    print(f"  {method}: {count} ä¸ªè§†é¢‘")

print(f"\nâœ… æ•°æ®å‡†å¤‡å®Œæˆï¼")
print(f"   ğŸ“Š æ•°æ®åˆ†å¸ƒ: çœŸå®è§†é¢‘ {real_count} | å‡è§†é¢‘ {fake_count}")
print(f"   ğŸ“ˆ å½“å‰æ¯”ä¾‹: {REAL_FAKE_RATIO}")
print(f"   ğŸ¯ æ•°æ®é›†è§„æ¨¡: {dataset_size} ({total_samples}æ ·æœ¬)")
print(f"   ğŸš€ å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼")