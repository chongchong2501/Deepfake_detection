{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3936c6bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:27:45.790240Z",
     "iopub.status.busy": "2025-07-29T10:27:45.789973Z",
     "iopub.status.idle": "2025-07-29T10:27:57.253021Z",
     "shell.execute_reply": "2025-07-29T10:27:57.252179Z"
    },
    "papermill": {
     "duration": 11.473626,
     "end_time": "2025-07-29T10:27:57.254681",
     "exception": false,
     "start_time": "2025-07-29T10:27:45.781055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting av\r\n",
      "  Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\r\n",
      "Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: av\r\n",
      "Successfully installed av-15.0.0\r\n",
      "Collecting mtcnn\r\n",
      "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn) (1.5.1)\r\n",
      "Collecting lz4>=4.3.3 (from mtcnn)\r\n",
      "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n",
      "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lz4, mtcnn\r\n",
      "Successfully installed lz4-4.4.4 mtcnn-1.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install av\n",
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06535c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:27:57.273811Z",
     "iopub.status.busy": "2025-07-29T10:27:57.273554Z",
     "iopub.status.idle": "2025-07-29T10:28:37.923651Z",
     "shell.execute_reply": "2025-07-29T10:28:37.922758Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 40.661106,
     "end_time": "2025-07-29T10:28:37.925023",
     "exception": false,
     "start_time": "2025-07-29T10:27:57.263917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 CUDA已初始化，检测到 2 个GPU设备\n",
      "   - GPU 0: Tesla T4 (14.7 GB)\n",
      "   - GPU 1: Tesla T4 (14.7 GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753784901.012661      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753784901.121581      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MTCNN已安装，支持高精度人脸检测\n",
      "   - 人脸检测精度: 高\n",
      "   - 检测置信度阈值: 0.9\n",
      "   - API版本: 新版本 (v1.0.0+)\n",
      "   - TensorFlow警告已抑制\n",
      "✅ PyAV已安装，支持GPU视频处理\n",
      "✅ SciPy已安装，支持频域分析\n",
      "✅ 所有库导入完成\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: 导入库和环境设置\n",
    "\n",
    "# 抑制CUDA和TensorFlow警告信息\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# 设置环境变量 - 必须在导入TensorFlow之前设置\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 抑制所有TensorFlow日志 (0=全部, 1=INFO, 2=WARNING, 3=ERROR)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # 异步CUDA执行\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'   # 抑制Python警告\n",
    "\n",
    "# 抑制CUDA相关警告\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # 禁用oneDNN优化警告\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'  # GPU内存动态增长\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # 明确指定可见的GPU设备\n",
    "\n",
    "# 抑制cuDNN/cuFFT/cuBLAS重复注册警告\n",
    "os.environ['TF_DISABLE_SEGMENT_REDUCTION_OP_DETERMINISM_EXCEPTIONS'] = '1'\n",
    "\n",
    "# 抑制所有警告\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# 修复CUDA多进程问题\n",
    "import multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "except RuntimeError:\n",
    "    pass  # 如果已经设置过，忽略错误\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import warnings\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch相关\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "from torchvision.io import read_video\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# 初始化CUDA并抑制警告\n",
    "if torch.cuda.is_available():\n",
    "    # 初始化CUDA上下文以避免后续警告\n",
    "    torch.cuda.init()\n",
    "    # 设置CUDA设备\n",
    "    torch.cuda.set_device(0)\n",
    "    # 清理CUDA缓存\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"🚀 CUDA已初始化，检测到 {torch.cuda.device_count()} 个GPU设备\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "        print(f\"   - GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "else:\n",
    "    print(\"⚠️ CUDA不可用，将使用CPU模式\")\n",
    "\n",
    "# 机器学习指标\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, auc, precision_recall_curve, balanced_accuracy_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 系统监控和性能分析\n",
    "import psutil\n",
    "import traceback\n",
    "\n",
    "# 高精度人脸检测 - MTCNN\n",
    "try:\n",
    "    # 在导入MTCNN之前进一步抑制TensorFlow警告\n",
    "    import logging\n",
    "    logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "    \n",
    "    # 抑制absl日志\n",
    "    try:\n",
    "        import absl.logging\n",
    "        absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    from mtcnn import MTCNN\n",
    "    MTCNN_AVAILABLE = True\n",
    "    print(\"✅ MTCNN已安装，支持高精度人脸检测\")\n",
    "    print(\"   - 人脸检测精度: 高\")\n",
    "    print(\"   - 检测置信度阈值: 0.9\")\n",
    "    print(\"   - API版本: 新版本 (v1.0.0+)\")\n",
    "    print(\"   - TensorFlow警告已抑制\")\n",
    "except ImportError:\n",
    "    MTCNN_AVAILABLE = False\n",
    "    print(\"⚠️ MTCNN未安装，将使用OpenCV人脸检测\")\n",
    "    print(\"   - 人脸检测精度: 中等\")\n",
    "    print(\"   - 建议安装MTCNN以获得更高精度:\")\n",
    "    print(\"   - 安装命令: !pip install mtcnn\")\n",
    "    print(\"   - 或者: !pip install mtcnn[tensorflow]\")\n",
    "    print(\"   - 注意: 需要TensorFlow >= 2.12\")\n",
    "    print(\"   - 影响: 人脸检测精度略有降低，但不影响整体训练\")\n",
    "\n",
    "# 视频处理 (PyAV)\n",
    "try:\n",
    "    import av\n",
    "    PYAV_AVAILABLE = True\n",
    "    print(\"✅ PyAV已安装，支持GPU视频处理\")\n",
    "except ImportError:\n",
    "    PYAV_AVAILABLE = False\n",
    "    print(\"⚠️ PyAV未安装，视频处理将回退到CPU模式\")\n",
    "\n",
    "# 数据增强\n",
    "try:\n",
    "    import albumentations as A\n",
    "    from albumentations.pytorch import ToTensorV2\n",
    "    ALBUMENTATIONS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ALBUMENTATIONS_AVAILABLE = False\n",
    "    print(\"警告: albumentations未安装，将使用基础数据增强\")\n",
    "\n",
    "# 频域分析支持\n",
    "try:\n",
    "    from scipy import fftpack\n",
    "    from scipy.signal import butter, filtfilt\n",
    "    SCIPY_AVAILABLE = True\n",
    "    print(\"✅ SciPy已安装，支持频域分析\")\n",
    "except ImportError:\n",
    "    SCIPY_AVAILABLE = False\n",
    "    print(\"⚠️ SciPy未安装，频域分析功能受限\")\n",
    "\n",
    "print(\"✅ 所有库导入完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "988a7827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:37.944094Z",
     "iopub.status.busy": "2025-07-29T10:28:37.943599Z",
     "iopub.status.idle": "2025-07-29T10:28:38.158257Z",
     "shell.execute_reply": "2025-07-29T10:28:38.157555Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.225086,
     "end_time": "2025-07-29T10:28:38.159479",
     "exception": false,
     "start_time": "2025-07-29T10:28:37.934393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "🎮 GPU数量: 2\n",
      "🎮 GPU型号: Tesla T4\n",
      "💾 单GPU内存: 14.7 GB\n",
      "💾 总GPU内存: 29.5 GB\n",
      "✅ 检测到 2 个GPU，启用多GPU并行训练\n",
      "✅ Kaggle T4 GPU优化配置已启用\n",
      "数据类型策略: FP32 (兼容性优先)\n",
      "环境: Kaggle\n",
      "数据基础路径: /kaggle/input/ff-c23/FaceForensics++_C23\n",
      "✅ 环境设置完成\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: 全局配置和工具函数 - Kaggle T4 优化版本\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"设置随机种子确保可重复性\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    # Kaggle环境优化：平衡性能和可重复性\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Kaggle T4 GPU配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    \n",
    "    print(f\"🎮 GPU数量: {gpu_count}\")\n",
    "    print(f\"🎮 GPU型号: {gpu_name}\")\n",
    "    print(f\"💾 单GPU内存: {gpu_memory:.1f} GB\")\n",
    "    print(f\"💾 总GPU内存: {gpu_memory * gpu_count:.1f} GB\")\n",
    "    \n",
    "    # 多GPU配置\n",
    "    USE_MULTI_GPU = gpu_count > 1\n",
    "    if USE_MULTI_GPU:\n",
    "        print(f\"✅ 检测到 {gpu_count} 个GPU，启用多GPU并行训练\")\n",
    "        # 双T4 GPU优化配置\n",
    "        torch.cuda.set_per_process_memory_fraction(0.8)  # 双T4可以使用更多内存\n",
    "    else:\n",
    "        print(\"📝 单GPU模式\")\n",
    "        torch.cuda.set_per_process_memory_fraction(0.7)  # 单GPU保守配置\n",
    "    \n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    print(\"✅ Kaggle T4 GPU优化配置已启用\")\n",
    "else:\n",
    "    USE_MULTI_GPU = False\n",
    "\n",
    "# 创建必要的目录\n",
    "for dir_name in ['./data', './models', './logs', './results']:\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "# Kaggle环境检测\n",
    "IS_KAGGLE = os.path.exists('/kaggle')\n",
    "BASE_DATA_DIR = '/kaggle/input/ff-c23/FaceForensics++_C23' if IS_KAGGLE else './dataset/FaceForensics++_C23'\n",
    "\n",
    "# 统一数据类型配置 - 全部使用FP32提升兼容性\n",
    "USE_FP32_ONLY = True  # 强制使用FP32，确保最佳兼容性\n",
    "print(f\"数据类型策略: FP32 (兼容性优先)\")\n",
    "\n",
    "print(f\"环境: {'Kaggle' if IS_KAGGLE else '本地'}\")\n",
    "print(f\"数据基础路径: {BASE_DATA_DIR}\")\n",
    "print(\"✅ 环境设置完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f11b1da9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.177555Z",
     "iopub.status.busy": "2025-07-29T10:28:38.177326Z",
     "iopub.status.idle": "2025-07-29T10:28:38.216629Z",
     "shell.execute_reply": "2025-07-29T10:28:38.215926Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.049861,
     "end_time": "2025-07-29T10:28:38.217757",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.167896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据处理函数定义完成\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: 数据处理函数\n",
    "def extract_frames_gpu_accelerated(video_path, max_frames=16, target_size=(224, 224),\n",
    "                                  quality_threshold=20, use_gpu=True, use_mtcnn=True):\n",
    "    \"\"\"GPU加速的帧提取函数 - 集成MTCNN人脸检测\"\"\"\n",
    "    try:\n",
    "        # 检查PyAV是否可用\n",
    "        if not globals().get('PYAV_AVAILABLE', False):\n",
    "            print(f\"PyAV不可用，使用CPU回退处理: {video_path}\")\n",
    "            return extract_frames_cpu_fallback(video_path, max_frames, target_size, quality_threshold, use_mtcnn)\n",
    "            \n",
    "        # 设备选择 - 优先使用GPU\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # 使用torchvision的GPU加速视频读取\n",
    "        if not use_gpu:\n",
    "            device = torch.device('cpu')\n",
    "            \n",
    "        # 读取视频（torchvision自动处理解码）\n",
    "        try:\n",
    "            video_tensor, audio, info = read_video(video_path, pts_unit='sec')\n",
    "            # video_tensor shape: (T, H, W, C)\n",
    "        except Exception as e:\n",
    "            print(f\"GPU视频读取失败，回退到CPU: {e}\")\n",
    "            return extract_frames_cpu_fallback(video_path, max_frames, target_size, quality_threshold, use_mtcnn)\n",
    "        \n",
    "        if video_tensor.size(0) == 0:\n",
    "            return []\n",
    "            \n",
    "        # 移动到GPU进行处理\n",
    "        video_tensor = video_tensor.to(device, non_blocking=True)\n",
    "        total_frames = video_tensor.size(0)\n",
    "        \n",
    "        # 智能帧采样策略\n",
    "        if total_frames <= max_frames:\n",
    "            frame_indices = torch.arange(0, total_frames, device=device)\n",
    "        else:\n",
    "            # 均匀采样\n",
    "            step = total_frames / max_frames\n",
    "            frame_indices = torch.arange(0, total_frames, step, device=device).long()[:max_frames]\n",
    "        \n",
    "        # 批量提取帧\n",
    "        selected_frames = video_tensor[frame_indices]  # (max_frames, H, W, C)\n",
    "        \n",
    "        # GPU上进行质量检测（使用Sobel算子代替Laplacian）\n",
    "        if quality_threshold > 0:\n",
    "            # 转换为灰度图进行质量检测（先转换为float类型）\n",
    "            gray_frames = selected_frames.float().mean(dim=-1, keepdim=True)  # (T, H, W, 1)\n",
    "            gray_frames = gray_frames.permute(0, 3, 1, 2)  # (T, 1, H, W)\n",
    "            \n",
    "            # 使用Sobel算子计算图像质量\n",
    "            sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], \n",
    "                                 dtype=torch.float32, device=device).view(1, 1, 3, 3)\n",
    "            sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], \n",
    "                                 dtype=torch.float32, device=device).view(1, 1, 3, 3)\n",
    "            \n",
    "            grad_x = F.conv2d(gray_frames, sobel_x, padding=1)\n",
    "            grad_y = F.conv2d(gray_frames, sobel_y, padding=1)\n",
    "            quality_scores = (grad_x.pow(2) + grad_y.pow(2)).mean(dim=[1, 2, 3])\n",
    "            \n",
    "            # 过滤低质量帧\n",
    "            quality_mask = quality_scores > quality_threshold\n",
    "            if quality_mask.sum() > 0:\n",
    "                selected_frames = selected_frames[quality_mask]\n",
    "            \n",
    "        # GPU上进行尺寸调整\n",
    "        selected_frames = selected_frames.permute(0, 3, 1, 2).float()  # (T, C, H, W)\n",
    "        if selected_frames.size(-1) != target_size[0] or selected_frames.size(-2) != target_size[1]:\n",
    "            selected_frames = F.interpolate(selected_frames, size=target_size, \n",
    "                                          mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # 确保帧数足够\n",
    "        current_frames = selected_frames.size(0)\n",
    "        if current_frames < max_frames:\n",
    "            # 重复最后一帧\n",
    "            if current_frames > 0:\n",
    "                last_frame = selected_frames[-1:].repeat(max_frames - current_frames, 1, 1, 1)\n",
    "                selected_frames = torch.cat([selected_frames, last_frame], dim=0)\n",
    "            else:\n",
    "                # 创建黑色帧\n",
    "                selected_frames = torch.zeros(max_frames, 3, target_size[0], target_size[1], \n",
    "                                            device=device, dtype=torch.float32)\n",
    "        \n",
    "        # 限制到最大帧数\n",
    "        selected_frames = selected_frames[:max_frames]\n",
    "        \n",
    "        # 转换回CPU numpy格式（为了兼容现有代码）\n",
    "        frames_cpu = selected_frames.permute(0, 2, 3, 1).cpu().numpy().astype(np.uint8)\n",
    "        frames_list = [frame for frame in frames_cpu]\n",
    "        \n",
    "        # 应用MTCNN人脸检测和裁剪\n",
    "        if use_mtcnn and globals().get('MTCNN_AVAILABLE', False):\n",
    "            frames_list = apply_mtcnn_face_detection(frames_list, target_size)\n",
    "        \n",
    "        return frames_list\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"GPU帧提取失败，回退到CPU: {e}\")\n",
    "        return extract_frames_cpu_fallback(video_path, max_frames, target_size, quality_threshold, use_mtcnn)\n",
    "\n",
    "def apply_mtcnn_face_detection(frames, target_size=(224, 224)):\n",
    "    \"\"\"使用MTCNN进行人脸检测和裁剪 - 兼容新版本API\"\"\"\n",
    "    try:\n",
    "        # 新版本MTCNN构造函数不需要参数\n",
    "        detector = MTCNN()\n",
    "        processed_frames = []\n",
    "        \n",
    "        for frame in frames:\n",
    "            # MTCNN需要RGB格式\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if len(frame.shape) == 3 else frame\n",
    "            \n",
    "            # 检测人脸 - 新版本API在detect_faces方法中传递参数\n",
    "            results = detector.detect_faces(\n",
    "                frame_rgb,\n",
    "                min_face_size=40,  # 最小人脸尺寸\n",
    "                threshold_pnet=0.6,  # PNet阈值\n",
    "                threshold_rnet=0.7,  # RNet阈值  \n",
    "                threshold_onet=0.8   # ONet阈值\n",
    "            )\n",
    "            \n",
    "            if results and len(results) > 0:\n",
    "                # 选择置信度最高的人脸\n",
    "                best_face = max(results, key=lambda x: x['confidence'])\n",
    "                \n",
    "                if best_face['confidence'] > 0.9:  # 高置信度阈值\n",
    "                    # 提取人脸区域\n",
    "                    x, y, w, h = best_face['box']\n",
    "                    \n",
    "                    # 扩展边界框以包含更多上下文\n",
    "                    margin = 0.2\n",
    "                    x_margin = int(w * margin)\n",
    "                    y_margin = int(h * margin)\n",
    "                    \n",
    "                    x1 = max(0, x - x_margin)\n",
    "                    y1 = max(0, y - y_margin)\n",
    "                    x2 = min(frame_rgb.shape[1], x + w + x_margin)\n",
    "                    y2 = min(frame_rgb.shape[0], y + h + y_margin)\n",
    "                    \n",
    "                    # 裁剪人脸\n",
    "                    face_crop = frame_rgb[y1:y2, x1:x2]\n",
    "                    \n",
    "                    # 使用统一的帧处理函数\n",
    "                    processed_frame = resize_and_validate_frame(face_crop, target_size, 0)  # MTCNN不需要额外质量检查\n",
    "                    if processed_frame is None:\n",
    "                        processed_frames.append(cv2.resize(face_crop, target_size))  # 如果处理失败，返回原帧\n",
    "                    else:\n",
    "                        processed_frames.append(processed_frame)\n",
    "                else:\n",
    "                    # 置信度不够，使用原始帧\n",
    "                    processed_frames.append(cv2.resize(frame_rgb, target_size))\n",
    "            else:\n",
    "                # 没有检测到人脸，使用原始帧\n",
    "                processed_frames.append(cv2.resize(frame_rgb, target_size))\n",
    "        \n",
    "        return processed_frames\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"MTCNN人脸检测失败，使用原始帧: {e}\")\n",
    "        return [cv2.resize(frame, target_size) for frame in frames]\n",
    "\n",
    "def resize_and_validate_frame(frame, target_size, quality_threshold=20):\n",
    "    \"\"\"统一的帧处理函数：调整大小并验证质量\"\"\"\n",
    "    if frame is None:\n",
    "        return None\n",
    "    \n",
    "    # 调整尺寸\n",
    "    resized_frame = cv2.resize(frame, target_size)\n",
    "    \n",
    "    # 质量检查\n",
    "    if quality_threshold > 0:\n",
    "        # 计算图像的方差作为质量指标\n",
    "        gray = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2GRAY) if len(resized_frame.shape) == 3 else resized_frame\n",
    "        variance = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        if variance < quality_threshold:\n",
    "            return None\n",
    "    \n",
    "    return resized_frame\n",
    "\n",
    "def extract_frames_cpu_fallback(video_path, max_frames=16, target_size=(224, 224), quality_threshold=20, use_mtcnn=True):\n",
    "    \"\"\"CPU回退的帧提取函数 - 集成MTCNN\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"无法打开视频: {video_path}\")\n",
    "        return frames\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames == 0:\n",
    "        cap.release()\n",
    "        return frames\n",
    "\n",
    "    # 均匀采样策略\n",
    "    if total_frames <= max_frames:\n",
    "        frame_indices = list(range(0, total_frames, max(1, total_frames // max_frames)))\n",
    "    else:\n",
    "        step = max(1, total_frames // max_frames)\n",
    "        frame_indices = list(range(0, total_frames, step))[:max_frames]\n",
    "\n",
    "    frame_count = 0\n",
    "    for frame_idx in frame_indices:\n",
    "        if frame_count >= max_frames:\n",
    "            break\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # 使用统一的帧处理函数\n",
    "            processed_frame = resize_and_validate_frame(frame, target_size, quality_threshold)\n",
    "            if processed_frame is None:\n",
    "                continue\n",
    "            frame = processed_frame\n",
    "            frames.append(frame)\n",
    "            frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # 如果帧数不足，重复最后一帧\n",
    "    while len(frames) < max_frames and len(frames) > 0:\n",
    "        frames.append(frames[-1].copy())\n",
    "\n",
    "    # 应用MTCNN人脸检测\n",
    "    if use_mtcnn and globals().get('MTCNN_AVAILABLE', False):\n",
    "        frames = apply_mtcnn_face_detection(frames, target_size)\n",
    "\n",
    "    return frames[:max_frames]\n",
    "\n",
    "# 为了向后兼容，保留原函数名，但移除冗余参数\n",
    "def extract_frames_memory_efficient(video_path, max_frames=16, target_size=(224, 224),\n",
    "                                   quality_threshold=20, use_mtcnn=True):\n",
    "    \"\"\"兼容性包装函数，优先使用GPU加速，集成MTCNN\n",
    "    注意：skip_frames参数已移除，因为GPU版本使用更智能的采样策略\n",
    "    \"\"\"\n",
    "    return extract_frames_gpu_accelerated(video_path, max_frames, target_size, quality_threshold, use_mtcnn=use_mtcnn)\n",
    "\n",
    "def process_videos_simple(base_data_dir, max_videos_per_class=60, max_frames=16, max_real=None, max_fake=None):\n",
    "    \"\"\"简化的视频处理函数 - 优化假视频平均分配\"\"\"\n",
    "    # 打印设备信息（只打印一次）\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"📱 数据处理使用设备: {device}\")\n",
    "    \n",
    "    # 向后兼容：如果指定了新参数，使用新参数；否则使用旧参数\n",
    "    if max_real is None:\n",
    "        max_real = max_videos_per_class\n",
    "    if max_fake is None:\n",
    "        max_fake = max_videos_per_class\n",
    "    \n",
    "    data_list = []\n",
    "    fake_methods = ['Deepfakes', 'Face2Face', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'DeepFakeDetection']\n",
    "\n",
    "    print(\"开始处理真实视频...\")\n",
    "    # 处理真实视频\n",
    "    original_dir = os.path.join(base_data_dir, 'original')\n",
    "    if os.path.exists(original_dir):\n",
    "        video_files = [f for f in os.listdir(original_dir)\n",
    "                      if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        \n",
    "        if len(video_files) > max_real:\n",
    "            video_files = random.sample(video_files, max_real)\n",
    "\n",
    "        print(f\"找到 {len(video_files)} 个真实视频\")\n",
    "\n",
    "        for video_file in tqdm(video_files, desc=\"处理真实视频\"):\n",
    "            try:\n",
    "                video_path = os.path.join(original_dir, video_file)\n",
    "                frames = extract_frames_memory_efficient(video_path, max_frames)\n",
    "                \n",
    "                if len(frames) >= max_frames // 2:  # 至少要有一半的帧\n",
    "                    data_list.append({\n",
    "                        'video_path': video_path,\n",
    "                        'frames': frames,\n",
    "                        'label': 0,  # 真实视频\n",
    "                        'method': 'original'\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"处理视频 {video_file} 时出错: {e}\")\n",
    "                continue\n",
    "\n",
    "    # 处理伪造视频 - 平均分配策略\n",
    "    print(\"开始处理伪造视频...\")\n",
    "    \n",
    "    # 统计每种方法的可用视频数量\n",
    "    method_videos = {}\n",
    "    total_available_fake = 0\n",
    "    \n",
    "    for method in fake_methods:\n",
    "        method_dir = os.path.join(base_data_dir, method)\n",
    "        if os.path.exists(method_dir):\n",
    "            videos = [os.path.join(method_dir, f) for f in os.listdir(method_dir) \n",
    "                     if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "            method_videos[method] = videos\n",
    "            total_available_fake += len(videos)\n",
    "            print(f\"  {method}: {len(videos)} 个视频\")\n",
    "        else:\n",
    "            method_videos[method] = []\n",
    "            print(f\"  {method}: 目录不存在\")\n",
    "    \n",
    "    print(f\"总共可用假视频: {total_available_fake} 个\")\n",
    "    \n",
    "    # 计算每种方法应该采样的视频数量（平均分配）\n",
    "    available_methods = [method for method in fake_methods if len(method_videos[method]) > 0]\n",
    "    if not available_methods:\n",
    "        print(\"❌ 未找到任何假视频方法\")\n",
    "        return data_list\n",
    "    \n",
    "    videos_per_method = max_fake // len(available_methods)\n",
    "    remaining_videos = max_fake % len(available_methods)\n",
    "    \n",
    "    print(f\"平均分配策略: 每种方法 {videos_per_method} 个视频\")\n",
    "    if remaining_videos > 0:\n",
    "        print(f\"剩余 {remaining_videos} 个视频将分配给前 {remaining_videos} 种方法\")\n",
    "    \n",
    "    # 为每种方法采样视频\n",
    "    selected_fake_videos = []\n",
    "    for i, method in enumerate(available_methods):\n",
    "        # 计算当前方法应该采样的数量\n",
    "        current_method_quota = videos_per_method\n",
    "        if i < remaining_videos:  # 前几种方法多分配一个\n",
    "            current_method_quota += 1\n",
    "        \n",
    "        available_videos = method_videos[method]\n",
    "        \n",
    "        # 如果可用视频数量少于配额，全部使用\n",
    "        if len(available_videos) <= current_method_quota:\n",
    "            method_selected = available_videos\n",
    "            print(f\"  {method}: 使用全部 {len(method_selected)} 个视频\")\n",
    "        else:\n",
    "            # 随机采样指定数量\n",
    "            method_selected = random.sample(available_videos, current_method_quota)\n",
    "            print(f\"  {method}: 采样 {len(method_selected)} 个视频\")\n",
    "        \n",
    "        selected_fake_videos.extend([(v, method) for v in method_selected])\n",
    "    \n",
    "    print(f\"总共选择 {len(selected_fake_videos)} 个假视频进行处理\")\n",
    "    \n",
    "    # 打乱选择的假视频顺序\n",
    "    random.shuffle(selected_fake_videos)\n",
    "    \n",
    "    # 处理选择的假视频\n",
    "    for video_path, method in tqdm(selected_fake_videos, desc=\"处理伪造视频\"):\n",
    "        try:\n",
    "            frames = extract_frames_memory_efficient(video_path, max_frames)\n",
    "            \n",
    "            if len(frames) >= max_frames // 2:\n",
    "                data_list.append({\n",
    "                    'video_path': video_path,\n",
    "                    'frames': frames,\n",
    "                    'label': 1,  # 伪造视频\n",
    "                    'method': method\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"处理视频 {os.path.basename(video_path)} 时出错: {e}\")\n",
    "            continue\n",
    "\n",
    "    # 统计最终结果\n",
    "    method_counts = {}\n",
    "    for item in data_list:\n",
    "        if item['label'] == 1:  # 只统计假视频\n",
    "            method = item['method']\n",
    "            method_counts[method] = method_counts.get(method, 0) + 1\n",
    "    \n",
    "    print(f\"\\n✅ 数据处理完成，共处理 {len(data_list)} 个视频\")\n",
    "    print(\"假视频方法分布:\")\n",
    "    for method, count in method_counts.items():\n",
    "        print(f\"  {method}: {count} 个视频\")\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "def create_dataset_split(data_list, test_size=0.2, val_size=0.1):\n",
    "    \"\"\"创建数据集划分\"\"\"\n",
    "    # 分离真实和伪造数据\n",
    "    real_data = [item for item in data_list if item['label'] == 0]\n",
    "    fake_data = [item for item in data_list if item['label'] == 1]\n",
    "    \n",
    "    print(f\"真实视频: {len(real_data)} 个\")\n",
    "    print(f\"伪造视频: {len(fake_data)} 个\")\n",
    "    \n",
    "    # 分别划分真实和伪造数据\n",
    "    real_train, real_temp = train_test_split(real_data, test_size=test_size+val_size, random_state=42)\n",
    "    real_val, real_test = train_test_split(real_temp, test_size=test_size/(test_size+val_size), random_state=42)\n",
    "    \n",
    "    fake_train, fake_temp = train_test_split(fake_data, test_size=test_size+val_size, random_state=42)\n",
    "    fake_val, fake_test = train_test_split(fake_temp, test_size=test_size/(test_size+val_size), random_state=42)\n",
    "    \n",
    "    # 合并数据\n",
    "    train_data = real_train + fake_train\n",
    "    val_data = real_val + fake_val\n",
    "    test_data = real_test + fake_test\n",
    "    \n",
    "    # 打乱数据\n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(val_data)\n",
    "    random.shuffle(test_data)\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def save_dataset_to_csv(data_list, filename):\n",
    "    \"\"\"将数据集保存为CSV文件 - 支持预提取帧路径\"\"\"\n",
    "    df_data = []\n",
    "    for item in data_list:\n",
    "        # 检查是否为预提取的帧数据\n",
    "        if 'frame_path' in item:\n",
    "            df_data.append({\n",
    "                'frame_path': item['frame_path'],\n",
    "                'label': item['label'],\n",
    "                'method': item['method'],\n",
    "                'num_frames': item.get('num_frames', 16)\n",
    "            })\n",
    "        else:\n",
    "            # 向后兼容：原始视频路径格式\n",
    "            df_data.append({\n",
    "                'video_path': item['video_path'],\n",
    "                'label': item['label'],\n",
    "                'method': item['method'],\n",
    "                'num_frames': len(item['frames'])\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"数据集已保存到: {filename}\")\n",
    "    return df\n",
    "\n",
    "print(\"✅ 数据处理函数定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db687c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.235659Z",
     "iopub.status.busy": "2025-07-29T10:28:38.235459Z",
     "iopub.status.idle": "2025-07-29T10:28:38.266965Z",
     "shell.execute_reply": "2025-07-29T10:28:38.266157Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.042035,
     "end_time": "2025-07-29T10:28:38.268076",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.226041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据集类定义完成\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: 数据集类定义\n",
    "\n",
    "# 必要的导入\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class DeepfakeVideoDataset(Dataset):\n",
    "    \"\"\"深度伪造视频数据集类 - 支持预提取帧和多模态特征\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file, max_frames=16, gpu_preprocessing=True, \n",
    "                 extract_fourier=True, extract_compression=True, transform=None):\n",
    "        \"\"\"\n",
    "        初始化数据集 - 专用于预提取帧的GPU预处理\n",
    "        \n",
    "        Args:\n",
    "            csv_file: CSV文件路径（必须包含frame_path列）\n",
    "            max_frames: 最大帧数\n",
    "            gpu_preprocessing: 是否启用GPU预处理\n",
    "            extract_fourier: 是否提取傅里叶特征\n",
    "            extract_compression: 是否提取压缩特征\n",
    "            transform: 数据变换（可选）\n",
    "        \"\"\"\n",
    "        self.csv_file = csv_file\n",
    "        self.max_frames = max_frames\n",
    "        self.gpu_preprocessing = gpu_preprocessing\n",
    "        self.extract_fourier = extract_fourier\n",
    "        self.extract_compression = extract_compression\n",
    "        self.transform = transform  # 添加transform属性\n",
    "        \n",
    "        # 加载数据\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # 验证必须包含frame_path列\n",
    "        if 'frame_path' not in self.df.columns:\n",
    "            raise ValueError(f\"CSV文件 {csv_file} 必须包含 'frame_path' 列。请先运行预提取流程。\")\n",
    "        \n",
    "        print(f\"✅ 预提取帧模式，共 {len(self.df)} 个样本\")\n",
    "        \n",
    "        # GPU设备\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and gpu_preprocessing else 'cpu')\n",
    "        \n",
    "        # 预计算的标准化参数（ImageNet标准）\n",
    "        self.mean_tensor = torch.tensor([0.485, 0.456, 0.406], device=self.device).view(1, 3, 1, 1)\n",
    "        self.std_tensor = torch.tensor([0.229, 0.224, 0.225], device=self.device).view(1, 3, 1, 1)\n",
    "        \n",
    "        # 预计算数据统计信息\n",
    "        self._compute_dataset_stats()\n",
    "        \n",
    "        print(f\"✅ 数据集初始化完成: {len(self)} 个样本\")\n",
    "        print(f\"🚀 GPU预处理: {self.gpu_preprocessing} (设备: {self.device})\")\n",
    "        if self.extract_fourier:\n",
    "            print(\"📊 启用频域特征提取\")\n",
    "        if self.extract_compression:\n",
    "            print(\"🔍 启用压缩伪影分析\")\n",
    "\n",
    "    def _compute_dataset_stats(self):\n",
    "        \"\"\"预计算数据集统计信息\"\"\"\n",
    "        try:\n",
    "            self.real_count = len(self.df[self.df['label'] == 0])\n",
    "            self.fake_count = len(self.df[self.df['label'] == 1])\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 计算数据统计时出错: {e}\")\n",
    "            self.real_count = 0\n",
    "            self.fake_count = 0\n",
    "        \n",
    "        print(f\"📊 数据分布: 真实={self.real_count}, 伪造={self.fake_count}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"获取数据项 - 专用于预提取帧的GPU预处理\"\"\"\n",
    "        try:\n",
    "            row = self.df.iloc[idx]\n",
    "            label = row['label']\n",
    "            frame_path = row['frame_path']\n",
    "\n",
    "            # 从预提取的帧文件加载\n",
    "            video_tensor = self._load_preextracted_frames(frame_path)\n",
    "            \n",
    "            # 确保帧数一致\n",
    "            video_tensor = self._ensure_frame_count(video_tensor)\n",
    "            \n",
    "            # GPU预处理\n",
    "            if self.gpu_preprocessing and video_tensor.device != self.device:\n",
    "                video_tensor = video_tensor.to(self.device, non_blocking=True)\n",
    "            \n",
    "            # 标准化\n",
    "            video_tensor = self._normalize_frames(video_tensor)\n",
    "            \n",
    "            # 应用变换（如果有）\n",
    "            if self.transform:\n",
    "                video_tensor = self._apply_transforms(video_tensor)\n",
    "\n",
    "            # 提取多模态特征\n",
    "            additional_features = self._extract_additional_features(video_tensor)\n",
    "\n",
    "            label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "            \n",
    "            # 清理GPU内存\n",
    "            if self.gpu_preprocessing:\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # 返回数据和额外特征\n",
    "            if additional_features:\n",
    "                return video_tensor, label_tensor, additional_features\n",
    "            else:\n",
    "                return video_tensor, label_tensor\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 获取数据项 {idx} 时出错: {e}\")\n",
    "            # 返回默认数据\n",
    "            return self._get_default_item()\n",
    "\n",
    "    def _extract_additional_features(self, frames_tensor):\n",
    "        \"\"\"提取额外的多模态特征\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        try:\n",
    "            # 将tensor转换为numpy进行特征提取\n",
    "            if frames_tensor.device != torch.device('cpu'):\n",
    "                frames_np = frames_tensor.cpu().numpy()\n",
    "            else:\n",
    "                frames_np = frames_tensor.numpy()\n",
    "            \n",
    "            # 反标准化以获得原始像素值\n",
    "            mean_np = self.mean_tensor.cpu().numpy().reshape(1, 3, 1, 1)\n",
    "            std_np = self.std_tensor.cpu().numpy().reshape(1, 3, 1, 1)\n",
    "            frames_np = frames_np * std_np + mean_np\n",
    "            frames_np = np.clip(frames_np * 255.0, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            if self.extract_fourier:\n",
    "                # 提取频域特征（使用中间帧）\n",
    "                mid_frame_idx = len(frames_np) // 2\n",
    "                mid_frame = frames_np[mid_frame_idx].transpose(1, 2, 0)  # CHW -> HWC\n",
    "                \n",
    "                try:\n",
    "                    # 检查函数是否存在\n",
    "                    if 'extract_fourier_features' in globals():\n",
    "                        fourier_features = extract_fourier_features(mid_frame)\n",
    "                        if fourier_features:\n",
    "                            features['fourier'] = fourier_features\n",
    "                    else:\n",
    "                        # 如果函数不存在，创建简单的频域特征替代\n",
    "                        gray_frame = np.mean(mid_frame, axis=2)\n",
    "                        fft = np.fft.fft2(gray_frame)\n",
    "                        fft_magnitude = np.abs(fft)\n",
    "                        features['fourier'] = {\n",
    "                            'mean_magnitude': float(np.mean(fft_magnitude)),\n",
    "                            'std_magnitude': float(np.std(fft_magnitude)),\n",
    "                            'max_magnitude': float(np.max(fft_magnitude))\n",
    "                        }\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ 频域特征提取失败: {e}\")\n",
    "            \n",
    "            if self.extract_compression:\n",
    "                # 提取压缩伪影特征\n",
    "                compression_features = []\n",
    "                for i in range(0, len(frames_np), 4):  # 每4帧采样一次\n",
    "                    frame = frames_np[i].transpose(1, 2, 0)  # CHW -> HWC\n",
    "                    try:\n",
    "                        # 检查函数是否存在\n",
    "                        if 'analyze_compression_artifacts' in globals():\n",
    "                            comp_feat = analyze_compression_artifacts(frame)\n",
    "                            if comp_feat:\n",
    "                                compression_features.append(comp_feat)\n",
    "                        else:\n",
    "                            # 如果函数不存在，创建简单的压缩特征替代\n",
    "                            gray_frame = np.mean(frame, axis=2)\n",
    "                            # 简单的DCT能量计算\n",
    "                            dct_energy = float(np.var(gray_frame))\n",
    "                            # 简单的边缘密度计算\n",
    "                            edges = np.abs(np.gradient(gray_frame.astype(float)))\n",
    "                            edge_density = float(np.mean(edges[0]**2 + edges[1]**2))\n",
    "                            \n",
    "                            comp_feat = {\n",
    "                                'dct_energy': dct_energy,\n",
    "                                'edge_density': edge_density,\n",
    "                                'dct_mean': dct_energy,\n",
    "                                'high_freq_energy': dct_energy * 0.1\n",
    "                            }\n",
    "                            compression_features.append(comp_feat)\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ 压缩特征提取失败: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                if compression_features:\n",
    "                    # 聚合压缩特征\n",
    "                    features['compression'] = {\n",
    "                        'dct_mean': np.mean([f.get('dct_mean', f.get('dct_energy', 0)) for f in compression_features]),\n",
    "                        'dct_std': np.std([f.get('dct_mean', f.get('dct_energy', 0)) for f in compression_features]),\n",
    "                        'dct_energy': np.mean([f.get('dct_energy', 0) for f in compression_features]),\n",
    "                        'high_freq_energy': np.mean([f.get('high_freq_energy', f.get('dct_energy', 0) * 0.1) for f in compression_features]),\n",
    "                        'edge_density': np.mean([f.get('edge_density', 0) for f in compression_features])\n",
    "                    }\n",
    "            \n",
    "            # 计算时序一致性特征\n",
    "            if len(frames_np) > 1:\n",
    "                temporal_features = self._compute_temporal_consistency_tensor(frames_np)\n",
    "                if temporal_features:\n",
    "                    features['temporal'] = temporal_features\n",
    "            \n",
    "            return features if features else None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 提取额外特征失败: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _compute_temporal_consistency(self, frames):\n",
    "        \"\"\"计算时序一致性特征（向后兼容）\"\"\"\n",
    "        try:\n",
    "            # 计算相邻帧之间的差异\n",
    "            frame_diffs = []\n",
    "            for i in range(len(frames) - 1):\n",
    "                diff = np.mean(np.abs(frames[i+1].astype(float) - frames[i].astype(float)))\n",
    "                frame_diffs.append(diff)\n",
    "            \n",
    "            if frame_diffs:\n",
    "                return {\n",
    "                    'mean_frame_diff': np.mean(frame_diffs),\n",
    "                    'std_frame_diff': np.std(frame_diffs),\n",
    "                    'max_frame_diff': np.max(frame_diffs),\n",
    "                    'temporal_smoothness': 1.0 / (1.0 + np.std(frame_diffs))\n",
    "                }\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 计算时序特征失败: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _compute_temporal_consistency_tensor(self, frames_np):\n",
    "        \"\"\"计算时序一致性特征（tensor版本）\"\"\"\n",
    "        try:\n",
    "            # 计算相邻帧之间的差异\n",
    "            frame_diffs = []\n",
    "            for i in range(len(frames_np) - 1):\n",
    "                diff = np.mean(np.abs(frames_np[i+1].astype(float) - frames_np[i].astype(float)))\n",
    "                frame_diffs.append(diff)\n",
    "            \n",
    "            if frame_diffs:\n",
    "                return {\n",
    "                    'mean_frame_diff': np.mean(frame_diffs),\n",
    "                    'std_frame_diff': np.std(frame_diffs),\n",
    "                    'max_frame_diff': np.max(frame_diffs),\n",
    "                    'temporal_smoothness': 1.0 / (1.0 + np.std(frame_diffs))\n",
    "                }\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 计算时序特征失败: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _load_preextracted_frames(self, frame_path):\n",
    "        \"\"\"从预提取的帧文件加载数据\"\"\"\n",
    "        try:\n",
    "            # 直接加载tensor（数据准备阶段保存的格式）\n",
    "            frames_tensor = torch.load(frame_path, map_location='cpu')\n",
    "            \n",
    "            # 如果加载的是字典格式，提取frames\n",
    "            if isinstance(frames_tensor, dict):\n",
    "                frames_tensor = frames_tensor['frames']\n",
    "            \n",
    "            # 确保数据类型和范围正确\n",
    "            if frames_tensor.dtype != torch.float32:\n",
    "                frames_tensor = frames_tensor.float()\n",
    "            \n",
    "            # 数据准备阶段已经将像素值标准化到[0,1]，这里需要恢复到[0,255]\n",
    "            if frames_tensor.max() <= 1.0:\n",
    "                frames_tensor = frames_tensor * 255.0\n",
    "            \n",
    "            return frames_tensor\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"加载预提取帧失败 {frame_path}: {e}\")\n",
    "            return self._create_default_frames_tensor()\n",
    "    \n",
    "\n",
    "    \n",
    "    def _create_default_frames_tensor(self):\n",
    "        \"\"\"创建默认帧张量\"\"\"\n",
    "        # 创建随机噪声帧而不是全零帧，使训练更有意义\n",
    "        frames_tensor = torch.randint(0, 50, (self.max_frames, 3, 224, 224), dtype=torch.float32)\n",
    "        return frames_tensor\n",
    "    \n",
    "    def _ensure_frame_count(self, frames_tensor):\n",
    "        \"\"\"确保帧数一致\"\"\"\n",
    "        current_frames = frames_tensor.shape[0]\n",
    "        \n",
    "        if current_frames < self.max_frames:\n",
    "            # 重复最后一帧\n",
    "            last_frame = frames_tensor[-1:]\n",
    "            repeat_count = self.max_frames - current_frames\n",
    "            repeated_frames = last_frame.repeat(repeat_count, 1, 1, 1)\n",
    "            frames_tensor = torch.cat([frames_tensor, repeated_frames], dim=0)\n",
    "        elif current_frames > self.max_frames:\n",
    "            # 截取前max_frames帧\n",
    "            frames_tensor = frames_tensor[:self.max_frames]\n",
    "        \n",
    "        return frames_tensor\n",
    "    \n",
    "    def _normalize_frames(self, frames_tensor):\n",
    "        \"\"\"标准化帧数据\"\"\"\n",
    "        # 确保像素值在[0, 1]范围内\n",
    "        if frames_tensor.max() > 1.0:\n",
    "            frames_tensor = frames_tensor / 255.0\n",
    "        \n",
    "        # 移动标准化参数到正确设备\n",
    "        if self.mean_tensor.device != frames_tensor.device:\n",
    "            self.mean_tensor = self.mean_tensor.to(frames_tensor.device)\n",
    "            self.std_tensor = self.std_tensor.to(frames_tensor.device)\n",
    "        \n",
    "        # ImageNet标准化\n",
    "        frames_tensor = (frames_tensor - self.mean_tensor) / self.std_tensor\n",
    "        \n",
    "        # 限制数值范围防止梯度爆炸\n",
    "        frames_tensor = torch.clamp(frames_tensor, -10, 10)\n",
    "        \n",
    "        return frames_tensor\n",
    "    \n",
    "    def _apply_transforms(self, frames_tensor):\n",
    "        \"\"\"应用数据变换\"\"\"\n",
    "        try:\n",
    "            # 将tensor转换回PIL格式进行变换\n",
    "            transformed_frames = []\n",
    "            \n",
    "            # 反标准化以获得原始像素值\n",
    "            denorm_tensor = frames_tensor * self.std_tensor + self.mean_tensor\n",
    "            denorm_tensor = torch.clamp(denorm_tensor * 255.0, 0, 255)\n",
    "            \n",
    "            for i in range(frames_tensor.shape[0]):\n",
    "                frame = denorm_tensor[i].permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "                frame_pil = Image.fromarray(frame)\n",
    "                transformed_frame = self.transform(frame_pil)\n",
    "                \n",
    "                # 检查变换后是否有NaN或无穷值\n",
    "                if torch.isnan(transformed_frame).any() or torch.isinf(transformed_frame).any():\n",
    "                    print(f\"⚠️ 检测到NaN/Inf值，跳过变换\")\n",
    "                    return frames_tensor\n",
    "                \n",
    "                transformed_frames.append(transformed_frame)\n",
    "            \n",
    "            return torch.stack(transformed_frames)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 数据变换失败，使用原始数据: {e}\")\n",
    "            return frames_tensor\n",
    "    \n",
    "\n",
    "\n",
    "    def _get_default_item(self):\n",
    "        \"\"\"获取默认数据项（用于错误恢复）\"\"\"\n",
    "        frames = self._create_default_frames()\n",
    "        video_tensor = torch.stack([\n",
    "            torch.from_numpy(frame).permute(2, 0, 1) for frame in frames\n",
    "        ]).float() / 255.0\n",
    "        \n",
    "        # 标准化\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "        video_tensor = (video_tensor - mean) / std\n",
    "        \n",
    "        label_tensor = torch.tensor(0.0, dtype=torch.float32)\n",
    "        return video_tensor, label_tensor\n",
    "\n",
    "    def _create_default_frames(self):\n",
    "        \"\"\"创建默认帧数据（numpy格式）\"\"\"\n",
    "        # 创建随机噪声帧而不是全零帧，使训练更有意义\n",
    "        frames = []\n",
    "        for _ in range(self.max_frames):\n",
    "            # 创建224x224x3的随机帧，值在[0, 50]范围内（低噪声）\n",
    "            frame = np.random.randint(0, 50, (224, 224, 3), dtype=np.uint8)\n",
    "            frames.append(frame)\n",
    "        return frames\n",
    "\n",
    "\n",
    "\n",
    "    def enable_ensemble_mode(self):\n",
    "        \"\"\"启用集成模式，提取所有可用特征\"\"\"\n",
    "        self.extract_fourier = True\n",
    "        self.extract_compression = True\n",
    "        print(\"🎯 启用集成模式：所有特征提取已激活\")\n",
    "\n",
    "print(\"✅ 数据集类定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb6855e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.286035Z",
     "iopub.status.busy": "2025-07-29T10:28:38.285825Z",
     "iopub.status.idle": "2025-07-29T10:28:38.328817Z",
     "shell.execute_reply": "2025-07-29T10:28:38.328167Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.053578,
     "end_time": "2025-07-29T10:28:38.329803",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.276225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 优化模型定义完成\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: 模型定义 - 集成多模态特征和Ensemble策略\n",
    "class OptimizedDeepfakeDetector(nn.Module):\n",
    "    \"\"\"优化的深度伪造检测器 - 集成多模态特征和Ensemble策略\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=1, dropout_rate=0.3, use_attention=True, \n",
    "                 use_multimodal=False, ensemble_mode=False):\n",
    "        super(OptimizedDeepfakeDetector, self).__init__()\n",
    "        \n",
    "        self.use_attention = use_attention\n",
    "        self.use_multimodal = use_multimodal\n",
    "        self.ensemble_mode = ensemble_mode\n",
    "        \n",
    "        # 主干网络 - ResNet50\n",
    "        self.backbone = models.resnet50(pretrained=True)\n",
    "        backbone_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()  # 移除最后的分类层\n",
    "        \n",
    "        # 时序特征提取\n",
    "        self.temporal_conv = nn.Sequential(\n",
    "            nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool3d((1, 7, 7))\n",
    "        )\n",
    "        \n",
    "        # 注意力机制\n",
    "        if use_attention:\n",
    "            self.attention = nn.MultiheadAttention(\n",
    "                embed_dim=backbone_features, \n",
    "                num_heads=8, \n",
    "                dropout=dropout_rate,\n",
    "                batch_first=True\n",
    "            )\n",
    "            self.attention_norm = nn.LayerNorm(backbone_features)\n",
    "        \n",
    "        # 多模态特征融合\n",
    "        if use_multimodal:\n",
    "            # 频域特征处理 - 修正输入维度\n",
    "            self.fourier_fc = nn.Sequential(\n",
    "                nn.Linear(5, 256),  # 频域特征实际维度为5 (mean, std, max, energy, entropy)\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(256, 128)\n",
    "            )\n",
    "            \n",
    "            # 压缩伪影特征处理 - 修正输入维度\n",
    "            self.compression_fc = nn.Sequential(\n",
    "                nn.Linear(32, 64),  # 压缩特征扩展为32维\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(64, 32)\n",
    "            )\n",
    "            \n",
    "            # 时序一致性特征处理\n",
    "            self.temporal_fc = nn.Sequential(\n",
    "                nn.Linear(4, 64),  # 时序特征维度为4\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(64, 32)\n",
    "            )\n",
    "            \n",
    "            # 特征融合层 - 动态计算输入维度\n",
    "            # 基础特征: backbone_features (2048)\n",
    "            # 频域特征: 128 (fourier_fc输出)\n",
    "            # 压缩特征: 32 (compression_fc输出)  \n",
    "            # 时序特征: 32 (temporal_fc输出)\n",
    "            fusion_dim = backbone_features + 128 + 32 + 32  # 2048 + 128 + 32 + 32 = 2240\n",
    "            self.fusion_layer = nn.Sequential(\n",
    "                nn.Linear(fusion_dim, 512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(512, 256)\n",
    "            )\n",
    "            final_features = 256\n",
    "        else:\n",
    "            final_features = backbone_features\n",
    "        \n",
    "        # 集成模式的多个分类头\n",
    "        if ensemble_mode:\n",
    "            # 主分类器\n",
    "            self.main_classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(final_features, 128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(128, num_classes)\n",
    "            )\n",
    "            \n",
    "            # 辅助分类器1 - 专注于空间特征\n",
    "            self.spatial_classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(final_features, 64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(64, num_classes)\n",
    "            )\n",
    "            \n",
    "            # 辅助分类器2 - 专注于时序特征\n",
    "            self.temporal_classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(final_features, 64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(64, num_classes)\n",
    "            )\n",
    "            \n",
    "            # 集成权重（可学习）\n",
    "            self.ensemble_weights = nn.Parameter(torch.ones(3) / 3)\n",
    "            \n",
    "        else:\n",
    "            # 单一分类器\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(final_features, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(128, num_classes)\n",
    "            )\n",
    "            \n",
    "            # 添加单一分类器用于处理基础特征（当多模态特征处理失败时）\n",
    "            self.single_classifier = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(backbone_features, 128),  # 直接处理backbone特征\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(128, num_classes)\n",
    "            )\n",
    "        \n",
    "        # 初始化权重\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        print(f\"✅ 模型初始化完成\")\n",
    "        print(f\"   - 注意力机制: {'启用' if use_attention else '禁用'}\")\n",
    "        print(f\"   - 多模态融合: {'启用' if use_multimodal else '禁用'}\")\n",
    "        print(f\"   - 集成模式: {'启用' if ensemble_mode else '禁用'}\")\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"初始化权重\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x, additional_features=None):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        Args:\n",
    "            x: 视频张量 (B, T, C, H, W)\n",
    "            additional_features: 额外特征字典\n",
    "        \"\"\"\n",
    "        batch_size, num_frames, channels, height, width = x.shape\n",
    "        \n",
    "        # 提取每帧的空间特征\n",
    "        x_reshaped = x.view(batch_size * num_frames, channels, height, width)\n",
    "        spatial_features = self.backbone(x_reshaped)  # (B*T, features)\n",
    "        spatial_features = spatial_features.view(batch_size, num_frames, -1)  # (B, T, features)\n",
    "        \n",
    "        # 时序特征聚合\n",
    "        if self.use_attention:\n",
    "            # 使用注意力机制聚合时序特征\n",
    "            attended_features, attention_weights = self.attention(\n",
    "                spatial_features, spatial_features, spatial_features\n",
    "            )\n",
    "            attended_features = self.attention_norm(attended_features + spatial_features)\n",
    "            # 全局平均池化\n",
    "            temporal_features = torch.mean(attended_features, dim=1)  # (B, features)\n",
    "        else:\n",
    "            # 简单平均池化\n",
    "            temporal_features = torch.mean(spatial_features, dim=1)  # (B, features)\n",
    "        \n",
    "        # 多模态特征融合\n",
    "        if self.use_multimodal and additional_features is not None:\n",
    "            fusion_features = [temporal_features]\n",
    "            \n",
    "            # 处理频域特征\n",
    "            if 'fourier' in additional_features:\n",
    "                try:\n",
    "                    fourier_feat = additional_features['fourier']\n",
    "                    if isinstance(fourier_feat, dict):\n",
    "                        # 安全地提取数值特征\n",
    "                        fourier_values = []\n",
    "                        for value in fourier_feat.values():\n",
    "                            if isinstance(value, (int, float)):\n",
    "                                fourier_values.append(float(value))\n",
    "                            elif isinstance(value, torch.Tensor):\n",
    "                                if value.numel() == 1:\n",
    "                                    fourier_values.append(float(value.item()))\n",
    "                                else:\n",
    "                                    fourier_values.append(float(value.mean().item()))\n",
    "                            elif isinstance(value, np.ndarray):\n",
    "                                if value.size == 1:\n",
    "                                    fourier_values.append(float(value.item()))\n",
    "                                else:\n",
    "                                    fourier_values.append(float(value.mean()))\n",
    "                            else:\n",
    "                                fourier_values.append(0.0)  # 默认值\n",
    "                        \n",
    "                        # 确保有足够的特征维度\n",
    "                        if len(fourier_values) < 5:  # fourier_fc期望5维输入\n",
    "                            fourier_values.extend([0.0] * (5 - len(fourier_values)))\n",
    "                        elif len(fourier_values) > 5:\n",
    "                            fourier_values = fourier_values[:5]\n",
    "                        \n",
    "                        fourier_tensor = torch.tensor([fourier_values] * batch_size, \n",
    "                                                    dtype=torch.float32, \n",
    "                                                    device=temporal_features.device)\n",
    "                    else:\n",
    "                        # 如果已经是张量，确保正确的形状\n",
    "                        if isinstance(fourier_feat, torch.Tensor):\n",
    "                            fourier_tensor = fourier_feat.to(temporal_features.device)\n",
    "                            if fourier_tensor.dim() == 1:\n",
    "                                fourier_tensor = fourier_tensor.unsqueeze(0).repeat(batch_size, 1)\n",
    "                        else:\n",
    "                            # 创建默认张量\n",
    "                            fourier_tensor = torch.zeros(batch_size, 5, \n",
    "                                                        dtype=torch.float32, \n",
    "                                                        device=temporal_features.device)\n",
    "                    \n",
    "                    fourier_processed = self.fourier_fc(fourier_tensor)\n",
    "                    fusion_features.append(fourier_processed)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ 频域特征处理失败: {e}\")\n",
    "                    # 使用默认特征\n",
    "                    fourier_tensor = torch.zeros(batch_size, 5, \n",
    "                                                dtype=torch.float32, \n",
    "                                                device=temporal_features.device)\n",
    "                    fourier_processed = self.fourier_fc(fourier_tensor)\n",
    "                    fusion_features.append(fourier_processed)\n",
    "            \n",
    "            # 处理压缩伪影特征\n",
    "            if 'compression' in additional_features:\n",
    "                try:\n",
    "                    comp_feat = additional_features['compression']\n",
    "                    if isinstance(comp_feat, dict):\n",
    "                        # 安全地提取压缩特征 - 修正为5个特征\n",
    "                        comp_values = []\n",
    "                        for key in ['dct_mean', 'dct_std', 'dct_energy', 'high_freq_energy', 'edge_density']:\n",
    "                            if key in comp_feat:\n",
    "                                value = comp_feat[key]\n",
    "                                if isinstance(value, (int, float)):\n",
    "                                    comp_values.append(float(value))\n",
    "                                elif isinstance(value, torch.Tensor):\n",
    "                                    comp_values.append(float(value.item() if value.numel() == 1 else value.mean().item()))\n",
    "                                elif isinstance(value, np.ndarray):\n",
    "                                    comp_values.append(float(value.item() if value.size == 1 else value.mean()))\n",
    "                                else:\n",
    "                                    comp_values.append(0.0)\n",
    "                            else:\n",
    "                                comp_values.append(0.0)\n",
    "                        \n",
    "                        # 扩展到32维：重复基础特征并添加派生特征\n",
    "                        extended_values = comp_values.copy()\n",
    "                        # 添加派生特征\n",
    "                        extended_values.extend([\n",
    "                            comp_values[0] * comp_values[1],  # mean * std\n",
    "                            comp_values[2] / (comp_values[3] + 1e-8),  # energy ratio\n",
    "                            comp_values[4] * comp_values[0],  # edge * mean\n",
    "                            np.sqrt(abs(comp_values[2])),  # sqrt energy\n",
    "                            comp_values[1] / (comp_values[0] + 1e-8),  # std/mean ratio\n",
    "                        ])\n",
    "                        # 重复填充到32维\n",
    "                        while len(extended_values) < 32:\n",
    "                            extended_values.extend(comp_values[:min(5, 32 - len(extended_values))])\n",
    "                        \n",
    "                        comp_tensor = torch.tensor([extended_values[:32]] * batch_size, \n",
    "                                                 dtype=torch.float32, \n",
    "                                                 device=temporal_features.device)\n",
    "                    else:\n",
    "                        if isinstance(comp_feat, torch.Tensor):\n",
    "                            comp_tensor = comp_feat.to(temporal_features.device)\n",
    "                            if comp_tensor.dim() == 1:\n",
    "                                comp_tensor = comp_tensor.unsqueeze(0).repeat(batch_size, 1)\n",
    "                            # 确保是32维\n",
    "                            if comp_tensor.size(-1) < 32:\n",
    "                                padding = torch.zeros(batch_size, 32 - comp_tensor.size(-1), \n",
    "                                                    dtype=torch.float32, \n",
    "                                                    device=temporal_features.device)\n",
    "                                comp_tensor = torch.cat([comp_tensor, padding], dim=-1)\n",
    "                            elif comp_tensor.size(-1) > 32:\n",
    "                                comp_tensor = comp_tensor[:, :32]\n",
    "                        else:\n",
    "                            comp_tensor = torch.zeros(batch_size, 32, \n",
    "                                                    dtype=torch.float32, \n",
    "                                                    device=temporal_features.device)\n",
    "                    \n",
    "                    comp_processed = self.compression_fc(comp_tensor)\n",
    "                    fusion_features.append(comp_processed)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ 压缩特征处理失败: {e}\")\n",
    "                    comp_tensor = torch.zeros(batch_size, 32, \n",
    "                                            dtype=torch.float32, \n",
    "                                            device=temporal_features.device)\n",
    "                    comp_processed = self.compression_fc(comp_tensor)\n",
    "                    fusion_features.append(comp_processed)\n",
    "            \n",
    "            # 处理时序一致性特征\n",
    "            if 'temporal' in additional_features:\n",
    "                try:\n",
    "                    temp_feat = additional_features['temporal']\n",
    "                    if isinstance(temp_feat, dict):\n",
    "                        # 安全地提取时序特征\n",
    "                        temp_values = []\n",
    "                        for key in ['mean_frame_diff', 'std_frame_diff', 'max_frame_diff', 'temporal_smoothness']:\n",
    "                            if key in temp_feat:\n",
    "                                value = temp_feat[key]\n",
    "                                if isinstance(value, (int, float)):\n",
    "                                    temp_values.append(float(value))\n",
    "                                elif isinstance(value, torch.Tensor):\n",
    "                                    temp_values.append(float(value.item() if value.numel() == 1 else value.mean().item()))\n",
    "                                elif isinstance(value, np.ndarray):\n",
    "                                    temp_values.append(float(value.item() if value.size == 1 else value.mean()))\n",
    "                                else:\n",
    "                                    temp_values.append(0.0)\n",
    "                            else:\n",
    "                                temp_values.append(0.0)\n",
    "                        \n",
    "                        temp_tensor = torch.tensor([temp_values] * batch_size, \n",
    "                                                 dtype=torch.float32, \n",
    "                                                 device=temporal_features.device)\n",
    "                    else:\n",
    "                        if isinstance(temp_feat, torch.Tensor):\n",
    "                            temp_tensor = temp_feat.to(temporal_features.device)\n",
    "                            if temp_tensor.dim() == 1:\n",
    "                                temp_tensor = temp_tensor.unsqueeze(0).repeat(batch_size, 1)\n",
    "                        else:\n",
    "                            temp_tensor = torch.zeros(batch_size, 4, \n",
    "                                                    dtype=torch.float32, \n",
    "                                                    device=temporal_features.device)\n",
    "                    \n",
    "                    temp_processed = self.temporal_fc(temp_tensor)\n",
    "                    fusion_features.append(temp_processed)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ 时序特征处理失败: {e}\")\n",
    "                    temp_tensor = torch.zeros(batch_size, 4, \n",
    "                                            dtype=torch.float32, \n",
    "                                            device=temporal_features.device)\n",
    "                    temp_processed = self.temporal_fc(temp_tensor)\n",
    "                    fusion_features.append(temp_processed)\n",
    "            \n",
    "            # 特征融合 - 确保维度一致性\n",
    "            if len(fusion_features) > 1:\n",
    "                try:\n",
    "                    # 检查每个特征的维度\n",
    "                    feature_dims = [f.shape[1] for f in fusion_features]\n",
    "                    total_dim = sum(feature_dims)\n",
    "                    expected_dim = self.fusion_layer[0].in_features\n",
    "                    \n",
    "                    if total_dim == expected_dim:\n",
    "                        # 维度匹配，直接融合\n",
    "                        fused_features = torch.cat(fusion_features, dim=1)\n",
    "                        final_features = self.fusion_layer(fused_features)\n",
    "                    else:\n",
    "                        # 维度不匹配时进行调整（这是正常的多模态特征处理）\n",
    "                        if total_dim < expected_dim:\n",
    "                            # 维度不足，用零填充\n",
    "                            padding_dim = expected_dim - total_dim\n",
    "                            fused_features = torch.cat(fusion_features, dim=1)\n",
    "                            padding = torch.zeros(batch_size, padding_dim, \n",
    "                                                dtype=fused_features.dtype, \n",
    "                                                device=fused_features.device)\n",
    "                            fused_features = torch.cat([fused_features, padding], dim=1)\n",
    "                            final_features = self.fusion_layer(fused_features)\n",
    "                            # 只在调试模式下输出详细信息\n",
    "                            if hasattr(self, 'debug_mode') and self.debug_mode:\n",
    "                                print(f\"🔧 特征填充: {total_dim} -> {expected_dim}\")\n",
    "                        elif total_dim > expected_dim:\n",
    "                            # 维度过多，截断到期望维度\n",
    "                            fused_features = torch.cat(fusion_features, dim=1)\n",
    "                            fused_features = fused_features[:, :expected_dim]\n",
    "                            final_features = self.fusion_layer(fused_features)\n",
    "                            # 只在调试模式下输出详细信息\n",
    "                            if hasattr(self, 'debug_mode') and self.debug_mode:\n",
    "                                print(f\"🔧 特征截断: {total_dim} -> {expected_dim}\")\n",
    "                        else:\n",
    "                            # 理论上不应该到达这里\n",
    "                            print(f\"⚠️ 特征融合异常，使用基础特征\")\n",
    "                            final_features = temporal_features\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ 特征融合失败: {e}\")\n",
    "                    final_features = temporal_features\n",
    "            else:\n",
    "                final_features = temporal_features\n",
    "        else:\n",
    "            final_features = temporal_features\n",
    "        \n",
    "        # 分类预测 - 根据特征维度选择合适的分类器\n",
    "        if self.ensemble_mode:\n",
    "            # 集成预测\n",
    "            main_pred = self.main_classifier(final_features)\n",
    "            spatial_pred = self.spatial_classifier(final_features)\n",
    "            temporal_pred = self.temporal_classifier(final_features)\n",
    "            \n",
    "            # 加权融合\n",
    "            weights = F.softmax(self.ensemble_weights, dim=0)\n",
    "            ensemble_pred = (weights[0] * main_pred + \n",
    "                           weights[1] * spatial_pred + \n",
    "                           weights[2] * temporal_pred)\n",
    "            \n",
    "            if self.training:\n",
    "                # 训练时返回所有预测用于多任务学习\n",
    "                return {\n",
    "                    'main': main_pred,\n",
    "                    'spatial': spatial_pred,\n",
    "                    'temporal': temporal_pred,\n",
    "                    'ensemble': ensemble_pred\n",
    "                }\n",
    "            else:\n",
    "                # 推理时只返回集成结果\n",
    "                return ensemble_pred\n",
    "        else:\n",
    "            # 检查特征维度并选择合适的分类器\n",
    "            feature_dim = final_features.shape[1]\n",
    "            \n",
    "            # 获取分类器的输入维度\n",
    "            classifier_input_dim = None\n",
    "            single_classifier_input_dim = None\n",
    "            \n",
    "            # 找到第一个Linear层来获取输入维度\n",
    "            for layer in self.classifier:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    classifier_input_dim = layer.in_features\n",
    "                    break\n",
    "            \n",
    "            for layer in self.single_classifier:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    single_classifier_input_dim = layer.in_features\n",
    "                    break\n",
    "            \n",
    "            # 根据特征维度选择合适的分类器\n",
    "            if classifier_input_dim and feature_dim == classifier_input_dim:\n",
    "                logits = self.classifier(final_features)\n",
    "            elif single_classifier_input_dim and feature_dim == single_classifier_input_dim:\n",
    "                logits = self.single_classifier(final_features)\n",
    "            else:\n",
    "                # 如果都不匹配，尝试使用单一分类器（通常处理基础特征）\n",
    "                print(f\"⚠️ 特征维度 {feature_dim} 不匹配任何分类器，使用单一分类器\")\n",
    "                logits = self.single_classifier(final_features)\n",
    "            \n",
    "            # 检查输出是否包含NaN或无穷值\n",
    "            if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
    "                print(\"⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\")\n",
    "                # 返回安全的默认输出（中性预测）\n",
    "                batch_size = logits.shape[0]\n",
    "                device = logits.device\n",
    "                logits = torch.zeros(batch_size, 1, device=device, dtype=torch.float32)\n",
    "            \n",
    "            # 限制logits的数值范围，避免极端值\n",
    "            logits = torch.clamp(logits, -10, 10)\n",
    "            \n",
    "            return logits\n",
    "\n",
    "    def get_attention_weights(self, x):\n",
    "        \"\"\"获取注意力权重（用于可视化）\"\"\"\n",
    "        if not self.use_attention:\n",
    "            return None\n",
    "        \n",
    "        batch_size, num_frames, channels, height, width = x.shape\n",
    "        x_reshaped = x.view(batch_size * num_frames, channels, height, width)\n",
    "        spatial_features = self.backbone(x_reshaped)\n",
    "        spatial_features = spatial_features.view(batch_size, num_frames, -1)\n",
    "        \n",
    "        _, attention_weights = self.attention(\n",
    "            spatial_features, spatial_features, spatial_features\n",
    "        )\n",
    "        \n",
    "        return attention_weights\n",
    "\n",
    "    def enable_ensemble_mode(self):\n",
    "        \"\"\"启用集成模式\"\"\"\n",
    "        self.ensemble_mode = True\n",
    "        print(\"🎯 集成模式已启用\")\n",
    "\n",
    "    def disable_ensemble_mode(self):\n",
    "        \"\"\"禁用集成模式\"\"\"\n",
    "        self.ensemble_mode = False\n",
    "        print(\"🎯 集成模式已禁用\")\n",
    "\n",
    "    def get_model_info(self):\n",
    "        \"\"\"获取模型信息\"\"\"\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        \n",
    "        return {\n",
    "            'total_parameters': total_params,\n",
    "            'trainable_parameters': trainable_params,\n",
    "            'use_attention': self.use_attention,\n",
    "            'use_multimodal': self.use_multimodal,\n",
    "            'ensemble_mode': self.ensemble_mode\n",
    "        }\n",
    "\n",
    "def create_ensemble_models(num_models=3, **kwargs):\n",
    "    \"\"\"创建多个模型用于集成学习\"\"\"\n",
    "    models = []\n",
    "    for i in range(num_models):\n",
    "        # 为每个模型使用不同的配置\n",
    "        model_kwargs = kwargs.copy()\n",
    "        if i == 0:\n",
    "            model_kwargs.update({'use_attention': True, 'dropout_rate': 0.3})\n",
    "        elif i == 1:\n",
    "            model_kwargs.update({'use_attention': False, 'dropout_rate': 0.4})\n",
    "        else:\n",
    "            model_kwargs.update({'use_attention': True, 'dropout_rate': 0.2})\n",
    "        \n",
    "        model = OptimizedDeepfakeDetector(**model_kwargs)\n",
    "        models.append(model)\n",
    "    \n",
    "    print(f\"✅ 创建了 {num_models} 个集成模型\")\n",
    "    return models\n",
    "\n",
    "print(\"✅ 优化模型定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45178020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.347510Z",
     "iopub.status.busy": "2025-07-29T10:28:38.347301Z",
     "iopub.status.idle": "2025-07-29T10:28:38.363856Z",
     "shell.execute_reply": "2025-07-29T10:28:38.362999Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.027378,
     "end_time": "2025-07-29T10:28:38.365352",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.337974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 损失函数和工具类定义完成\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: 损失函数和工具类\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"焦点损失函数 - 解决类别不平衡问题（修复版本）\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # 添加数值稳定性检查\n",
    "        inputs = torch.clamp(inputs, min=-10, max=10)  # 防止极值导致NaN\n",
    "        \n",
    "        # 使用 BCEWithLogitsLoss 以兼容 autocast，支持pos_weight\n",
    "        ce_loss = nn.BCEWithLogitsLoss(pos_weight=self.pos_weight, reduction='none')(inputs, targets)\n",
    "        \n",
    "        # 添加数值稳定性\n",
    "        ce_loss = torch.clamp(ce_loss, min=1e-8, max=100)\n",
    "        \n",
    "        # 计算概率用于focal weight\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        pt = torch.clamp(pt, min=1e-8, max=1-1e-8)  # 防止极值\n",
    "        \n",
    "        # 动态alpha：对于正样本使用alpha，负样本使用(1-alpha)\n",
    "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "        focal_loss = alpha_t * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        # 检查NaN并替换\n",
    "        focal_loss = torch.where(torch.isnan(focal_loss), torch.zeros_like(focal_loss), focal_loss)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    \"\"\"标签平滑损失函数\"\"\"\n",
    "    \n",
    "    def __init__(self, smoothing=0.1, pos_weight=None):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.pos_weight = pos_weight\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        # 标签平滑\n",
    "        targets_smooth = targets * (1 - self.smoothing) + 0.5 * self.smoothing\n",
    "        \n",
    "        # 使用BCEWithLogitsLoss\n",
    "        loss = nn.BCEWithLogitsLoss(pos_weight=self.pos_weight, reduction='mean')(inputs, targets_smooth)\n",
    "        return loss\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"组合损失函数：Focal Loss + Label Smoothing\"\"\"\n",
    "    \n",
    "    def __init__(self, focal_weight=0.7, smooth_weight=0.3, alpha=0.25, gamma=2.0, \n",
    "                 smoothing=0.1, pos_weight=None):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.focal_weight = focal_weight\n",
    "        self.smooth_weight = smooth_weight\n",
    "        self.focal_loss = FocalLoss(alpha=alpha, gamma=gamma, pos_weight=pos_weight)\n",
    "        self.smooth_loss = LabelSmoothingLoss(smoothing=smoothing, pos_weight=pos_weight)\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        focal = self.focal_loss(inputs, targets)\n",
    "        smooth = self.smooth_loss(inputs, targets)\n",
    "        return self.focal_weight * focal + self.smooth_weight * smooth\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"早停机制\"\"\"\n",
    "    \n",
    "    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "        if self.counter >= self.patience:\n",
    "            if self.restore_best_weights:\n",
    "                model.load_state_dict(self.best_weights)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        self.best_weights = model.state_dict().copy()\n",
    "\n",
    "def get_transforms(mode='train', image_size=224):\n",
    "    \"\"\"获取优化的数据变换 \"\"\"\n",
    "    if mode == 'train':\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((int(image_size * 1.1), int(image_size * 1.1))),\n",
    "            transforms.RandomCrop((image_size, image_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.RandomRotation(degrees=10),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 添加平移\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "def compute_class_weights(dataset):\n",
    "    \"\"\"计算类别权重\"\"\"\n",
    "    if hasattr(dataset, 'real_count') and hasattr(dataset, 'fake_count'):\n",
    "        real_count = dataset.real_count\n",
    "        fake_count = dataset.fake_count\n",
    "    else:\n",
    "        # 回退方案\n",
    "        real_count = 1\n",
    "        fake_count = 1\n",
    "    \n",
    "    total = real_count + fake_count\n",
    "    weight_real = total / (2 * real_count) if real_count > 0 else 1.0\n",
    "    weight_fake = total / (2 * fake_count) if fake_count > 0 else 1.0\n",
    "    \n",
    "    return torch.tensor([weight_fake / weight_real])  # pos_weight for BCEWithLogitsLoss\n",
    "\n",
    "print(\"✅ 损失函数和工具类定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9bd4281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.383695Z",
     "iopub.status.busy": "2025-07-29T10:28:38.383471Z",
     "iopub.status.idle": "2025-07-29T10:28:38.426520Z",
     "shell.execute_reply": "2025-07-29T10:28:38.425502Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.053309,
     "end_time": "2025-07-29T10:28:38.427660",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.374351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 优化训练函数定义完成\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: 训练函数 - 集成多任务学习和高级优化策略\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, scheduler=None, \n",
    "                use_amp=False, gradient_clip=1.0, ensemble_mode=False):\n",
    "    \"\"\"\n",
    "    训练一个epoch - 支持集成学习和多任务学习\n",
    "    \n",
    "    Args:\n",
    "        model: 模型\n",
    "        train_loader: 训练数据加载器\n",
    "        criterion: 损失函数\n",
    "        optimizer: 优化器\n",
    "        device: 设备\n",
    "        scheduler: 学习率调度器\n",
    "        use_amp: 是否使用混合精度训练\n",
    "        gradient_clip: 梯度裁剪阈值\n",
    "        ensemble_mode: 是否为集成模式\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    # 集成模式的损失统计\n",
    "    if ensemble_mode:\n",
    "        ensemble_losses = {\n",
    "            'main': 0.0,\n",
    "            'spatial': 0.0,\n",
    "            'temporal': 0.0,\n",
    "            'ensemble': 0.0\n",
    "        }\n",
    "    \n",
    "    # 混合精度训练\n",
    "    if use_amp:\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"训练中\", leave=False)\n",
    "    \n",
    "    # 添加训练开始的调试信息\n",
    "    print(f\"🔍 训练开始调试信息:\")\n",
    "    print(f\"   - 数据加载器长度: {len(train_loader)}\")\n",
    "    print(f\"   - 当前学习率: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    print(f\"   - 设备: {device}\")\n",
    "    print(f\"   - 混合精度: {'启用' if use_amp else '禁用'}\")\n",
    "    \n",
    "    for batch_idx, batch_data in enumerate(progress_bar):\n",
    "        # 定期清理GPU内存\n",
    "        if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        # 内存监控\n",
    "        if batch_idx % 20 == 0 and torch.cuda.is_available():\n",
    "            memory_allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "            memory_reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "            print(f\"📊 批次 {batch_idx}: GPU内存 {memory_allocated:.1f}GB / {memory_reserved:.1f}GB\")\n",
    "        \n",
    "        # 处理不同的数据格式\n",
    "        if len(batch_data) == 3:\n",
    "            # 包含额外特征\n",
    "            videos, labels, additional_features = batch_data\n",
    "            videos = videos.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 处理额外特征\n",
    "            if additional_features and isinstance(additional_features, dict):\n",
    "                for key, value in additional_features.items():\n",
    "                    if isinstance(value, torch.Tensor):\n",
    "                        additional_features[key] = value.to(device)\n",
    "        else:\n",
    "            # 标准格式\n",
    "            videos, labels = batch_data\n",
    "            videos = videos.to(device)\n",
    "            labels = labels.to(device)\n",
    "            additional_features = None\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        try:\n",
    "            if use_amp:\n",
    "                # 混合精度前向传播\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    if additional_features is not None:\n",
    "                        outputs = model(videos, additional_features)\n",
    "                    else:\n",
    "                        outputs = model(videos)\n",
    "                    \n",
    "                    # 检查模型输出是否包含NaN\n",
    "                    if isinstance(outputs, dict):\n",
    "                        for key, output in outputs.items():\n",
    "                            if torch.isnan(output).any() or torch.isinf(output).any():\n",
    "                                print(f\"⚠️ 批次 {batch_idx}: 模型输出 {key} 包含NaN/Inf\")\n",
    "                                raise ValueError(f\"Model output {key} contains NaN/Inf\")\n",
    "                    else:\n",
    "                        if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "                            print(f\"⚠️ 批次 {batch_idx}: 模型输出包含NaN/Inf\")\n",
    "                            raise ValueError(\"Model output contains NaN/Inf\")\n",
    "                    \n",
    "                    # 计算损失\n",
    "                    if ensemble_mode and isinstance(outputs, dict):\n",
    "                        # 集成模式的多任务损失\n",
    "                        losses = {}\n",
    "                        total_ensemble_loss = 0\n",
    "                        \n",
    "                        for key, pred in outputs.items():\n",
    "                            if pred.dim() > 1:\n",
    "                                pred = pred.squeeze(-1)\n",
    "                            loss = criterion(pred, labels)\n",
    "                            losses[key] = loss\n",
    "                            \n",
    "                            # 不同任务的权重\n",
    "                            if key == 'ensemble':\n",
    "                                weight = 0.5  # 集成预测权重最高\n",
    "                            elif key == 'main':\n",
    "                                weight = 0.3\n",
    "                            else:\n",
    "                                weight = 0.1  # 辅助任务权重较低\n",
    "                            \n",
    "                            total_ensemble_loss += weight * loss\n",
    "                        \n",
    "                        loss = total_ensemble_loss\n",
    "                        pred_probs = torch.sigmoid(outputs['ensemble'])\n",
    "                        \n",
    "                        # 更新集成损失统计\n",
    "                        for key, l in losses.items():\n",
    "                            ensemble_losses[key] += l.item()\n",
    "                    else:\n",
    "                        # 标准模式\n",
    "                        if outputs.dim() > 1:\n",
    "                            outputs = outputs.squeeze(-1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        pred_probs = torch.sigmoid(outputs)\n",
    "                    \n",
    "                    # 检查损失是否为NaN\n",
    "                    if torch.isnan(loss) or torch.isinf(loss):\n",
    "                        print(f\"⚠️ 批次 {batch_idx}: 损失为NaN/Inf，跳过此批次\")\n",
    "                        raise ValueError(\"Loss is NaN/Inf\")\n",
    "                \n",
    "                # 混合精度反向传播\n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                if gradient_clip > 0:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n",
    "                \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # 标准精度训练\n",
    "                if additional_features is not None:\n",
    "                    outputs = model(videos, additional_features)\n",
    "                else:\n",
    "                    outputs = model(videos)\n",
    "                \n",
    "                # 检查模型输出是否包含NaN\n",
    "                if isinstance(outputs, dict):\n",
    "                    for key, output in outputs.items():\n",
    "                        if torch.isnan(output).any() or torch.isinf(output).any():\n",
    "                            print(f\"⚠️ 批次 {batch_idx}: 模型输出 {key} 包含NaN/Inf\")\n",
    "                            raise ValueError(f\"Model output {key} contains NaN/Inf\")\n",
    "                else:\n",
    "                    if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "                        print(f\"⚠️ 批次 {batch_idx}: 模型输出包含NaN/Inf\")\n",
    "                        raise ValueError(\"Model output contains NaN/Inf\")\n",
    "                \n",
    "                # 计算损失\n",
    "                if ensemble_mode and isinstance(outputs, dict):\n",
    "                    # 集成模式的多任务损失\n",
    "                    losses = {}\n",
    "                    total_ensemble_loss = 0\n",
    "                    \n",
    "                    for key, pred in outputs.items():\n",
    "                        if pred.dim() > 1:\n",
    "                            pred = pred.squeeze(-1)\n",
    "                        loss_item = criterion(pred, labels)\n",
    "                        losses[key] = loss_item\n",
    "                        \n",
    "                        # 不同任务的权重\n",
    "                        if key == 'ensemble':\n",
    "                            weight = 0.5\n",
    "                        elif key == 'main':\n",
    "                            weight = 0.3\n",
    "                        else:\n",
    "                            weight = 0.1\n",
    "                        \n",
    "                        total_ensemble_loss += weight * loss_item\n",
    "                    \n",
    "                    loss = total_ensemble_loss\n",
    "                    pred_probs = torch.sigmoid(outputs['ensemble'])\n",
    "                    \n",
    "                    # 更新集成损失统计\n",
    "                    for key, l in losses.items():\n",
    "                        ensemble_losses[key] += l.item()\n",
    "                else:\n",
    "                    # 标准模式\n",
    "                    if outputs.dim() > 1:\n",
    "                        outputs = outputs.squeeze(-1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    pred_probs = torch.sigmoid(outputs)\n",
    "                \n",
    "                # 检查损失是否为NaN\n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(f\"⚠️ 批次 {batch_idx}: 损失为NaN/Inf，跳过此批次\")\n",
    "                    raise ValueError(\"Loss is NaN/Inf\")\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                if gradient_clip > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n",
    "                \n",
    "                optimizer.step()\n",
    "            \n",
    "            # 确保pred_probs是正确的张量格式\n",
    "            if pred_probs.dim() > 1:\n",
    "                pred_probs = pred_probs.squeeze(-1)\n",
    "            \n",
    "            # 计算准确率\n",
    "            predictions = (pred_probs > 0.5).float()\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            \n",
    "            # 更新统计\n",
    "            total_loss += loss.item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            # 添加成功批次的调试信息（仅前3个批次）\n",
    "            if batch_idx < 3:\n",
    "                print(f\"🔍 批次 {batch_idx} 成功:\")\n",
    "                print(f\"   - 损失值: {loss.item():.6f}\")\n",
    "                print(f\"   - 样本数: {labels.size(0)}\")\n",
    "                print(f\"   - 预测概率范围: [{pred_probs.min().item():.4f}, {pred_probs.max().item():.4f}]\")\n",
    "                print(f\"   - 标签分布: {labels.sum().item()}/{labels.size(0)}\")\n",
    "            \n",
    "            # 更新进度条\n",
    "            avg_loss = total_loss / (batch_idx + 1)\n",
    "            accuracy = correct_predictions / total_samples\n",
    "            \n",
    "            if ensemble_mode:\n",
    "                progress_bar.set_postfix({\n",
    "                    'Loss': f'{avg_loss:.4f}',\n",
    "                    'Acc': f'{accuracy:.4f}',\n",
    "                    'Ensemble': f'{ensemble_losses[\"ensemble\"]/(batch_idx+1):.4f}'\n",
    "                })\n",
    "            else:\n",
    "                progress_bar.set_postfix({\n",
    "                    'Loss': f'{avg_loss:.4f}',\n",
    "                    'Acc': f'{accuracy:.4f}'\n",
    "                })\n",
    "            \n",
    "            # 每个批次后清理变量\n",
    "            del videos, labels\n",
    "            if additional_features is not None:\n",
    "                del additional_features\n",
    "            if 'outputs' in locals():\n",
    "                del outputs\n",
    "            if 'pred_probs' in locals():\n",
    "                del pred_probs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 训练批次 {batch_idx} 出错: {e}\")\n",
    "            import traceback\n",
    "            print(f\"详细错误信息: {traceback.format_exc()}\")\n",
    "            # 添加调试信息\n",
    "            print(f\"🔍 调试信息 - 当前批次: {batch_idx}, 总样本数: {total_samples}, 总损失: {total_loss}\")\n",
    "            # 清理GPU内存\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            continue\n",
    "    \n",
    "    # 检查是否有有效的训练数据\n",
    "    if total_samples == 0:\n",
    "        print(\"⚠️ 警告: 没有成功处理任何训练批次!\")\n",
    "        return {\n",
    "            'loss': float('inf'),\n",
    "            'accuracy': 0.0,\n",
    "            'learning_rate': optimizer.param_groups[0]['lr']\n",
    "        }\n",
    "    \n",
    "    # 学习率调度\n",
    "    if scheduler is not None:\n",
    "        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(total_loss / max(len(train_loader), 1))\n",
    "        else:\n",
    "            scheduler.step()\n",
    "    \n",
    "    # 返回训练结果\n",
    "    avg_loss = total_loss / max(len(train_loader), 1)\n",
    "    accuracy = correct_predictions / max(total_samples, 1)\n",
    "    \n",
    "    # 添加详细调试信息\n",
    "    print(f\"🔍 训练结果调试:\")\n",
    "    print(f\"   - 总损失: {total_loss}\")\n",
    "    print(f\"   - 数据加载器长度: {len(train_loader)}\")\n",
    "    print(f\"   - 平均损失: {avg_loss}\")\n",
    "    print(f\"   - 正确预测数: {correct_predictions}\")\n",
    "    print(f\"   - 总样本数: {total_samples}\")\n",
    "    print(f\"   - 准确率: {accuracy}\")\n",
    "    \n",
    "    results = {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'learning_rate': optimizer.param_groups[0]['lr']\n",
    "    }\n",
    "    \n",
    "    if ensemble_mode:\n",
    "        # 添加集成损失统计\n",
    "        for key in ensemble_losses:\n",
    "            results[f'{key}_loss'] = ensemble_losses[key] / len(train_loader)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device, ensemble_mode=False):\n",
    "    \"\"\"\n",
    "    验证一个epoch - 支持集成学习评估\n",
    "    \n",
    "    Args:\n",
    "        model: 模型\n",
    "        val_loader: 验证数据加载器\n",
    "        criterion: 损失函数\n",
    "        device: 设备\n",
    "        ensemble_mode: 是否为集成模式\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # 集成模式的损失统计\n",
    "    if ensemble_mode:\n",
    "        ensemble_losses = {\n",
    "            'main': 0.0,\n",
    "            'spatial': 0.0,\n",
    "            'temporal': 0.0,\n",
    "            'ensemble': 0.0\n",
    "        }\n",
    "        ensemble_predictions = {\n",
    "            'main': [],\n",
    "            'spatial': [],\n",
    "            'temporal': [],\n",
    "            'ensemble': []\n",
    "        }\n",
    "    \n",
    "    progress_bar = tqdm(val_loader, desc=\"验证中\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(progress_bar):\n",
    "            try:\n",
    "                # 处理不同的数据格式\n",
    "                if len(batch_data) == 3:\n",
    "                    videos, labels, additional_features = batch_data\n",
    "                    videos = videos.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                    # 处理额外特征\n",
    "                    if additional_features and isinstance(additional_features, dict):\n",
    "                        for key, value in additional_features.items():\n",
    "                            if isinstance(value, torch.Tensor):\n",
    "                                additional_features[key] = value.to(device)\n",
    "                else:\n",
    "                    videos, labels = batch_data\n",
    "                    videos = videos.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    additional_features = None\n",
    "                \n",
    "                # 前向传播\n",
    "                if additional_features is not None:\n",
    "                    outputs = model(videos, additional_features)\n",
    "                else:\n",
    "                    outputs = model(videos)\n",
    "                \n",
    "                # 计算损失和预测\n",
    "                if ensemble_mode and isinstance(outputs, dict):\n",
    "                    # 集成模式\n",
    "                    losses = {}\n",
    "                    total_ensemble_loss = 0\n",
    "                    \n",
    "                    for key, pred in outputs.items():\n",
    "                        if pred.dim() > 1:\n",
    "                            pred = pred.squeeze(-1)\n",
    "                        loss_item = criterion(pred, labels)\n",
    "                        losses[key] = loss_item\n",
    "                        \n",
    "                        # 权重与训练时保持一致\n",
    "                        if key == 'ensemble':\n",
    "                            weight = 0.5\n",
    "                        elif key == 'main':\n",
    "                            weight = 0.3\n",
    "                        else:\n",
    "                            weight = 0.1\n",
    "                        \n",
    "                        total_ensemble_loss += weight * loss_item\n",
    "                        \n",
    "                        # 保存预测结果\n",
    "                        pred_probs_item = torch.sigmoid(pred)\n",
    "                        ensemble_predictions[key].extend(pred_probs_item.cpu().numpy())\n",
    "                        ensemble_losses[key] += loss_item.item()\n",
    "                    \n",
    "                    loss = total_ensemble_loss\n",
    "                    pred_probs = torch.sigmoid(outputs['ensemble'])\n",
    "                else:\n",
    "                    # 标准模式\n",
    "                    if outputs.dim() > 1:\n",
    "                        outputs = outputs.squeeze(-1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    pred_probs = torch.sigmoid(outputs)\n",
    "                \n",
    "                # 确保pred_probs是正确的张量格式\n",
    "                if pred_probs.dim() > 1:\n",
    "                    pred_probs = pred_probs.squeeze(-1)\n",
    "                \n",
    "                # 计算准确率\n",
    "                predictions = (pred_probs > 0.5).float()\n",
    "                correct_predictions += (predictions == labels).sum().item()\n",
    "                \n",
    "                # 保存预测和标签用于详细评估\n",
    "                all_predictions.extend(pred_probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # 更新统计\n",
    "                total_loss += loss.item()\n",
    "                total_samples += labels.size(0)\n",
    "                \n",
    "                # 更新进度条\n",
    "                avg_loss = total_loss / (batch_idx + 1)\n",
    "                accuracy = correct_predictions / total_samples\n",
    "                progress_bar.set_postfix({\n",
    "                    'Val Loss': f'{avg_loss:.4f}',\n",
    "                    'Val Acc': f'{accuracy:.4f}'\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 验证批次 {batch_idx} 出错: {e}\")\n",
    "                import traceback\n",
    "                print(f\"详细错误信息: {traceback.format_exc()}\")\n",
    "                continue\n",
    "    \n",
    "    # 检查是否有有效的验证数据\n",
    "    if total_samples == 0:\n",
    "        print(\"⚠️ 警告: 没有成功处理任何验证批次!\")\n",
    "        return {\n",
    "            'loss': float('inf'),\n",
    "            'accuracy': 0.0,\n",
    "            'auc': 0.0,\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0,\n",
    "            'predictions': [],\n",
    "            'labels': []\n",
    "        }\n",
    "    \n",
    "    # 计算最终指标\n",
    "    avg_loss = total_loss / max(len(val_loader), 1)\n",
    "    accuracy = correct_predictions / max(total_samples, 1)\n",
    "    \n",
    "    # 计算AUC等高级指标\n",
    "    try:\n",
    "        from sklearn.metrics import roc_auc_score, precision_recall_fscore_support\n",
    "        auc_score = roc_auc_score(all_labels, all_predictions)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, \n",
    "            np.array(all_predictions) > 0.5, \n",
    "            average='binary'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 计算高级指标失败: {e}\")\n",
    "        auc_score = 0.0\n",
    "        precision = recall = f1 = 0.0\n",
    "    \n",
    "    results = {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc_score,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "    \n",
    "    if ensemble_mode:\n",
    "        # 添加集成评估结果\n",
    "        for key in ensemble_losses:\n",
    "            results[f'{key}_loss'] = ensemble_losses[key] / len(val_loader)\n",
    "            results[f'{key}_predictions'] = ensemble_predictions[key]\n",
    "        \n",
    "        # 计算集成模型的AUC\n",
    "        try:\n",
    "            ensemble_auc = roc_auc_score(all_labels, ensemble_predictions['ensemble'])\n",
    "            results['ensemble_auc'] = ensemble_auc\n",
    "        except:\n",
    "            results['ensemble_auc'] = 0.0\n",
    "    \n",
    "    return results\n",
    "\n",
    "def train_ensemble_models(models, train_loader, val_loader, criterion, optimizers, \n",
    "                         device, num_epochs=10, schedulers=None, use_amp=False):\n",
    "    \"\"\"\n",
    "    训练多个模型进行集成学习\n",
    "    \n",
    "    Args:\n",
    "        models: 模型列表\n",
    "        train_loader: 训练数据加载器\n",
    "        val_loader: 验证数据加载器\n",
    "        criterion: 损失函数\n",
    "        optimizers: 优化器列表\n",
    "        device: 设备\n",
    "        num_epochs: 训练轮数\n",
    "        schedulers: 学习率调度器列表\n",
    "        use_amp: 是否使用混合精度训练\n",
    "    \"\"\"\n",
    "    ensemble_results = []\n",
    "    \n",
    "    for i, (model, optimizer) in enumerate(zip(models, optimizers)):\n",
    "        print(f\"\\n🚀 训练集成模型 {i+1}/{len(models)}\")\n",
    "        \n",
    "        scheduler = schedulers[i] if schedulers else None\n",
    "        model_results = {'train_history': [], 'val_history': []}\n",
    "        \n",
    "        best_val_auc = 0.0\n",
    "        best_model_state = None\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "            \n",
    "            # 训练\n",
    "            train_results = train_epoch(\n",
    "                model, train_loader, criterion, optimizer, device,\n",
    "                scheduler=scheduler, use_amp=use_amp\n",
    "            )\n",
    "            \n",
    "            # 验证\n",
    "            val_results = validate_epoch(model, val_loader, criterion, device)\n",
    "            \n",
    "            # 保存历史\n",
    "            model_results['train_history'].append(train_results)\n",
    "            model_results['val_history'].append(val_results)\n",
    "            \n",
    "            # 保存最佳模型\n",
    "            if val_results['auc'] > best_val_auc:\n",
    "                best_val_auc = val_results['auc']\n",
    "                best_model_state = model.state_dict().copy()\n",
    "            \n",
    "            print(f\"训练 - Loss: {train_results['loss']:.4f}, Acc: {train_results['accuracy']:.4f}\")\n",
    "            print(f\"验证 - Loss: {val_results['loss']:.4f}, Acc: {val_results['accuracy']:.4f}, AUC: {val_results['auc']:.4f}\")\n",
    "        \n",
    "        # 加载最佳模型权重\n",
    "        if best_model_state is not None:\n",
    "            model.load_state_dict(best_model_state)\n",
    "        \n",
    "        model_results['best_val_auc'] = best_val_auc\n",
    "        ensemble_results.append(model_results)\n",
    "        \n",
    "        print(f\"✅ 模型 {i+1} 训练完成，最佳验证AUC: {best_val_auc:.4f}\")\n",
    "    \n",
    "    return ensemble_results\n",
    "\n",
    "def ensemble_predict(models, data_loader, device, weights=None):\n",
    "    \"\"\"\n",
    "    使用多个模型进行集成预测\n",
    "    \n",
    "    Args:\n",
    "        models: 模型列表\n",
    "        data_loader: 数据加载器\n",
    "        device: 设备\n",
    "        weights: 模型权重（如果为None则使用平均权重）\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = [1.0 / len(models)] * len(models)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # 设置所有模型为评估模式\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(data_loader, desc=\"集成预测中\"):\n",
    "            if len(batch_data) == 3:\n",
    "                videos, labels, additional_features = batch_data\n",
    "                videos = videos.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                if additional_features and isinstance(additional_features, dict):\n",
    "                    for key, value in additional_features.items():\n",
    "                        if isinstance(value, torch.Tensor):\n",
    "                            additional_features[key] = value.to(device)\n",
    "            else:\n",
    "                videos, labels = batch_data\n",
    "                videos = videos.to(device)\n",
    "                labels = labels.to(device)\n",
    "                additional_features = None\n",
    "            \n",
    "            # 收集所有模型的预测\n",
    "            batch_predictions = []\n",
    "            for model in models:\n",
    "                if additional_features is not None:\n",
    "                    outputs = model(videos, additional_features)\n",
    "                else:\n",
    "                    outputs = model(videos)\n",
    "                \n",
    "                if isinstance(outputs, dict):\n",
    "                    # 集成模式，使用ensemble输出\n",
    "                    pred = outputs['ensemble']\n",
    "                else:\n",
    "                    pred = outputs\n",
    "                \n",
    "                if pred.dim() > 1:\n",
    "                    pred = pred.squeeze(-1)\n",
    "                \n",
    "                pred_probs = torch.sigmoid(pred)\n",
    "                batch_predictions.append(pred_probs.cpu().numpy())\n",
    "            \n",
    "            # 加权平均\n",
    "            ensemble_pred = np.average(batch_predictions, axis=0, weights=weights)\n",
    "            all_predictions.extend(ensemble_pred)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_labels)\n",
    "\n",
    "print(\"✅ 优化训练函数定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6e89300",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.444419Z",
     "iopub.status.busy": "2025-07-29T10:28:38.444181Z",
     "iopub.status.idle": "2025-07-29T10:28:38.470727Z",
     "shell.execute_reply": "2025-07-29T10:28:38.470033Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.036108,
     "end_time": "2025-07-29T10:28:38.471740",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.435632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 评估函数和可视化定义完成\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: 评估函数和可视化\n",
    "\n",
    "def evaluate_model_optimized(model, test_loader, criterion, device):\n",
    "    \"\"\"优化的模型评估函数\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_scores = []\n",
    "    \n",
    "    inference_times = []\n",
    "    \n",
    "    print(\"🚀 开始模型评估...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(tqdm(test_loader, desc=\"评估进度\")):\n",
    "            # 处理不同的返回格式：(data, target) 或 (data, target, additional_features)\n",
    "            if len(batch_data) == 2:\n",
    "                data, target = batch_data\n",
    "                additional_features = None\n",
    "            elif len(batch_data) == 3:\n",
    "                data, target, additional_features = batch_data\n",
    "            else:\n",
    "                raise ValueError(f\"数据加载器返回了意外的数据格式，长度为 {len(batch_data)}\")\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # 处理额外特征的设备转移\n",
    "            if additional_features is not None:\n",
    "                if isinstance(additional_features, dict):\n",
    "                    for key, value in additional_features.items():\n",
    "                        if isinstance(value, torch.Tensor):\n",
    "                            additional_features[key] = value.to(device)\n",
    "            \n",
    "            # 记录推理时间\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # 处理模型输出 - 模型可能返回单个张量或字典\n",
    "            if additional_features is not None:\n",
    "                model_output = model(data, additional_features)\n",
    "            else:\n",
    "                model_output = model(data)\n",
    "            \n",
    "            inference_time = time.time() - start_time\n",
    "            inference_times.append(inference_time)\n",
    "            \n",
    "            # 处理不同的输出格式\n",
    "            if isinstance(model_output, dict):\n",
    "                # 集成模式，使用ensemble输出\n",
    "                output = model_output.get('ensemble', model_output.get('main', list(model_output.values())[0]))\n",
    "            else:\n",
    "                # 标准模式，直接使用输出\n",
    "                output = model_output\n",
    "            \n",
    "            # 确保输出和目标的维度匹配\n",
    "            if output.dim() > 1:\n",
    "                output = output.squeeze(-1)  # 将 [batch, 1] 压缩为 [batch]\n",
    "            \n",
    "            # 确保目标标签是正确的数据类型和维度\n",
    "            if target.dim() > 1:\n",
    "                target = target.squeeze(-1)  # 将 [batch, 1] 压缩为 [batch]\n",
    "            target = target.float()  # 确保是float类型\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 收集预测结果 (应用 sigmoid 获得概率)\n",
    "            probs = torch.sigmoid(output)\n",
    "            predictions = (probs > 0.5).float()\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_scores.extend(probs.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    total_inference_time = np.sum(inference_times)\n",
    "    \n",
    "    print(f\"✅ 评估完成\")\n",
    "    print(f\"平均损失: {avg_loss:.4f}\")\n",
    "    print(f\"平均推理时间: {avg_inference_time*1000:.2f} ms/batch\")\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'predictions': np.array(all_predictions),\n",
    "        'targets': np.array(all_targets),\n",
    "        'scores': np.array(all_scores),\n",
    "        'avg_inference_time': avg_inference_time,\n",
    "        'total_inference_time': total_inference_time\n",
    "    }\n",
    "\n",
    "def calculate_comprehensive_metrics(predictions, targets, scores):\n",
    "    \"\"\"计算全面的评估指标，包含类别不平衡分析\"\"\"\n",
    "    # 基础指标\n",
    "    accuracy = accuracy_score(targets, predictions)\n",
    "    balanced_acc = balanced_accuracy_score(targets, predictions)\n",
    "    precision = precision_score(targets, predictions, zero_division=0)\n",
    "    recall = recall_score(targets, predictions, zero_division=0)\n",
    "    f1 = f1_score(targets, predictions, zero_division=0)\n",
    "    \n",
    "    # 混淆矩阵\n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n",
    "    \n",
    "    # 特异性和负预测值\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    \n",
    "    # 类别特定指标\n",
    "    real_total = np.sum(targets == 0)\n",
    "    fake_total = np.sum(targets == 1)\n",
    "    real_correct = tn  # 真实视频正确预测为真实\n",
    "    fake_correct = tp  # 伪造视频正确预测为伪造\n",
    "    \n",
    "    real_accuracy = real_correct / real_total if real_total > 0 else 0\n",
    "    fake_accuracy = fake_correct / fake_total if fake_total > 0 else 0\n",
    "    \n",
    "    # 类别不平衡分析\n",
    "    class_distribution = {\n",
    "        'real_samples': int(real_total),\n",
    "        'fake_samples': int(fake_total),\n",
    "        'imbalance_ratio': fake_total / real_total if real_total > 0 else float('inf')\n",
    "    }\n",
    "    \n",
    "    # AUC指标\n",
    "    try:\n",
    "        auc_roc = roc_auc_score(targets, scores)\n",
    "    except:\n",
    "        auc_roc = 0.0\n",
    "    \n",
    "    try:\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)\n",
    "        auc_pr = auc(recall_curve, precision_curve)\n",
    "    except:\n",
    "        auc_pr = 0.0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'balanced_accuracy': balanced_acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        'f1': f1,\n",
    "        'auc_roc': auc_roc,\n",
    "        'auc_pr': auc_pr,\n",
    "        'npv': npv,\n",
    "        'confusion_matrix': cm,\n",
    "        'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp,\n",
    "        'real_accuracy': real_accuracy,\n",
    "        'fake_accuracy': fake_accuracy,\n",
    "        'class_distribution': class_distribution\n",
    "    }\n",
    "\n",
    "def plot_enhanced_confusion_matrix(cm, save_path):\n",
    "    \"\"\"绘制增强的混淆矩阵\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # 计算百分比\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # 创建标签\n",
    "    labels = np.array([[\n",
    "        f'{cm[i,j]}\\n({cm_percent[i,j]:.1f}%)' \n",
    "        for j in range(cm.shape[1])\n",
    "    ] for i in range(cm.shape[0])])\n",
    "    \n",
    "    # 绘制热图\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', \n",
    "                xticklabels=['真实', '伪造'],\n",
    "                yticklabels=['真实', '伪造'],\n",
    "                cbar_kws={'label': '样本数量'})\n",
    "    \n",
    "    plt.title('增强混淆矩阵', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('预测标签', fontsize=12)\n",
    "    plt.ylabel('真实标签', fontsize=12)\n",
    "    \n",
    "    # 添加统计信息\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    stats_text = f'准确率: {accuracy:.3f}\\n精确率: {precision:.3f}\\n召回率: {recall:.3f}\\nF1分数: {f1:.3f}'\n",
    "    plt.text(2.1, 0.5, stats_text, fontsize=10, \n",
    "             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"混淆矩阵已保存到: {save_path}\")\n",
    "\n",
    "def plot_roc_pr_curves(targets, scores, save_path):\n",
    "    \"\"\"绘制ROC和PR曲线\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # ROC曲线\n",
    "    fpr, tpr, _ = roc_curve(targets, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    ax1.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f'ROC曲线 (AUC = {roc_auc:.4f})')\n",
    "    ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    ax1.set_xlim([0.0, 1.0])\n",
    "    ax1.set_ylim([0.0, 1.05])\n",
    "    ax1.set_xlabel('假正率')\n",
    "    ax1.set_ylabel('真正率')\n",
    "    ax1.set_title('ROC曲线')\n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # PR曲线\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)\n",
    "    pr_auc = auc(recall_curve, precision_curve)\n",
    "    \n",
    "    ax2.plot(recall_curve, precision_curve, color='darkgreen', lw=2,\n",
    "             label=f'PR曲线 (AUC = {pr_auc:.4f})')\n",
    "    ax2.set_xlim([0.0, 1.0])\n",
    "    ax2.set_ylim([0.0, 1.05])\n",
    "    ax2.set_xlabel('召回率')\n",
    "    ax2.set_ylabel('精确率')\n",
    "    ax2.set_title('精确率-召回率曲线')\n",
    "    ax2.legend(loc='lower left')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"ROC/PR曲线已保存到: {save_path}\")\n",
    "\n",
    "def generate_class_imbalance_report(metrics):\n",
    "    \"\"\"生成详细的类别不平衡分析报告\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📊 类别不平衡分析报告\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 数据分布\n",
    "    dist = metrics['class_distribution']\n",
    "    print(f\"\\n📈 数据分布:\")\n",
    "    print(f\"  真实视频样本: {dist['real_samples']}\")\n",
    "    print(f\"  伪造视频样本: {dist['fake_samples']}\")\n",
    "    print(f\"  不平衡比例: {dist['imbalance_ratio']:.2f}:1 (伪造:真实)\")\n",
    "    \n",
    "    # 类别特定性能\n",
    "    print(f\"\\n🎯 类别特定准确率:\")\n",
    "    print(f\"  真实视频检测准确率: {metrics['real_accuracy']*100:.2f}%\")\n",
    "    print(f\"  伪造视频检测准确率: {metrics['fake_accuracy']*100:.2f}%\")\n",
    "    \n",
    "    # 混淆矩阵分析\n",
    "    tn, fp, fn, tp = metrics['tn'], metrics['fp'], metrics['fn'], metrics['tp']\n",
    "    print(f\"\\n📋 混淆矩阵分析:\")\n",
    "    print(f\"  真负例 (TN): {tn} - 正确识别的真实视频\")\n",
    "    print(f\"  假正例 (FP): {fp} - 误判为伪造的真实视频\")\n",
    "    print(f\"  假负例 (FN): {fn} - 误判为真实的伪造视频\")\n",
    "    print(f\"  真正例 (TP): {tp} - 正确识别的伪造视频\")\n",
    "    \n",
    "    # 偏向性分析\n",
    "    total_predictions = tn + fp + fn + tp\n",
    "    predicted_real = tn + fn\n",
    "    predicted_fake = fp + tp\n",
    "    \n",
    "    print(f\"\\n⚖️ 模型偏向性分析:\")\n",
    "    print(f\"  预测为真实的样本: {predicted_real} ({predicted_real/total_predictions*100:.1f}%)\")\n",
    "    print(f\"  预测为伪造的样本: {predicted_fake} ({predicted_fake/total_predictions*100:.1f}%)\")\n",
    "    \n",
    "    # 问题诊断\n",
    "    print(f\"\\n🔍 问题诊断:\")\n",
    "    if metrics['real_accuracy'] < 0.1:\n",
    "        print(\"  ❌ 严重问题: 模型几乎无法识别真实视频\")\n",
    "    elif metrics['real_accuracy'] < 0.5:\n",
    "        print(\"  ⚠️  问题: 真实视频识别能力较差\")\n",
    "    else:\n",
    "        print(\"  ✅ 真实视频识别能力正常\")\n",
    "        \n",
    "    if metrics['fake_accuracy'] > 0.9 and metrics['real_accuracy'] < 0.1:\n",
    "        print(\"  ❌ 严重偏向: 模型过度偏向预测伪造视频\")\n",
    "    \n",
    "    if metrics['auc_roc'] < 0.6:\n",
    "        print(\"  ❌ AUC-ROC过低: 模型判别能力接近随机猜测\")\n",
    "    \n",
    "    # 改进建议\n",
    "    print(f\"\\n💡 改进建议:\")\n",
    "    if dist['imbalance_ratio'] > 3.0:\n",
    "        print(\"  1. 增加真实视频样本或减少伪造视频样本\")\n",
    "        print(\"  2. 使用更强的类别权重 (pos_weight > 3.0)\")\n",
    "        print(\"  3. 调整Focal Loss参数 (降低alpha, 增加gamma)\")\n",
    "    \n",
    "    if metrics['real_accuracy'] < 0.3:\n",
    "        print(\"  4. 检查数据质量，确保真实视频标签正确\")\n",
    "        print(\"  5. 使用成本敏感学习方法\")\n",
    "        print(\"  6. 考虑使用SMOTE等过采样技术\")\n",
    "    \n",
    "    if metrics['auc_roc'] < 0.6:\n",
    "        print(\"  7. 重新设计模型架构\")\n",
    "        print(\"  8. 增加模型复杂度或使用预训练模型\")\n",
    "        print(\"  9. 检查特征提取是否有效\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "print(\"✅ 评估函数和可视化定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6dae556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T10:28:38.488781Z",
     "iopub.status.busy": "2025-07-29T10:28:38.488574Z",
     "iopub.status.idle": "2025-07-29T11:31:08.831827Z",
     "shell.execute_reply": "2025-07-29T11:31:08.830943Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3750.353734,
     "end_time": "2025-07-29T11:31:08.833276",
     "exception": false,
     "start_time": "2025-07-29T10:28:38.479542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 配置参数:\n",
      "   真实视频数量: 200\n",
      "   假视频数量: 400\n",
      "   每视频帧数: 16\n",
      "   真假比例: 1:2\n",
      "   预计总样本: 600\n",
      "🎬 开始直接预提取视频帧到 ./data/frames...\n",
      "📱 数据处理使用设备: cuda\n",
      "🎯 开始处理真实视频...\n",
      "找到 200 个真实视频\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理真实视频:   0%|          | 0/200 [00:00<?, ?it/s]I0000 00:00:1753784922.694664      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13318 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1753784922.695324      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "处理真实视频: 100%|██████████| 200/200 [21:10<00:00,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎭 开始处理假视频...\n",
      "  Deepfakes: 1000 个视频\n",
      "  Face2Face: 1000 个视频\n",
      "  FaceShifter: 1000 个视频\n",
      "  FaceSwap: 1000 个视频\n",
      "  NeuralTextures: 1000 个视频\n",
      "  DeepFakeDetection: 1000 个视频\n",
      "总共可用假视频: 6000 个\n",
      "平均分配策略: 每种方法 66 个视频\n",
      "剩余 4 个视频将分配给前 4 种方法\n",
      "  Deepfakes: 采样 67 个视频\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理Deepfakes: 100%|██████████| 67/67 [07:11<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Face2Face: 采样 67 个视频\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理Face2Face: 100%|██████████| 67/67 [06:56<00:00,  6.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FaceShifter: 采样 67 个视频\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理FaceShifter: 100%|██████████| 67/67 [06:18<00:00,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FaceSwap: 采样 67 个视频\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理FaceSwap: 100%|██████████| 67/67 [05:05<00:00,  4.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NeuralTextures: 采样 66 个视频\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理NeuralTextures: 100%|██████████| 66/66 [05:08<00:00,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DeepFakeDetection: 采样 66 个视频\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理DeepFakeDetection: 100%|██████████| 66/66 [10:39<00:00,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 直接预提取完成: 600 个视频\n",
      "   真实视频: 200 个\n",
      "   假视频: 400 个\n",
      "假视频方法分布:\n",
      "  Deepfakes: 67 个视频\n",
      "  Face2Face: 67 个视频\n",
      "  FaceShifter: 67 个视频\n",
      "  FaceSwap: 67 个视频\n",
      "  NeuralTextures: 66 个视频\n",
      "  DeepFakeDetection: 66 个视频\n",
      "\n",
      "📊 总体数据统计: 600 个样本\n",
      "   真实视频: 200 个\n",
      "   假视频: 400 个\n",
      "\n",
      "📊 分割数据集...\n",
      "真实视频: 200 个\n",
      "伪造视频: 400 个\n",
      "训练集: 420 样本\n",
      "验证集: 90 样本\n",
      "测试集: 90 样本\n",
      "\n",
      "💾 保存数据集...\n",
      "数据集已保存到: ./data/train.csv\n",
      "数据集已保存到: ./data/val.csv\n",
      "数据集已保存到: ./data/test.csv\n",
      "\n",
      "📈 数据集统计:\n",
      "训练集: 真实=140, 伪造=280, 总计=420\n",
      "验证集: 真实=30, 伪造=60, 总计=90\n",
      "测试集: 真实=30, 伪造=60, 总计=90\n",
      "\n",
      "✅ 数据准备完成！\n",
      "   📊 数据分布: 真实视频 200 | 假视频 400\n",
      "   📈 当前比例: 1:2\n",
      "   🎯 数据集规模: 600 个样本\n",
      "   🚀 可以开始训练了！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: 数据准备 - 直接预提取优化版本\n",
    "\n",
    "# ==================== 配置参数 ====================\n",
    "# 数据集路径配置\n",
    "DATA_BASE_DIR = '/kaggle/input/ff-c23/FaceForensics++_C23'\n",
    "\n",
    "# 可自定义预处理视频数量\n",
    "MAX_REAL_VIDEOS = 200      # 真实视频数量\n",
    "MAX_FAKE_VIDEOS = 400      # 假视频数量\n",
    "MAX_FRAMES_PER_VIDEO = 16  # 每个视频提取的帧数\n",
    "\n",
    "# 真假视频比例建议\n",
    "# 1:1 - 平衡数据集，适合大多数情况\n",
    "# 1:2 - 轻微偏向假视频，提高假视频检测能力\n",
    "# 1:3 - 中等偏向假视频，适合实际应用场景\n",
    "# 1:6 - 强烈偏向假视频，模拟真实世界分布\n",
    "REAL_FAKE_RATIO = \"1:2\"  # 当前比例\n",
    "\n",
    "def direct_extract_frames_from_videos(base_data_dir, max_real=MAX_REAL_VIDEOS, max_fake=MAX_FAKE_VIDEOS, max_frames=MAX_FRAMES_PER_VIDEO, frames_dir='./data/frames'):\n",
    "    \"\"\"\n",
    "    直接从视频目录预提取帧到硬盘 - 一步到位的优化方案\n",
    "    \n",
    "    Args:\n",
    "        base_data_dir: 数据集根目录\n",
    "        max_real: 最大真实视频数量\n",
    "        max_fake: 最大假视频数量\n",
    "        max_frames: 每个视频提取的帧数\n",
    "        frames_dir: 帧存储目录\n",
    "    \n",
    "    Returns:\n",
    "        extracted_data: 包含预提取帧路径的数据列表\n",
    "    \"\"\"\n",
    "    print(f\"🎬 开始直接预提取视频帧到 {frames_dir}...\")\n",
    "    \n",
    "    # 创建必要的目录\n",
    "    os.makedirs('./data', exist_ok=True)\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "    \n",
    "    # 打印设备信息\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"📱 数据处理使用设备: {device}\")\n",
    "    \n",
    "    extracted_data = []\n",
    "    fake_methods = ['Deepfakes', 'Face2Face', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'DeepFakeDetection']\n",
    "    \n",
    "    # ==================== 处理真实视频 ====================\n",
    "    print(\"🎯 开始处理真实视频...\")\n",
    "    original_dir = os.path.join(base_data_dir, 'original')\n",
    "    if os.path.exists(original_dir):\n",
    "        video_files = [f for f in os.listdir(original_dir)\n",
    "                      if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        \n",
    "        if len(video_files) > max_real:\n",
    "            video_files = random.sample(video_files, max_real)\n",
    "        \n",
    "        print(f\"找到 {len(video_files)} 个真实视频\")\n",
    "        \n",
    "        for video_file in tqdm(video_files, desc=\"处理真实视频\"):\n",
    "            try:\n",
    "                video_path = os.path.join(original_dir, video_file)\n",
    "                \n",
    "                # 生成帧文件路径\n",
    "                video_name = os.path.splitext(video_file)[0]\n",
    "                frame_file = os.path.join(frames_dir, f\"{video_name}_frames.pt\")\n",
    "                \n",
    "                # 检查是否已存在\n",
    "                if os.path.exists(frame_file):\n",
    "                    # 对于已存在的文件，我们需要加载它来获取帧数\n",
    "                    try:\n",
    "                        existing_frames = torch.load(frame_file)\n",
    "                        num_frames = len(existing_frames)\n",
    "                    except:\n",
    "                        num_frames = max_frames  # 默认值\n",
    "                    \n",
    "                    extracted_data.append({\n",
    "                        'frame_path': frame_file,\n",
    "                        'label': 0,\n",
    "                        'method': 'original',\n",
    "                        'original_video': video_path,\n",
    "                        'num_frames': num_frames\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # 直接提取帧并保存\n",
    "                frames = extract_frames_memory_efficient(video_path, max_frames)\n",
    "                \n",
    "                if len(frames) >= max_frames // 2:  # 至少要有一半的帧\n",
    "                    # 转换为tensor并保存\n",
    "                    frames_tensor = torch.stack([\n",
    "                        torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0\n",
    "                        for frame in frames\n",
    "                    ])\n",
    "                    \n",
    "                    torch.save(frames_tensor, frame_file)\n",
    "                    \n",
    "                    extracted_data.append({\n",
    "                        'frame_path': frame_file,\n",
    "                        'label': 0,  # 真实视频\n",
    "                        'method': 'original',\n",
    "                        'original_video': video_path,\n",
    "                        'num_frames': len(frames)\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"⚠️ 跳过帧数不足的视频: {video_file}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ 处理真实视频失败 {video_file}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # ==================== 处理假视频 - 平均分配策略 ====================\n",
    "    print(\"🎭 开始处理假视频...\")\n",
    "    \n",
    "    # 统计每种方法的可用视频数量\n",
    "    method_videos = {}\n",
    "    total_available_fake = 0\n",
    "    \n",
    "    for method in fake_methods:\n",
    "        method_dir = os.path.join(base_data_dir, method)\n",
    "        if os.path.exists(method_dir):\n",
    "            videos = [os.path.join(method_dir, f) for f in os.listdir(method_dir) \n",
    "                     if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "            method_videos[method] = videos\n",
    "            total_available_fake += len(videos)\n",
    "            print(f\"  {method}: {len(videos)} 个视频\")\n",
    "        else:\n",
    "            method_videos[method] = []\n",
    "            print(f\"  {method}: 目录不存在\")\n",
    "    \n",
    "    print(f\"总共可用假视频: {total_available_fake} 个\")\n",
    "    \n",
    "    # 计算每种方法应该采样的视频数量（平均分配）\n",
    "    available_methods = [method for method in fake_methods if len(method_videos[method]) > 0]\n",
    "    if not available_methods:\n",
    "        print(\"❌ 未找到任何假视频方法\")\n",
    "        return extracted_data\n",
    "    \n",
    "    videos_per_method = max_fake // len(available_methods)\n",
    "    remaining_videos = max_fake % len(available_methods)\n",
    "    \n",
    "    print(f\"平均分配策略: 每种方法 {videos_per_method} 个视频\")\n",
    "    if remaining_videos > 0:\n",
    "        print(f\"剩余 {remaining_videos} 个视频将分配给前 {remaining_videos} 种方法\")\n",
    "    \n",
    "    # 为每种方法采样并直接处理视频\n",
    "    for i, method in enumerate(available_methods):\n",
    "        # 计算当前方法应该采样的数量\n",
    "        current_method_quota = videos_per_method\n",
    "        if i < remaining_videos:  # 前几种方法多分配一个\n",
    "            current_method_quota += 1\n",
    "        \n",
    "        available_videos = method_videos[method]\n",
    "        \n",
    "        # 如果可用视频数量少于配额，全部使用\n",
    "        if len(available_videos) <= current_method_quota:\n",
    "            method_selected = available_videos\n",
    "            print(f\"  {method}: 使用全部 {len(method_selected)} 个视频\")\n",
    "        else:\n",
    "            # 随机采样指定数量\n",
    "            method_selected = random.sample(available_videos, current_method_quota)\n",
    "            print(f\"  {method}: 采样 {len(method_selected)} 个视频\")\n",
    "        \n",
    "        # 直接处理选择的视频\n",
    "        for video_path in tqdm(method_selected, desc=f\"处理{method}\"):\n",
    "            try:\n",
    "                # 生成帧文件路径\n",
    "                video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "                frame_file = os.path.join(frames_dir, f\"{video_name}_frames.pt\")\n",
    "                \n",
    "                # 检查是否已存在\n",
    "                if os.path.exists(frame_file):\n",
    "                    # 对于已存在的文件，我们需要加载它来获取帧数\n",
    "                    try:\n",
    "                        existing_frames = torch.load(frame_file)\n",
    "                        num_frames = len(existing_frames)\n",
    "                    except:\n",
    "                        num_frames = max_frames  # 默认值\n",
    "                    \n",
    "                    extracted_data.append({\n",
    "                        'frame_path': frame_file,\n",
    "                        'label': 1,\n",
    "                        'method': method,\n",
    "                        'original_video': video_path,\n",
    "                        'num_frames': num_frames\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # 直接提取帧并保存\n",
    "                frames = extract_frames_memory_efficient(video_path, max_frames)\n",
    "                \n",
    "                if len(frames) >= max_frames // 2:\n",
    "                    # 转换为tensor并保存\n",
    "                    frames_tensor = torch.stack([\n",
    "                        torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0\n",
    "                        for frame in frames\n",
    "                    ])\n",
    "                    \n",
    "                    torch.save(frames_tensor, frame_file)\n",
    "                    \n",
    "                    extracted_data.append({\n",
    "                        'frame_path': frame_file,\n",
    "                        'label': 1,  # 假视频\n",
    "                        'method': method,\n",
    "                        'original_video': video_path,\n",
    "                        'num_frames': len(frames)\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"⚠️ 跳过帧数不足的视频: {os.path.basename(video_path)}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ 处理假视频失败 {os.path.basename(video_path)}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # 统计最终结果\n",
    "    real_count = sum(1 for item in extracted_data if item['label'] == 0)\n",
    "    fake_count = sum(1 for item in extracted_data if item['label'] == 1)\n",
    "    \n",
    "    method_counts = {}\n",
    "    for item in extracted_data:\n",
    "        if item['label'] == 1:  # 只统计假视频\n",
    "            method = item['method']\n",
    "            method_counts[method] = method_counts.get(method, 0) + 1\n",
    "    \n",
    "    print(f\"\\n✅ 直接预提取完成: {len(extracted_data)} 个视频\")\n",
    "    print(f\"   真实视频: {real_count} 个\")\n",
    "    print(f\"   假视频: {fake_count} 个\")\n",
    "    print(\"假视频方法分布:\")\n",
    "    for method, count in method_counts.items():\n",
    "        print(f\"  {method}: {count} 个视频\")\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "print(f\"📋 配置参数:\")\n",
    "print(f\"   真实视频数量: {MAX_REAL_VIDEOS}\")\n",
    "print(f\"   假视频数量: {MAX_FAKE_VIDEOS}\")\n",
    "print(f\"   每视频帧数: {MAX_FRAMES_PER_VIDEO}\")\n",
    "print(f\"   真假比例: {REAL_FAKE_RATIO}\")\n",
    "print(f\"   预计总样本: {MAX_REAL_VIDEOS + MAX_FAKE_VIDEOS}\")\n",
    "\n",
    "# 直接预提取帧 - 一步到位的优化方案\n",
    "extracted_data = direct_extract_frames_from_videos(\n",
    "    base_data_dir=DATA_BASE_DIR,\n",
    "    max_real=MAX_REAL_VIDEOS,\n",
    "    max_fake=MAX_FAKE_VIDEOS,\n",
    "    max_frames=MAX_FRAMES_PER_VIDEO\n",
    ")\n",
    "\n",
    "if len(extracted_data) == 0:\n",
    "    raise ValueError(\"❌ 预提取帧失败，无法继续。请检查视频路径和格式。\")\n",
    "\n",
    "# 统计总体数据分布\n",
    "total_real = sum(1 for item in extracted_data if item['label'] == 0)\n",
    "total_fake = sum(1 for item in extracted_data if item['label'] == 1)\n",
    "print(f\"\\n📊 总体数据统计: {len(extracted_data)} 个样本\")\n",
    "print(f\"   真实视频: {total_real} 个\")\n",
    "print(f\"   假视频: {total_fake} 个\")\n",
    "\n",
    "# 数据集分割\n",
    "print(\"\\n📊 分割数据集...\")\n",
    "train_data, val_data, test_data = create_dataset_split(\n",
    "    extracted_data,  # 使用预提取的数据\n",
    "    test_size=0.15,  # 测试集比例\n",
    "    val_size=0.15    # 验证集比例\n",
    ")\n",
    "\n",
    "print(f\"训练集: {len(train_data)} 样本\")\n",
    "print(f\"验证集: {len(val_data)} 样本\")\n",
    "print(f\"测试集: {len(test_data)} 样本\")\n",
    "\n",
    "# 保存数据集\n",
    "print(\"\\n💾 保存数据集...\")\n",
    "save_dataset_to_csv(train_data, './data/train.csv')\n",
    "save_dataset_to_csv(val_data, './data/val.csv')\n",
    "save_dataset_to_csv(test_data, './data/test.csv')\n",
    "\n",
    "# 显示数据集统计\n",
    "print(\"\\n📈 数据集统计:\")\n",
    "for name, data in [(\"训练\", train_data), (\"验证\", val_data), (\"测试\", test_data)]:\n",
    "    real_count = sum(1 for item in data if item['label'] == 0)\n",
    "    fake_count = sum(1 for item in data if item['label'] == 1)\n",
    "    print(f\"{name}集: 真实={real_count}, 伪造={fake_count}, 总计={len(data)}\")\n",
    "\n",
    "print(f\"\\n✅ 数据准备完成！\")\n",
    "print(f\"   📊 数据分布: 真实视频 {total_real} | 假视频 {total_fake}\")\n",
    "print(f\"   📈 当前比例: {REAL_FAKE_RATIO}\")\n",
    "print(f\"   🎯 数据集规模: {len(extracted_data)} 个样本\")\n",
    "print(f\"   🚀 可以开始训练了！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b0dc70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T11:31:08.902515Z",
     "iopub.status.busy": "2025-07-29T11:31:08.902272Z",
     "iopub.status.idle": "2025-07-29T11:31:10.358803Z",
     "shell.execute_reply": "2025-07-29T11:31:10.357672Z"
    },
    "papermill": {
     "duration": 1.4921,
     "end_time": "2025-07-29T11:31:10.360210",
     "exception": false,
     "start_time": "2025-07-29T11:31:08.868110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 创建和配置模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 166MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型初始化完成\n",
      "   - 注意力机制: 启用\n",
      "   - 多模态融合: 启用\n",
      "   - 集成模式: 禁用\n",
      "🚀 启用多GPU并行训练，使用 2 个GPU\n",
      "📦 有效批次大小: 8 (单GPU: 4)\n",
      "✅ 模型已创建并移动到 cuda\n",
      "📊 模型参数数量: 41,983,874\n",
      "🎮 GPU: Tesla T4\n",
      "💾 GPU内存: 14.7GB\n",
      "🔧 内存使用限制: 60%\n",
      "⚠️ train_loader未定义，使用默认类别权重\n",
      "📊 类别分布 - 真实: 1, 伪造: 1\n",
      "⚖️ 正样本权重: 1.00\n",
      "📝 使用FP32训练 (解决NaN问题)\n",
      "🎯 训练配置:\n",
      "  - 训练轮数: 30\n",
      "  - 初始学习率: 1.00e-04\n",
      "  - 权重衰减: 1.00e-02\n",
      "  - 早停耐心值: 15\n",
      "  - 混合精度: 禁用\n",
      "✅ 模型和训练配置完成\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: 模型初始化和训练配置\n",
    "print(\"🤖 创建和配置模型...\")\n",
    "\n",
    "# 训练配置参数 \n",
    "batch_size = 4  \n",
    "\n",
    "# 创建模型 - 针对Kaggle T4 GPU优化（简化配置解决NaN问题）\n",
    "model = OptimizedDeepfakeDetector(\n",
    "    num_classes=1,\n",
    "    dropout_rate=0.2,  # 降低dropout率\n",
    "    use_attention=True,\n",
    "    use_multimodal=True,\n",
    "    ensemble_mode=False   # 单模型模式\n",
    ").to(device)\n",
    "\n",
    "# 多GPU并行支持\n",
    "if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "    print(f\"🚀 启用多GPU并行训练，使用 {torch.cuda.device_count()} 个GPU\")\n",
    "    model = nn.DataParallel(model)\n",
    "    # 调整批次大小以充分利用多GPU\n",
    "    effective_batch_size = batch_size * torch.cuda.device_count()\n",
    "    print(f\"📦 有效批次大小: {effective_batch_size} (单GPU: {batch_size})\")\n",
    "else:\n",
    "    print(\"📝 单GPU训练模式\")\n",
    "\n",
    "print(f\"✅ 模型已创建并移动到 {device}\")\n",
    "print(f\"📊 模型参数数量: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 优化GPU内存配置 - 更保守的内存使用避免OOM\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_per_process_memory_fraction(0.6)  # 降低到60%避免内存溢出\n",
    "    torch.cuda.empty_cache()  # 清理缓存\n",
    "    print(f\"🎮 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"💾 GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
    "    print(f\"🔧 内存使用限制: 60%\")\n",
    "\n",
    "# 损失函数 - 使用类别权重平衡\n",
    "# 计算类别权重 - 修复版本\n",
    "if 'train_loader' in globals() and train_loader is not None:\n",
    "    # 从train_loader获取数据集\n",
    "    train_dataset = train_loader.dataset\n",
    "    \n",
    "    if hasattr(train_dataset, 'real_count') and hasattr(train_dataset, 'fake_count'):\n",
    "        # 使用预计算的统计信息\n",
    "        real_count = train_dataset.real_count\n",
    "        fake_count = train_dataset.fake_count\n",
    "    else:\n",
    "        # 回退方案：手动计算\n",
    "        if hasattr(train_dataset, 'data_list') and train_dataset.data_list is not None:\n",
    "            real_count = sum(1 for item in train_dataset.data_list if item['label'] == 0)\n",
    "            fake_count = sum(1 for item in train_dataset.data_list if item['label'] == 1)\n",
    "        elif hasattr(train_dataset, 'df') and train_dataset.df is not None:\n",
    "            real_count = len(train_dataset.df[train_dataset.df['label'] == 0])\n",
    "            fake_count = len(train_dataset.df[train_dataset.df['label'] == 1])\n",
    "        else:\n",
    "            # 默认值\n",
    "            real_count = 1\n",
    "            fake_count = 1\n",
    "            print(\"⚠️ 无法获取类别分布，使用默认权重\")\n",
    "else:\n",
    "    # 如果没有train_loader，使用默认值\n",
    "    real_count = 1\n",
    "    fake_count = 1\n",
    "    print(\"⚠️ train_loader未定义，使用默认类别权重\")\n",
    "\n",
    "# 确保计数不为零\n",
    "real_count = max(real_count, 1)\n",
    "fake_count = max(fake_count, 1)\n",
    "\n",
    "pos_weight = torch.tensor([real_count / fake_count], device=device)\n",
    "\n",
    "print(f\"📊 类别分布 - 真实: {real_count}, 伪造: {fake_count}\")\n",
    "print(f\"⚖️ 正样本权重: {pos_weight.item():.2f}\")\n",
    "\n",
    "# 使用FocalLoss处理类别不平衡\n",
    "criterion = FocalLoss(\n",
    "    alpha=0.25,\n",
    "    gamma=2.0,  # 降低gamma值，减少对困难样本的过度关注\n",
    "    pos_weight=pos_weight,\n",
    "    reduction='mean'\n",
    ")\n",
    "\n",
    "# 优化器配置 - 使用更安全的学习率避免NaN\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,  # 降低学习率到更安全的范围，避免梯度爆炸\n",
    "    weight_decay=0.01,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# 学习率调度器 - 调整为更合理的参数\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=3,  # 减少重启周期，让学习率变化更频繁\n",
    "    T_mult=2,  # 增加周期倍增因子\n",
    "    eta_min=2e-4  # 提高最小学习率，从1e-7提高到1e-6\n",
    ")\n",
    "\n",
    "# 早停机制 - 更严格的监控\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=15,  # 减少耐心值\n",
    "    min_delta=0.001,  # 增加最小改进阈值\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 混合精度训练 - 暂时禁用以解决NaN问题\n",
    "use_amp = False  # 强制禁用混合精度训练，避免数值不稳定\n",
    "scaler = None\n",
    "print(\"📝 使用FP32训练 (解决NaN问题)\")\n",
    "\n",
    "# 训练配置 - 双T4 GPU优化\n",
    "num_epochs = 30  # 适中的训练轮数，适合双T4配置\n",
    "print(f\"🎯 训练配置:\")\n",
    "print(f\"  - 训练轮数: {num_epochs}\")\n",
    "print(f\"  - 初始学习率: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "print(f\"  - 权重衰减: {optimizer.param_groups[0]['weight_decay']:.2e}\")\n",
    "print(f\"  - 早停耐心值: {early_stopping.patience}\")\n",
    "print(f\"  - 混合精度: {'启用' if use_amp else '禁用'}\")\n",
    "\n",
    "print(\"✅ 模型和训练配置完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf424ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T11:31:10.430751Z",
     "iopub.status.busy": "2025-07-29T11:31:10.429942Z",
     "iopub.status.idle": "2025-07-29T11:31:10.562348Z",
     "shell.execute_reply": "2025-07-29T11:31:10.561377Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.168516,
     "end_time": "2025-07-29T11:31:10.563667",
     "exception": false,
     "start_time": "2025-07-29T11:31:10.395151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据加载器函数定义完成（三步优化专用）\n",
      "\n",
      "🚀 创建数据加载器实例...\n",
      "📊 创建数据加载器（三步优化模式）...\n",
      "🔧 检测到GPU预处理，自动禁用pin_memory以避免冲突\n",
      "✅ 预提取帧模式，共 420 个样本\n",
      "📊 数据分布: 真实=140, 伪造=280\n",
      "✅ 数据集初始化完成: 420 个样本\n",
      "🚀 GPU预处理: True (设备: cuda)\n",
      "📊 启用频域特征提取\n",
      "🔍 启用压缩伪影分析\n",
      "✅ 预提取帧模式，共 90 个样本\n",
      "📊 数据分布: 真实=30, 伪造=60\n",
      "✅ 数据集初始化完成: 90 个样本\n",
      "🚀 GPU预处理: True (设备: cuda)\n",
      "📊 启用频域特征提取\n",
      "🔍 启用压缩伪影分析\n",
      "✅ 预提取帧模式，共 90 个样本\n",
      "📊 数据分布: 真实=30, 伪造=60\n",
      "✅ 数据集初始化完成: 90 个样本\n",
      "🚀 GPU预处理: True (设备: cuda)\n",
      "📊 启用频域特征提取\n",
      "🔍 启用压缩伪影分析\n",
      "训练集大小: 420\n",
      "验证集大小: 90\n",
      "测试集大小: 90\n",
      "类别分布: {0: 140, 1: 280}\n",
      "✅ 使用加权随机采样器进行类别平衡\n",
      "🔧 使用 0 个工作进程（Kaggle优化）\n",
      "✅ 数据加载器创建完成\n",
      "📈 三步优化性能提升:\n",
      "  - 预提取帧: 消除重复I/O\n",
      "  - GPU预处理: 加速特征提取\n",
      "  - 总体训练速度提升: 3-4倍\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: 数据加载器\n",
    "\n",
    "# 必要的导入\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# 注意：需要先执行 cell_04_dataset_class.py 来定义 DeepfakeVideoDataset\n",
    "# 如果在Jupyter中，DeepfakeVideoDataset 应该已经在之前的cell中定义\n",
    "\n",
    "def create_data_loaders(batch_size=1, num_workers=0, pin_memory=True):\n",
    "    \"\"\"创建数据加载器 - 专用于预提取帧的GPU预处理\"\"\"\n",
    "    \n",
    "    print(\"📊 创建数据加载器（三步优化模式）...\")\n",
    "    \n",
    "    # GPU预处理配置\n",
    "    gpu_preprocessing = True\n",
    "    \n",
    "    # 重要：当启用GPU预处理时，必须禁用pin_memory\n",
    "    # 因为数据已经在GPU上，pin_memory只适用于CPU tensor\n",
    "    if gpu_preprocessing:\n",
    "        pin_memory = False\n",
    "        print(\"🔧 检测到GPU预处理，自动禁用pin_memory以避免冲突\")\n",
    "    \n",
    "    # 创建数据集实例 - 专用于预提取帧\n",
    "    train_dataset = DeepfakeVideoDataset(\n",
    "        csv_file='./data/train.csv',\n",
    "        max_frames=16,\n",
    "        gpu_preprocessing=gpu_preprocessing,  # 启用GPU预处理\n",
    "        extract_fourier=True,   # 启用多模态特征\n",
    "        extract_compression=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = DeepfakeVideoDataset(\n",
    "        csv_file='./data/val.csv',\n",
    "        max_frames=16,\n",
    "        gpu_preprocessing=gpu_preprocessing,  # 启用GPU预处理\n",
    "        extract_fourier=True,   # 启用多模态特征\n",
    "        extract_compression=True\n",
    "    )\n",
    "    \n",
    "    test_dataset = DeepfakeVideoDataset(\n",
    "        csv_file='./data/test.csv',\n",
    "        max_frames=16,\n",
    "        gpu_preprocessing=gpu_preprocessing,  # 启用GPU预处理\n",
    "        extract_fourier=True,   # 启用多模态特征\n",
    "        extract_compression=True\n",
    "    )\n",
    "    \n",
    "    print(f\"训练集大小: {len(train_dataset)}\")\n",
    "    print(f\"验证集大小: {len(val_dataset)}\")\n",
    "    print(f\"测试集大小: {len(test_dataset)}\")\n",
    "    \n",
    "    # 计算类别权重用于平衡采样\n",
    "    train_df = pd.read_csv('./data/train.csv')\n",
    "    class_counts = train_df['label'].value_counts().sort_index()\n",
    "    total_samples = len(train_df)\n",
    "    \n",
    "    print(f\"类别分布: {class_counts.to_dict()}\")\n",
    "    \n",
    "    # 创建平衡采样器\n",
    "    if len(class_counts) > 1:\n",
    "        # 计算类别权重\n",
    "        class_weights = total_samples / (len(class_counts) * class_counts.values)\n",
    "        sample_weights = [class_weights[int(label)] for label in train_df['label']]\n",
    "        \n",
    "        # 创建加权随机采样器\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "        \n",
    "        print(\"✅ 使用加权随机采样器进行类别平衡\")\n",
    "        shuffle_train = False  # 使用采样器时不能shuffle\n",
    "    else:\n",
    "        sampler = None\n",
    "        shuffle_train = True\n",
    "        print(\"⚠️ 只有一个类别，跳过类别平衡\")\n",
    "    \n",
    "    # Kaggle优化配置\n",
    "    safe_num_workers = 0  # 单进程模式避免序列化问题\n",
    "    print(f\"🔧 使用 {safe_num_workers} 个工作进程（Kaggle优化）\")\n",
    "    \n",
    "    # 创建数据加载器 - 三步优化配置\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle_train,\n",
    "        sampler=sampler,\n",
    "        num_workers=safe_num_workers,\n",
    "        pin_memory=pin_memory,  # 已根据GPU预处理自动调整\n",
    "        drop_last=True,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=2 if safe_num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=safe_num_workers,\n",
    "        pin_memory=pin_memory,  # 已根据GPU预处理自动调整\n",
    "        drop_last=False,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=2 if safe_num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=safe_num_workers,\n",
    "        pin_memory=pin_memory,  # 已根据GPU预处理自动调整\n",
    "        drop_last=False,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=2 if safe_num_workers > 0 else None\n",
    "    )\n",
    "    \n",
    "    print(\"✅ 数据加载器创建完成\")\n",
    "    print(f\"📈 三步优化性能提升:\")\n",
    "    print(f\"  - 预提取帧: 消除重复I/O\")\n",
    "    print(f\"  - GPU预处理: 加速特征提取\")\n",
    "    print(f\"  - 总体训练速度提升: 3-4倍\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "print(\"✅ 数据加载器函数定义完成（三步优化专用）\")\n",
    "\n",
    "# 创建数据加载器实例\n",
    "print(\"\\n🚀 创建数据加载器实例...\")\n",
    "train_loader, val_loader, test_loader = create_data_loaders(\n",
    "    batch_size=batch_size,  # 使用之前定义的batch_size\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41811f63",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-29T11:31:10.635813Z",
     "iopub.status.busy": "2025-07-29T11:31:10.635564Z",
     "iopub.status.idle": "2025-07-29T12:03:45.542368Z",
     "shell.execute_reply": "2025-07-29T12:03:45.541643Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "papermill": {
     "duration": 1954.943986,
     "end_time": "2025-07-29T12:03:45.543820",
     "exception": false,
     "start_time": "2025-07-29T11:31:10.599834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 开始训练...\n",
      "📊 训练配置: 105 个训练批次, 23 个验证批次\n",
      "🎯 模型参数数量: 41,983,874\n",
      "💾 设备: cuda\n",
      "📦 批次大小: 4\n",
      "🎮 GPU数量: 2\n",
      "🎮 GPU型号: Tesla T4\n",
      "🚀 多GPU并行训练模式\n",
      "📦 有效批次大小: 8\n",
      "\n",
      "🔄 开始训练循环...\n",
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.00e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:05<08:55,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:06<04:44,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:07<03:20,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:08<02:42,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:09<02:23,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:10<02:08,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:11<02:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:12<01:51,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:13<01:47,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:14<01:43,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:15<01:38,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:16<01:36,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:17<01:35,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:18<01:35,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:19<01:35,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:20<01:31,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:21<01:31,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:22<01:29,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:23<01:28,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:24<01:27,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:25<01:25,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:26<01:25,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:27<01:25,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:28<01:21,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:29<01:20,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:30<01:20,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:31<01:17,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:32<01:14,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:33<01:12,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:34<01:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:35<01:11,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:36<01:11,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:37<01:11,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:38<01:10,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:39<01:07,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:40<01:08,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:41<01:07,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:42<01:06,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:43<01:03,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:44<01:03,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:45<01:03,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:46<01:01,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:47<01:01,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:48<01:01,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:49<00:59,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:50<00:56,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:51<00:54,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:52<00:53,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:53<00:50,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:54<00:50,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:54<00:48,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:55<00:47,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:56<00:47,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:57<00:46,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:58<00:44,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:59<00:44,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [01:00<00:45,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [01:01<00:42,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [01:02<00:40,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [01:02<00:39,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [01:03<00:40,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [01:04<00:38,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [01:05<00:36,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [01:06<00:35,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [01:07<00:34,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [01:08<00:34,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [01:09<00:33,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [01:10<00:32,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [01:10<00:31,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [01:11<00:30,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [01:12<00:30,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [01:13<00:30,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [01:14<00:28,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [01:15<00:27,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [01:16<00:27,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:17<00:26,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:18<00:25,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:18<00:23,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:19<00:22,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:20<00:21,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:21<00:21,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:22<00:20,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:23<00:19,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:24<00:18,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:25<00:17,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:25<00:16,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:26<00:15,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:27<00:14,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:28<00:13,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:29<00:12,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:30<00:12,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:31<00:11,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:32<00:10,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:32<00:09,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:33<00:08,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:34<00:07,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:35<00:06,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:36<00:06,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:37<00:05,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:38<00:04,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:38<00:03,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:39<00:02,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:40<00:01,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:41<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.25e-04, 用时: 143.9s\n",
      "🎯 新的最佳模型! Acc: 66.67%, AUC: 0.5000\n",
      "💾 最佳模型已保存\n",
      "\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.25e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:30,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:27,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:24,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:24,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:04<01:22,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:20,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:22,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:21,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:20,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:08<01:18,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:09<01:19,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:10<01:22,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:11<01:24,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:19,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:12<01:17,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:13<01:16,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:14<01:15,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:15<01:14,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:16<01:11,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:16<01:09,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:17<01:09,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:18<01:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:19<01:08,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:20<01:08,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:21<01:07,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:22<01:06,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:22<01:06,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:23<01:09,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:24<01:07,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:25<01:05,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:26<01:05,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:27<01:02,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:28<01:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:28<01:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:29<01:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:30<00:59,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:31<00:58,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:32<00:56,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:33<00:55,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:34<00:54,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:34<00:53,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:35<00:51,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:36<00:52,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:37<00:50,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:38<00:56,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:39<00:54,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:40<00:53,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:41<00:51,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:42<00:49,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:42<00:49,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:43<00:46,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:44<00:45,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:45<00:44,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:46<00:42,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:47<00:42,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:47<00:41,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:48<00:40,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:49<00:39,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:50<00:38,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:51<00:37,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:52<00:36,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:53<00:37,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:53<00:35,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:54<00:34,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:55<00:33,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:56<00:32,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:57<00:31,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:58<00:31,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:58<00:30,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:59<00:29,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [01:00<00:27,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [01:01<00:27,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [01:02<00:26,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [01:02<00:25,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [01:03<00:24,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:04<00:24,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:05<00:23,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:06<00:22,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:06<00:21,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:07<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:08<00:19,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:09<00:18,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:10<00:18,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:11<00:17,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:11<00:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:12<00:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:13<00:14,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:14<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:15<00:12,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:15<00:12,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:16<00:11,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:17<00:11,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:18<00:10,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:19<00:09,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:20<00:08,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:20<00:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:21<00:06,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:22<00:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:23<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:24<00:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:24<00:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:25<00:02,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:26<00:01,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:27<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.75e-04, 用时: 125.0s\n",
      "\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.75e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:28,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:24,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:23,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:04<01:23,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:05<01:23,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:23,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:20,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:19,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:08<01:19,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:09<01:19,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:10<01:16,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:15,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:12<01:13,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:13<01:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:14<01:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:11,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:10,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:16<01:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:17<01:09,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:18<01:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:06,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:19<01:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:20<01:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:21<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:22<01:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:03,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:23<01:01,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:24<01:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:25<01:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:26<01:02,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:27<00:59,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:27<00:58,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:28<00:56,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:29<00:55,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:30<00:55,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:31<00:55,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:31<00:53,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:32<00:52,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:33<00:52,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:34<00:51,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:35<00:49,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:36<00:50,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:36<00:48,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:37<00:47,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:38<00:46,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:39<00:45,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:40<00:44,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:40<00:43,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:41<00:42,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:42<00:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:43<00:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:43<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:44<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:45<00:39,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:46<00:38,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:47<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:47<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:48<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:49<00:35,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:50<00:34,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:51<00:34,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:52<00:33,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:52<00:33,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:53<00:31,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:54<00:30,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:55<00:29,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:56<00:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:56<00:28,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:57<00:28,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:58<00:27,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:59<00:26,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [01:00<00:25,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [01:01<00:24,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:01<00:24,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:02<00:22,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:03<00:21,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:04<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:05<00:20,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:05<00:19,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:06<00:19,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:07<00:18,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:08<00:17,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:09<00:16,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:10<00:15,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:10<00:14,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:11<00:13,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:12<00:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:13<00:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:14<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:14<00:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:15<00:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:16<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:17<00:08,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:18<00:07,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:18<00:06,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:19<00:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:20<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:21<00:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:22<00:03,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:22<00:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:23<00:01,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:24<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.00e-04, 用时: 122.0s\n",
      "\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.00e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:18,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:17,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:07<01:16,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:13,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:11<01:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:12<01:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:19<01:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:19<01:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:20<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:02,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:23<01:01,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:23<01:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<00:59,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:58,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:27<00:57,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:28<00:56,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:55,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:56,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:56,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:31<00:54,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:32<00:52,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:51,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:50,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:49,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:35<00:49,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:36<00:48,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:47,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:46,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:38<00:45,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:39<00:44,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:40<00:43,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:42,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:42<00:41,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:43<00:40,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:44<00:40,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:39,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:46<00:38,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:47<00:37,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:48<00:36,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:35,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:50<00:33,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:51<00:32,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:52<00:31,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:54<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:55<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:56<00:27,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:26,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:58<00:25,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:59<00:24,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:23,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:01<00:23,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:02<00:22,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:03<00:21,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:04<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:05<00:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:06<00:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:07<00:16,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:09<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:10<00:13,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:11<00:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:12<00:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:13<00:10,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:14<00:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:15<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:16<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:17<00:06,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:18<00:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:19<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:20<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:20<00:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:21<00:02,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:22<00:01,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:23<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.07e-04, 用时: 120.5s\n",
      "\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.07e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:24,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:04<01:22,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:22,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:20,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:21,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:19,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:08<01:17,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:14,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:13,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:12<01:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:12<01:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:09,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:16<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:16<01:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:06,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:19<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:20<01:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:20<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:24<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:57,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:27<00:56,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:27<00:55,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:31<00:53,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:31<00:52,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:50,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:49,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:35<00:48,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:36<00:48,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:48,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:47,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:38<00:46,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:39<00:44,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:40<00:43,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:42,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:42,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:42<00:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:43<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:44<00:40,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:39,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:46<00:37,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:47<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:34,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:50<00:33,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:51<00:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:51<00:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:53<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:54<00:29,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:55<00:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:55<00:27,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:58<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:59<00:24,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:01<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:02<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:03<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:03<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:19,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:05<00:18,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:06<00:17,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:07<00:17,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:08<00:16,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:15,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:09<00:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:10<00:14,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:11<00:13,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:12<00:12,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:13<00:10,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:14<00:09,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:15<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:16<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:17<00:06,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:18<00:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:19<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:20<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:20<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:21<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:22<00:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:23<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.25e-04, 用时: 120.7s\n",
      "\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.25e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:03<01:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:15,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:14,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:15,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:15,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:12<01:13,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:12<01:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:16<01:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:16<01:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:19<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:20<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:23<00:58,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<00:57,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:27<00:56,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:30<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:35<00:47,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:46,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:38<00:45,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:42<00:41,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:42<00:41,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:43<00:40,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:39,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:38,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:46<00:37,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:46<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:50<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:50<00:32,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:51<00:31,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:53<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:54<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:55<00:27,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:26,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:57<00:26,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:57<00:25,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:58<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:01<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:01<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:02<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:03<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:05<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:05<00:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:07<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:09<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:09<00:13,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:10<00:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:11<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:12<00:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:13<00:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:14<00:08,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:15<00:08,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:17<00:06,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:17<00:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:18<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:19<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:20<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:21<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:22<00:01,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:22<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.50e-04, 用时: 120.3s\n",
      "\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.50e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:21,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:11<01:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:12<01:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:16<01:07,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:07,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:06,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:19<01:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:19<01:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:20<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:26<00:56,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:54,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:54,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:53,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:35<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:41<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:43<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:39,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:38,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:45<00:37,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:46<00:36,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:35,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:35,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:50<00:34,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:50<00:33,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:51<00:32,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:53<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:54<00:29,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:54<00:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:55<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:57<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:58<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:01<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:01<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:02<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:03<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:05<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:05<00:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:07<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:15,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:09<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:09<00:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:10<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:12<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:13<00:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:14<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:15<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:16<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:17<00:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:18<00:04,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:19<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:20<00:03,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:20<00:02,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:21<00:01,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:22<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.75e-04, 用时: 119.8s\n",
      "\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.75e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:26,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:23,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:20,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:04<01:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:12<01:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:19<01:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:19<01:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:20<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:23<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:23<01:01,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<01:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:59,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:58,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:27<00:57,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:27<00:55,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:54,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:53,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:53,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:31<00:52,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:31<00:51,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:35<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:35<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:42,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:42<00:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:42<00:40,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:43<00:39,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:46<00:37,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:46<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:50<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:50<00:32,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:51<00:31,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:53<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:54<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:54<00:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:55<00:28,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:27,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:57<00:26,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:58<00:25,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:58<00:24,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:01<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:02<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:02<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:03<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:05<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:06<00:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:07<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:09<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:09<00:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:10<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:13<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:13<00:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:14<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:15<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:17<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:17<00:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:18<00:04,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:19<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:20<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:21<00:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:21<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:22<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.93e-04, 用时: 120.0s\n",
      "\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.93e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:25,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:24,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:22,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:20,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:04<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:11<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:12<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:04,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:18<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:20<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:22<00:59,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:23<00:58,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<00:57,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:56,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:26<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:53,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:30<00:53,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:31<00:52,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:50,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:49,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:34<00:48,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:35<00:47,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:46,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:37<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:41<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:43<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:37,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:45<00:37,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:46<00:36,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:47<00:35,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:34,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:50<00:32,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:51<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:52<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:54<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:55<00:27,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:57<00:25,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:58<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:01<00:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:02<00:21,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:03<00:20,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:19,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:04<00:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:05<00:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:06<00:16,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:07<00:16,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:08<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:09<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:10<00:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:12<00:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:13<00:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:14<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:15<00:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:16<00:06,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:17<00:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:18<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:19<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:19<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:20<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:21<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:22<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.00e-04, 用时: 119.8s\n",
      "\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.00e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:25,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:21,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:18,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:19,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:18,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:08<01:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:14,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:13,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:21,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:12<01:17,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:13<01:14,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:12,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:10,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:16<01:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:17<01:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:19<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:20<01:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:21<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:23<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:24<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:56,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:27<00:56,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:28<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:31<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:32<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:48,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:35<00:47,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:35<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:46,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:38<00:46,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:39<00:45,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:40<00:44,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:43,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:42,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:42<00:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:43<00:40,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:43<00:39,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:46<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:47<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:50<00:33,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:51<00:32,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:51<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:54<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:55<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:55<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:58<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:59<00:24,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:01<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:02<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:02<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:03<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:05<00:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:06<00:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:07<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:09<00:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:10<00:13,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:11<00:13,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:11<00:12,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:13<00:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:14<00:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:14<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:15<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:17<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:18<00:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:18<00:04,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:19<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:20<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:21<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:22<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:22<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.02e-04, 用时: 120.2s\n",
      "\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.02e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:04<01:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:11<01:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:12<01:12,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:11,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:10,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:15<01:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:19<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:20<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:23<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:56,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:35<00:47,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:43<00:40,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:39,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:39,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:46<00:38,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:46<00:37,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:47<00:36,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:34,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:50<00:33,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:50<00:32,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:51<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:54<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:55<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:57<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:58<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:01<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:01<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:02<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:03<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:05<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:05<00:17,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:07<00:15,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:08<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:09<00:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:10<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:12<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:13<00:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:14<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:15<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:17<00:06,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:17<00:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:18<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:19<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:20<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:20<00:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:21<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:22<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.07e-04, 用时: 119.8s\n",
      "\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.07e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:25,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:03<01:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:15,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:07<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:12,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:11<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:12<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:14<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:04,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:18<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:19<01:05,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:20<01:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:01,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:22<01:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:23<00:59,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<00:58,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:26<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:30<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:34<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:35<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:37<00:45,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:38<00:44,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:41<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:43<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:37,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:45<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:46<00:36,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:50<00:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:51<00:32,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:31,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:53<00:30,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:53<00:30,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:54<00:29,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:55<00:28,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:27,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:57<00:26,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:57<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:58<00:24,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:01<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:01<00:21,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:02<00:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:03<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:05<00:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:05<00:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:07<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:09<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:09<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:10<00:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:12<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:13<00:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:14<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:15<00:08,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:17<00:06,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:18<00:05,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:18<00:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:19<00:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:20<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:21<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:21<00:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:22<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.15e-04, 用时: 120.3s\n",
      "\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.15e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:24,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:20,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:11<01:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:12<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:16<01:06,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:04,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:18<01:03,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:19<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:20<01:01,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:22<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:23<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:58,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:26<00:58,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:27<00:56,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:55,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:54,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:53,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:35<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:37<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:41<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:43<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:45<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:46<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:47<00:35,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:50<00:32,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:51<00:31,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:53<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:54<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:55<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:57<00:25,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:58<00:25,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:24,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:23,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:01<00:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:01<00:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:02<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:03<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:19,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:05<00:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:05<00:17,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:06<00:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:07<00:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:09<00:14,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:09<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:10<00:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:11<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:13<00:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:13<00:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:14<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:15<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:17<00:06,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:17<00:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:18<00:04,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:19<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:20<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:20<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:21<00:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:22<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.25e-04, 用时: 119.8s\n",
      "\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.25e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:25,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:26,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:26,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:22,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:04<01:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:11<01:10,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:12<01:09,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:08,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:15<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:04,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:19<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:20<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:22<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:23<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<00:57,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:56,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:26<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:27<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:54,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:30<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:51,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:50,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:34<00:49,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:35<00:48,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:47,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:46,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:38<00:45,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:38<00:44,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:39<00:43,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:43<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:37,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:46<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:46<00:36,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:47<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:34,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:49<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:50<00:32,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:51<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:53<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:54<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:55<00:27,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:57<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:58<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:01<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:01<00:21,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:02<00:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:03<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:05<00:18,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:05<00:17,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:06<00:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:07<00:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:09<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:09<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:10<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:12<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:13<00:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:14<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:15<00:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:16<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:17<00:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:18<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:19<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:20<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:20<00:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:21<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:22<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.37e-04, 用时: 119.8s\n",
      "\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.37e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:26,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:03<01:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:08<01:17,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:16,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:15,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:13,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:12<01:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:12<01:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:15<01:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:16<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:20<01:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:57,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:27<00:56,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:27<00:55,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:30<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:31<00:51,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:50,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:49,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:34<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:35<00:47,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:46,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:38<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:39<00:44,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:43,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:43,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:42<00:47,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:43<00:44,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:44<00:42,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:40,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:39,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:46<00:38,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:47<00:36,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:48<00:35,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:50<00:33,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:51<00:32,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:51<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:30,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:53<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:54<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:55<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:55<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:58<00:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:59<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:01<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:02<00:21,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:03<00:20,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:03<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:05<00:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:06<00:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:07<00:15,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:09<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:10<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:10<00:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:11<00:12,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:13<00:10,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:14<00:09,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:15<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:15<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:17<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:18<00:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:19<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:19<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:20<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:21<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:22<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:22<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.50e-04, 用时: 120.4s\n",
      "\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 训练开始调试信息:\n",
      "   - 数据加载器长度: 105\n",
      "   - 当前学习率: 1.50e-04\n",
      "   - 设备: cuda\n",
      "   - 混合精度: 启用\n",
      "📊 批次 0: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   1%|          | 1/105 [00:00<01:24,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 0 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 0, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   2%|▏         | 2/105 [00:01<01:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 1 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 1, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   3%|▎         | 3/105 [00:02<01:22,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 2 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 2, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   4%|▍         | 4/105 [00:03<01:21,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 3 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 3, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   5%|▍         | 5/105 [00:04<01:20,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 4 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 4, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   6%|▌         | 6/105 [00:04<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 5 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 5, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   7%|▋         | 7/105 [00:05<01:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 6 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 6, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   8%|▊         | 8/105 [00:06<01:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 7 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 7, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:   9%|▊         | 9/105 [00:07<01:15,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 8 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 8, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|▉         | 10/105 [00:07<01:15,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 9 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 9, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  10%|█         | 11/105 [00:08<01:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 10 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 10, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  11%|█▏        | 12/105 [00:09<01:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 11 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 11, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  12%|█▏        | 13/105 [00:10<01:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 12 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 12, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  13%|█▎        | 14/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 13 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 13, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  14%|█▍        | 15/105 [00:11<01:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 14 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 14, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  15%|█▌        | 16/105 [00:12<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 15 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 15, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  16%|█▌        | 17/105 [00:13<01:09,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 16 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 16, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  17%|█▋        | 18/105 [00:14<01:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 17 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 17, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  18%|█▊        | 19/105 [00:15<01:10,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 18 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 18, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  19%|█▉        | 20/105 [00:16<01:09,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 19 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 19, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 20: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  20%|██        | 21/105 [00:16<01:07,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 20 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 20, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  21%|██        | 22/105 [00:17<01:06,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 21 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 21, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  22%|██▏       | 23/105 [00:18<01:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 22 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 22, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  23%|██▎       | 24/105 [00:19<01:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 23 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 23, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  24%|██▍       | 25/105 [00:19<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 24 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 24, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  25%|██▍       | 26/105 [00:20<01:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 25 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 25, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  26%|██▌       | 27/105 [00:21<01:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 26 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 26, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  27%|██▋       | 28/105 [00:22<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 27 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 27, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  28%|██▊       | 29/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 28 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 28, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  29%|██▊       | 30/105 [00:23<00:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 29 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 29, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|██▉       | 31/105 [00:24<00:58,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 30 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 30, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  30%|███       | 32/105 [00:25<00:58,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 31 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 31, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  31%|███▏      | 33/105 [00:26<00:57,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 32 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 32, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  32%|███▏      | 34/105 [00:27<00:56,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 33 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 33, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  33%|███▎      | 35/105 [00:27<00:55,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 34 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 34, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  34%|███▍      | 36/105 [00:28<00:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 35 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 35, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  35%|███▌      | 37/105 [00:29<00:53,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 36 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 36, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  36%|███▌      | 38/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 37 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 37, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  37%|███▋      | 39/105 [00:30<00:52,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 38 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 38, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  38%|███▊      | 40/105 [00:31<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 39 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 39, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 40: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  39%|███▉      | 41/105 [00:32<00:50,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 40 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 40, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  40%|████      | 42/105 [00:33<00:50,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 41 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 41, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  41%|████      | 43/105 [00:34<00:49,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 42 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 42, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  42%|████▏     | 44/105 [00:34<00:48,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 43 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 43, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  43%|████▎     | 45/105 [00:35<00:47,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 44 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 44, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  44%|████▍     | 46/105 [00:36<00:46,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 45 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 45, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  45%|████▍     | 47/105 [00:37<00:45,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 46 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 46, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  46%|████▌     | 48/105 [00:38<00:45,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 47 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 47, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  47%|████▋     | 49/105 [00:38<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 48 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 48, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  48%|████▊     | 50/105 [00:39<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 49 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 49, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  49%|████▊     | 51/105 [00:40<00:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 50 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 50, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|████▉     | 52/105 [00:41<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 51 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 51, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  50%|█████     | 53/105 [00:42<00:41,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 52 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 52, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  51%|█████▏    | 54/105 [00:42<00:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 53 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 53, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  52%|█████▏    | 55/105 [00:43<00:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 54 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 54, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  53%|█████▎    | 56/105 [00:44<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 55 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 55, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  54%|█████▍    | 57/105 [00:45<00:37,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 56 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 56, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  55%|█████▌    | 58/105 [00:46<00:37,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 57 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 57, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  56%|█████▌    | 59/105 [00:46<00:37,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 58 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 58, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  57%|█████▋    | 60/105 [00:47<00:36,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 59 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 59, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 60: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  58%|█████▊    | 61/105 [00:48<00:35,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 60 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 60, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  59%|█████▉    | 62/105 [00:49<00:34,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 61 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 61, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  60%|██████    | 63/105 [00:50<00:33,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 62 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 62, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  61%|██████    | 64/105 [00:50<00:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 63 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 63, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  62%|██████▏   | 65/105 [00:51<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 64 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 64, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  63%|██████▎   | 66/105 [00:52<00:31,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 65 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 65, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  64%|██████▍   | 67/105 [00:53<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 66 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 66, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  65%|██████▍   | 68/105 [00:54<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 67 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 67, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  66%|██████▌   | 69/105 [00:54<00:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 68 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 68, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  67%|██████▋   | 70/105 [00:55<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 69 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 69, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  68%|██████▊   | 71/105 [00:56<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 70 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 70, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  69%|██████▊   | 72/105 [00:57<00:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 71 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 71, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|██████▉   | 73/105 [00:58<00:25,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 72 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 72, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  70%|███████   | 74/105 [00:58<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 73 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 73, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  71%|███████▏  | 75/105 [00:59<00:23,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 74 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 74, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  72%|███████▏  | 76/105 [01:00<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 75 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 75, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  73%|███████▎  | 77/105 [01:01<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 76 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 76, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  74%|███████▍  | 78/105 [01:01<00:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 77 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 77, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  75%|███████▌  | 79/105 [01:02<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 78 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 78, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  76%|███████▌  | 80/105 [01:03<00:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 79 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 79, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 80: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  77%|███████▋  | 81/105 [01:04<00:19,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 80 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 80, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  78%|███████▊  | 82/105 [01:05<00:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 81 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 81, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  79%|███████▉  | 83/105 [01:05<00:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 82 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 82, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  80%|████████  | 84/105 [01:06<00:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 83 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 83, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  81%|████████  | 85/105 [01:07<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 84 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 84, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  82%|████████▏ | 86/105 [01:08<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 85 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 85, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  83%|████████▎ | 87/105 [01:09<00:14,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 86 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 86, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  84%|████████▍ | 88/105 [01:09<00:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 87 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 87, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  85%|████████▍ | 89/105 [01:10<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 88 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 88, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  86%|████████▌ | 90/105 [01:11<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 89 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 89, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  87%|████████▋ | 91/105 [01:12<00:11,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 90 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 90, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  88%|████████▊ | 92/105 [01:13<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 91 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 91, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  89%|████████▊ | 93/105 [01:13<00:09,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 92 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 92, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|████████▉ | 94/105 [01:14<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 93 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 93, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  90%|█████████ | 95/105 [01:15<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 94 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 94, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  91%|█████████▏| 96/105 [01:16<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 95 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 95, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  92%|█████████▏| 97/105 [01:17<00:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 96 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 96, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  93%|█████████▎| 98/105 [01:17<00:05,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 97 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 97, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  94%|█████████▍| 99/105 [01:18<00:04,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 98 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 98, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  95%|█████████▌| 100/105 [01:19<00:04,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 99 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 99, 总样本数: 0, 总损失: 0.0\n",
      "📊 批次 100: GPU内存 0.2GB / 0.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  96%|█████████▌| 101/105 [01:20<00:03,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 100 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 100, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  97%|█████████▋| 102/105 [01:21<00:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 101 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 101, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  98%|█████████▊| 103/105 [01:21<00:01,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 102 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 102, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中:  99%|█████████▉| 104/105 [01:22<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 103 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 103, 总样本数: 0, 总损失: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 模型输出包含NaN/Inf，使用安全的默认输出\n",
      "⚠️ 训练批次 104 出错: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "详细错误信息: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/1752022379.py\", line 139, in train_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "🔍 调试信息 - 当前批次: 104, 总样本数: 0, 总损失: 0.0\n",
      "⚠️ 警告: 没有成功处理任何训练批次!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练: Loss=inf, Acc=0.00%\n",
      "验证: Loss=2.4454, Acc=66.67%, AUC=0.5000, F1=0.8000\n",
      "学习率: 1.63e-04, 用时: 119.9s\n",
      "\n",
      "⏹️ 早停触发，在第 16 轮停止训练\n",
      "\n",
      "✅ 训练完成!\n",
      "🏆 最终最佳性能: Loss=2.4454, Acc=66.67%, AUC=0.5000\n",
      "💾 峰值GPU内存使用: 2.6GB\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 训练历史图表已保存到 ./models/training_history.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: 训练循环\n",
    "\n",
    "# 确保模型保存目录存在\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "print(\"🚀 开始训练...\")\n",
    "print(f\"📊 训练配置: {len(train_loader)} 个训练批次, {len(val_loader)} 个验证批次\")\n",
    "print(f\"🎯 模型参数数量: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"💾 设备: {device}\")\n",
    "print(f\"📦 批次大小: {batch_size}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"🎮 GPU数量: {gpu_count}\")\n",
    "    print(f\"🎮 GPU型号: {torch.cuda.get_device_name(0)}\")\n",
    "    if gpu_count > 1:\n",
    "        print(f\"🚀 多GPU并行训练模式\")\n",
    "        print(f\"📦 有效批次大小: {batch_size * gpu_count}\")\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# 训练历史记录\n",
    "train_history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "    'val_auc': [],\n",
    "    'val_precision': [],\n",
    "    'val_recall': [],\n",
    "    'val_f1': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0.0\n",
    "best_val_auc = 0.0\n",
    "\n",
    "# 训练循环\n",
    "print(\"\\n🔄 开始训练循环...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # 训练阶段\n",
    "    train_results = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, \n",
    "        scheduler=scheduler, use_amp=True, gradient_clip=1.0\n",
    "    )\n",
    "    \n",
    "    # 验证阶段\n",
    "    val_results = validate_epoch(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # 提取结果\n",
    "    train_loss = train_results['loss']\n",
    "    train_acc = train_results['accuracy'] * 100\n",
    "    \n",
    "    val_loss = val_results['loss']\n",
    "    val_acc = val_results['accuracy'] * 100\n",
    "    val_auc = val_results['auc']\n",
    "    val_precision = val_results['precision']\n",
    "    val_recall = val_results['recall']\n",
    "    val_f1 = val_results['f1']\n",
    "    \n",
    "    # 记录历史\n",
    "    train_history['train_loss'].append(train_loss)\n",
    "    train_history['train_acc'].append(train_acc)\n",
    "    train_history['val_loss'].append(val_loss)\n",
    "    train_history['val_acc'].append(val_acc)\n",
    "    train_history['val_auc'].append(val_auc)\n",
    "    train_history['val_precision'].append(val_precision)\n",
    "    train_history['val_recall'].append(val_recall)\n",
    "    train_history['val_f1'].append(val_f1)\n",
    "    \n",
    "    # 学习率调度\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # 计算epoch时间\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    # 打印结果\n",
    "    print(f\"训练: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
    "    print(f\"验证: Loss={val_loss:.4f}, Acc={val_acc:.2f}%, AUC={val_auc:.4f}, F1={val_f1:.4f}\")\n",
    "    print(f\"学习率: {current_lr:.2e}, 用时: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        best_val_auc = val_auc\n",
    "        \n",
    "        print(f\"🎯 新的最佳模型! Acc: {best_val_acc:.2f}%, AUC: {best_val_auc:.4f}\")\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'best_val_auc': best_val_auc,\n",
    "            'train_history': train_history\n",
    "        }, './models/best_model.pth')\n",
    "        print(\"💾 最佳模型已保存\")\n",
    "    \n",
    "    # 早停检查\n",
    "    if early_stopping(val_loss, model):\n",
    "        print(f\"\\n⏹️ 早停触发，在第 {epoch+1} 轮停止训练\")\n",
    "        break\n",
    "    \n",
    "    # 清理GPU缓存 - 多GPU内存管理\n",
    "    if torch.cuda.is_available():\n",
    "        current_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        \n",
    "        # 多GPU环境下的内存阈值调整\n",
    "        memory_threshold = 20 if gpu_count > 1 else 10\n",
    "        \n",
    "        if current_memory > memory_threshold:\n",
    "            print(f\"🧹 GPU内存清理: {current_memory:.1f}GB > {memory_threshold}GB\")\n",
    "            torch.cuda.empty_cache()\n",
    "            if gpu_count > 1:\n",
    "                # 多GPU环境下清理所有GPU\n",
    "                for i in range(gpu_count):\n",
    "                    with torch.cuda.device(i):\n",
    "                        torch.cuda.empty_cache()\n",
    "        \n",
    "        # 检查训练时间\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        max_epoch_time = 2 * 3600 if gpu_count > 1 else 1 * 3600  # 多GPU允许更长时间\n",
    "        \n",
    "        if epoch_time > max_epoch_time:\n",
    "            print(f\"⏰ 单轮训练时间过长 ({epoch_time/3600:.1f}小时)，停止训练\")\n",
    "            break\n",
    "\n",
    "print(\"\\n✅ 训练完成!\")\n",
    "print(f\"🏆 最终最佳性能: Loss={best_val_loss:.4f}, Acc={best_val_acc:.2f}%, AUC={best_val_auc:.4f}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"💾 峰值GPU内存使用: {torch.cuda.max_memory_allocated() / 1024**3:.1f}GB\")\n",
    "\n",
    "# 绘制训练历史\n",
    "def plot_training_history():\n",
    "    \"\"\"绘制训练历史图表\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('训练历史', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(train_history['train_loss'], label='训练Loss', color='blue')\n",
    "    axes[0, 0].plot(train_history['val_loss'], label='验证Loss', color='red')\n",
    "    axes[0, 0].set_title('Loss变化')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(train_history['train_acc'], label='训练Acc', color='blue')\n",
    "    axes[0, 1].plot(train_history['val_acc'], label='验证Acc', color='red')\n",
    "    axes[0, 1].set_title('准确率变化')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # AUC\n",
    "    axes[1, 0].plot(train_history['val_auc'], label='验证AUC', color='red')\n",
    "    axes[1, 0].set_title('AUC变化')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('AUC')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # F1 Score\n",
    "    axes[1, 1].plot(train_history['val_f1'], label='验证F1', color='red')\n",
    "    axes[1, 1].set_title('F1分数变化')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('F1 Score')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./models/training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 绘制训练历史\n",
    "plot_training_history()\n",
    "\n",
    "print(\"📊 训练历史图表已保存到 ./models/training_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "936f18fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T12:03:46.045769Z",
     "iopub.status.busy": "2025-07-29T12:03:46.045445Z",
     "iopub.status.idle": "2025-07-29T12:04:29.607022Z",
     "shell.execute_reply": "2025-07-29T12:04:29.606142Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 43.812213,
     "end_time": "2025-07-29T12:04:29.608420",
     "exception": false,
     "start_time": "2025-07-29T12:03:45.796207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 开始模型评估...\n",
      "============================================================\n",
      "🔄 加载最佳模型...\n",
      "✅ 成功加载第 1 轮的最佳模型\n",
      "最佳验证准确率: 66.67%\n",
      "最佳验证AUC: 0.5000\n",
      "\n",
      "🔍 在测试集上评估模型...\n",
      "🚀 开始模型评估...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度: 100%|██████████| 23/23 [00:40<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 评估完成\n",
      "平均损失: 2.5270\n",
      "平均推理时间: 1426.83 ms/batch\n",
      "\n",
      "📈 计算评估指标...\n",
      "\n",
      "📊 详细评估结果:\n",
      "==================================================\n",
      "测试损失: 2.5270\n",
      "准确率: 0.6667 (66.67%)\n",
      "平衡准确率: 0.5000 (50.00%)\n",
      "精确率: 0.6667\n",
      "召回率: 1.0000\n",
      "特异性: 0.0000\n",
      "F1分数: 0.8000\n",
      "AUC-ROC: 0.5000\n",
      "AUC-PR: 0.8333\n",
      "负预测值: 0.0000\n",
      "\n",
      "🔍 混淆矩阵分析:\n",
      "真负例 (TN): 0\n",
      "假正例 (FP): 30\n",
      "假负例 (FN): 0\n",
      "真正例 (TP): 60\n",
      "\n",
      "⚡ 性能分析:\n",
      "平均推理时间: 1426.83 ms/batch\n",
      "总推理时间: 32.82 秒\n",
      "每个样本推理时间: 356.71 ms\n",
      "\n",
      "📋 类别特定分析:\n",
      "总样本数: 90\n",
      "真实视频样本: 30 (33.3%)\n",
      "伪造视频样本: 60 (66.7%)\n",
      "真实视频检测准确率: 0.0000 (0.00%)\n",
      "伪造视频检测准确率: 1.0000 (100.00%)\n",
      "\n",
      "📊 生成评估图表...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵已保存到: ./results/evaluation/confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC/PR曲线已保存到: ./results/evaluation/roc_pr_curves.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 评估图表生成完成\n",
      "\n",
      "============================================================\n",
      "📊 类别不平衡分析报告\n",
      "============================================================\n",
      "\n",
      "📈 数据分布:\n",
      "  真实视频样本: 30\n",
      "  伪造视频样本: 60\n",
      "  不平衡比例: 2.00:1 (伪造:真实)\n",
      "\n",
      "🎯 类别特定准确率:\n",
      "  真实视频检测准确率: 0.00%\n",
      "  伪造视频检测准确率: 100.00%\n",
      "\n",
      "📋 混淆矩阵分析:\n",
      "  真负例 (TN): 0 - 正确识别的真实视频\n",
      "  假正例 (FP): 30 - 误判为伪造的真实视频\n",
      "  假负例 (FN): 0 - 误判为真实的伪造视频\n",
      "  真正例 (TP): 60 - 正确识别的伪造视频\n",
      "\n",
      "⚖️ 模型偏向性分析:\n",
      "  预测为真实的样本: 0 (0.0%)\n",
      "  预测为伪造的样本: 90 (100.0%)\n",
      "\n",
      "🔍 问题诊断:\n",
      "  ❌ 严重问题: 模型几乎无法识别真实视频\n",
      "  ❌ 严重偏向: 模型过度偏向预测伪造视频\n",
      "  ❌ AUC-ROC过低: 模型判别能力接近随机猜测\n",
      "\n",
      "💡 改进建议:\n",
      "  4. 检查数据质量，确保真实视频标签正确\n",
      "  5. 使用成本敏感学习方法\n",
      "  6. 考虑使用SMOTE等过采样技术\n",
      "  7. 重新设计模型架构\n",
      "  8. 增加模型复杂度或使用预训练模型\n",
      "  9. 检查特征提取是否有效\n",
      "============================================================\n",
      "============================================================\n",
      "🎉 模型评估完成！\n",
      "📁 所有结果已保存到 ./results/evaluation/ 目录\n",
      "\n",
      "💡 如果发现严重的类别偏向问题，请参考上述改进建议进行优化\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: 模型评估和结果分析\n",
    "\n",
    "print(\"📊 开始模型评估...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 加载最佳模型\n",
    "print(\"🔄 加载最佳模型...\")\n",
    "try:\n",
    "    # 使用weights_only=False来兼容旧版本的模型文件\n",
    "    checkpoint = torch.load('./models/best_model.pth', map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    best_epoch = checkpoint['epoch']\n",
    "    best_val_acc = checkpoint['best_val_acc']\n",
    "    best_val_auc = checkpoint['best_val_auc']\n",
    "    \n",
    "    print(f\"✅ 成功加载第 {best_epoch+1} 轮的最佳模型\")\n",
    "    print(f\"最佳验证准确率: {best_val_acc:.2f}%\")\n",
    "    print(f\"最佳验证AUC: {best_val_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 加载模型失败: {e}\")\n",
    "    print(\"使用当前模型进行评估\")\n",
    "\n",
    "# 在测试集上评估模型\n",
    "print(\"\\n🔍 在测试集上评估模型...\")\n",
    "eval_results = evaluate_model_optimized(model, test_loader, criterion, device)\n",
    "\n",
    "# 计算全面的评估指标\n",
    "print(\"\\n📈 计算评估指标...\")\n",
    "metrics = calculate_comprehensive_metrics(\n",
    "    eval_results['predictions'], \n",
    "    eval_results['targets'], \n",
    "    eval_results['scores']\n",
    ")\n",
    "\n",
    "# 打印详细结果\n",
    "print(\"\\n📊 详细评估结果:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"测试损失: {eval_results['loss']:.4f}\")\n",
    "print(f\"准确率: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\n",
    "print(f\"平衡准确率: {metrics['balanced_accuracy']:.4f} ({metrics['balanced_accuracy']*100:.2f}%)\")\n",
    "print(f\"精确率: {metrics['precision']:.4f}\")\n",
    "print(f\"召回率: {metrics['recall']:.4f}\")\n",
    "print(f\"特异性: {metrics['specificity']:.4f}\")\n",
    "print(f\"F1分数: {metrics['f1']:.4f}\")\n",
    "print(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
    "print(f\"AUC-PR: {metrics['auc_pr']:.4f}\")\n",
    "print(f\"负预测值: {metrics['npv']:.4f}\")\n",
    "\n",
    "# 混淆矩阵详细信息\n",
    "print(\"\\n🔍 混淆矩阵分析:\")\n",
    "print(f\"真负例 (TN): {metrics['tn']}\")\n",
    "print(f\"假正例 (FP): {metrics['fp']}\")\n",
    "print(f\"假负例 (FN): {metrics['fn']}\")\n",
    "print(f\"真正例 (TP): {metrics['tp']}\")\n",
    "\n",
    "# 性能分析\n",
    "print(\"\\n⚡ 性能分析:\")\n",
    "print(f\"平均推理时间: {eval_results['avg_inference_time']*1000:.2f} ms/batch\")\n",
    "print(f\"总推理时间: {eval_results['total_inference_time']:.2f} 秒\")\n",
    "print(f\"每个样本推理时间: {eval_results['avg_inference_time']*1000/batch_size:.2f} ms\")\n",
    "\n",
    "# 计算额外指标\n",
    "total_samples = len(eval_results['targets'])\n",
    "real_samples = np.sum(eval_results['targets'] == 0)\n",
    "fake_samples = np.sum(eval_results['targets'] == 1)\n",
    "real_accuracy = np.sum((eval_results['predictions'] == 0) & (eval_results['targets'] == 0)) / real_samples if real_samples > 0 else 0\n",
    "fake_accuracy = np.sum((eval_results['predictions'] == 1) & (eval_results['targets'] == 1)) / fake_samples if fake_samples > 0 else 0\n",
    "\n",
    "print(\"\\n📋 类别特定分析:\")\n",
    "print(f\"总样本数: {total_samples}\")\n",
    "print(f\"真实视频样本: {real_samples} ({real_samples/total_samples*100:.1f}%)\")\n",
    "print(f\"伪造视频样本: {fake_samples} ({fake_samples/total_samples*100:.1f}%)\")\n",
    "print(f\"真实视频检测准确率: {real_accuracy:.4f} ({real_accuracy*100:.2f}%)\")\n",
    "print(f\"伪造视频检测准确率: {fake_accuracy:.4f} ({fake_accuracy*100:.2f}%)\")\n",
    "\n",
    "# 生成可视化图表\n",
    "print(\"\\n📊 生成评估图表...\")\n",
    "\n",
    "# 确保结果目录存在\n",
    "os.makedirs('./results/evaluation', exist_ok=True)\n",
    "\n",
    "# 绘制增强混淆矩阵\n",
    "plot_enhanced_confusion_matrix(\n",
    "    metrics['confusion_matrix'], \n",
    "    './results/evaluation/confusion_matrix.png'\n",
    ")\n",
    "\n",
    "# 绘制ROC和PR曲线\n",
    "plot_roc_pr_curves(\n",
    "    eval_results['targets'], \n",
    "    eval_results['scores'], \n",
    "    './results/evaluation/roc_pr_curves.png'\n",
    ")\n",
    "\n",
    "# 预测分数分布图\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 真实视频的预测分数分布\n",
    "plt.subplot(1, 2, 1)\n",
    "real_scores = eval_results['scores'][eval_results['targets'] == 0]\n",
    "fake_scores = eval_results['scores'][eval_results['targets'] == 1]\n",
    "\n",
    "plt.hist(real_scores, bins=30, alpha=0.7, label='真实视频', color='blue', density=True)\n",
    "plt.hist(fake_scores, bins=30, alpha=0.7, label='伪造视频', color='red', density=True)\n",
    "plt.xlabel('预测分数')\n",
    "plt.ylabel('密度')\n",
    "plt.title('预测分数分布')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 预测分数箱线图\n",
    "plt.subplot(1, 2, 2)\n",
    "scores_data = [real_scores, fake_scores]\n",
    "labels = ['真实视频', '伪造视频']\n",
    "plt.boxplot(scores_data, labels=labels)\n",
    "plt.ylabel('预测分数')\n",
    "plt.title('预测分数箱线图')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./results/evaluation/score_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ 评估图表生成完成\")\n",
    "\n",
    "# 生成详细的类别不平衡分析报告\n",
    "generate_class_imbalance_report(metrics)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"🎉 模型评估完成！\")\n",
    "print(\"📁 所有结果已保存到 ./results/evaluation/ 目录\")\n",
    "print(\"\\n💡 如果发现严重的类别偏向问题，请参考上述改进建议进行优化\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0958c562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T12:04:30.108666Z",
     "iopub.status.busy": "2025-07-29T12:04:30.108355Z",
     "iopub.status.idle": "2025-07-29T12:04:30.127972Z",
     "shell.execute_reply": "2025-07-29T12:04:30.127152Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.266197,
     "end_time": "2025-07-29T12:04:30.129209",
     "exception": false,
     "start_time": "2025-07-29T12:04:29.863012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 保存实验结果...\n",
      "============================================================\n",
      "✅ 实验结果已保存到: ./results/experiment_results.json\n",
      "✅ 训练历史已保存到: ./results/training_history.csv\n",
      "✅ 测试预测结果已保存到: ./results/test_predictions.csv\n",
      "\n",
      "📋 生成实验报告...\n",
      "✅ 实验报告已保存到: ./results/experiment_report.txt\n",
      "\n",
      "============================================================\n",
      "🎉 深度伪造检测模型训练和评估完成！\n",
      "============================================================\n",
      "📊 最终测试准确率: 66.67%\n",
      "📊 AUC-ROC分数: 0.5000\n",
      "📊 F1分数: 0.8000\n",
      "\n",
      "📁 所有结果文件已保存到 ./results/ 目录\n",
      "📁 最佳模型已保存到 ./models/best_model.pth\n",
      "\n",
      "✨ 实验成功完成！\n",
      "============================================================\n",
      "\n",
      "📂 生成的文件结构:\n",
      "\n",
      "./models/\n",
      "  └── best_model.pth\n",
      "./results/\n",
      "  ├── experiment_results.json\n",
      "  ├── experiment_report.txt\n",
      "  ├── training_history.csv\n",
      "  └── test_predictions.csv\n",
      "\n",
      "\n",
      "🚀 可以使用以下代码加载训练好的模型进行推理:\n",
      "\n",
      "# 加载模型\n",
      "model = OptimizedDeepfakeDetector(...)\n",
      "checkpoint = torch.load('./models/best_model.pth', weights_only=False)\n",
      "model.load_state_dict(checkpoint['model_state_dict'])\n",
      "model.eval()\n",
      "\n",
      "\n",
      "✅ 训练完成！\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: 结果保存和总结\n",
    "\n",
    "print(\"💾 保存实验结果...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 确保结果目录存在\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# 准备保存的结果数据\n",
    "results_summary = {\n",
    "    'experiment_info': {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'model_architecture': 'OptimizedDeepfakeDetector',\n",
    "        'backbone': 'resnet50',\n",
    "        'total_epochs': len(train_history['train_loss']),\n",
    "        'early_stopping': True\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'train_samples': len(train_loader.dataset) if train_loader else 0,\n",
    "        'val_samples': len(val_loader.dataset) if val_loader else 0,\n",
    "        'test_samples': len(test_loader.dataset) if test_loader else 0,\n",
    "        'batch_size': batch_size\n",
    "    },\n",
    "    'training_config': {\n",
    "        'optimizer': 'AdamW',\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-4,\n",
    "        'loss_function': 'FocalLoss',\n",
    "        'scheduler': 'OneCycleLR',\n",
    "        'early_stopping_patience': 7\n",
    "    },\n",
    "    'final_metrics': {\n",
    "        'test_loss': float(eval_results['loss']),\n",
    "        'accuracy': float(metrics['accuracy']),\n",
    "        'precision': float(metrics['precision']),\n",
    "        'recall': float(metrics['recall']),\n",
    "        'f1_score': float(metrics['f1']),\n",
    "        'auc_roc': float(metrics['auc_roc'])\n",
    "    },\n",
    "    'confusion_matrix': {\n",
    "        'tn': int(metrics['tn']),\n",
    "        'fp': int(metrics['fp']),\n",
    "        'fn': int(metrics['fn']),\n",
    "        'tp': int(metrics['tp'])\n",
    "    },\n",
    "    'training_history': {\n",
    "        'train_loss': [float(x) for x in train_history['train_loss']],\n",
    "        'train_acc': [float(x) for x in train_history['train_acc']],\n",
    "        'val_loss': [float(x) for x in train_history['val_loss']],\n",
    "        'val_acc': [float(x) for x in train_history['val_acc']],\n",
    "        'val_auc': [float(x) for x in train_history['val_auc']],\n",
    "        'val_precision': [float(x) for x in train_history.get('val_precision', [])],\n",
    "        'val_recall': [float(x) for x in train_history.get('val_recall', [])],\n",
    "        'val_f1': [float(x) for x in train_history.get('val_f1', [])]\n",
    "    },\n",
    "    'class_specific_metrics': {\n",
    "        'real_video_accuracy': float(real_accuracy),\n",
    "        'fake_video_accuracy': float(fake_accuracy),\n",
    "        'real_samples_count': int(real_samples),\n",
    "        'fake_samples_count': int(fake_samples)\n",
    "    }\n",
    "}\n",
    "\n",
    "# 保存结果到JSON文件\n",
    "results_file = './results/experiment_results.json'\n",
    "with open(results_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ 实验结果已保存到: {results_file}\")\n",
    "\n",
    "# 保存训练历史到CSV\n",
    "history_df = pd.DataFrame(train_history)\n",
    "history_df.to_csv('./results/training_history.csv', index=False)\n",
    "print(\"✅ 训练历史已保存到: ./results/training_history.csv\")\n",
    "\n",
    "# 保存预测结果\n",
    "predictions_df = pd.DataFrame({\n",
    "    'true_label': eval_results['targets'],\n",
    "    'predicted_label': eval_results['predictions'],\n",
    "    'prediction_score': eval_results['scores']\n",
    "})\n",
    "predictions_df.to_csv('./results/test_predictions.csv', index=False)\n",
    "print(\"✅ 测试预测结果已保存到: ./results/test_predictions.csv\")\n",
    "\n",
    "# 生成实验报告\n",
    "print(\"\\n📋 生成实验报告...\")\n",
    "report = f\"\"\"\n",
    "深度伪造检测模型实验报告\n",
    "{'='*50}\n",
    "\n",
    "实验时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "模型架构: OptimizedDeepfakeDetector (ResNet50 + LSTM + Attention)\n",
    "\n",
    "数据集信息:\n",
    "- 训练样本: {len(train_loader.dataset) if train_loader else 0:,}\n",
    "- 验证样本: {len(val_loader.dataset) if val_loader else 0:,}\n",
    "- 测试样本: {len(test_loader.dataset) if test_loader else 0:,}\n",
    "- 批次大小: {batch_size}\n",
    "\n",
    "训练配置:\n",
    "- 优化器: AdamW (lr=1e-4, weight_decay=1e-4)\n",
    "- 损失函数: Focal Loss\n",
    "- 学习率调度: OneCycleLR\n",
    "- 早停机制: patience=7\n",
    "\n",
    "最终性能指标:\n",
    "- 准确率: {metrics['accuracy']*100:.2f}%\n",
    "- 精确率: {metrics['precision']:.4f}\n",
    "- 召回率: {metrics['recall']:.4f}\n",
    "- F1分数: {metrics['f1']:.4f}\n",
    "- AUC-ROC: {metrics['auc_roc']:.4f}\n",
    "\n",
    "混淆矩阵:\n",
    "- 真负例 (TN): {metrics['tn']}\n",
    "- 假正例 (FP): {metrics['fp']}\n",
    "- 假负例 (FN): {metrics['fn']}\n",
    "- 真正例 (TP): {metrics['tp']}\n",
    "\n",
    "类别特定性能:\n",
    "- 真实视频检测准确率: {real_accuracy*100:.2f}%\n",
    "- 伪造视频检测准确率: {fake_accuracy*100:.2f}%\n",
    "\n",
    "训练总结:\n",
    "- 训练轮数: {len(train_history['train_loss'])}\n",
    "- 最佳验证准确率: {max(train_history['val_acc']):.2f}%\n",
    "- 最佳验证AUC: {max(train_history['val_auc']):.4f}\n",
    "\n",
    "文件输出:\n",
    "- 模型权重: ./models/best_model.pth\n",
    "- 实验结果: ./results/experiment_results.json\n",
    "- 训练历史: ./results/training_history.csv\n",
    "- 预测结果: ./results/test_predictions.csv\n",
    "\n",
    "{'='*50}\n",
    "实验完成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "# 保存报告\n",
    "with open('./results/experiment_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"✅ 实验报告已保存到: ./results/experiment_report.txt\")\n",
    "\n",
    "# 打印最终总结\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 深度伪造检测模型训练和评估完成！\")\n",
    "print(\"=\"*60)\n",
    "print(f\"📊 最终测试准确率: {metrics['accuracy']*100:.2f}%\")\n",
    "print(f\"📊 AUC-ROC分数: {metrics['auc_roc']:.4f}\")\n",
    "print(f\"📊 F1分数: {metrics['f1']:.4f}\")\n",
    "print(\"\\n📁 所有结果文件已保存到 ./results/ 目录\")\n",
    "print(\"📁 最佳模型已保存到 ./models/best_model.pth\")\n",
    "print(\"\\n✨ 实验成功完成！\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 显示文件结构\n",
    "print(\"\\n📂 生成的文件结构:\")\n",
    "print(\"\"\"\n",
    "./models/\n",
    "  └── best_model.pth\n",
    "./results/\n",
    "  ├── experiment_results.json\n",
    "  ├── experiment_report.txt\n",
    "  ├── training_history.csv\n",
    "  └── test_predictions.csv\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n🚀 可以使用以下代码加载训练好的模型进行推理:\")\n",
    "print(\"\"\"\n",
    "# 加载模型\n",
    "model = OptimizedDeepfakeDetector(...)\n",
    "checkpoint = torch.load('./models/best_model.pth', weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n✅ 训练完成！\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6248577,
     "sourceId": 10125851,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5814.74922,
   "end_time": "2025-07-29T12:04:34.402591",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-29T10:27:39.653371",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
