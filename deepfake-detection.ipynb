{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10125851,"sourceType":"datasetVersion","datasetId":6248577}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cell 1: 导入库和环境设置","metadata":{}},{"cell_type":"code","source":"# Cell 1: 导入库和环境设置\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport random\nimport warnings\nimport gc\nimport json\nimport time\nimport sys\nfrom pathlib import Path\nfrom datetime import datetime\nwarnings.filterwarnings('ignore')\n\n# PyTorch相关\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as TF\nimport torchvision.models as models\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\nfrom torch.cuda.amp import GradScaler, autocast\n\n# 机器学习指标\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    roc_auc_score, confusion_matrix, classification_report,\n    roc_curve, auc, precision_recall_curve, balanced_accuracy_score\n)\nfrom sklearn.model_selection import train_test_split\n\n# 数据增强\ntry:\n    import albumentations as A\n    from albumentations.pytorch import ToTensorV2\n    ALBUMENTATIONS_AVAILABLE = True\nexcept ImportError:\n    ALBUMENTATIONS_AVAILABLE = False\n    print(\"警告: albumentations未安装，将使用基础数据增强\")\n\nprint(\"✅ 所有库导入完成\")","metadata":{"_uuid":"f6ebcf0d-d34a-4e53-b9c4-c85254661e41","_cell_guid":"4883bd2d-9463-4607-9e61-df4d76492a78","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-05T12:41:33.707947Z","iopub.execute_input":"2025-07-05T12:41:33.708712Z","iopub.status.idle":"2025-07-05T12:41:33.715824Z","shell.execute_reply.started":"2025-07-05T12:41:33.708688Z","shell.execute_reply":"2025-07-05T12:41:33.714994Z"}},"outputs":[{"name":"stdout","text":"✅ 所有库导入完成\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Cell 2: 全局配置和工具函数","metadata":{}},{"cell_type":"code","source":"# Cell 2: 全局配置和工具函数\n\ndef set_seed(seed=42):\n    \"\"\"设置随机种子确保可重复性\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n# 检查GPU可用性\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"使用设备: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU型号: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n    \n    # GPU性能优化配置\n    torch.backends.cudnn.benchmark = True  # 启用cudnn自动调优\n    torch.backends.cudnn.deterministic = False  # 允许非确定性算法以提高性能\n    torch.cuda.set_per_process_memory_fraction(0.95)  # 设置GPU内存使用比例\n    \n    # 启用TensorFloat-32 (TF32) 以提高性能\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.allow_tf32 = True\n    \n    print(\"✅ GPU性能优化配置已启用\")\n\n# 创建必要的目录\nfor dir_name in ['./data', './models', './logs', './results', './results/evaluation']:\n    os.makedirs(dir_name, exist_ok=True)\n\n# 检查是否在Kaggle环境中\nIS_KAGGLE = os.path.exists('/kaggle')\nBASE_DATA_DIR = '/kaggle/input/ff-c23/FaceForensics++_C23' if IS_KAGGLE else './FaceForensics++_C23'\n\nprint(f\"环境: {'Kaggle' if IS_KAGGLE else '本地'}\")\nprint(f\"数据基础路径: {BASE_DATA_DIR}\")\nprint(\"✅ 环境设置完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T12:41:33.716987Z","iopub.execute_input":"2025-07-05T12:41:33.717282Z","iopub.status.idle":"2025-07-05T12:41:33.756123Z","shell.execute_reply.started":"2025-07-05T12:41:33.717257Z","shell.execute_reply":"2025-07-05T12:41:33.755401Z"}},"outputs":[{"name":"stdout","text":"使用设备: cuda\nGPU型号: Tesla T4\nGPU内存: 14.7 GB\n环境: Kaggle\n数据基础路径: /kaggle/input/ff-c23/FaceForensics++_C23\n✅ 环境设置完成\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Cell 3: 数据处理模块\n","metadata":{}},{"cell_type":"code","source":"# Cell 3: 数据处理模块\n\ndef extract_frames_memory_efficient(video_path, max_frames=16, target_size=(128, 128),\n                                   quality_threshold=20, skip_frames=3):\n    \"\"\"内存友好的帧提取函数\"\"\"\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n\n    if not cap.isOpened():\n        print(f\"无法打开视频: {video_path}\")\n        return frames\n\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    if total_frames == 0:\n        cap.release()\n        return frames\n\n    # 均匀采样策略\n    if total_frames <= max_frames:\n        frame_indices = list(range(0, total_frames, skip_frames))\n    else:\n        step = max(1, total_frames // max_frames)\n        frame_indices = list(range(0, total_frames, step))[:max_frames]\n\n    frame_count = 0\n    for frame_idx in frame_indices:\n        if frame_count >= max_frames:\n            break\n\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n        ret, frame = cap.read()\n\n        if ret:\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            \n            # 简化质量检测\n            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n            quality = cv2.Laplacian(gray, cv2.CV_64F).var()\n\n            if quality > quality_threshold:\n                frame = cv2.resize(frame, target_size)\n                frames.append(frame)\n                frame_count += 1\n\n    cap.release()\n\n    # 如果帧数不足，重复最后一帧\n    while len(frames) < max_frames and len(frames) > 0:\n        frames.append(frames[-1].copy())\n\n    return frames[:max_frames]\n\ndef process_videos_simple(base_data_dir, max_videos_per_class=60, max_frames=16):\n    \"\"\"简化的视频处理函数\"\"\"\n    data_list = []\n    fake_methods = ['Deepfakes', 'Face2Face', 'FaceShifter', 'FaceSwap', 'NeuralTextures']\n\n    print(\"开始处理真实视频...\")\n    # 处理真实视频\n    original_dir = os.path.join(base_data_dir, 'original')\n    if os.path.exists(original_dir):\n        video_files = [f for f in os.listdir(original_dir)\n                      if f.endswith(('.mp4', '.avi', '.mov'))]\n        \n        if len(video_files) > max_videos_per_class:\n            video_files = random.sample(video_files, max_videos_per_class)\n\n        print(f\"找到 {len(video_files)} 个真实视频\")\n\n        for video_file in tqdm(video_files, desc=\"处理真实视频\"):\n            try:\n                video_path = os.path.join(original_dir, video_file)\n                frames = extract_frames_memory_efficient(video_path, max_frames)\n                \n                if len(frames) >= max_frames // 2:  # 至少要有一半的帧\n                    data_list.append({\n                        'video_path': video_path,\n                        'frames': frames,\n                        'label': 0,  # 真实视频\n                        'method': 'original'\n                    })\n            except Exception as e:\n                print(f\"处理视频 {video_file} 时出错: {e}\")\n                continue\n\n    # 处理伪造视频\n    print(\"开始处理伪造视频...\")\n    for method in fake_methods:\n        method_dir = os.path.join(base_data_dir, method)\n        if os.path.exists(method_dir):\n            video_files = [f for f in os.listdir(method_dir)\n                          if f.endswith(('.mp4', '.avi', '.mov'))]\n            \n            if len(video_files) > max_videos_per_class:\n                video_files = random.sample(video_files, max_videos_per_class)\n\n            print(f\"处理 {method}: {len(video_files)} 个视频\")\n\n            for video_file in tqdm(video_files, desc=f\"处理{method}\"):\n                try:\n                    video_path = os.path.join(method_dir, video_file)\n                    frames = extract_frames_memory_efficient(video_path, max_frames)\n                    \n                    if len(frames) >= max_frames // 2:\n                        data_list.append({\n                            'video_path': video_path,\n                            'frames': frames,\n                            'label': 1,  # 伪造视频\n                            'method': method\n                        })\n                except Exception as e:\n                    print(f\"处理视频 {video_file} 时出错: {e}\")\n                    continue\n\n    print(f\"\\n✅ 数据处理完成，共处理 {len(data_list)} 个视频\")\n    return data_list\n\ndef create_dataset_split(data_list, test_size=0.2, val_size=0.1):\n    \"\"\"创建数据集划分\"\"\"\n    # 分离真实和伪造数据\n    real_data = [item for item in data_list if item['label'] == 0]\n    fake_data = [item for item in data_list if item['label'] == 1]\n    \n    print(f\"真实视频: {len(real_data)} 个\")\n    print(f\"伪造视频: {len(fake_data)} 个\")\n    \n    # 分别划分真实和伪造数据\n    real_train, real_temp = train_test_split(real_data, test_size=test_size+val_size, random_state=42)\n    real_val, real_test = train_test_split(real_temp, test_size=test_size/(test_size+val_size), random_state=42)\n    \n    fake_train, fake_temp = train_test_split(fake_data, test_size=test_size+val_size, random_state=42)\n    fake_val, fake_test = train_test_split(fake_temp, test_size=test_size/(test_size+val_size), random_state=42)\n    \n    # 合并数据\n    train_data = real_train + fake_train\n    val_data = real_val + fake_val\n    test_data = real_test + fake_test\n    \n    # 打乱数据\n    random.shuffle(train_data)\n    random.shuffle(val_data)\n    random.shuffle(test_data)\n    \n    return train_data, val_data, test_data\n\ndef save_dataset_to_csv(data_list, filename):\n    \"\"\"将数据集保存为CSV文件\"\"\"\n    df_data = []\n    for item in data_list:\n        df_data.append({\n            'video_path': item['video_path'],\n            'label': item['label'],\n            'method': item['method'],\n            'num_frames': len(item['frames'])\n        })\n    \n    df = pd.DataFrame(df_data)\n    df.to_csv(filename, index=False)\n    print(f\"数据集已保存到: {filename}\")\n    return df\n\nprint(\"✅ 数据处理函数定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T12:41:33.757093Z","iopub.execute_input":"2025-07-05T12:41:33.757327Z","iopub.status.idle":"2025-07-05T12:41:33.784326Z","shell.execute_reply.started":"2025-07-05T12:41:33.757311Z","shell.execute_reply":"2025-07-05T12:41:33.783588Z"}},"outputs":[{"name":"stdout","text":"✅ 数据处理函数定义完成\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Cell 4: 数据集类定义\n","metadata":{}},{"cell_type":"code","source":"# Cell 4: 数据集类定义\n\nclass DeepfakeVideoDataset(Dataset):\n    \"\"\"深度伪造视频数据集类 - GPU优化版本\"\"\"\n    \n    def __init__(self, csv_file=None, data_list=None, transform=None, max_frames=32, gpu_preprocessing=True):\n        if csv_file is not None:\n            self.df = pd.read_csv(csv_file)\n            self.data_list = None\n        elif data_list is not None:\n            self.data_list = data_list\n            self.df = None\n        else:\n            raise ValueError(\"必须提供csv_file或data_list\")\n            \n        self.transform = transform\n        self.max_frames = max_frames\n        self.gpu_preprocessing = gpu_preprocessing and torch.cuda.is_available()\n        \n        # GPU预处理的标准化参数\n        if self.gpu_preprocessing:\n            self.mean = torch.tensor([0.485, 0.456, 0.406]).cuda()\n            self.std = torch.tensor([0.229, 0.224, 0.225]).cuda()\n    \n    def __len__(self):\n        if self.df is not None:\n            return len(self.df)\n        return len(self.data_list)\n    \n    def __getitem__(self, idx):\n        if self.data_list is not None:\n            # 直接从内存中的数据列表获取\n            item = self.data_list[idx]\n            frames = item['frames']\n            label = item['label']\n        else:\n            # 从CSV文件获取路径并重新提取帧\n            row = self.df.iloc[idx]\n            video_path = row['video_path']\n            label = row['label']\n            frames = extract_frames_memory_efficient(video_path, self.max_frames)\n        \n        # 确保有足够的帧\n        if len(frames) == 0:\n            # 创建黑色帧作为fallback\n            frames = [np.zeros((128, 128, 3), dtype=np.uint8) for _ in range(self.max_frames)]  # 降低分辨率\n        \n        while len(frames) < self.max_frames:\n            frames.append(frames[-1].copy() if frames else np.zeros((128, 128, 3), dtype=np.uint8))\n        \n        frames = frames[:self.max_frames]\n        \n        # GPU优化的预处理\n        if self.gpu_preprocessing and not self.transform:\n            # 快速转换为tensor并移到GPU\n            frames_array = np.stack(frames)  # (T, H, W, C)\n            video_tensor = torch.from_numpy(frames_array).permute(0, 3, 1, 2).float()  # (T, C, H, W)\n            video_tensor = video_tensor.cuda(non_blocking=True) / 255.0\n            \n            # GPU上进行标准化\n            video_tensor = (video_tensor - self.mean.view(1, 3, 1, 1)) / self.std.view(1, 3, 1, 1)\n        else:\n            # 传统CPU预处理\n            if self.transform:\n                frames = [self.transform(frame) for frame in frames]\n            else:\n                # 默认变换\n                frames = [torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0 for frame in frames]\n            \n            # 堆叠帧 (T, C, H, W)\n            video_tensor = torch.stack(frames)\n        \n        label_tensor = torch.tensor(label, dtype=torch.float32)\n        \n        return video_tensor, label_tensor\n\nprint(\"✅ 数据集类定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T12:41:33.858253Z","iopub.execute_input":"2025-07-05T12:41:33.858843Z","iopub.status.idle":"2025-07-05T12:41:33.868157Z","shell.execute_reply.started":"2025-07-05T12:41:33.858823Z","shell.execute_reply":"2025-07-05T12:41:33.867420Z"}},"outputs":[{"name":"stdout","text":"✅ 数据集类定义完成\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Cell 5: 模型定义","metadata":{}},{"cell_type":"code","source":"# Cell 5: 模型定义\n\nclass OptimizedDeepfakeDetector(nn.Module):\n    \"\"\"优化的深度伪造检测模型\"\"\"\n    \n    def __init__(self, backbone='resnet50', hidden_dim=512, num_layers=2, \n                 dropout=0.3, use_attention=True):\n        super(OptimizedDeepfakeDetector, self).__init__()\n        \n        self.use_attention = use_attention\n        \n        # 特征提取器\n        if backbone == 'resnet50':\n            self.backbone = models.resnet50(pretrained=True)\n            feature_dim = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        elif backbone == 'resnet18':\n            self.backbone = models.resnet18(pretrained=True)\n            feature_dim = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        else:\n            raise ValueError(f\"不支持的backbone: {backbone}\")\n        \n        # 时序建模\n        self.lstm = nn.LSTM(\n            input_size=feature_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0,\n            bidirectional=True\n        )\n        \n        lstm_output_dim = hidden_dim * 2  # 双向LSTM\n        \n        # 注意力机制\n        if self.use_attention:\n            self.attention = nn.MultiheadAttention(\n                embed_dim=lstm_output_dim,\n                num_heads=8,\n                dropout=dropout,\n                batch_first=True\n            )\n        \n        # 分类器 (移除 Sigmoid，因为使用 BCEWithLogitsLoss)\n        self.classifier = nn.Sequential(\n            nn.Linear(lstm_output_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, 1)\n        )\n        \n    def forward(self, x):\n        # x shape: (batch_size, num_frames, channels, height, width)\n        batch_size, num_frames = x.shape[:2]\n        \n        # 重塑为 (batch_size * num_frames, channels, height, width)\n        x = x.view(-1, *x.shape[2:])\n        \n        # 特征提取\n        features = self.backbone(x)  # (batch_size * num_frames, feature_dim)\n        \n        # 重塑回时序格式\n        features = features.view(batch_size, num_frames, -1)\n        \n        # LSTM处理\n        lstm_out, _ = self.lstm(features)  # (batch_size, num_frames, hidden_dim*2)\n        \n        # 注意力机制\n        attention_weights = None\n        if self.use_attention:\n            attended_out, attention_weights = self.attention(lstm_out, lstm_out, lstm_out)\n            # 全局平均池化\n            pooled = attended_out.mean(dim=1)  # (batch_size, hidden_dim*2)\n        else:\n            # 简单的全局平均池化\n            pooled = lstm_out.mean(dim=1)\n        \n        # 分类\n        output = self.classifier(pooled)\n        \n        return output.squeeze(-1), attention_weights\n\nprint(\"✅ 模型定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T12:41:33.869650Z","iopub.execute_input":"2025-07-05T12:41:33.870133Z","iopub.status.idle":"2025-07-05T12:41:33.895669Z","shell.execute_reply.started":"2025-07-05T12:41:33.870111Z","shell.execute_reply":"2025-07-05T12:41:33.894921Z"}},"outputs":[{"name":"stdout","text":"✅ 模型定义完成\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Cell 6: 损失函数和工具类","metadata":{}},{"cell_type":"code","source":"# Cell 6: 损失函数和工具类\n\nclass FocalLoss(nn.Module):\n    \"\"\"焦点损失函数 - 解决类别不平衡问题\"\"\"\n    \n    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        # 使用 BCEWithLogitsLoss 以兼容 autocast\n        ce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n        # 计算概率用于focal weight\n        pt = torch.exp(-ce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n\n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        else:\n            return focal_loss\n\nclass EarlyStopping:\n    \"\"\"早停机制\"\"\"\n    \n    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.restore_best_weights = restore_best_weights\n        self.best_loss = None\n        self.counter = 0\n        self.best_weights = None\n\n    def __call__(self, val_loss, model):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n            self.save_checkpoint(model)\n        elif val_loss < self.best_loss - self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0\n            self.save_checkpoint(model)\n        else:\n            self.counter += 1\n\n        if self.counter >= self.patience:\n            if self.restore_best_weights:\n                model.load_state_dict(self.best_weights)\n            return True\n        return False\n\n    def save_checkpoint(self, model):\n        self.best_weights = model.state_dict().copy()\n\ndef get_transforms(mode='train', image_size=160):\n    \"\"\"获取数据变换\"\"\"\n    if mode == 'train':\n        return transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((int(image_size * 1.1), int(image_size * 1.1))),\n            transforms.RandomCrop((image_size, image_size)),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n            transforms.RandomRotation(degrees=10),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))\n        ])\n    else:\n        return transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((image_size, image_size)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\nprint(\"✅ 损失函数和工具类定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T12:41:33.896337Z","iopub.execute_input":"2025-07-05T12:41:33.896549Z","iopub.status.idle":"2025-07-05T12:41:33.919073Z","shell.execute_reply.started":"2025-07-05T12:41:33.896532Z","shell.execute_reply":"2025-07-05T12:41:33.918496Z"}},"outputs":[{"name":"stdout","text":"✅ 损失函数和工具类定义完成\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Cell 7: 训练和验证函数","metadata":{}},{"cell_type":"code","source":"# Cell 7: 训练和验证函数\n\nfrom torch.cuda.amp import autocast\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm\n\ndef train_epoch(model, train_loader, criterion, optimizer, device, scaler=None):\n    \"\"\"GPU优化的训练一个epoch\"\"\"\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n\n    pbar = tqdm(train_loader, desc='Training', leave=False)\n\n    for batch_idx, (data, target) in enumerate(pbar):\n        # 非阻塞数据传输到GPU\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n        \n        # 更高效的梯度清零\n        optimizer.zero_grad(set_to_none=True)\n\n        if scaler is not None:\n            # 混合精度训练\n            with autocast():\n                output, _ = model(data)\n                loss = criterion(output, target)\n            \n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            output, _ = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n\n        total_loss += loss.item()\n        \n        # 在GPU上计算准确率\n        with torch.no_grad():\n            probs = torch.sigmoid(output)\n            predicted = (probs > 0.5).float()\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n            # 批量收集预测结果\n            all_preds.extend(probs.detach().cpu().numpy())\n            all_targets.extend(target.detach().cpu().numpy())\n\n        pbar.set_postfix({\n            'Loss': f'{loss.item():.4f}',\n            'Acc': f'{100.*correct/total:.2f}%'\n        })\n        \n        # 定期清理GPU缓存\n        if batch_idx % 10 == 0 and torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n    avg_loss = total_loss / len(train_loader)\n    accuracy = 100. * correct / total\n\n    try:\n        auc_score = roc_auc_score(all_targets, all_preds)\n    except:\n        auc_score = 0.0\n\n    return avg_loss, accuracy, auc_score\n\ndef validate_epoch(model, val_loader, criterion, device, scaler=None):\n    \"\"\"GPU优化的验证一个epoch\"\"\"\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n        pbar = tqdm(val_loader, desc='Validation', leave=False)\n\n        for batch_idx, (data, target) in enumerate(pbar):\n            # 非阻塞数据传输到GPU\n            data = data.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            \n            # 混合精度推理\n            with autocast():\n                output, _ = model(data)\n                loss = criterion(output, target)\n\n            total_loss += loss.item()\n            \n            # 在GPU上计算准确率\n            probs = torch.sigmoid(output)\n            predicted = (probs > 0.5).float()\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n            # 批量收集预测结果\n            all_preds.extend(probs.cpu().numpy())\n            all_targets.extend(target.cpu().numpy())\n\n            pbar.set_postfix({\n                'Loss': f'{loss.item():.4f}',\n                'Acc': f'{100.*correct/total:.2f}%'\n            })\n            \n            # 定期清理GPU缓存\n            if batch_idx % 20 == 0 and torch.cuda.is_available():\n                torch.cuda.empty_cache()\n\n    avg_loss = total_loss / len(val_loader)\n    accuracy = 100. * correct / total\n\n    try:\n        auc_score = roc_auc_score(all_targets, all_preds)\n    except:\n        auc_score = 0.0\n\n    return avg_loss, accuracy, auc_score\n\nprint(\"✅ 训练和验证函数定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T12:41:33.919928Z","iopub.execute_input":"2025-07-05T12:41:33.920184Z","iopub.status.idle":"2025-07-05T12:41:33.942894Z","shell.execute_reply.started":"2025-07-05T12:41:33.920168Z","shell.execute_reply":"2025-07-05T12:41:33.942333Z"}},"outputs":[{"name":"stdout","text":"✅ 训练和验证函数定义完成\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Cell 8: 评估函数和可视化","metadata":{}},{"cell_type":"code","source":"# Cell 8: 评估函数和可视化\n\ndef evaluate_model_optimized(model, test_loader, criterion, device):\n    \"\"\"优化的模型评估函数\"\"\"\n    model.eval()\n    total_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    all_scores = []\n    \n    inference_times = []\n    \n    print(\"🚀 开始模型评估...\")\n    \n    with torch.no_grad():\n        for batch_idx, (data, target) in enumerate(tqdm(test_loader, desc=\"评估进度\")):\n            data, target = data.to(device), target.to(device)\n            \n            # 记录推理时间\n            start_time = time.time()\n            output, attention_weights = model(data)\n            inference_time = time.time() - start_time\n            inference_times.append(inference_time)\n            \n            # 计算损失\n            loss = criterion(output, target)\n            total_loss += loss.item()\n            \n            # 收集预测结果 (应用 sigmoid 获得概率)\n            probs = torch.sigmoid(output)\n            predictions = (probs > 0.5).float()\n            all_predictions.extend(predictions.cpu().numpy())\n            all_targets.extend(target.cpu().numpy())\n            all_scores.extend(probs.cpu().numpy())\n    \n    avg_loss = total_loss / len(test_loader)\n    avg_inference_time = np.mean(inference_times)\n    total_inference_time = np.sum(inference_times)\n    \n    print(f\"✅ 评估完成\")\n    print(f\"平均损失: {avg_loss:.4f}\")\n    print(f\"平均推理时间: {avg_inference_time*1000:.2f} ms/batch\")\n    \n    return {\n        'loss': avg_loss,\n        'predictions': np.array(all_predictions),\n        'targets': np.array(all_targets),\n        'scores': np.array(all_scores),\n        'avg_inference_time': avg_inference_time,\n        'total_inference_time': total_inference_time\n    }\n\ndef calculate_comprehensive_metrics(predictions, targets, scores):\n    \"\"\"计算全面的评估指标\"\"\"\n    # 基础指标\n    accuracy = accuracy_score(targets, predictions)\n    balanced_acc = balanced_accuracy_score(targets, predictions)\n    precision = precision_score(targets, predictions, zero_division=0)\n    recall = recall_score(targets, predictions, zero_division=0)\n    f1 = f1_score(targets, predictions, zero_division=0)\n    \n    # 混淆矩阵\n    cm = confusion_matrix(targets, predictions)\n    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n    \n    # 特异性和负预测值\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n    \n    # AUC指标\n    try:\n        auc_roc = roc_auc_score(targets, scores)\n    except:\n        auc_roc = 0.0\n    \n    try:\n        precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)\n        auc_pr = auc(recall_curve, precision_curve)\n    except:\n        auc_pr = 0.0\n    \n    return {\n        'accuracy': accuracy,\n        'balanced_accuracy': balanced_acc,\n        'precision': precision,\n        'recall': recall,\n        'specificity': specificity,\n        'f1': f1,\n        'auc_roc': auc_roc,\n        'auc_pr': auc_pr,\n        'npv': npv,\n        'confusion_matrix': cm,\n        'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n    }\n\ndef plot_enhanced_confusion_matrix(cm, save_path):\n    \"\"\"绘制增强的混淆矩阵\"\"\"\n    plt.figure(figsize=(10, 8))\n    \n    # 计算百分比\n    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n    \n    # 创建标签\n    labels = np.array([[\n        f'{cm[i,j]}\\n({cm_percent[i,j]:.1f}%)' \n        for j in range(cm.shape[1])\n    ] for i in range(cm.shape[0])])\n    \n    # 绘制热图\n    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', \n                xticklabels=['真实', '伪造'],\n                yticklabels=['真实', '伪造'],\n                cbar_kws={'label': '样本数量'})\n    \n    plt.title('增强混淆矩阵', fontsize=16, fontweight='bold')\n    plt.xlabel('预测标签', fontsize=12)\n    plt.ylabel('真实标签', fontsize=12)\n    \n    # 添加统计信息\n    tn, fp, fn, tp = cm.ravel()\n    accuracy = (tp + tn) / (tp + tn + fp + fn)\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    stats_text = f'准确率: {accuracy:.3f}\\n精确率: {precision:.3f}\\n召回率: {recall:.3f}\\nF1分数: {f1:.3f}'\n    plt.text(2.1, 0.5, stats_text, fontsize=10, \n             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n    \n    plt.tight_layout()\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n    print(f\"混淆矩阵已保存到: {save_path}\")\n\ndef plot_roc_pr_curves(targets, scores, save_path):\n    \"\"\"绘制ROC和PR曲线\"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n    \n    # ROC曲线\n    fpr, tpr, _ = roc_curve(targets, scores)\n    roc_auc = auc(fpr, tpr)\n    \n    ax1.plot(fpr, tpr, color='darkorange', lw=2,\n             label=f'ROC曲线 (AUC = {roc_auc:.4f})')\n    ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    ax1.set_xlim([0.0, 1.0])\n    ax1.set_ylim([0.0, 1.05])\n    ax1.set_xlabel('假正率')\n    ax1.set_ylabel('真正率')\n    ax1.set_title('ROC曲线')\n    ax1.legend(loc='lower right')\n    ax1.grid(True, alpha=0.3)\n    \n    # PR曲线\n    precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)\n    pr_auc = auc(recall_curve, precision_curve)\n    \n    ax2.plot(recall_curve, precision_curve, color='darkgreen', lw=2,\n             label=f'PR曲线 (AUC = {pr_auc:.4f})')\n    ax2.set_xlim([0.0, 1.0])\n    ax2.set_ylim([0.0, 1.05])\n    ax2.set_xlabel('召回率')\n    ax2.set_ylabel('精确率')\n    ax2.set_title('精确率-召回率曲线')\n    ax2.legend(loc='lower left')\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n    print(f\"ROC/PR曲线已保存到: {save_path}\")\n\nprint(\"✅ 评估函数和可视化定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T12:41:33.944333Z","iopub.execute_input":"2025-07-05T12:41:33.944526Z","iopub.status.idle":"2025-07-05T12:41:33.967312Z","shell.execute_reply.started":"2025-07-05T12:41:33.944511Z","shell.execute_reply":"2025-07-05T12:41:33.966629Z"}},"outputs":[{"name":"stdout","text":"✅ 评估函数和可视化定义完成\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Cell 9: 数据处理和准备\n","metadata":{}},{"cell_type":"code","source":"# Cell 9: 数据处理和准备\n\n# 如果需要处理数据（首次运行）\nif not os.path.exists('./data/train.csv'):\n    print(\"📁 开始数据处理...\")\n    data_list = process_videos_simple(BASE_DATA_DIR, max_videos_per_class=120, max_frames=16)\n    \n    if len(data_list) == 0:\n        print(\"❌ 未找到数据，请检查数据路径\")\n        raise ValueError(\"数据路径错误或数据不存在\")\n    \n    train_data, val_data, test_data = create_dataset_split(data_list)\n    \n    # 保存数据集\n    save_dataset_to_csv(train_data, './data/train.csv')\n    save_dataset_to_csv(val_data, './data/val.csv')\n    save_dataset_to_csv(test_data, './data/test.csv')\n    \n    print(f\"训练集: {len(train_data)} 个样本\")\n    print(f\"验证集: {len(val_data)} 个样本\")\n    print(f\"测试集: {len(test_data)} 个样本\")\nelse:\n    print(\"📊 数据集已存在，跳过数据处理步骤\")\n    # 读取现有数据集信息\n    train_df = pd.read_csv('./data/train.csv')\n    val_df = pd.read_csv('./data/val.csv')\n    test_df = pd.read_csv('./data/test.csv')\n    \n    print(f\"训练集: {len(train_df)} 个样本\")\n    print(f\"验证集: {len(val_df)} 个样本\")\n    print(f\"测试集: {len(test_df)} 个样本\")\n    \n    # 显示数据分布\n    print(\"\\n数据分布:\")\n    print(\"训练集标签分布:\")\n    print(train_df['label'].value_counts())\n    print(\"\\n验证集标签分布:\")\n    print(val_df['label'].value_counts())\n    print(\"\\n测试集标签分布:\")\n    print(test_df['label'].value_counts())\n\nprint(\"✅ 数据准备完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T12:41:33.967840Z","iopub.execute_input":"2025-07-05T12:41:33.967992Z","iopub.status.idle":"2025-07-05T14:58:30.505269Z","shell.execute_reply.started":"2025-07-05T12:41:33.967980Z","shell.execute_reply":"2025-07-05T14:58:30.504435Z"}},"outputs":[{"name":"stdout","text":"📁 开始数据处理...\n开始处理真实视频...\n找到 200 个真实视频\n","output_type":"stream"},{"name":"stderr","text":"处理真实视频: 100%|██████████| 200/200 [22:22<00:00,  6.71s/it]\n","output_type":"stream"},{"name":"stdout","text":"开始处理伪造视频...\n处理 Deepfakes: 200 个视频\n","output_type":"stream"},{"name":"stderr","text":"处理Deepfakes: 100%|██████████| 200/200 [23:52<00:00,  7.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"处理 Face2Face: 200 个视频\n","output_type":"stream"},{"name":"stderr","text":"处理Face2Face: 100%|██████████| 200/200 [23:10<00:00,  6.95s/it]\n","output_type":"stream"},{"name":"stdout","text":"处理 FaceShifter: 200 个视频\n","output_type":"stream"},{"name":"stderr","text":"处理FaceShifter: 100%|██████████| 200/200 [22:01<00:00,  6.61s/it]\n","output_type":"stream"},{"name":"stdout","text":"处理 FaceSwap: 200 个视频\n","output_type":"stream"},{"name":"stderr","text":"处理FaceSwap: 100%|██████████| 200/200 [21:36<00:00,  6.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"处理 NeuralTextures: 200 个视频\n","output_type":"stream"},{"name":"stderr","text":"处理NeuralTextures: 100%|██████████| 200/200 [23:52<00:00,  7.16s/it]","output_type":"stream"},{"name":"stdout","text":"\n✅ 数据处理完成，共处理 1089 个视频\n真实视频: 183 个\n伪造视频: 906 个\n数据集已保存到: ./data/train.csv\n数据集已保存到: ./data/val.csv\n数据集已保存到: ./data/test.csv\n训练集: 762 个样本\n验证集: 108 个样本\n测试集: 219 个样本\n✅ 数据准备完成\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Cell 10: 创建数据加载器\n","metadata":{}},{"cell_type":"code","source":"# Cell 10: 创建数据加载器\n\nprint(\"📊 创建数据加载器...\")\n\n# 获取数据变换 - 简化变换以减少CPU负担\ntrain_transform = None  # 使用GPU预处理替代CPU变换\nval_transform = None\n\n# 创建数据集 - 启用GPU预处理\ntrain_dataset = DeepfakeVideoDataset('./data/train.csv', transform=train_transform, max_frames=16, gpu_preprocessing=True)\nval_dataset = DeepfakeVideoDataset('./data/val.csv', transform=val_transform, max_frames=16, gpu_preprocessing=True)\ntest_dataset = DeepfakeVideoDataset('./data/test.csv', transform=val_transform, max_frames=16, gpu_preprocessing=True)\n\n# 优化批次大小以减少CPU瓶颈\nif torch.cuda.is_available():\n    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n    gpu_count = torch.cuda.device_count()\n    print(f\"检测到 {gpu_count} 个GPU，每个GPU内存: {gpu_memory:.1f} GB\")\n    \n    # 大幅降低批次大小以减少CPU负担\n    batch_size = 4  # 固定使用小批次\nelse:\n    batch_size = 2\n\nprint(f\"使用批次大小: {batch_size} (优化CPU性能)\")\n\n# 大幅降低worker数量以减少CPU瓶颈\nnum_workers = 2  # 固定使用2个worker\nprint(f\"使用 {num_workers} 个数据加载worker (优化CPU性能)\")\n\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=batch_size, \n    shuffle=True, \n    num_workers=num_workers,\n    pin_memory=torch.cuda.is_available(),\n    drop_last=True,\n    persistent_workers=False,  # 禁用以减少内存占用\n    prefetch_factor=1  # 降低预取因子\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=num_workers,\n    pin_memory=torch.cuda.is_available(),\n    persistent_workers=False,  # 禁用以减少内存占用\n    prefetch_factor=1  # 降低预取因子\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=num_workers,\n    pin_memory=torch.cuda.is_available(),\n    persistent_workers=False,  # 禁用以减少内存占用\n    prefetch_factor=1  # 降低预取因子\n)\n\nprint(f\"训练批次数: {len(train_loader)}\")\nprint(f\"验证批次数: {len(val_loader)}\")\nprint(f\"测试批次数: {len(test_loader)}\")\n\n# 测试数据加载器\nprint(\"\\n🔍 测试数据加载器...\")\ntry:\n    sample_batch = next(iter(train_loader))\n    videos, labels = sample_batch\n    print(f\"视频张量形状: {videos.shape}\")\n    print(f\"标签张量形状: {labels.shape}\")\n    print(f\"视频数据类型: {videos.dtype}\")\n    print(f\"标签数据类型: {labels.dtype}\")\n    print(f\"视频数据范围: [{videos.min():.3f}, {videos.max():.3f}]\")\n    print(f\"标签分布: {labels.unique(return_counts=True)}\")\n    print(\"✅ 数据加载器测试成功\")\nexcept Exception as e:\n    print(f\"❌ 数据加载器测试失败: {e}\")\n    raise e\n\nprint(\"✅ 数据加载器创建完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T14:58:30.506218Z","iopub.execute_input":"2025-07-05T14:58:30.506452Z","iopub.status.idle":"2025-07-05T15:08:03.846653Z","shell.execute_reply.started":"2025-07-05T14:58:30.506417Z","shell.execute_reply":"2025-07-05T15:08:03.833408Z"}},"outputs":[{"name":"stdout","text":"📊 创建数据加载器...\n检测到 2 个GPU，每个GPU内存: 14.7 GB\n使用批次大小: 12\n使用 8 个数据加载worker\n训练批次数: 63\n验证批次数: 9\n测试批次数: 19\n\n🔍 测试数据加载器...\n视频张量形状: torch.Size([12, 32, 3, 160, 160])\n标签张量形状: torch.Size([12])\n视频数据类型: torch.float32\n标签数据类型: torch.float32\n视频数据范围: [-2.118, 2.640]\n标签分布: (tensor([0., 1.]), tensor([ 1, 11]))\n✅ 数据加载器测试成功\n✅ 数据加载器创建完成\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# Cell 11: 模型初始化和训练配置\n","metadata":{}},{"cell_type":"code","source":"# Cell 11: 模型初始化和训练配置 - GPU优化版本\n\nprint(\"🤖 创建和配置模型...\")\n\n# 创建模型 - 针对T4*2 GPU优化\nmodel = OptimizedDeepfakeDetector(\n    backbone='resnet50',  # 使用ResNet50以充分利用T4*2 GPU性能\n    hidden_dim=512,      # 增加隐藏层维度\n    num_layers=2,        # 增加LSTM层数\n    dropout=0.4,         # 适当增加dropout防止过拟合\n    use_attention=True\n).to(device)\n\n# 多GPU支持 - 充分利用T4*2配置\nif torch.cuda.device_count() > 1:\n    print(f\"使用 {torch.cuda.device_count()} 个GPU进行并行训练\")\n    model = nn.DataParallel(model)\nelse:\n    print(\"使用单GPU训练\")\n\n# 计算模型参数数量\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"模型总参数数量: {total_params:,}\")\nprint(f\"可训练参数数量: {trainable_params:,}\")\nprint(f\"模型大小估计: {total_params * 4 / 1024**2:.1f} MB\")\n\n# 损失函数\ncriterion = FocalLoss(alpha=1, gamma=2)\nprint(\"使用焦点损失函数 (Focal Loss)\")\n\n# 优化器 - 针对ResNet50优化\noptimizer = optim.AdamW(\n    model.parameters(), \n    lr=2e-4,  # 稍微提高学习率以适应更大模型\n    weight_decay=1e-4,\n    betas=(0.9, 0.999)\n)\nprint(\"使用AdamW优化器 (lr=2e-4)\")\n\n# 学习率调度器 - 更保守的调度\nscheduler = ReduceLROnPlateau(\n    optimizer, \n    mode='min', \n    factor=0.6,  # 更保守的衰减因子\n    patience=4,  # 增加patience\n    verbose=True,\n    min_lr=1e-7\n)\nprint(\"使用ReduceLROnPlateau学习率调度器 (factor=0.6, patience=4)\")\n\n# 早停机制 - 增加patience以适应更大模型\nearly_stopping = EarlyStopping(patience=8, min_delta=0.001)\nprint(\"配置早停机制 (patience=8)\")\n\n# 混合精度训练\nif torch.cuda.is_available():\n    scaler = GradScaler()\n    print(\"启用混合精度训练 (AMP)\")\nelse:\n    scaler = None\n    print(\"CPU模式，不使用混合精度训练\")\n\n# 训练配置 - 针对T4*2 GPU和更大数据集优化\nnum_epochs = 25  # 增加训练轮数以充分训练更大的模型\nprint(f\"训练轮数: {num_epochs}\")\n\n# 测试模型前向传播\nprint(\"\\n🔍 测试模型前向传播...\")\ntry:\n    model.eval()\n    with torch.no_grad():\n        sample_batch = next(iter(train_loader))\n        videos, labels = sample_batch\n        videos, labels = videos.to(device), labels.to(device)\n        \n        # 前向传播\n        outputs, attention_weights = model(videos)\n        loss = criterion(outputs, labels)\n        \n        print(f\"输入形状: {videos.shape}\")\n        print(f\"输出形状: {outputs.shape}\")\n        print(f\"损失值: {loss.item():.4f}\")\n        print(f\"Logits范围: [{outputs.min():.3f}, {outputs.max():.3f}]\")\n        \n        # 显示概率范围\n        probs = torch.sigmoid(outputs)\n        print(f\"概率范围: [{probs.min():.3f}, {probs.max():.3f}]\")\n        \n        if attention_weights is not None:\n            print(f\"注意力权重形状: {attention_weights.shape}\")\n        \n        print(\"✅ 模型前向传播测试成功\")\nexcept Exception as e:\n    print(f\"❌ 模型前向传播测试失败: {e}\")\n    raise e\n\nprint(\"✅ 模型配置完成，准备开始训练\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T15:08:03.859831Z","iopub.execute_input":"2025-07-05T15:08:03.860225Z","iopub.status.idle":"2025-07-05T15:25:13.844911Z","shell.execute_reply.started":"2025-07-05T15:08:03.860170Z","shell.execute_reply":"2025-07-05T15:25:13.844014Z"}},"outputs":[{"name":"stdout","text":"🤖 创建和配置模型...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:05<00:00, 20.0MB/s]\n","output_type":"stream"},{"name":"stdout","text":"使用 2 个GPU进行并行训练\n模型总参数数量: 45,156,417\n可训练参数数量: 45,156,417\n模型大小估计: 172.3 MB\n使用焦点损失函数 (Focal Loss)\n使用AdamW优化器 (lr=2e-4)\n使用ReduceLROnPlateau学习率调度器 (factor=0.6, patience=4)\n配置早停机制 (patience=8)\n启用混合精度训练 (AMP)\n训练轮数: 25\n\n🔍 测试模型前向传播...\n输入形状: torch.Size([12, 32, 3, 160, 160])\n输出形状: torch.Size([12])\n损失值: 0.1815\nLogits范围: [-0.052, -0.047]\n概率范围: [0.487, 0.488]\n注意力权重形状: torch.Size([12, 32, 32])\n✅ 模型前向传播测试成功\n✅ 模型配置完成，准备开始训练\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# Cell 12: 模型训练主循环\n","metadata":{}},{"cell_type":"code","source":"# Cell 12: 训练循环 - GPU优化版本\n\nprint(\"🚀 开始训练...\")\n\n# 训练历史记录\ntrain_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []\nbest_val_loss = float('inf')\nbest_model_state = None\n\n# 训练循环\nfor epoch in range(num_epochs):\n    print(f\"\\n{'='*50}\")\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"{'='*50}\")\n    \n    # 训练阶段 - 使用混合精度\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, scaler)\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n    \n    # 验证阶段 - 使用混合精度\n    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device, scaler)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    \n    # 学习率调度\n    scheduler.step(val_loss)\n    current_lr = optimizer.param_groups[0]['lr']\n    \n    # 打印结果\n    print(f\"\\n📊 Epoch {epoch+1} 结果:\")\n    print(f\"训练损失: {train_loss:.4f} | 训练准确率: {train_acc:.4f}\")\n    print(f\"验证损失: {val_loss:.4f} | 验证准确率: {val_acc:.4f}\")\n    print(f\"当前学习率: {current_lr:.2e}\")\n    \n    # GPU内存使用情况\n    if torch.cuda.is_available():\n        memory_allocated = torch.cuda.memory_allocated() / 1024**3\n        memory_reserved = torch.cuda.memory_reserved() / 1024**3\n        print(f\"GPU内存: {memory_allocated:.1f}GB / {memory_reserved:.1f}GB\")\n    \n    # 保存最佳模型\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        best_model_state = model.state_dict().copy()\n        print(f\"🎯 新的最佳验证损失: {best_val_loss:.4f}\")\n    \n    # 早停检查\n    if early_stopping(val_loss):\n        print(f\"\\n⏹️ 早停触发，在第 {epoch+1} 轮停止训练\")\n        break\n    \n    # 清理GPU缓存\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\nprint(\"\\n✅ 训练完成!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T15:25:13.845839Z","iopub.execute_input":"2025-07-05T15:25:13.846136Z","iopub.status.idle":"2025-07-05T16:11:32.772769Z","shell.execute_reply.started":"2025-07-05T15:25:13.846110Z","shell.execute_reply":"2025-07-05T16:11:32.765175Z"}},"outputs":[{"name":"stdout","text":"🎯 开始训练模型...\n============================================================\n\nEpoch 1/25\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"                                                                                      \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/4266167438.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# 训练阶段\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     train_loss, train_acc, train_auc = train_epoch(\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     )\n","\u001b[0;32m/tmp/ipykernel_35/349398126.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, device, scaler)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":22},{"cell_type":"markdown","source":"# Cell 13: 模型评估和结果分析\n","metadata":{}},{"cell_type":"code","source":"# Cell 13: 模型评估和结果分析\n\nprint(\"📊 开始模型评估...\")\nprint(\"=\" * 60)\n\n# 加载最佳模型\nprint(\"🔄 加载最佳模型...\")\ntry:\n    checkpoint = torch.load('./models/best_model.pth', map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    best_epoch = checkpoint['epoch']\n    best_val_acc = checkpoint['best_val_acc']\n    best_val_auc = checkpoint['best_val_auc']\n    \n    print(f\"✅ 成功加载第 {best_epoch+1} 轮的最佳模型\")\n    print(f\"最佳验证准确率: {best_val_acc:.2f}%\")\n    print(f\"最佳验证AUC: {best_val_auc:.4f}\")\nexcept Exception as e:\n    print(f\"❌ 加载模型失败: {e}\")\n    print(\"使用当前模型进行评估\")\n\n# 在测试集上评估模型\nprint(\"\\n🔍 在测试集上评估模型...\")\neval_results = evaluate_model_optimized(model, test_loader, criterion, device)\n\n# 计算全面的评估指标\nprint(\"\\n📈 计算评估指标...\")\nmetrics = calculate_comprehensive_metrics(\n    eval_results['predictions'], \n    eval_results['targets'], \n    eval_results['scores']\n)\n\n# 打印详细结果\nprint(\"\\n📊 详细评估结果:\")\nprint(\"=\" * 50)\nprint(f\"测试损失: {eval_results['loss']:.4f}\")\nprint(f\"准确率: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\nprint(f\"平衡准确率: {metrics['balanced_accuracy']:.4f} ({metrics['balanced_accuracy']*100:.2f}%)\")\nprint(f\"精确率: {metrics['precision']:.4f}\")\nprint(f\"召回率: {metrics['recall']:.4f}\")\nprint(f\"特异性: {metrics['specificity']:.4f}\")\nprint(f\"F1分数: {metrics['f1']:.4f}\")\nprint(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")\nprint(f\"AUC-PR: {metrics['auc_pr']:.4f}\")\nprint(f\"负预测值: {metrics['npv']:.4f}\")\n\n# 混淆矩阵详细信息\nprint(\"\\n🔍 混淆矩阵分析:\")\nprint(f\"真负例 (TN): {metrics['tn']}\")\nprint(f\"假正例 (FP): {metrics['fp']}\")\nprint(f\"假负例 (FN): {metrics['fn']}\")\nprint(f\"真正例 (TP): {metrics['tp']}\")\n\n# 性能分析\nprint(\"\\n⚡ 性能分析:\")\nprint(f\"平均推理时间: {eval_results['avg_inference_time']*1000:.2f} ms/batch\")\nprint(f\"总推理时间: {eval_results['total_inference_time']:.2f} 秒\")\nprint(f\"每个样本推理时间: {eval_results['avg_inference_time']*1000/batch_size:.2f} ms\")\n\n# 计算额外指标\ntotal_samples = len(eval_results['targets'])\nreal_samples = np.sum(eval_results['targets'] == 0)\nfake_samples = np.sum(eval_results['targets'] == 1)\nreal_accuracy = np.sum((eval_results['predictions'] == 0) & (eval_results['targets'] == 0)) / real_samples if real_samples > 0 else 0\nfake_accuracy = np.sum((eval_results['predictions'] == 1) & (eval_results['targets'] == 1)) / fake_samples if fake_samples > 0 else 0\n\nprint(\"\\n📋 类别特定分析:\")\nprint(f\"总样本数: {total_samples}\")\nprint(f\"真实视频样本: {real_samples} ({real_samples/total_samples*100:.1f}%)\")\nprint(f\"伪造视频样本: {fake_samples} ({fake_samples/total_samples*100:.1f}%)\")\nprint(f\"真实视频检测准确率: {real_accuracy:.4f} ({real_accuracy*100:.2f}%)\")\nprint(f\"伪造视频检测准确率: {fake_accuracy:.4f} ({fake_accuracy*100:.2f}%)\")\n\n# 生成可视化图表\nprint(\"\\n📊 生成评估图表...\")\n\n# 绘制增强混淆矩阵\nplot_enhanced_confusion_matrix(\n    metrics['confusion_matrix'], \n    './results/evaluation/confusion_matrix.png'\n)\n\n# 绘制ROC和PR曲线\nplot_roc_pr_curves(\n    eval_results['targets'], \n    eval_results['scores'], \n    './results/evaluation/roc_pr_curves.png'\n)\n\n# 预测分数分布图\nplt.figure(figsize=(12, 5))\n\n# 真实视频的预测分数分布\nplt.subplot(1, 2, 1)\nreal_scores = eval_results['scores'][eval_results['targets'] == 0]\nfake_scores = eval_results['scores'][eval_results['targets'] == 1]\n\nplt.hist(real_scores, bins=30, alpha=0.7, label='真实视频', color='blue', density=True)\nplt.hist(fake_scores, bins=30, alpha=0.7, label='伪造视频', color='red', density=True)\nplt.xlabel('预测分数')\nplt.ylabel('密度')\nplt.title('预测分数分布')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n# 预测分数箱线图\nplt.subplot(1, 2, 2)\nscores_data = [real_scores, fake_scores]\nlabels = ['真实视频', '伪造视频']\nplt.boxplot(scores_data, labels=labels)\nplt.ylabel('预测分数')\nplt.title('预测分数箱线图')\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('./results/evaluation/score_distribution.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"✅ 评估图表生成完成\")\nprint(\"=\" * 60)\nprint(\"🎉 模型评估完成！\")\nprint(\"📁 所有结果已保存到 ./results/evaluation/ 目录\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:11:32.775060Z","iopub.status.idle":"2025-07-05T16:11:32.778302Z","shell.execute_reply.started":"2025-07-05T16:11:32.778094Z","shell.execute_reply":"2025-07-05T16:11:32.778112Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 14: 结果保存和总结\n","metadata":{}},{"cell_type":"code","source":"# Cell 14: 结果保存和总结\n\nprint(\"💾 保存实验结果...\")\nprint(\"=\" * 60)\n\n# 准备保存的结果数据\nresults_summary = {\n    'experiment_info': {\n        'timestamp': datetime.now().isoformat(),\n        'model_architecture': 'OptimizedDeepfakeDetector',\n        'backbone': 'resnet18',\n        'total_epochs': len(train_history['train_loss']),\n        'best_epoch': best_epoch + 1 if 'best_epoch' in locals() else len(train_history['train_loss']),\n        'early_stopping': True,\n        'mixed_precision': torch.cuda.is_available()\n    },\n    'dataset_info': {\n        'train_samples': len(train_dataset),\n        'val_samples': len(val_dataset),\n        'test_samples': len(test_dataset),\n        'batch_size': batch_size,\n        'num_workers': 2\n    },\n    'training_config': {\n        'optimizer': 'AdamW',\n        'learning_rate': 1e-4,\n        'weight_decay': 1e-4,\n        'loss_function': 'FocalLoss',\n        'scheduler': 'ReduceLROnPlateau',\n        'early_stopping_patience': 5\n    },\n    'final_metrics': {\n        'test_loss': float(eval_results['loss']),\n        'accuracy': float(metrics['accuracy']),\n        'balanced_accuracy': float(metrics['balanced_accuracy']),\n        'precision': float(metrics['precision']),\n        'recall': float(metrics['recall']),\n        'specificity': float(metrics['specificity']),\n        'f1_score': float(metrics['f1']),\n        'auc_roc': float(metrics['auc_roc']),\n        'auc_pr': float(metrics['auc_pr']),\n        'npv': float(metrics['npv'])\n    },\n    'confusion_matrix': {\n        'tn': int(metrics['tn']),\n        'fp': int(metrics['fp']),\n        'fn': int(metrics['fn']),\n        'tp': int(metrics['tp'])\n    },\n    'performance': {\n        'avg_inference_time_ms': float(eval_results['avg_inference_time'] * 1000),\n        'total_inference_time_s': float(eval_results['total_inference_time']),\n        'samples_per_second': float(len(eval_results['targets']) / eval_results['total_inference_time'])\n    },\n    'training_history': {\n        'train_loss': [float(x) for x in train_history['train_loss']],\n        'train_acc': [float(x) for x in train_history['train_acc']],\n        'train_auc': [float(x) for x in train_history['train_auc']],\n        'val_loss': [float(x) for x in train_history['val_loss']],\n        'val_acc': [float(x) for x in train_history['val_acc']],\n        'val_auc': [float(x) for x in train_history['val_auc']],\n        'learning_rates': [float(x) for x in train_history['lr']]\n    },\n    'class_specific_metrics': {\n        'real_video_accuracy': float(real_accuracy),\n        'fake_video_accuracy': float(fake_accuracy),\n        'real_samples_count': int(real_samples),\n        'fake_samples_count': int(fake_samples)\n    }\n}\n\n# 保存结果到JSON文件\nresults_file = './results/experiment_results.json'\nwith open(results_file, 'w', encoding='utf-8') as f:\n    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n\nprint(f\"✅ 实验结果已保存到: {results_file}\")\n\n# 保存训练历史到CSV\nhistory_df = pd.DataFrame(train_history)\nhistory_df.to_csv('./results/training_history.csv', index=False)\nprint(\"✅ 训练历史已保存到: ./results/training_history.csv\")\n\n# 保存预测结果\npredictions_df = pd.DataFrame({\n    'true_label': eval_results['targets'],\n    'predicted_label': eval_results['predictions'],\n    'prediction_score': eval_results['scores']\n})\npredictions_df.to_csv('./results/test_predictions.csv', index=False)\nprint(\"✅ 测试预测结果已保存到: ./results/test_predictions.csv\")\n\n# 生成实验报告\nprint(\"\\n📋 生成实验报告...\")\nreport = f\"\"\"\n深度伪造检测模型实验报告\n{'='*50}\n\n实验时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n模型架构: OptimizedDeepfakeDetector (ResNet18 + LSTM + Attention)\n\n数据集信息:\n- 训练样本: {len(train_dataset):,}\n- 验证样本: {len(val_dataset):,}\n- 测试样本: {len(test_dataset):,}\n- 批次大小: {batch_size}\n\n训练配置:\n- 优化器: AdamW (lr=1e-4, weight_decay=1e-4)\n- 损失函数: Focal Loss (alpha=1, gamma=2)\n- 学习率调度: ReduceLROnPlateau\n- 早停机制: patience=5\n- 混合精度训练: {'启用' if torch.cuda.is_available() else '禁用'}\n\n最终性能指标:\n- 准确率: {metrics['accuracy']*100:.2f}%\n- 平衡准确率: {metrics['balanced_accuracy']*100:.2f}%\n- 精确率: {metrics['precision']:.4f}\n- 召回率: {metrics['recall']:.4f}\n- F1分数: {metrics['f1']:.4f}\n- AUC-ROC: {metrics['auc_roc']:.4f}\n- AUC-PR: {metrics['auc_pr']:.4f}\n\n混淆矩阵:\n- 真负例 (TN): {metrics['tn']}\n- 假正例 (FP): {metrics['fp']}\n- 假负例 (FN): {metrics['fn']}\n- 真正例 (TP): {metrics['tp']}\n\n类别特定性能:\n- 真实视频检测准确率: {real_accuracy*100:.2f}%\n- 伪造视频检测准确率: {fake_accuracy*100:.2f}%\n\n推理性能:\n- 平均推理时间: {eval_results['avg_inference_time']*1000:.2f} ms/batch\n- 处理速度: {len(eval_results['targets'])/eval_results['total_inference_time']:.1f} samples/s\n\n训练总结:\n- 训练轮数: {len(train_history['train_loss'])}\n- 最佳验证准确率: {max(train_history['val_acc']):.2f}%\n- 最佳验证AUC: {max(train_history['val_auc']):.4f}\n\n文件输出:\n- 模型权重: ./models/best_model.pth\n- 训练历史图: ./results/training_history.png\n- 混淆矩阵图: ./results/evaluation/confusion_matrix.png\n- ROC/PR曲线图: ./results/evaluation/roc_pr_curves.png\n- 分数分布图: ./results/evaluation/score_distribution.png\n- 实验结果: ./results/experiment_results.json\n- 训练历史: ./results/training_history.csv\n- 预测结果: ./results/test_predictions.csv\n\n{'='*50}\n实验完成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\"\"\"\n\n# 保存报告\nwith open('./results/experiment_report.txt', 'w', encoding='utf-8') as f:\n    f.write(report)\n\nprint(\"✅ 实验报告已保存到: ./results/experiment_report.txt\")\n\n# 打印最终总结\nprint(\"\\n\" + \"=\"*60)\nprint(\"🎉 深度伪造检测模型训练和评估完成！\")\nprint(\"=\"*60)\nprint(f\"📊 最终测试准确率: {metrics['accuracy']*100:.2f}%\")\nprint(f\"📊 AUC-ROC分数: {metrics['auc_roc']:.4f}\")\nprint(f\"📊 F1分数: {metrics['f1']:.4f}\")\nprint(f\"⚡ 推理速度: {len(eval_results['targets'])/eval_results['total_inference_time']:.1f} samples/s\")\nprint(\"\\n📁 所有结果文件已保存到 ./results/ 目录\")\nprint(\"📁 最佳模型已保存到 ./models/best_model.pth\")\nprint(\"\\n✨ 实验成功完成！可以在Kaggle中查看所有生成的图表和结果文件。\")\nprint(\"=\"*60)\n\n# 显示文件结构\nprint(\"\\n📂 生成的文件结构:\")\nprint(\"\"\"\n./models/\n  └── best_model.pth\n./results/\n  ├── experiment_results.json\n  ├── experiment_report.txt\n  ├── training_history.csv\n  ├── training_history.png\n  ├── test_predictions.csv\n  └── evaluation/\n      ├── confusion_matrix.png\n      ├── roc_pr_curves.png\n      └── score_distribution.png\n\"\"\")\n\nprint(\"\\n🚀 可以使用以下代码加载训练好的模型进行推理:\")\nprint(\"\"\"\n# 加载模型\nmodel = OptimizedDeepfakeDetector(...)\ncheckpoint = torch.load('./models/best_model.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\n\n# 进行推理 (注意: 模型输出 logits，需要应用 sigmoid 获得概率)\nwith torch.no_grad():\n    logits, attention = model(video_tensor)\n    probs = torch.sigmoid(logits)  # 转换为概率\n    prediction = (probs > 0.5).float()\n    confidence = probs.item()\n\"\"\")\n\nprint(\"\\n💡 提示: 在Kaggle中运行时，建议按顺序执行所有cell，确保数据路径正确设置。\")\nprint(\"\\n⚠️  重要: 模型输出的是 logits，使用时必须先应用 sigmoid 函数转换为概率值！\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:11:32.778923Z","iopub.status.idle":"2025-07-05T16:11:32.779236Z","shell.execute_reply.started":"2025-07-05T16:11:32.779089Z","shell.execute_reply":"2025-07-05T16:11:32.779101Z"}},"outputs":[],"execution_count":null}]}