# Cell 9: æ•°æ®å¤„ç†å’Œå‡†å¤‡

# å¦‚æœéœ€è¦å¤„ç†æ•°æ®ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
if not os.path.exists('./data/train.csv'):
    print("ğŸ“ å¼€å§‹æ•°æ®å¤„ç†...")
    data_list = process_videos_simple(BASE_DATA_DIR, max_videos_per_class=120, max_frames=16)
    
    if len(data_list) == 0:
        print("âŒ æœªæ‰¾åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„")
        raise ValueError("æ•°æ®è·¯å¾„é”™è¯¯æˆ–æ•°æ®ä¸å­˜åœ¨")
    
    train_data, val_data, test_data = create_dataset_split(data_list)
    
    # ä¿å­˜æ•°æ®é›†
    save_dataset_to_csv(train_data, './data/train.csv')
    save_dataset_to_csv(val_data, './data/val.csv')
    save_dataset_to_csv(test_data, './data/test.csv')
    
    print(f"è®­ç»ƒé›†: {len(train_data)} ä¸ªæ ·æœ¬")
    print(f"éªŒè¯é›†: {len(val_data)} ä¸ªæ ·æœ¬")
    print(f"æµ‹è¯•é›†: {len(test_data)} ä¸ªæ ·æœ¬")
else:
    print("ğŸ“Š æ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®å¤„ç†æ­¥éª¤")
    # è¯»å–ç°æœ‰æ•°æ®é›†ä¿¡æ¯
    train_df = pd.read_csv('./data/train.csv')
    val_df = pd.read_csv('./data/val.csv')
    test_df = pd.read_csv('./data/test.csv')
    
    print(f"è®­ç»ƒé›†: {len(train_df)} ä¸ªæ ·æœ¬")
    print(f"éªŒè¯é›†: {len(val_df)} ä¸ªæ ·æœ¬")
    print(f"æµ‹è¯•é›†: {len(test_df)} ä¸ªæ ·æœ¬")
    
    # æ˜¾ç¤ºæ•°æ®åˆ†å¸ƒ
    print("\nåŸå§‹æ•°æ®åˆ†å¸ƒ:")
    print("è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ:")
    print(train_df['label'].value_counts())
    print("\néªŒè¯é›†æ ‡ç­¾åˆ†å¸ƒ:")
    print(val_df['label'].value_counts())
    print("\næµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ:")
    print(test_df['label'].value_counts())
    
    # æ£€æŸ¥ç±»åˆ«ä¸å¹³è¡¡å¹¶è¿›è¡Œé‡é‡‡æ ·
    real_count = (train_df['label'] == 0).sum()
    fake_count = (train_df['label'] == 1).sum()
    imbalance_ratio = fake_count / real_count if real_count > 0 else float('inf')
    
    print(f"\nç±»åˆ«ä¸å¹³è¡¡æ¯”ä¾‹: {imbalance_ratio:.2f} (ä¼ªé€ /çœŸå®)")
    
    if imbalance_ratio > 2.0:  # å¦‚æœä¸å¹³è¡¡æ¯”ä¾‹è¶…è¿‡2:1
        print("ğŸ”„ æ£€æµ‹åˆ°ä¸¥é‡ç±»åˆ«ä¸å¹³è¡¡ï¼Œè¿›è¡Œæ•°æ®é‡é‡‡æ ·...")
        
        # åˆ†ç¦»çœŸå®å’Œä¼ªé€ æ ·æœ¬
        real_samples = train_df[train_df['label'] == 0]
        fake_samples = train_df[train_df['label'] == 1]
        
        # è®¡ç®—éœ€è¦è¿‡é‡‡æ ·çš„æ•°é‡ï¼ˆä½¿æ¯”ä¾‹æ¥è¿‘1:2ï¼‰
        target_real_count = fake_count // 2
        if target_real_count > real_count:
            # è¿‡é‡‡æ ·çœŸå®æ ·æœ¬
            oversample_count = target_real_count - real_count
            oversampled_real = real_samples.sample(n=oversample_count, replace=True, random_state=42)
            
            # åˆå¹¶é‡é‡‡æ ·åçš„æ•°æ®
            balanced_train_df = pd.concat([real_samples, oversampled_real, fake_samples], ignore_index=True)
            balanced_train_df = balanced_train_df.sample(frac=1, random_state=42).reset_index(drop=True)  # æ‰“ä¹±
            
            # ä¿å­˜é‡é‡‡æ ·åçš„è®­ç»ƒé›†
            balanced_train_df.to_csv('./data/train_balanced.csv', index=False)
            
            print(f"é‡é‡‡æ ·åè®­ç»ƒé›†: {len(balanced_train_df)} ä¸ªæ ·æœ¬")
            print("é‡é‡‡æ ·åæ ‡ç­¾åˆ†å¸ƒ:")
            print(balanced_train_df['label'].value_counts())
            
            # æ›´æ–°è®­ç»ƒæ•°æ®å¼•ç”¨
            train_df = balanced_train_df
        else:
            print("çœŸå®æ ·æœ¬æ•°é‡å·²è¶³å¤Ÿï¼Œæ— éœ€è¿‡é‡‡æ ·")
    else:
        print("ç±»åˆ«åˆ†å¸ƒç›¸å¯¹å¹³è¡¡ï¼Œæ— éœ€é‡é‡‡æ ·")

print("âœ… æ•°æ®å‡†å¤‡å®Œæˆ")