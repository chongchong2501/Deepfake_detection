{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##  1.环境设置和数据下载","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# 第1段：环境设置和导入\n# =============================================================================\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# PyTorch相关\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\n# 机器学习指标\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    roc_auc_score, confusion_matrix, classification_report,\n    roc_curve, auc\n)\n\n# 设置随机种子\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n# 检查GPU可用性\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"使用设备: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU型号: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n\n# 创建必要的目录\nos.makedirs('./data', exist_ok=True)\nos.makedirs('./models', exist_ok=True)\nos.makedirs('./logs', exist_ok=True)\nos.makedirs('./results', exist_ok=True)\n\nprint(\"✅ 环境设置完成\")","metadata":{"_uuid":"f6ebcf0d-d34a-4e53-b9c4-c85254661e41","_cell_guid":"4883bd2d-9463-4607-9e61-df4d76492a78","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-04T06:55:55.360300Z","iopub.execute_input":"2025-07-04T06:55:55.360596Z","iopub.status.idle":"2025-07-04T06:56:08.341271Z","shell.execute_reply.started":"2025-07-04T06:55:55.360571Z","shell.execute_reply":"2025-07-04T06:56:08.340282Z"}},"outputs":[{"name":"stdout","text":"使用设备: cuda\nGPU型号: Tesla T4\nGPU内存: 14.7 GB\n✅ 环境设置完成\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"##  2.数据下载与预处理\n","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# 第2段：数据下载和预处理\n# =============================================================================\n\n# 检查是否在Kaggle环境中\nIS_KAGGLE = os.path.exists('/kaggle')\n\nif IS_KAGGLE:\n    # Kaggle环境中的数据路径\n    DATA_DIR = '/kaggle/input/ff-c23'\n    print(\"检测到Kaggle环境\")\nelse:\n    # 本地环境\n    DATA_DIR = './ff-c23'\n    print(\"本地环境\")\n\n# 视频帧提取函数\ndef extract_frames_from_video(video_path, max_frames=30, target_size=(128, 128)):\n    \"\"\"\n    从视频中提取帧\n    \"\"\"\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    \n    if not cap.isOpened():\n        print(f\"无法打开视频: {video_path}\")\n        return frames\n    \n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    if total_frames == 0:\n        cap.release()\n        return frames\n    \n    # 计算采样间隔\n    if total_frames <= max_frames:\n        frame_indices = list(range(total_frames))\n    else:\n        frame_indices = np.linspace(0, total_frames-1, max_frames, dtype=int)\n    \n    for frame_idx in frame_indices:\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n        ret, frame = cap.read()\n        \n        if ret:\n            # 转换颜色空间\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            # 调整大小\n            frame = cv2.resize(frame, target_size)\n            frames.append(frame)\n    \n    cap.release()\n    return frames\n\n# 处理所有视频\ndef process_videos(data_dir, max_videos_per_class=100, max_frames=30):\n    \"\"\"\n    处理所有视频并创建数据集\n    \"\"\"\n    data_list = []\n    \n    # 定义类别和对应的标签\n    categories = {\n        'real': 0,      # 真实视频\n        'fake': 1       # 伪造视频\n    }\n    \n    for category, label in categories.items():\n        category_dir = os.path.join(data_dir, category)\n        \n        if not os.path.exists(category_dir):\n            print(f\"目录不存在: {category_dir}\")\n            continue\n        \n        video_files = [f for f in os.listdir(category_dir) if f.endswith(('.mp4', '.avi', '.mov'))]\n        \n        # 限制视频数量\n        if len(video_files) > max_videos_per_class:\n            video_files = random.sample(video_files, max_videos_per_class)\n        \n        print(f\"处理 {category} 类别的 {len(video_files)} 个视频...\")\n        \n        for video_file in tqdm(video_files, desc=f\"处理{category}视频\"):\n            video_path = os.path.join(category_dir, video_file)\n            \n            # 提取帧\n            frames = extract_frames_from_video(video_path, max_frames)\n            \n            if len(frames) > 0:\n                # 保存帧数据路径\n                frame_save_dir = os.path.join('./data', 'frames', category)\n                os.makedirs(frame_save_dir, exist_ok=True)\n                \n                video_name = os.path.splitext(video_file)[0]\n                frame_save_path = os.path.join(frame_save_dir, f\"{video_name}.npy\")\n                \n                # 保存帧数据\n                np.save(frame_save_path, np.array(frames))\n                \n                data_list.append({\n                    'video_path': video_path,\n                    'frame_path': frame_save_path,\n                    'label': label,\n                    'category': category,\n                    'num_frames': len(frames)\n                })\n    \n    return data_list\n\n# 检查是否已有预处理数据\nif os.path.exists('./data/train.csv') and os.path.exists('./data/val.csv'):\n    print(\"✅ 发现已有预处理数据\")\n    train_df = pd.read_csv('./data/train.csv')\n    val_df = pd.read_csv('./data/val.csv')\n    print(f\"训练集: {len(train_df)} 个样本\")\n    print(f\"验证集: {len(val_df)} 个样本\")\nelse:\n    print(\"开始处理视频数据...\")\n    # 处理视频\n    data_list = process_videos(DATA_DIR, max_videos_per_class=50, max_frames=30)\n    \n    if len(data_list) == 0:\n        print(\"❌ 没有找到有效的视频数据\")\n    else:\n        # 创建DataFrame\n        df = pd.DataFrame(data_list)\n        \n        # 划分训练集和验证集\n        from sklearn.model_selection import train_test_split\n        \n        train_df, val_df = train_test_split(\n            df, test_size=0.2, random_state=42, stratify=df['label']\n        )\n        \n        # 保存CSV文件\n        train_df.to_csv('./data/train.csv', index=False)\n        val_df.to_csv('./data/val.csv', index=False)\n        \n        print(f\"✅ 数据处理完成\")\n        print(f\"训练集: {len(train_df)} 个样本\")\n        print(f\"验证集: {len(val_df)} 个样本\")\n        print(f\"真实视频: {len(df[df['label']==0])} 个\")\n        print(f\"伪造视频: {len(df[df['label']==1])} 个\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:57:27.225220Z","iopub.execute_input":"2025-07-04T06:57:27.225786Z","iopub.status.idle":"2025-07-04T06:57:27.252417Z","shell.execute_reply.started":"2025-07-04T06:57:27.225760Z","shell.execute_reply":"2025-07-04T06:57:27.251725Z"}},"outputs":[{"name":"stdout","text":"检测到Kaggle环境\n开始处理视频数据...\n目录不存在: /kaggle/input/ff-c23/real\n目录不存在: /kaggle/input/ff-c23/fake\n❌ 没有找到有效的视频数据\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 3.数据集类定义 ","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# 第3段：数据集类定义\n# =============================================================================\n\nclass DeepfakeVideoDataset(Dataset):\n    def __init__(self, csv_file, transform=None, max_frames=30):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        self.max_frames = max_frames\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        \n        # 加载帧数据\n        frames = np.load(row['frame_path'])\n        label = row['label']\n        \n        # 确保帧数量\n        if len(frames) < self.max_frames:\n            # 如果帧数不足，重复最后一帧\n            last_frame = frames[-1]\n            padding = np.repeat(last_frame[np.newaxis, :], self.max_frames - len(frames), axis=0)\n            frames = np.concatenate([frames, padding], axis=0)\n        elif len(frames) > self.max_frames:\n            # 如果帧数过多，均匀采样\n            indices = np.linspace(0, len(frames)-1, self.max_frames, dtype=int)\n            frames = frames[indices]\n        \n        # 应用变换\n        if self.transform:\n            transformed_frames = []\n            for frame in frames:\n                transformed_frame = self.transform(frame)\n                transformed_frames.append(transformed_frame)\n            frames = torch.stack(transformed_frames)\n        else:\n            frames = torch.tensor(frames, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n        \n        return frames, torch.tensor(label, dtype=torch.float32)\n\n# 数据转换\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nprint(\"✅ 数据集类定义完成\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.模型定义","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# 第4段：模型定义\n# =============================================================================\n\n# CNN特征提取器\nclass CNNFeatureExtractor(nn.Module):\n    def __init__(self, pretrained=True):\n        super(CNNFeatureExtractor, self).__init__()\n        # 使用ResNet18作为特征提取器\n        self.backbone = models.resnet18(pretrained=pretrained)\n        # 移除最后的分类层\n        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])\n        self.feature_dim = 512\n    \n    def forward(self, x):\n        # x shape: (batch_size, channels, height, width)\n        features = self.backbone(x)\n        features = features.view(features.size(0), -1)  # 展平\n        return features\n\n# 注意力层\nclass AttentionLayer(nn.Module):\n    def __init__(self, hidden_dim):\n        super(AttentionLayer, self).__init__()\n        self.attention = nn.Linear(hidden_dim, 1)\n    \n    def forward(self, x):\n        # x shape: (batch_size, seq_len, hidden_dim)\n        attention_weights = torch.softmax(self.attention(x), dim=1)\n        # 加权求和\n        attended = torch.sum(attention_weights * x, dim=1)\n        return attended, attention_weights\n\n# 标准深度伪造检测模型\nclass DeepfakeDetector(nn.Module):\n    def __init__(self, num_classes=1, hidden_dim=256, num_layers=2, dropout=0.3):\n        super(DeepfakeDetector, self).__init__()\n        \n        # CNN特征提取器\n        self.cnn = CNNFeatureExtractor(pretrained=True)\n        \n        # LSTM层\n        self.lstm = nn.LSTM(\n            input_size=self.cnn.feature_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0,\n            bidirectional=True\n        )\n        \n        # 注意力层\n        self.attention = AttentionLayer(hidden_dim * 2)  # 双向LSTM\n        \n        # 分类器\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, num_classes),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        batch_size, seq_len, channels, height, width = x.size()\n        \n        # 重塑为(batch_size * seq_len, channels, height, width)\n        x = x.view(batch_size * seq_len, channels, height, width)\n        \n        # CNN特征提取\n        features = self.cnn(x)  # (batch_size * seq_len, feature_dim)\n        \n        # 重塑为(batch_size, seq_len, feature_dim)\n        features = features.view(batch_size, seq_len, -1)\n        \n        # LSTM处理\n        lstm_out, _ = self.lstm(features)  # (batch_size, seq_len, hidden_dim * 2)\n        \n        # 注意力机制\n        attended, attention_weights = self.attention(lstm_out)\n        \n        # 分类\n        output = self.classifier(attended)\n        \n        return output.squeeze(), attention_weights\n\n# 轻量级深度伪造检测模型\nclass LightweightDeepfakeDetector(nn.Module):\n    def __init__(self, num_classes=1, hidden_dim=128, dropout=0.3):\n        super(LightweightDeepfakeDetector, self).__init__()\n        \n        # 使用MobileNetV2作为特征提取器\n        self.backbone = models.mobilenet_v2(pretrained=True)\n        self.backbone.classifier = nn.Identity()  # 移除分类层\n        self.feature_dim = 1280\n        \n        # GRU层（比LSTM更轻量）\n        self.gru = nn.GRU(\n            input_size=self.feature_dim,\n            hidden_size=hidden_dim,\n            num_layers=1,\n            batch_first=True,\n            bidirectional=True\n        )\n        \n        # 注意力层\n        self.attention = AttentionLayer(hidden_dim * 2)\n        \n        # 分类器\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, num_classes),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        batch_size, seq_len, channels, height, width = x.size()\n        \n        # 重塑为(batch_size * seq_len, channels, height, width)\n        x = x.view(batch_size * seq_len, channels, height, width)\n        \n        # CNN特征提取\n        features = self.backbone(x)  # (batch_size * seq_len, feature_dim)\n        \n        # 重塑为(batch_size, seq_len, feature_dim)\n        features = features.view(batch_size, seq_len, -1)\n        \n        # GRU处理\n        gru_out, _ = self.gru(features)  # (batch_size, seq_len, hidden_dim * 2)\n        \n        # 注意力机制\n        attended, attention_weights = self.attention(gru_out)\n        \n        # 分类\n        output = self.classifier(attended)\n        \n        return output.squeeze(), attention_weights\n\n# 模型创建函数\ndef create_model(model_type='standard', device='cpu'):\n    if model_type == 'standard':\n        model = DeepfakeDetector()\n    elif model_type == 'lightweight':\n        model = LightweightDeepfakeDetector()\n    else:\n        raise ValueError(f\"不支持的模型类型: {model_type}\")\n    \n    return model.to(device)\n\nprint(\"✅ 模型定义完成\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.训练和验证函数","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# 第5段：训练和验证函数\n# =============================================================================\n\n# 训练函数\ndef train(model, train_loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    \n    progress_bar = tqdm(train_loader, desc='训练')\n    \n    for inputs, labels in progress_bar:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        # 梯度清零\n        optimizer.zero_grad()\n        \n        # 前向传播\n        if isinstance(model.forward(inputs), tuple):\n            outputs, _ = model(inputs)\n        else:\n            outputs = model(inputs)\n        \n        outputs = outputs.squeeze()\n        \n        # 计算损失\n        loss = criterion(outputs, labels)\n        \n        # 反向传播\n        loss.backward()\n        \n        # 梯度裁剪\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        # 优化\n        optimizer.step()\n        \n        # 统计\n        running_loss += loss.item() * inputs.size(0)\n        \n        # 收集预测和目标\n        preds = (outputs > 0.5).float().cpu().numpy()\n        all_predictions.extend(preds)\n        all_targets.extend(labels.cpu().numpy())\n        \n        # 更新进度条\n        progress_bar.set_postfix({'loss': loss.item()})\n    \n    # 计算平均损失和指标\n    epoch_loss = running_loss / len(train_loader.dataset)\n    accuracy = accuracy_score(all_targets, all_predictions)\n    precision = precision_score(all_targets, all_predictions, zero_division=0)\n    recall = recall_score(all_targets, all_predictions, zero_division=0)\n    f1 = f1_score(all_targets, all_predictions, zero_division=0)\n    \n    return epoch_loss, accuracy, precision, recall, f1\n\n# 验证函数\ndef validate(model, val_loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    all_scores = []\n    \n    with torch.no_grad():\n        progress_bar = tqdm(val_loader, desc='验证')\n        \n        for inputs, labels in progress_bar:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            # 前向传播\n            if isinstance(model.forward(inputs), tuple):\n                outputs, _ = model(inputs)\n            else:\n                outputs = model(inputs)\n            \n            outputs = outputs.squeeze()\n            \n            # 计算损失\n            loss = criterion(outputs, labels)\n            \n            # 统计\n            running_loss += loss.item() * inputs.size(0)\n            \n            # 收集预测和目标\n            preds = (outputs > 0.5).float().cpu().numpy()\n            all_predictions.extend(preds)\n            all_targets.extend(labels.cpu().numpy())\n            all_scores.extend(outputs.cpu().numpy())\n            \n            # 更新进度条\n            progress_bar.set_postfix({'loss': loss.item()})\n    \n    # 计算平均损失和指标\n    epoch_loss = running_loss / len(val_loader.dataset)\n    accuracy = accuracy_score(all_targets, all_predictions)\n    precision = precision_score(all_targets, all_predictions, zero_division=0)\n    recall = recall_score(all_targets, all_predictions, zero_division=0)\n    f1 = f1_score(all_targets, all_predictions, zero_division=0)\n    auc_score = roc_auc_score(all_targets, all_scores) if len(set(all_targets)) > 1 else 0.0\n    \n    return epoch_loss, accuracy, precision, recall, f1, auc_score\n\n# 保存检查点函数\ndef save_checkpoint(model, optimizer, epoch, metrics, save_dir, model_type, is_best=False):\n    checkpoint = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'metrics': metrics\n    }\n    \n    # 保存最新检查点\n    latest_path = os.path.join(save_dir, f'{model_type}_model_latest.pth')\n    torch.save(checkpoint, latest_path)\n    \n    # 如果是最佳模型，保存最佳检查点\n    if is_best:\n        best_path = os.path.join(save_dir, f'{model_type}_model_best.pth')\n        torch.save(checkpoint, best_path)\n\n# 绘制训练曲线函数\ndef plot_training_curves(train_losses, val_losses, train_metrics, val_metrics, save_dir):\n    epochs = range(1, len(train_losses) + 1)\n    \n    # 创建子图\n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n    \n    # 损失曲线\n    axes[0, 0].plot(epochs, train_losses, 'b-', label='训练损失')\n    axes[0, 0].plot(epochs, val_losses, 'r-', label='验证损失')\n    axes[0, 0].set_title('损失曲线')\n    axes[0, 0].set_xlabel('Epoch')\n    axes[0, 0].set_ylabel('损失')\n    axes[0, 0].legend()\n    axes[0, 0].grid(True)\n    \n    # 准确率曲线\n    train_acc = [m['accuracy'] for m in train_metrics]\n    val_acc = [m['accuracy'] for m in val_metrics]\n    axes[0, 1].plot(epochs, train_acc, 'b-', label='训练准确率')\n    axes[0, 1].plot(epochs, val_acc, 'r-', label='验证准确率')\n    axes[0, 1].set_title('准确率曲线')\n    axes[0, 1].set_xlabel('Epoch')\n    axes[0, 1].set_ylabel('准确率')\n    axes[0, 1].legend()\n    axes[0, 1].grid(True)\n    \n    # F1分数曲线\n    train_f1 = [m['f1'] for m in train_metrics]\n    val_f1 = [m['f1'] for m in val_metrics]\n    axes[1, 0].plot(epochs, train_f1, 'b-', label='训练F1')\n    axes[1, 0].plot(epochs, val_f1, 'r-', label='验证F1')\n    axes[1, 0].set_title('F1分数曲线')\n    axes[1, 0].set_xlabel('Epoch')\n    axes[1, 0].set_ylabel('F1分数')\n    axes[1, 0].legend()\n    axes[1, 0].grid(True)\n    \n    # AUC曲线\n    val_auc = [m.get('auc', 0) for m in val_metrics]\n    axes[1, 1].plot(epochs, val_auc, 'r-', label='验证AUC')\n    axes[1, 1].set_title('AUC曲线')\n    axes[1, 1].set_xlabel('Epoch')\n    axes[1, 1].set_ylabel('AUC')\n    axes[1, 1].legend()\n    axes[1, 1].grid(True)\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(save_dir, 'training_curves.png'), dpi=300, bbox_inches='tight')\n    plt.close()\n\nprint(\"✅ 训练和验证函数定义完成\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  6.模型训练","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# 第6段：模型训练\n# =============================================================================\n\n# 训练参数\nMODEL_TYPE = 'lightweight'  # 'standard' 或 'lightweight'\nNUM_EPOCHS = 10\nBATCH_SIZE = 8\nLEARNING_RATE = 0.0001\nWEIGHT_DECAY = 1e-5\nNUM_FRAMES = 30\n\nprint(f\"训练参数:\")\nprint(f\"- 模型类型: {MODEL_TYPE}\")\nprint(f\"- 训练轮数: {NUM_EPOCHS}\")\nprint(f\"- 批量大小: {BATCH_SIZE}\")\nprint(f\"- 学习率: {LEARNING_RATE}\")\nprint(f\"- 权重衰减: {WEIGHT_DECAY}\")\nprint(f\"- 帧数: {NUM_FRAMES}\")\n\n# 创建数据集\ntrain_dataset = DeepfakeVideoDataset(\n    csv_file='./data/train.csv',\n    transform=transform,\n    max_frames=NUM_FRAMES\n)\n\nval_dataset = DeepfakeVideoDataset(\n    csv_file='./data/val.csv',\n    transform=transform,\n    max_frames=NUM_FRAMES\n)\n\n# 创建数据加载器\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\nprint(f\"训练集大小: {len(train_dataset)}\")\nprint(f\"验证集大小: {len(val_dataset)}\")\n\n# 创建模型\nmodel = create_model(model_type=MODEL_TYPE, device=device)\nprint(f\"模型类型: {MODEL_TYPE}\")\n\n# 定义损失函数和优化器\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n# 学习率调度器\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n)\n\n# 初始化变量\nstart_epoch = 0\nbest_val_loss = float('inf')\ntrain_losses = []\nval_losses = []\ntrain_metrics = []\nval_metrics = []\n\nprint(\"✅ 训练准备完成\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.执行训练循环","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# 第7段：执行训练循环\n# =============================================================================\n\n# 训练循环\nprint(\"开始训练...\")\nfor epoch in range(start_epoch, NUM_EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n    \n    # 训练\n    train_loss, train_acc, train_prec, train_rec, train_f1 = train(\n        model, train_loader, criterion, optimizer, device\n    )\n    \n    # 验证\n    val_loss, val_acc, val_prec, val_rec, val_f1, val_auc = validate(\n        model, val_loader, criterion, device\n    )\n    \n    # 更新学习率\n    scheduler.step(val_loss)\n    \n    # 记录指标\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    \n    train_metrics.append({\n        'accuracy': train_acc,\n        'precision': train_prec,\n        'recall': train_rec,\n        'f1': train_f1\n    })\n    \n    val_metrics.append({\n        'accuracy': val_acc,\n        'precision': val_prec,\n        'recall': val_rec,\n        'f1': val_f1,\n        'auc': val_auc\n    })\n    \n    # 打印指标\n    print(f\"训练损失: {train_loss:.4f}, 准确率: {train_acc:.4f}, F1: {train_f1:.4f}\")\n    print(f\"验证损失: {val_loss:.4f}, 准确率: {val_acc:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}\")\n    \n    # 检查是否是最佳模型\n    is_best = val_loss < best_val_loss\n    if is_best:\n        best_val_loss = val_loss\n        print(\"🎉 发现更好的模型！\")\n    \n    # 保存检查点\n    metrics = {\n        'train_loss': train_loss,\n        'val_loss': val_loss,\n        'train_acc': train_acc,\n        'val_acc': val_acc,\n        'train_f1': train_f1,\n        'val_f1': val_f1,\n        'val_auc': val_auc\n    }\n    save_checkpoint(model, optimizer, epoch, metrics, './models', MODEL_TYPE, is_best)\n    \n    # 绘制训练曲线\n    plot_training_curves(train_losses, val_losses, train_metrics, val_metrics, './logs')\n\nprint(\"✅ 训练完成！\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8.模型评估","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# 第8段：模型评估\n# =============================================================================\n\n# 评估函数\ndef evaluate_model(model, test_loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    all_scores = []\n    \n    with torch.no_grad():\n        progress_bar = tqdm(test_loader, desc='评估')\n        \n        for inputs, labels in progress_bar:\n            inputs = inputs.to(device)\n            labels = labels.float().to(device)\n            \n            # 前向传播\n            if isinstance(model.forward(inputs), tuple):\n                outputs, _ = model(inputs)\n            else:\n                outputs = model(inputs)\n            \n            outputs = outputs.squeeze()\n            \n            # 计算损失\n            loss = criterion(outputs, labels)\n            \n            # 统计\n            running_loss += loss.item() * inputs.size(0)\n            \n            # 收集预测和目标\n            preds = (outputs > 0.5).float().cpu().numpy()\n            all_predictions.extend(preds)\n            all_targets.extend(labels.cpu().numpy())\n            all_scores.extend(outputs.cpu().numpy())\n            \n            # 更新进度条\n            progress_bar.set_postfix({'loss': loss.item()})\n    \n    # 计算平均损失\n    test_loss = running_loss / len(test_loader.dataset)\n    \n    return test_loss, all_predictions, all_targets, all_scores\n\n# 计算并打印指标\ndef calculate_metrics(predictions, targets, scores):\n    accuracy = accuracy_score(targets, predictions)\n    precision = precision_score(targets, predictions, zero_division=0)\n    recall = recall_score(targets, predictions, zero_division=0)\n    f1 = f1_score(targets, predictions, zero_division=0)\n    auc_score = roc_auc_score(targets, scores) if len(set(targets)) > 1 else 0.0\n    \n    print(f\"准确率: {accuracy:.4f}\")\n    print(f\"精确率: {precision:.4f}\")\n    print(f\"召回率: {recall:.4f}\")\n    print(f\"F1分数: {f1:.4f}\")\n    print(f\"AUC-ROC: {auc_score:.4f}\")\n    \n    # 打印分类报告\n    print(\"\\n分类报告:\")\n    print(classification_report(targets, predictions, target_names=['真实', '伪造']))\n    \n    # 计算混淆矩阵\n    cm = confusion_matrix(targets, predictions)\n    \n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'auc': auc_score,\n        'confusion_matrix': cm\n    }\n\n# 绘制混淆矩阵\ndef plot_confusion_matrix(cm, save_path):\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n                xticklabels=['真实', '伪造'], yticklabels=['真实', '伪造'])\n    plt.xlabel('预测标签')\n    plt.ylabel('真实标签')\n    plt.title('混淆矩阵')\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.show()\n    plt.close()\n\n# 绘制ROC曲线\ndef plot_roc_curve(targets, scores, save_path):\n    fpr, tpr, _ = roc_curve(targets, scores)\n    roc_auc = auc(fpr, tpr)\n    \n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC曲线 (AUC = {roc_auc:.4f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('假阳性率')\n    plt.ylabel('真阳性率')\n    plt.title('接收者操作特征曲线')\n    plt.legend(loc='lower right')\n    plt.grid(True, linestyle='--', alpha=0.7)\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.show()\n    plt.close()\n\nprint(\"✅ 评估函数定义完成\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9.执行模型评估","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# 第9段：执行模型评估\n# =============================================================================\n\n# 加载最佳模型\nbest_model_path = os.path.join('./models', f'{MODEL_TYPE}_model_best.pth')\nif os.path.exists(best_model_path):\n    checkpoint = torch.load(best_model_path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    print(f\"✅ 加载最佳模型: {best_model_path}\")\nelse:\n    print(\"⚠️ 未找到最佳模型，使用当前模型\")\n\n# 创建测试数据加载器（使用验证集作为测试集）\ntest_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\nprint(f\"测试集大小: {len(val_dataset)}\")\n\n# 评估模型\nprint(\"开始评估...\")\ntest_loss, predictions, targets, scores = evaluate_model(model, test_loader, criterion, device)\nprint(f\"测试损失: {test_loss:.4f}\")\n\n# 计算指标\nmetrics = calculate_metrics(predictions, targets, scores)\n\n# 绘制混淆矩阵\ncm_path = os.path.join('./results', 'confusion_matrix.png')\nplot_confusion_matrix(metrics['confusion_matrix'], cm_path)\nprint(f\"✅ 混淆矩阵已保存到 {cm_path}\")\n\n# 绘制ROC曲线\nroc_path = os.path.join('./results', 'roc_curve.png')\nplot_roc_curve(targets, scores, roc_path)\nprint(f\"✅ ROC曲线已保存到 {roc_path}\")\n\n# 保存评估结果\nresults = {\n    'test_loss': test_loss,\n    'accuracy': metrics['accuracy'],\n    'precision': metrics['precision'],\n    'recall': metrics['recall'],\n    'f1': metrics['f1'],\n    'auc': metrics['auc']\n}\n\nresults_df = pd.DataFrame([results])\nresults_df.to_csv(os.path.join('./results', 'evaluation_results.csv'), index=False)\nprint(f\"✅ 评估结果已保存到 ./results/evaluation_results.csv\")\n\nprint(\"\\n🎉 评估完成！\")\nprint(f\"最终结果: 准确率={metrics['accuracy']:.4f}, F1={metrics['f1']:.4f}, AUC={metrics['auc']:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}