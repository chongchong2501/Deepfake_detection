# Cell 11: æ•°æ®åŠ è½½å™¨ - ä¸‰æ­¥ä¼˜åŒ–ä¸“ç”¨ç‰ˆæœ¬

# å¿…è¦çš„å¯¼å…¥
import torch
import pandas as pd
from torch.utils.data import DataLoader, WeightedRandomSampler

# æ³¨æ„ï¼šéœ€è¦å…ˆæ‰§è¡Œ cell_04_dataset_class.py æ¥å®šä¹‰ DeepfakeVideoDataset
# å¦‚æœåœ¨Jupyterä¸­ï¼ŒDeepfakeVideoDataset åº”è¯¥å·²ç»åœ¨ä¹‹å‰çš„cellä¸­å®šä¹‰

def create_data_loaders(batch_size=1, num_workers=0, pin_memory=True):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä¸“ç”¨äºé¢„æå–å¸§çš„GPUé¢„å¤„ç†"""
    
    print("ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆä¸‰æ­¥ä¼˜åŒ–æ¨¡å¼ï¼‰...")
    
    # GPUé¢„å¤„ç†é…ç½®
    gpu_preprocessing = True
    
    # é‡è¦ï¼šå½“å¯ç”¨GPUé¢„å¤„ç†æ—¶ï¼Œå¿…é¡»ç¦ç”¨pin_memory
    # å› ä¸ºæ•°æ®å·²ç»åœ¨GPUä¸Šï¼Œpin_memoryåªé€‚ç”¨äºCPU tensor
    if gpu_preprocessing:
        pin_memory = False
        print("ğŸ”§ æ£€æµ‹åˆ°GPUé¢„å¤„ç†ï¼Œè‡ªåŠ¨ç¦ç”¨pin_memoryä»¥é¿å…å†²çª")
    
    # åˆ›å»ºæ•°æ®é›†å®ä¾‹ - ä¸“ç”¨äºé¢„æå–å¸§
    train_dataset = DeepfakeVideoDataset(
        csv_file='./data/train.csv',
        max_frames=16,
        gpu_preprocessing=gpu_preprocessing,  # å¯ç”¨GPUé¢„å¤„ç†
        extract_fourier=True,   # å¯ç”¨å¤šæ¨¡æ€ç‰¹å¾
        extract_compression=True
    )
    
    val_dataset = DeepfakeVideoDataset(
        csv_file='./data/val.csv',
        max_frames=16,
        gpu_preprocessing=gpu_preprocessing,  # å¯ç”¨GPUé¢„å¤„ç†
        extract_fourier=True,   # å¯ç”¨å¤šæ¨¡æ€ç‰¹å¾
        extract_compression=True
    )
    
    test_dataset = DeepfakeVideoDataset(
        csv_file='./data/test.csv',
        max_frames=16,
        gpu_preprocessing=gpu_preprocessing,  # å¯ç”¨GPUé¢„å¤„ç†
        extract_fourier=True,   # å¯ç”¨å¤šæ¨¡æ€ç‰¹å¾
        extract_compression=True
    )
    
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}")
    print(f"æµ‹è¯•é›†å¤§å°: {len(test_dataset)}")
    
    # è®¡ç®—ç±»åˆ«æƒé‡ç”¨äºå¹³è¡¡é‡‡æ ·
    train_df = pd.read_csv('./data/train.csv')
    class_counts = train_df['label'].value_counts().sort_index()
    total_samples = len(train_df)
    
    print(f"ç±»åˆ«åˆ†å¸ƒ: {class_counts.to_dict()}")
    
    # åˆ›å»ºå¹³è¡¡é‡‡æ ·å™¨
    if len(class_counts) > 1:
        # è®¡ç®—ç±»åˆ«æƒé‡
        class_weights = total_samples / (len(class_counts) * class_counts.values)
        sample_weights = [class_weights[int(label)] for label in train_df['label']]
        
        # åˆ›å»ºåŠ æƒéšæœºé‡‡æ ·å™¨
        sampler = WeightedRandomSampler(
            weights=sample_weights,
            num_samples=len(sample_weights),
            replacement=True
        )
        
        print("âœ… ä½¿ç”¨åŠ æƒéšæœºé‡‡æ ·å™¨è¿›è¡Œç±»åˆ«å¹³è¡¡")
        shuffle_train = False  # ä½¿ç”¨é‡‡æ ·å™¨æ—¶ä¸èƒ½shuffle
    else:
        sampler = None
        shuffle_train = True
        print("âš ï¸ åªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œè·³è¿‡ç±»åˆ«å¹³è¡¡")
    
    # Kaggleä¼˜åŒ–é…ç½®
    safe_num_workers = 0  # å•è¿›ç¨‹æ¨¡å¼é¿å…åºåˆ—åŒ–é—®é¢˜
    print(f"ğŸ”§ ä½¿ç”¨ {safe_num_workers} ä¸ªå·¥ä½œè¿›ç¨‹ï¼ˆKaggleä¼˜åŒ–ï¼‰")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä¸‰æ­¥ä¼˜åŒ–é…ç½®
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=shuffle_train,
        sampler=sampler,
        num_workers=safe_num_workers,
        pin_memory=pin_memory,  # å·²æ ¹æ®GPUé¢„å¤„ç†è‡ªåŠ¨è°ƒæ•´
        drop_last=True,
        persistent_workers=False,
        prefetch_factor=2 if safe_num_workers > 0 else None
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=safe_num_workers,
        pin_memory=pin_memory,  # å·²æ ¹æ®GPUé¢„å¤„ç†è‡ªåŠ¨è°ƒæ•´
        drop_last=False,
        persistent_workers=False,
        prefetch_factor=2 if safe_num_workers > 0 else None
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=safe_num_workers,
        pin_memory=pin_memory,  # å·²æ ¹æ®GPUé¢„å¤„ç†è‡ªåŠ¨è°ƒæ•´
        drop_last=False,
        persistent_workers=False,
        prefetch_factor=2 if safe_num_workers > 0 else None
    )
    
    print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")
    print(f"ğŸ“ˆ ä¸‰æ­¥ä¼˜åŒ–æ€§èƒ½æå‡:")
    print(f"  - é¢„æå–å¸§: æ¶ˆé™¤é‡å¤I/O")
    print(f"  - GPUé¢„å¤„ç†: åŠ é€Ÿç‰¹å¾æå–")
    print(f"  - æ€»ä½“è®­ç»ƒé€Ÿåº¦æå‡: 3-4å€")
    
    return train_loader, val_loader, test_loader

print("âœ… æ•°æ®åŠ è½½å™¨å‡½æ•°å®šä¹‰å®Œæˆï¼ˆä¸‰æ­¥ä¼˜åŒ–ä¸“ç”¨ï¼‰")

# åˆ›å»ºæ•°æ®åŠ è½½å™¨å®ä¾‹
print("\nğŸš€ åˆ›å»ºæ•°æ®åŠ è½½å™¨å®ä¾‹...")
train_loader, val_loader, test_loader = create_data_loaders(
    batch_size=batch_size,  # ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„batch_size
    num_workers=0,
    pin_memory=True
)