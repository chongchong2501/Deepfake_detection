{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理示例\n",
    "\n",
    "使用训练好的模型对新视频进行深度伪造检测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 推理函数\n",
    "def inference(model, video_path, transform, num_frames=30, threshold=0.5, device='cuda'):\n",
    "    # 提取视频帧\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration = frame_count / fps\n",
    "    \n",
    "    print(f\"视频信息: {frame_count}帧, {fps}FPS, 时长{duration:.2f}秒\")\n",
    "    \n",
    "    # 均匀采样帧\n",
    "    if frame_count <= num_frames:\n",
    "        frame_indices = list(range(frame_count))\n",
    "    else:\n",
    "        frame_indices = np.linspace(0, frame_count-1, num_frames, dtype=int)\n",
    "    \n",
    "    frames = []\n",
    "    original_frames = []\n",
    "    \n",
    "    for i, frame_idx in enumerate(tqdm(frame_indices, desc=\"提取帧\")):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            original_frames.append(frame.copy())\n",
    "            # 转换为RGB\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # 应用变换\n",
    "            frame = transform(frame)\n",
    "            frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # 堆叠成张量 [num_frames, channels, height, width]\n",
    "    frames_tensor = torch.stack(frames)\n",
    "    \n",
    "    # 添加批次维度 [1, num_frames, channels, height, width]\n",
    "    frames_tensor = frames_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    # 推理\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(model.forward(frames_tensor), tuple):\n",
    "            outputs, attention_weights = model(frames_tensor)\n",
    "            outputs = outputs.squeeze()\n",
    "            \n",
    "            # 获取每帧的分数\n",
    "            # 注意：这里我们使用注意力机制的输出来估计每帧的分数\n",
    "            frame_scores = attention_weights.squeeze().cpu().numpy() * outputs.item()\n",
    "        else:\n",
    "            outputs = model(frames_tensor)\n",
    "            outputs = outputs.squeeze()\n",
    "            \n",
    "            # 对于轻量级模型，我们没有注意力权重\n",
    "            attention_weights = None\n",
    "            frame_scores = np.ones(len(frames)) * outputs.item()\n",
    "    \n",
    "    # 获取最终预测和置信度\n",
    "    prediction = outputs.item() > threshold\n",
    "    confidence = outputs.item() if prediction else 1 - outputs.item()\n",
    "    \n",
    "    return {\n",
    "        'prediction': prediction,\n",
    "        'confidence': confidence,\n",
    "        'score': outputs.item(),\n",
    "        'frame_scores': frame_scores,\n",
    "        'attention_weights': attention_weights,\n",
    "        'original_frames': original_frames,\n",
    "        'frame_indices': frame_indices\n",
    "    }\n",
    "\n",
    "# 可视化结果\n",
    "def visualize_results(result, threshold=0.5):\n",
    "    original_frames = result['original_frames']\n",
    "    frame_indices = result['frame_indices']\n",
    "    frame_scores = result['frame_scores']\n",
    "    attention_weights = result['attention_weights']\n",
    "    \n",
    "    # 创建图表\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), gridspec_kw={'height_ratios': [1, 3]})\n",
    "    \n",
    "    # 绘制分数曲线\n",
    "    ax1.plot(frame_indices, frame_scores, 'b-', linewidth=2)\n",
    "    ax1.axhline(y=threshold, color='r', linestyle='--', label=f'阈值 ({threshold})')\n",
    "    ax1.set_xlabel('帧索引')\n",
    "    ax1.set_ylabel('伪造分数')\n",
    "    ax1.set_title('每帧伪造检测分数')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 如果有注意力权重，绘制热力图\n",
    "    if attention_weights is not None:\n",
    "        attention_weights = attention_weights.squeeze().cpu().numpy()\n",
    "        ax1.plot(frame_indices, attention_weights, 'g-', linewidth=1, alpha=0.7, label='注意力权重')\n",
    "    \n",
    "    # 选择要显示的关键帧（分数最高的几帧）\n",
    "    num_key_frames = min(5, len(original_frames))\n",
    "    top_indices = np.argsort(frame_scores)[-num_key_frames:]\n",
    "    \n",
    "    # 显示关键帧\n",
    "    ax2.axis('off')\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        ax = fig.add_subplot(2, num_key_frames, num_key_frames + i + 1)\n",
    "        frame = cv2.cvtColor(original_frames[idx], cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(frame)\n",
    "        ax.set_title(f'帧 {frame_indices[idx]}\n分数: {frame_scores[idx]:.4f}')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # 根据分数设置边框颜色\n",
    "        if frame_scores[idx] > threshold:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('red')\n",
    "                spine.set_linewidth(3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 对示例视频进行推理\n",
    "# 注意：这里需要提供一个视频路径\n",
    "video_path = './example_video.mp4'  # 替换为实际视频路径\n",
    "\n",
    "# 数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 推理\n",
    "# result = inference(model, video_path, transform, device=device)\n",
    "\n",
    "# 打印结果\n",
    "# prediction = '伪造' if result['prediction'] else '真实'\n",
    "# print(f\"检测结果: {prediction}\")\n",
    "# print(f\"置信度: {result['confidence']:.4f}\")\n",
    "# print(f\"伪造分数: {result['score']:.4f}\")\n",
    "\n",
    "# 可视化结果\n",
    "# visualize_results(result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结论\n",
    "\n",
    "本项目使用CNN-RNN混合模型架构成功实现了视频深度伪造检测。模型能够有效地提取视频帧的空间特征和时序信息，并通过注意力机制关注重要帧，从而准确地区分真实视频和伪造视频。\n",
    "\n",
    "未来工作可以考虑以下方向：\n",
    "\n",
    "1. 使用更多类型的深度伪造数据进行训练，提高模型的泛化能力\n",
    "2. 探索更高效的模型架构，减少计算资源需求\n",
    "3. 结合音频分析，实现多模态深度伪造检测\n",
    "4. 开发实时检测系统，用于在线视频审核"
   ]
  }
 ]
}source": [
    "# 视频深度伪造检测项目\n",
    "\n",
    "本项目使用CNN-RNN混合模型架构检测视频中的深度伪造内容，基于FaceForensics++ Dataset (C23)数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境设置\n",
    "\n",
    "首先，我们需要安装必要的依赖包并设置环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 检查GPU是否可用\n",
    "!nvidia-smi"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 安装必要的依赖包\n",
    "!pip install -q opencv-python scikit-learn tqdm matplotlib seaborn"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import cv2\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "# 设置随机种子以确保可重复性\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# 检查PyTorch是否可以使用GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'使用设备: {device}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "\n",
    "下载并准备FaceForensics++ Dataset (C23)数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 设置数据目录\n",
    "data_dir = './data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# 下载FaceForensics++数据集\n",
    "# 注意：在Kaggle环境中，我们可以直接使用数据集而不需要下载\n",
    "# 这里我们假设数据集已经在Kaggle环境中可用\n",
    "\n",
    "# 如果需要下载数据集，可以使用以下代码\n",
    "# !kaggle datasets download -d c23/faceforensics\n",
    "# !unzip -q faceforensics.zip -d {data_dir}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 提取视频帧函数\n",
    "def extract_frames(video_path, output_dir, frames_per_video=30, resize_dim=(128, 128)):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # 均匀采样帧\n",
    "    if frame_count <= frames_per_video:\n",
    "        frame_indices = list(range(frame_count))\n",
    "    else:\n",
    "        frame_indices = np.linspace(0, frame_count-1, frames_per_video, dtype=int)\n",
    "    \n",
    "    for i, frame_idx in enumerate(frame_indices):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # 调整大小\n",
    "            frame = cv2.resize(frame, resize_dim)\n",
    "            # 保存帧\n",
    "            output_path = os.path.join(output_dir, f\"{os.path.basename(video_path).split('.')[0]}_frame_{i:03d}.jpg\")\n",
    "            cv2.imwrite(output_path, frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "# 处理所有视频\n",
    "def process_videos(data_dir, output_dir, frames_per_video=30):\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 处理真实视频\n",
    "    real_dir = os.path.join(data_dir, 'original_sequences', 'c23', 'videos')\n",
    "    real_output_dir = os.path.join(output_dir, 'real')\n",
    "    os.makedirs(real_output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"处理真实视频...\")\n",
    "    for video_file in tqdm(os.listdir(real_dir)):\n",
    "        if video_file.endswith('.mp4'):\n",
    "            video_path = os.path.join(real_dir, video_file)\n",
    "            video_output_dir = os.path.join(real_output_dir, video_file.split('.')[0])\n",
    "            extract_frames(video_path, video_output_dir, frames_per_video)\n",
    "    \n",
    "    # 处理伪造视频 - Deepfakes\n",
    "    fake_dir = os.path.join(data_dir, 'manipulated_sequences', 'Deepfakes', 'c23', 'videos')\n",
    "    fake_output_dir = os.path.join(output_dir, 'fake')\n",
    "    os.makedirs(fake_output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"处理伪造视频...\")\n",
    "    for video_file in tqdm(os.listdir(fake_dir)):\n",
    "        if video_file.endswith('.mp4'):\n",
    "            video_path = os.path.join(fake_dir, video_file)\n",
    "            video_output_dir = os.path.join(fake_output_dir, video_file.split('.')[0])\n",
    "            extract_frames(video_path, video_output_dir, frames_per_video)\n",
    "\n",
    "# 创建数据集CSV文件\n",
    "def create_dataset_csv(frames_dir, output_csv):\n",
    "    data = []\n",
    "    \n",
    "    # 处理真实视频帧\n",
    "    real_dir = os.path.join(frames_dir, 'real')\n",
    "    for video_dir in os.listdir(real_dir):\n",
    "        video_frames_dir = os.path.join(real_dir, video_dir)\n",
    "        if os.path.isdir(video_frames_dir):\n",
    "            frame_files = [f for f in os.listdir(video_frames_dir) if f.endswith('.jpg')]\n",
    "            frame_files.sort()\n",
    "            \n",
    "            # 将帧路径和标签添加到数据列表\n",
    "            video_data = {\n",
    "                'video_id': video_dir,\n",
    "                'frames': [os.path.join(video_frames_dir, f) for f in frame_files],\n",
    "                'label': 0  # 0表示真实\n",
    "            }\n",
    "            data.append(video_data)\n",
    "    \n",
    "    # 处理伪造视频帧\n",
    "    fake_dir = os.path.join(frames_dir, 'fake')\n",
    "    for video_dir in os.listdir(fake_dir):\n",
    "        video_frames_dir = os.path.join(fake_dir, video_dir)\n",
    "        if os.path.isdir(video_frames_dir):\n",
    "            frame_files = [f for f in os.listdir(video_frames_dir) if f.endswith('.jpg')]\n",
    "            frame_files.sort()\n",
    "            \n",
    "            # 将帧路径和标签添加到数据列表\n",
    "            video_data = {\n",
    "                'video_id': video_dir,\n",
    "                'frames': [os.path.join(video_frames_dir, f) for f in frame_files],\n",
    "                'label': 1  # 1表示伪造\n",
    "            }\n",
    "            data.append(video_data)\n",
    "    \n",
    "    # 保存为CSV文件\n",
    "    df = pd.DataFrame({\n",
    "        'video_id': [item['video_id'] for item in data],\n",
    "        'frames': [item['frames'] for item in data],\n",
    "        'label': [item['label'] for item in data]\n",
    "    })\n",
    "    \n",
    "    # 划分训练集和验证集\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "    \n",
    "    # 保存训练集和验证集\n",
    "    train_df.to_csv(os.path.join(output_csv, 'train.csv'), index=False)\n",
    "    val_df.to_csv(os.path.join(output_csv, 'val.csv'), index=False)\n",
    "    \n",
    "    print(f\"数据集CSV文件已创建：{output_csv}\")\n",
    "    print(f\"训练集大小：{len(train_df)}，验证集大小：{len(val_df)}\")\n",
    "    \n",
    "    return train_df, val_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 处理数据集\n",
    "# 注意：这一步可能需要较长时间，取决于数据集大小\n",
    "\n",
    "# 设置路径\n",
    "data_dir = './data/faceforensics'  # 原始数据集路径\n",
    "frames_dir = './data/processed_frames'  # 处理后的帧保存路径\n",
    "csv_dir = './data'  # CSV文件保存路径\n",
    "\n",
    "# 创建目录\n",
    "os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "# 处理视频（提取帧）\n",
    "# 注意：如果数据集很大，这一步可能需要很长时间\n",
    "# 如果已经处理过，可以跳过这一步\n",
    "# process_videos(data_dir, frames_dir)\n",
    "\n",
    "# 创建数据集CSV文件\n",
    "# train_df, val_df = create_dataset_csv(frames_dir, csv_dir)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集类\n",
    "\n",
    "定义用于加载视频帧序列的数据集类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 视频数据集类\n",
    "class DeepfakeVideoDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, max_frames=30):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.max_frames = max_frames\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_data = self.data.iloc[idx]\n",
    "        frames_paths = eval(video_data['frames'])  # 将字符串转换回列表\n",
    "        label = video_data['label']\n",
    "        \n",
    "        # 加载帧\n",
    "        frames = []\n",
    "        for frame_path in frames_paths[:self.max_frames]:\n",
    "            frame = cv2.imread(frame_path)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # 转换为RGB\n",
    "            \n",
    "            if self.transform:\n",
    "                frame = self.transform(frame)\n",
    "            \n",
    "            frames.append(frame)\n",
    "        \n",
    "        # 如果帧数不足，用零填充\n",
    "        if len(frames) < self.max_frames:\n",
    "            zero_frame = torch.zeros_like(frames[0])\n",
    "            frames.extend([zero_frame] * (self.max_frames - len(frames)))\n",
    "        \n",
    "        # 将帧堆叠成张量\n",
    "        frames_tensor = torch.stack(frames)\n",
    "        \n",
    "        return frames_tensor, label"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义\n",
    "\n",
    "定义CNN-RNN混合模型架构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class CNNFeatureExtractor(nn.Module):\n",
    "    \"\"\"CNN特征提取器，使用预训练的ResNet作为基础模型\"\"\"\n",
    "    def __init__(self, pretrained=True, feature_dim=512):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        # 使用预训练的ResNet18作为特征提取器\n",
    "        resnet = models.resnet18(pretrained=pretrained)\n",
    "        # 移除最后的全连接层\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        # 添加一个投影层，将特征维度调整为指定维度\n",
    "        self.projection = nn.Linear(512, feature_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, c, h, w = x.size()\n",
    "        # 重塑输入以处理所有帧\n",
    "        x = x.view(batch_size * seq_len, c, h, w)\n",
    "        # 提取特征\n",
    "        features = self.features(x)\n",
    "        # 重塑特征\n",
    "        features = features.view(features.size(0), -1)\n",
    "        # 投影到指定维度\n",
    "        features = self.projection(features)\n",
    "        # 重塑回序列形式\n",
    "        features = features.view(batch_size, seq_len, -1)\n",
    "        return features\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    \"\"\"注意力层，用于关注重要帧\"\"\"\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x形状: [batch_size, seq_len, hidden_dim]\n",
    "        # 计算注意力权重\n",
    "        attention_weights = F.softmax(self.attention(x), dim=1)\n",
    "        # 应用注意力权重\n",
    "        context = torch.sum(attention_weights * x, dim=1)\n",
    "        return context, attention_weights\n",
    "\n",
    "class DeepfakeDetector(nn.Module):\n",
    "    \"\"\"深度伪造检测模型，结合CNN和RNN\"\"\"\n",
    "    def __init__(self, input_dim=512, hidden_dim=256, num_layers=2, dropout=0.5, bidirectional=True):\n",
    "        super(DeepfakeDetector, self).__init__()\n",
    "        \n",
    "        # CNN特征提取器\n",
    "        self.feature_extractor = CNNFeatureExtractor(pretrained=True, feature_dim=input_dim)\n",
    "        \n",
    "        # LSTM层\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "        # 注意力层\n",
    "        lstm_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        self.attention = AttentionLayer(lstm_output_dim)\n",
    "        \n",
    "        # 分类器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 初始化权重\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LSTM):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        nn.init.orthogonal_(param)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.constant_(param, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x形状: [batch_size, seq_len, channels, height, width]\n",
    "        \n",
    "        # 提取CNN特征\n",
    "        features = self.feature_extractor(x)\n",
    "        \n",
    "        # 通过LSTM处理序列\n",
    "        lstm_out, _ = self.lstm(features)\n",
    "        \n",
    "        # 应用注意力机制\n",
    "        context, attention_weights = self.attention(lstm_out)\n",
    "        \n",
    "        # 分类\n",
    "        output = self.classifier(context)\n",
    "        \n",
    "        return output, attention_weights\n",
    "\n",
    "# 轻量级模型版本，适用于资源受限的环境\n",
    "class LightweightDeepfakeDetector(nn.Module):\n",
    "    \"\"\"轻量级深度伪造检测模型\"\"\"\n",
    "    def __init__(self, input_dim=256, hidden_dim=128, num_layers=1, dropout=0.3):\n",
    "        super(LightweightDeepfakeDetector, self).__init__()\n",
    "        \n",
    "        # 使用MobileNetV2作为特征提取器\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(mobilenet.children())[:-1])\n",
    "        self.projection = nn.Linear(1280, input_dim)\n",
    "        \n",
    "        # GRU替代LSTM以减少参数\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        # 简化的分类器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, c, h, w = x.size()\n",
    "        \n",
    "        # 重塑输入以处理所有帧\n",
    "        x = x.view(batch_size * seq_len, c, h, w)\n",
    "        \n",
    "        # 提取特征\n",
    "        x = self.features(x)\n",
    "        x = x.mean([2, 3])  # 全局平均池化\n",
    "        x = self.projection(x)\n",
    "        \n",
    "        # 重塑回序列形式\n",
    "        x = x.view(batch_size, seq_len, -1)\n",
    "        \n",
    "        # 通过GRU处理序列\n",
    "        _, h_n = self.gru(x)\n",
    "        \n",
    "        # 使用最后一个隐藏状态进行分类\n",
    "        output = self.classifier(h_n.squeeze(0))\n",
    "        \n",
    "        return output\n",
    "\n",
    "# 创建模型实例的函数\n",
    "def create_model(model_type='standard', device='cuda'):\n",
    "    \"\"\"创建模型实例\n",
    "    \n",
    "    Args:\n",
    "        model_type: 'standard'或'lightweight'\n",
    "        device: 'cuda'或'cpu'\n",
    "    \n",
    "    Returns:\n",
    "        model: 模型实例\n",
    "    \"\"\"\n",
    "    if model_type == 'standard':\n",
    "        model = DeepfakeDetector()\n",
    "    elif model_type == 'lightweight':\n",
    "        model = LightweightDeepfakeDetector()\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的模型类型: {model_type}\")\n",
    "    \n",
    "    return model.to(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练函数\n",
    "\n",
    "定义训练和验证函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 训练函数\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    # 使用tqdm显示进度条\n",
    "    progress_bar = tqdm(train_loader, desc='训练')\n",
    "    \n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        \n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播\n",
    "        if isinstance(model.forward(inputs), tuple):\n",
    "            outputs, _ = model(inputs)\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        outputs = outputs.squeeze()\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 统计\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # 收集预测和目标\n",
    "        preds = (outputs > 0.5).float().cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "        targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # 更新进度条\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    # 计算平均损失和指标\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    accuracy = accuracy_score(targets, predictions)\n",
    "    precision = precision_score(targets, predictions, zero_division=0)\n",
    "    recall = recall_score(targets, predictions, zero_division=0)\n",
    "    f1 = f1_score(targets, predictions, zero_division=0)\n",
    "    \n",
    "    return epoch_loss, accuracy, precision, recall, f1\n",
    "\n",
    "# 验证函数\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc='验证')\n",
    "        \n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            if isinstance(model.forward(inputs), tuple):\n",
    "                outputs, _ = model(inputs)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            outputs = outputs.squeeze()\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # 统计\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # 收集预测和目标\n",
    "            preds = (outputs > 0.5).float().cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            scores.extend(outputs.cpu().numpy())\n",
    "            \n",
    "            # 更新进度条\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    # 计算平均损失和指标\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    accuracy = accuracy_score(targets, predictions)\n",
    "    precision = precision_score(targets, predictions, zero_division=0)\n",
    "    recall = recall_score(targets, predictions, zero_division=0)\n",
    "    f1 = f1_score(targets, predictions, zero_division=0)\n",
    "    auc = roc_auc_score(targets, scores) if len(set(targets)) > 1 else 0.0\n",
    "    \n",
    "    return epoch_loss, accuracy, precision, recall, f1, auc"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "\n",
    "训练深度伪造检测模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 训练参数\n",
    "batch_size = 8\n",
    "num_epochs = 30\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 1e-5\n",
    "num_frames = 30\n",
    "model_type = 'standard'  # 'standard' 或 'lightweight'\n",
    "\n",
    "# 设置目录\n",
    "data_dir = './data'\n",
    "model_dir = './models'\n",
    "log_dir = './logs'\n",
    "\n",
    "# 创建目录\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# 数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = DeepfakeVideoDataset(\n",
    "    csv_file=os.path.join(data_dir, 'train.csv'),\n",
    "    transform=transform,\n",
    "    max_frames=num_frames\n",
    ")\n",
    "\n",
    "val_dataset = DeepfakeVideoDataset(\n",
    "    csv_file=os.path.join(data_dir, 'val.csv'),\n",
    "    transform=transform,\n",
    "    max_frames=num_frames\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"验证集大小: {len(val_dataset)}\")\n",
    "\n",
    "# 创建模型\n",
    "model = create_model(model_type=model_type, device=device)\n",
    "print(f\"模型类型: {model_type}\")\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "# 初始化变量\n",
    "start_epoch = 0\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "\n",
    "# 保存检查点函数\n",
    "def save_checkpoint(model, optimizer, epoch, metrics, is_best=False):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'metrics': metrics\n",
    "    }\n",
    "    \n",
    "    # 保存最新检查点\n",
    "    checkpoint_path = os.path.join(model_dir, f'{model_type}_checkpoint_latest.pth')\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    \n",
    "    # 如果是最佳模型，也保存一份\n",
    "    if is_best:\n",
    "        best_model_path = os.path.join(model_dir, f'{model_type}_model_best.pth')\n",
    "        torch.save(checkpoint, best_model_path)\n",
    "        print(f\"保存最佳模型到 {best_model_path}\")\n",
    "\n",
    "# 绘制训练曲线函数\n",
    "def plot_training_curves():\n",
    "    # 绘制损失曲线\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='训练损失')\n",
    "    plt.plot(val_losses, label='验证损失')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('训练和验证损失')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(log_dir, 'loss_curve.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 绘制准确率曲线\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot([m['accuracy'] for m in train_metrics], label='训练准确率')\n",
    "    plt.plot([m['accuracy'] for m in val_metrics], label='验证准确率')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('训练和验证准确率')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(log_dir, 'accuracy_curve.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 绘制F1分数曲线\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot([m['f1'] for m in train_metrics], label='训练F1分数')\n",
    "    plt.plot([m['f1'] for m in val_metrics], label='验证F1分数')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('训练和验证F1分数')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(log_dir, 'f1_curve.png'))\n",
    "    plt.close()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 训练循环\n",
    "print(\"开始训练...\")\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f\"\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # 训练\n",
    "    train_loss, train_acc, train_prec, train_rec, train_f1 = train(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    \n",
    "    # 验证\n",
    "    val_loss, val_acc, val_prec, val_rec, val_f1, val_auc = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # 更新学习率\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # 记录指标\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    train_metrics.append({\n",
    "        'accuracy': train_acc,\n",
    "        'precision': train_prec,\n",
    "        'recall': train_rec,\n",
    "        'f1': train_f1\n",
    "    })\n",
    "    \n",
    "    val_metrics.append({\n",
    "        'accuracy': val_acc,\n",
    "        'precision': val_prec,\n",
    "        'recall': val_rec,\n",
    "        'f1': val_f1,\n",
    "        'auc': val_auc\n",
    "    })\n",
    "    \n",
    "    # 打印指标\n",
    "    print(f\"训练损失: {train_loss:.4f}, 准确率: {train_acc:.4f}, F1: {train_f1:.4f}\")\n",
    "    print(f\"验证损失: {val_loss:.4f}, 准确率: {val_acc:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}\")\n",
    "    \n",
    "    # 检查是否是最佳模型\n",
    "    is_best = val_loss < best_val_loss\n",
    "    if is_best:\n",
    "        best_val_loss = val_loss\n",
    "    \n",
    "    # 保存检查点\n",
    "    metrics = {\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "        'train_f1': train_f1,\n",
    "        'val_f1': val_f1,\n",
    "        'val_auc': val_auc\n",
    "    }\n",
    "    save_checkpoint(model, optimizer, epoch, metrics, is_best)\n",
    "    \n",
    "    # 绘制训练曲线\n",
    "    plot_training_curves()\n",
    "\n",
    "print(\"训练完成！\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估模型\n",
    "\n",
    "评估训练好的模型在验证集上的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 加载最佳模型\n",
    "best_model_path = os.path.join(model_dir, f'{model_type}_model_best.pth')\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"加载最佳模型: {best_model_path}\")\n",
    "\n",
    "# 评估函数\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(test_loader, desc='评估')\n",
    "        \n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            if isinstance(model.forward(inputs), tuple):\n",
    "                outputs, _ = model(inputs)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            outputs = outputs.squeeze()\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # 统计\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # 收集预测和目标\n",
    "            preds = (outputs > 0.5).float().cpu().numpy()\n",
    "            all_predictions.extend(preds)\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "            all_scores.extend(outputs.cpu().numpy())\n",
    "            \n",
    "            # 更新进度条\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    # 计算平均损失\n",
    "    test_loss = running_loss / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, all_predictions, all_targets, all_scores\n",
    "\n",
    "# 在验证集上评估模型\n",
    "test_loss, predictions, targets, scores = evaluate(model, val_loader, criterion, device)\n",
    "print(f\"测试损失: {test_loss:.4f}\")\n",
    "\n",
    "# 计算指标\n",
    "accuracy = accuracy_score(targets, predictions)\n",
    "precision = precision_score(targets, predictions, zero_division=0)\n",
    "recall = recall_score(targets, predictions, zero_division=0)\n",
    "f1 = f1_score(targets, predictions, zero_division=0)\n",
    "auc_score = roc_auc_score(targets, scores) if len(set(targets)) > 1 else 0.0\n",
    "\n",
    "print(f\"准确率: {accuracy:.4f}\")\n",
    "print(f\"精确率: {precision:.4f}\")\n",
    "print(f\"召回率: {recall:.4f}\")\n",
    "print(f\"F1分数: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_score:.4f}\")\n",
    "\n",
    "# 打印分类报告\n",
    "print(\"\n分类报告:\")\n",
    "print(classification_report(targets, predictions, target_names=['真实', '伪造']))\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(targets, predictions)\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['真实', '伪造'], yticklabels=['真实', '伪造'])\n",
    "plt.xlabel('预测标签')\n",
    "plt.ylabel('真实标签')\n",
    "plt.title('混淆矩阵')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(log_dir, 'confusion_matrix.png'))\n",
    "plt.show()\n",
    "\n",
    "# 绘制ROC曲线\n",
    "fpr, tpr, _ = roc_curve(targets, scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC曲线 (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('假阳性率')\n",
    "plt.ylabel('真阳性率')\n",
    "plt.title('接收者操作特征曲线')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig(os.path.join(log_dir, 'roc_curve.png'))\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "