# Cell 11: æ¨¡å‹åˆå§‹åŒ–å’Œè®­ç»ƒé…ç½® - Kaggle T4 GPUä¼˜åŒ–ç‰ˆæœ¬

import torch.nn as nn

print("ğŸ¤– åˆ›å»ºå’Œé…ç½®æ¨¡å‹...")

# åˆ›å»ºæ¨¡å‹ - ä½¿ç”¨æ›´å¼ºçš„EfficientNet backbone
model = OptimizedDeepfakeDetector(
    backbone='efficientnet_b0',  # ä½¿ç”¨EfficientNet
    hidden_dim=512,
    num_layers=2,
    dropout=0.3,
    use_attention=True
)
if torch.cuda.is_available() and torch.cuda.device_count() > 1:
    print(f"ä½¿ç”¨å¤šGPUè®­ç»ƒ: {torch.cuda.device_count()} GPUs")
    model = nn.DataParallel(model)
model = model.to(device)

# å•GPUé…ç½®
if torch.cuda.is_available():
    torch.cuda.set_per_process_memory_fraction(0.9)
    print("ä½¿ç”¨å•GPUè®­ç»ƒ")

# è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f"æ¨¡å‹æ€»å‚æ•°æ•°é‡: {total_params:,}")
print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}")
print(f"æ¨¡å‹å¤§å°ä¼°è®¡: {total_params * 4 / 1024**2:.1f} MB")

# æŸå¤±å‡½æ•° - ä½¿ç”¨å¹³è¡¡çš„é…ç½®ï¼Œç§»é™¤pos_weightåå‘
criterion = FocalLoss(alpha=0.25, gamma=2.0, pos_weight=None)  # æ›´å¹³è¡¡çš„å‚æ•°
print(f"æŸå¤±å‡½æ•°: FocalLoss (alpha=0.25, gamma=2.0, æ— pos_weightåå‘)")

# ä¼˜åŒ–å™¨ - é™ä½å­¦ä¹ ç‡
base_lr = 0.0001  # é™ä½å­¦ä¹ ç‡
optimizer = optim.AdamW(
    model.parameters(), 
    lr=base_lr,
    weight_decay=0.01
)
print(f"ä¼˜åŒ–å™¨: AdamW (lr={base_lr})")

# å­¦ä¹ ç‡è°ƒåº¦å™¨ - å¢åŠ è®­ç»ƒè½®æ•°
scheduler = torch.optim.lr_scheduler.OneCycleLR(
    optimizer,
    max_lr=base_lr * 10,  # è°ƒæ•´æœ€å¤§å­¦ä¹ ç‡
    epochs=50,  # å¢åŠ è®­ç»ƒè½®æ•°
    steps_per_epoch=len(train_loader),
    pct_start=0.3,
    anneal_strategy='cos'
)
print(f"å­¦ä¹ ç‡è°ƒåº¦å™¨: OneCycleLR (50 epochs)")

# æ—©åœæœºåˆ¶ - å¢åŠ patience
early_stopping = EarlyStopping(patience=15, min_delta=0.001)  # å¢åŠ patience
print(f"æ—©åœæœºåˆ¶: patience=15, min_delta=0.001")

# è®­ç»ƒé…ç½® - ç»Ÿä¸€ä½¿ç”¨FP32æ•°æ®ç±»å‹
scaler = None
print("æ•°æ®ç±»å‹: FP32 (ç¡®ä¿å…¼å®¹æ€§)")

num_epochs = 50  # å¢åŠ è®­ç»ƒè½®æ•°
print(f"è®­ç»ƒè½®æ•°: {num_epochs}")

# æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
print("\nğŸ” æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
try:
    model.eval()
    with torch.no_grad():
        sample_batch = next(iter(train_loader))
        videos, labels = sample_batch
        videos, labels = videos.to(device), labels.to(device)
        
        # å‰å‘ä¼ æ’­ï¼ˆç»Ÿä¸€ä½¿ç”¨FP32ï¼‰
        outputs, attention_weights = model(videos)
        loss = criterion(outputs, labels)
        
        print(f"è¾“å…¥å½¢çŠ¶: {videos.shape}")
        print(f"è¾“å…¥æ•°æ®ç±»å‹: {videos.dtype}")
        print(f"è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
        print(f"æŸå¤±å€¼: {loss.item():.4f}")
        
        # æ˜¾ç¤ºæ¦‚ç‡èŒƒå›´
        probs = torch.sigmoid(outputs)
        print(f"æ¦‚ç‡èŒƒå›´: [{probs.min():.3f}, {probs.max():.3f}]")
        
        print("âœ… æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•æˆåŠŸ")
except Exception as e:
    print(f"âŒ æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
    raise e

print("âœ… æ¨¡å‹é…ç½®å®Œæˆï¼Œå‡†å¤‡å¼€å§‹è®­ç»ƒ")