# Cell 11: æ¨¡å‹åˆå§‹åŒ–å’Œè®­ç»ƒé…ç½® - GPUä¼˜åŒ–ç‰ˆæœ¬

print("ğŸ¤– åˆ›å»ºå’Œé…ç½®é«˜æ€§èƒ½æ¨¡å‹...")

# å¯ç”¨GPUä¼˜åŒ–è®¾ç½®
if torch.cuda.is_available():
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    print("âœ… å¯ç”¨CUDNNä¼˜åŒ–")

# åˆ›å»ºæ¨¡å‹ - é’ˆå¯¹T4*2 GPUæ·±åº¦ä¼˜åŒ–
model = OptimizedDeepfakeDetector(
    backbone='resnet50',  # ä½¿ç”¨ResNet50ä»¥å……åˆ†åˆ©ç”¨T4*2 GPUæ€§èƒ½
    hidden_dim=768,      # å¢åŠ éšè—å±‚ç»´åº¦ä»¥å……åˆ†åˆ©ç”¨GPUè®¡ç®—èƒ½åŠ›
    num_layers=3,        # å¢åŠ LSTMå±‚æ•°æå‡æ¨¡å‹å®¹é‡
    dropout=0.4,         # é€‚å½“å¢åŠ dropouté˜²æ­¢è¿‡æ‹Ÿåˆ
    use_attention=True
).to(device)

# é«˜æ•ˆå¤šGPUå¹¶è¡Œç­–ç•¥ - å……åˆ†åˆ©ç”¨T4*2é…ç½®
gpu_count = torch.cuda.device_count()
if gpu_count > 1:
    print(f"ğŸš€ æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUï¼Œå¯ç”¨é«˜æ€§èƒ½å¹¶è¡Œè®­ç»ƒ")
    print(f"GPUä¿¡æ¯: {[torch.cuda.get_device_name(i) for i in range(gpu_count)]}")
    
    # ä½¿ç”¨DataParallelè¿›è¡Œæ¨¡å‹å¹¶è¡Œ
    model = nn.DataParallel(model)
    
    # è®¾ç½®GPUå†…å­˜åˆ†é…ç­–ç•¥
    torch.cuda.set_per_process_memory_fraction(0.95)  # ä½¿ç”¨95%æ˜¾å­˜
    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    print(f"ğŸ’¾ GPUå†…å­˜åˆ†é…: 95% ({total_memory*0.95:.1f}GB per GPU)")
else:
    print("ä½¿ç”¨å•GPUè®­ç»ƒ")
    if torch.cuda.is_available():
        torch.cuda.set_per_process_memory_fraction(0.9)

# è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f"æ¨¡å‹æ€»å‚æ•°æ•°é‡: {total_params:,}")
print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}")
print(f"æ¨¡å‹å¤§å°ä¼°è®¡: {total_params * 4 / 1024**2:.1f} MB")

# é«˜æ€§èƒ½æŸå¤±å‡½æ•° - é’ˆå¯¹å¤§æ‰¹æ¬¡ä¼˜åŒ–
criterion = FocalLoss(alpha=0.25, gamma=2.0)
print(f"æŸå¤±å‡½æ•°: FocalLoss (alpha=0.25, gamma=2.0) - å¤§æ‰¹æ¬¡ä¼˜åŒ–")

# é«˜æ•ˆä¼˜åŒ–å™¨ - é’ˆå¯¹å¤§æ‰¹æ¬¡å’Œå¤šGPUä¼˜åŒ–
base_lr = 0.001
if torch.cuda.device_count() > 1:
    # å¤šGPUæ—¶ä½¿ç”¨çº¿æ€§ç¼©æ”¾å­¦ä¹ ç‡
    scaled_lr = base_lr * torch.cuda.device_count() * (batch_size / 8)
    print(f"ğŸ”¥ å¤šGPUå­¦ä¹ ç‡ç¼©æ”¾: {base_lr} -> {scaled_lr:.6f}")
else:
    scaled_lr = base_lr * (batch_size / 8)  # æ ¹æ®æ‰¹æ¬¡å¤§å°ç¼©æ”¾
    print(f"ğŸ“ˆ æ‰¹æ¬¡å¤§å°å­¦ä¹ ç‡ç¼©æ”¾: {base_lr} -> {scaled_lr:.6f}")

optimizer = optim.AdamW(
    model.parameters(), 
    lr=scaled_lr,
    weight_decay=0.01,
    betas=(0.9, 0.999),
    eps=1e-8,
    amsgrad=True  # å¯ç”¨AMSGradå˜ä½“æå‡ç¨³å®šæ€§
)
print(f"ä¼˜åŒ–å™¨: AdamW (lr={scaled_lr:.6f}, AMSGrad=True)")

# é«˜æ•ˆå­¦ä¹ ç‡è°ƒåº¦å™¨ - æ”¯æŒå¤§æ‰¹æ¬¡è®­ç»ƒ
scheduler = torch.optim.lr_scheduler.OneCycleLR(
    optimizer,
    max_lr=scaled_lr * 10,  # å³°å€¼å­¦ä¹ ç‡
    epochs=25,  # ä½¿ç”¨å®é™…çš„epochæ•°
    steps_per_epoch=len(train_loader),
    pct_start=0.3,  # 30%æ—¶é—´ç”¨äºwarm-up
    anneal_strategy='cos',
    div_factor=10,  # åˆå§‹å­¦ä¹ ç‡ = max_lr / div_factor
    final_div_factor=100  # æœ€ç»ˆå­¦ä¹ ç‡ = max_lr / final_div_factor
)
print(f"å­¦ä¹ ç‡è°ƒåº¦å™¨: OneCycleLR (é«˜æ•ˆå¤§æ‰¹æ¬¡è®­ç»ƒ)")

# æ™ºèƒ½æ—©åœæœºåˆ¶
early_stopping = EarlyStopping(patience=10, min_delta=0.0005)  # å¢åŠ patienceé€‚åº”å¤§æ‰¹æ¬¡
print(f"æ—©åœæœºåˆ¶: patience=10, min_delta=0.0005 (å¤§æ‰¹æ¬¡ä¼˜åŒ–)")

# é«˜æ•ˆæ··åˆç²¾åº¦è®­ç»ƒ
if torch.cuda.is_available():
    scaler = GradScaler(
        init_scale=2.**16,  # æ›´é«˜çš„åˆå§‹ç¼©æ”¾å› å­
        growth_factor=2.0,
        backoff_factor=0.5,
        growth_interval=2000
    )
    print(f"æ··åˆç²¾åº¦è®­ç»ƒ: é«˜æ•ˆé…ç½® (init_scale=65536)")
    print(f"ğŸ¯ é¢„æœŸè®­ç»ƒåŠ é€Ÿ: 1.5-2x (æ··åˆç²¾åº¦ + å¤§æ‰¹æ¬¡ + å¤šGPU)")
else:
    scaler = None
    print("CPUæ¨¡å¼ï¼Œä¸ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")

# è®­ç»ƒé…ç½® - é’ˆå¯¹T4*2 GPUå’Œæ›´å¤§æ•°æ®é›†ä¼˜åŒ–
num_epochs = 25  # å¢åŠ è®­ç»ƒè½®æ•°ä»¥å……åˆ†è®­ç»ƒæ›´å¤§çš„æ¨¡å‹
print(f"è®­ç»ƒè½®æ•°: {num_epochs}")

# æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
print("\nğŸ” æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
try:
    model.eval()
    with torch.no_grad():
        sample_batch = next(iter(train_loader))
        videos, labels = sample_batch
        videos, labels = videos.to(device), labels.to(device)
        
        # å‰å‘ä¼ æ’­
        outputs, attention_weights = model(videos)
        loss = criterion(outputs, labels)
        
        print(f"è¾“å…¥å½¢çŠ¶: {videos.shape}")
        print(f"è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
        print(f"æŸå¤±å€¼: {loss.item():.4f}")
        print(f"LogitsèŒƒå›´: [{outputs.min():.3f}, {outputs.max():.3f}]")
        
        # æ˜¾ç¤ºæ¦‚ç‡èŒƒå›´
        probs = torch.sigmoid(outputs)
        print(f"æ¦‚ç‡èŒƒå›´: [{probs.min():.3f}, {probs.max():.3f}]")
        
        if attention_weights is not None:
            print(f"æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {attention_weights.shape}")
        
        print("âœ… æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•æˆåŠŸ")
except Exception as e:
    print(f"âŒ æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
    raise e

print("âœ… æ¨¡å‹é…ç½®å®Œæˆï¼Œå‡†å¤‡å¼€å§‹è®­ç»ƒ")