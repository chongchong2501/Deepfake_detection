# Cell 14: ç»“æœä¿å­˜å’Œæ€»ç»“

print("ğŸ’¾ ä¿å­˜å®éªŒç»“æœ...")
print("=" * 60)

# å‡†å¤‡ä¿å­˜çš„ç»“æœæ•°æ®
results_summary = {
    'experiment_info': {
        'timestamp': datetime.now().isoformat(),
        'model_architecture': 'OptimizedDeepfakeDetector',
        'backbone': 'resnet18',
        'total_epochs': len(train_history['train_loss']),
        'best_epoch': best_epoch + 1 if 'best_epoch' in locals() else len(train_history['train_loss']),
        'early_stopping': True,
        'mixed_precision': torch.cuda.is_available()
    },
    'dataset_info': {
        'train_samples': len(train_dataset),
        'val_samples': len(val_dataset),
        'test_samples': len(test_dataset),
        'batch_size': batch_size,
        'num_workers': 2
    },
    'training_config': {
        'optimizer': 'AdamW',
        'learning_rate': 1e-4,
        'weight_decay': 1e-4,
        'loss_function': 'FocalLoss',
        'scheduler': 'ReduceLROnPlateau',
        'early_stopping_patience': 5
    },
    'final_metrics': {
        'test_loss': float(eval_results['loss']),
        'accuracy': float(metrics['accuracy']),
        'balanced_accuracy': float(metrics['balanced_accuracy']),
        'precision': float(metrics['precision']),
        'recall': float(metrics['recall']),
        'specificity': float(metrics['specificity']),
        'f1_score': float(metrics['f1']),
        'auc_roc': float(metrics['auc_roc']),
        'auc_pr': float(metrics['auc_pr']),
        'npv': float(metrics['npv'])
    },
    'confusion_matrix': {
        'tn': int(metrics['tn']),
        'fp': int(metrics['fp']),
        'fn': int(metrics['fn']),
        'tp': int(metrics['tp'])
    },
    'performance': {
        'avg_inference_time_ms': float(eval_results['avg_inference_time'] * 1000),
        'total_inference_time_s': float(eval_results['total_inference_time']),
        'samples_per_second': float(len(eval_results['targets']) / eval_results['total_inference_time'])
    },
    'training_history': {
        'train_loss': [float(x) for x in train_history['train_loss']],
        'train_acc': [float(x) for x in train_history['train_acc']],
        'train_auc': [float(x) for x in train_history['train_auc']],
        'val_loss': [float(x) for x in train_history['val_loss']],
        'val_acc': [float(x) for x in train_history['val_acc']],
        'val_auc': [float(x) for x in train_history['val_auc']],
        'learning_rates': [float(x) for x in train_history['lr']]
    },
    'class_specific_metrics': {
        'real_video_accuracy': float(real_accuracy),
        'fake_video_accuracy': float(fake_accuracy),
        'real_samples_count': int(real_samples),
        'fake_samples_count': int(fake_samples)
    }
}

# ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
results_file = './results/experiment_results.json'
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(results_summary, f, indent=2, ensure_ascii=False)

print(f"âœ… å®éªŒç»“æœå·²ä¿å­˜åˆ°: {results_file}")

# ä¿å­˜è®­ç»ƒå†å²åˆ°CSV
history_df = pd.DataFrame(train_history)
history_df.to_csv('./results/training_history.csv', index=False)
print("âœ… è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: ./results/training_history.csv")

# ä¿å­˜é¢„æµ‹ç»“æœ
predictions_df = pd.DataFrame({
    'true_label': eval_results['targets'],
    'predicted_label': eval_results['predictions'],
    'prediction_score': eval_results['scores']
})
predictions_df.to_csv('./results/test_predictions.csv', index=False)
print("âœ… æµ‹è¯•é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: ./results/test_predictions.csv")

# ç”Ÿæˆå®éªŒæŠ¥å‘Š
print("\nğŸ“‹ ç”Ÿæˆå®éªŒæŠ¥å‘Š...")
report = f"""
æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹å®éªŒæŠ¥å‘Š
{'='*50}

å®éªŒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
æ¨¡å‹æ¶æ„: OptimizedDeepfakeDetector (ResNet18 + LSTM + Attention)

æ•°æ®é›†ä¿¡æ¯:
- è®­ç»ƒæ ·æœ¬: {len(train_dataset):,}
- éªŒè¯æ ·æœ¬: {len(val_dataset):,}
- æµ‹è¯•æ ·æœ¬: {len(test_dataset):,}
- æ‰¹æ¬¡å¤§å°: {batch_size}

è®­ç»ƒé…ç½®:
- ä¼˜åŒ–å™¨: AdamW (lr=1e-4, weight_decay=1e-4)
- æŸå¤±å‡½æ•°: Focal Loss (alpha=1, gamma=2)
- å­¦ä¹ ç‡è°ƒåº¦: ReduceLROnPlateau
- æ—©åœæœºåˆ¶: patience=5
- æ··åˆç²¾åº¦è®­ç»ƒ: {'å¯ç”¨' if torch.cuda.is_available() else 'ç¦ç”¨'}

æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡:
- å‡†ç¡®ç‡: {metrics['accuracy']*100:.2f}%
- å¹³è¡¡å‡†ç¡®ç‡: {metrics['balanced_accuracy']*100:.2f}%
- ç²¾ç¡®ç‡: {metrics['precision']:.4f}
- å¬å›ç‡: {metrics['recall']:.4f}
- F1åˆ†æ•°: {metrics['f1']:.4f}
- AUC-ROC: {metrics['auc_roc']:.4f}
- AUC-PR: {metrics['auc_pr']:.4f}

æ··æ·†çŸ©é˜µ:
- çœŸè´Ÿä¾‹ (TN): {metrics['tn']}
- å‡æ­£ä¾‹ (FP): {metrics['fp']}
- å‡è´Ÿä¾‹ (FN): {metrics['fn']}
- çœŸæ­£ä¾‹ (TP): {metrics['tp']}

ç±»åˆ«ç‰¹å®šæ€§èƒ½:
- çœŸå®è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: {real_accuracy*100:.2f}%
- ä¼ªé€ è§†é¢‘æ£€æµ‹å‡†ç¡®ç‡: {fake_accuracy*100:.2f}%

æ¨ç†æ€§èƒ½:
- å¹³å‡æ¨ç†æ—¶é—´: {eval_results['avg_inference_time']*1000:.2f} ms/batch
- å¤„ç†é€Ÿåº¦: {len(eval_results['targets'])/eval_results['total_inference_time']:.1f} samples/s

è®­ç»ƒæ€»ç»“:
- è®­ç»ƒè½®æ•°: {len(train_history['train_loss'])}
- æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {max(train_history['val_acc']):.2f}%
- æœ€ä½³éªŒè¯AUC: {max(train_history['val_auc']):.4f}

æ–‡ä»¶è¾“å‡º:
- æ¨¡å‹æƒé‡: ./models/best_model.pth
- è®­ç»ƒå†å²å›¾: ./results/training_history.png
- æ··æ·†çŸ©é˜µå›¾: ./results/evaluation/confusion_matrix.png
- ROC/PRæ›²çº¿å›¾: ./results/evaluation/roc_pr_curves.png
- åˆ†æ•°åˆ†å¸ƒå›¾: ./results/evaluation/score_distribution.png
- å®éªŒç»“æœ: ./results/experiment_results.json
- è®­ç»ƒå†å²: ./results/training_history.csv
- é¢„æµ‹ç»“æœ: ./results/test_predictions.csv

{'='*50}
å®éªŒå®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

# ä¿å­˜æŠ¥å‘Š
with open('./results/experiment_report.txt', 'w', encoding='utf-8') as f:
    f.write(report)

print("âœ… å®éªŒæŠ¥å‘Šå·²ä¿å­˜åˆ°: ./results/experiment_report.txt")

# æ‰“å°æœ€ç»ˆæ€»ç»“
print("\n" + "="*60)
print("ğŸ‰ æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å®Œæˆï¼")
print("="*60)
print(f"ğŸ“Š æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {metrics['accuracy']*100:.2f}%")
print(f"ğŸ“Š AUC-ROCåˆ†æ•°: {metrics['auc_roc']:.4f}")
print(f"ğŸ“Š F1åˆ†æ•°: {metrics['f1']:.4f}")
print(f"âš¡ æ¨ç†é€Ÿåº¦: {len(eval_results['targets'])/eval_results['total_inference_time']:.1f} samples/s")
print("\nğŸ“ æ‰€æœ‰ç»“æœæ–‡ä»¶å·²ä¿å­˜åˆ° ./results/ ç›®å½•")
print("ğŸ“ æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ° ./models/best_model.pth")
print("\nâœ¨ å®éªŒæˆåŠŸå®Œæˆï¼å¯ä»¥åœ¨Kaggleä¸­æŸ¥çœ‹æ‰€æœ‰ç”Ÿæˆçš„å›¾è¡¨å’Œç»“æœæ–‡ä»¶ã€‚")
print("="*60)

# æ˜¾ç¤ºæ–‡ä»¶ç»“æ„
print("\nğŸ“‚ ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„:")
print("""
./models/
  â””â”€â”€ best_model.pth
./results/
  â”œâ”€â”€ experiment_results.json
  â”œâ”€â”€ experiment_report.txt
  â”œâ”€â”€ training_history.csv
  â”œâ”€â”€ training_history.png
  â”œâ”€â”€ test_predictions.csv
  â””â”€â”€ evaluation/
      â”œâ”€â”€ confusion_matrix.png
      â”œâ”€â”€ roc_pr_curves.png
      â””â”€â”€ score_distribution.png
""")

print("\nğŸš€ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†:")
print("""
# åŠ è½½æ¨¡å‹
model = OptimizedDeepfakeDetector(...)
checkpoint = torch.load('./models/best_model.pth')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# è¿›è¡Œæ¨ç†
with torch.no_grad():
    outputs, attention = model(video_tensor)
    prediction = torch.sigmoid(outputs).cpu().numpy()
""")

print("\nğŸ’¡ æç¤º: åœ¨Kaggleä¸­è¿è¡Œæ—¶ï¼Œå»ºè®®æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰cellï¼Œç¡®ä¿æ•°æ®è·¯å¾„æ­£ç¡®è®¾ç½®ã€‚")