{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10125851,"sourceType":"datasetVersion","datasetId":6248577}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install av","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:53:15.603749Z","iopub.execute_input":"2025-07-06T09:53:15.604009Z","iopub.status.idle":"2025-07-06T09:53:21.017086Z","shell.execute_reply.started":"2025-07-06T09:53:15.603982Z","shell.execute_reply":"2025-07-06T09:53:21.016118Z"}},"outputs":[{"name":"stdout","text":"Collecting av\n  Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\nDownloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: av\nSuccessfully installed av-15.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Cell 1: 导入库和环境设置","metadata":{}},{"cell_type":"code","source":"# Cell 1: 导入库和环境设置\n\n# 修复CUDA多进程问题\nimport multiprocessing as mp\ntry:\n    mp.set_start_method('spawn', force=True)\nexcept RuntimeError:\n    pass  # 如果已经设置过，忽略错误\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport random\nimport warnings\nimport gc\nimport json\nimport time\nimport sys\nfrom pathlib import Path\nfrom datetime import datetime\nwarnings.filterwarnings('ignore')\n\n# PyTorch相关\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as TF\nimport torchvision.models as models\nfrom torchvision.io import read_video\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\nfrom torch.cuda.amp import GradScaler, autocast\n\n# 机器学习指标\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    roc_auc_score, confusion_matrix, classification_report,\n    roc_curve, auc, precision_recall_curve, balanced_accuracy_score\n)\nfrom sklearn.model_selection import train_test_split\n\n# 系统监控和性能分析\nimport psutil\nimport traceback\n\n\n# 视频处理 (PyAV)\ntry:\n    import av\n    PYAV_AVAILABLE = True\n    print(\"✅ PyAV已安装，支持GPU视频处理\")\nexcept ImportError:\n    PYAV_AVAILABLE = False\n    print(\"⚠️ PyAV未安装，视频处理将回退到CPU模式\")\n\n# 数据增强\ntry:\n    import albumentations as A\n    from albumentations.pytorch import ToTensorV2\n    ALBUMENTATIONS_AVAILABLE = True\nexcept ImportError:\n    ALBUMENTATIONS_AVAILABLE = False\n    print(\"警告: albumentations未安装，将使用基础数据增强\")\n\nprint(\"✅ 所有库导入完成\")","metadata":{"_uuid":"f6ebcf0d-d34a-4e53-b9c4-c85254661e41","_cell_guid":"4883bd2d-9463-4607-9e61-df4d76492a78","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-06T09:53:21.018536Z","iopub.execute_input":"2025-07-06T09:53:21.018800Z","iopub.status.idle":"2025-07-06T09:53:31.485053Z","shell.execute_reply.started":"2025-07-06T09:53:21.018775Z","shell.execute_reply":"2025-07-06T09:53:31.484306Z"}},"outputs":[{"name":"stdout","text":"✅ PyAV已安装，支持GPU视频处理\n✅ 所有库导入完成\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Cell 2: 全局配置和工具函数","metadata":{}},{"cell_type":"code","source":"# Cell 2: 全局配置和工具函数 - Kaggle T4 优化版本\n\ndef set_seed(seed=42):\n    \"\"\"设置随机种子确保可重复性\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    # Kaggle环境优化：平衡性能和可重复性\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = True\n\nset_seed(42)\n\n# Kaggle T4 GPU配置\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"使用设备: {device}\")\n\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n    print(f\"GPU型号: {gpu_name}\")\n    print(f\"GPU内存: {gpu_memory:.1f} GB\")\n    \n    # Kaggle T4 GPU优化配置\n    torch.cuda.set_per_process_memory_fraction(0.9)  # 保守内存使用\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.allow_tf32 = True\n    \n    print(\"✅ Kaggle T4 GPU优化配置已启用\")\n\n# 创建必要的目录\nfor dir_name in ['./data', './models', './logs', './results']:\n    os.makedirs(dir_name, exist_ok=True)\n\n# Kaggle环境检测\nIS_KAGGLE = os.path.exists('/kaggle')\nBASE_DATA_DIR = '/kaggle/input/ff-c23/FaceForensics++_C23' if IS_KAGGLE else './FaceForensics++_C23'\n\n# 统一数据类型配置 - 全部使用FP32提升兼容性\nUSE_FP32_ONLY = True  # 强制使用FP32，确保最佳兼容性\nprint(f\"数据类型策略: FP32 (兼容性优先)\")\n\nprint(f\"环境: {'Kaggle' if IS_KAGGLE else '本地'}\")\nprint(f\"数据基础路径: {BASE_DATA_DIR}\")\nprint(\"✅ 环境设置完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:53:31.485737Z","iopub.execute_input":"2025-07-06T09:53:31.486060Z","iopub.status.idle":"2025-07-06T09:53:31.783621Z","shell.execute_reply.started":"2025-07-06T09:53:31.486043Z","shell.execute_reply":"2025-07-06T09:53:31.783076Z"}},"outputs":[{"name":"stdout","text":"使用设备: cuda\nGPU型号: Tesla T4\nGPU内存: 14.7 GB\n✅ GPU性能优化配置已启用\n环境: Kaggle\n数据基础路径: /kaggle/input/ff-c23/FaceForensics++_C23\n✅ 环境设置完成\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Cell 3: 数据处理模块\n","metadata":{}},{"cell_type":"code","source":"# Cell 3: GPU加速数据处理模块\n\ndef extract_frames_gpu_accelerated(video_path, max_frames=16, target_size=(224, 224),\n                                  quality_threshold=20, use_gpu=True):\n    \"\"\"GPU加速的帧提取函数\"\"\"\n    try:\n        # 检查PyAV是否可用\n        if not globals().get('PYAV_AVAILABLE', False):\n            print(f\"PyAV不可用，使用CPU回退处理: {video_path}\")\n            return extract_frames_cpu_fallback(video_path, max_frames, target_size, quality_threshold)\n            \n        # 使用torchvision的GPU加速视频读取\n        if use_gpu and torch.cuda.is_available():\n            device = torch.device('cuda')\n        else:\n            device = torch.device('cpu')\n            \n        # 读取视频（torchvision自动处理解码）\n        try:\n            video_tensor, audio, info = read_video(video_path, pts_unit='sec')\n            # video_tensor shape: (T, H, W, C)\n        except Exception as e:\n            print(f\"GPU视频读取失败，回退到CPU: {e}\")\n            return extract_frames_cpu_fallback(video_path, max_frames, target_size, quality_threshold)\n        \n        if video_tensor.size(0) == 0:\n            return []\n            \n        # 移动到GPU进行处理\n        video_tensor = video_tensor.to(device, non_blocking=True)\n        total_frames = video_tensor.size(0)\n        \n        # 智能帧采样策略\n        if total_frames <= max_frames:\n            frame_indices = torch.arange(0, total_frames, device=device)\n        else:\n            # 均匀采样\n            step = total_frames / max_frames\n            frame_indices = torch.arange(0, total_frames, step, device=device).long()[:max_frames]\n        \n        # 批量提取帧\n        selected_frames = video_tensor[frame_indices]  # (max_frames, H, W, C)\n        \n        # GPU上进行质量检测（使用Sobel算子代替Laplacian）\n        if quality_threshold > 0:\n            # 转换为灰度图进行质量检测（先转换为float类型）\n            gray_frames = selected_frames.float().mean(dim=-1, keepdim=True)  # (T, H, W, 1)\n            gray_frames = gray_frames.permute(0, 3, 1, 2)  # (T, 1, H, W)\n            \n            # 使用Sobel算子计算图像质量\n            sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], \n                                 dtype=torch.float32, device=device).view(1, 1, 3, 3)\n            sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], \n                                 dtype=torch.float32, device=device).view(1, 1, 3, 3)\n            \n            grad_x = F.conv2d(gray_frames, sobel_x, padding=1)\n            grad_y = F.conv2d(gray_frames, sobel_y, padding=1)\n            quality_scores = (grad_x.pow(2) + grad_y.pow(2)).mean(dim=[1, 2, 3])\n            \n            # 过滤低质量帧\n            quality_mask = quality_scores > quality_threshold\n            if quality_mask.sum() > 0:\n                selected_frames = selected_frames[quality_mask]\n            \n        # GPU上进行尺寸调整\n        selected_frames = selected_frames.permute(0, 3, 1, 2).float()  # (T, C, H, W)\n        if selected_frames.size(-1) != target_size[0] or selected_frames.size(-2) != target_size[1]:\n            selected_frames = F.interpolate(selected_frames, size=target_size, \n                                          mode='bilinear', align_corners=False)\n        \n        # 确保帧数足够\n        current_frames = selected_frames.size(0)\n        if current_frames < max_frames:\n            # 重复最后一帧\n            if current_frames > 0:\n                last_frame = selected_frames[-1:].repeat(max_frames - current_frames, 1, 1, 1)\n                selected_frames = torch.cat([selected_frames, last_frame], dim=0)\n            else:\n                # 创建黑色帧\n                selected_frames = torch.zeros(max_frames, 3, target_size[0], target_size[1], \n                                            device=device, dtype=torch.float32)\n        \n        # 限制到最大帧数\n        selected_frames = selected_frames[:max_frames]\n        \n        # 转换回CPU numpy格式（为了兼容现有代码）\n        frames_cpu = selected_frames.permute(0, 2, 3, 1).cpu().numpy().astype(np.uint8)\n        frames_list = [frame for frame in frames_cpu]\n        \n        return frames_list\n        \n    except Exception as e:\n        print(f\"GPU帧提取失败，回退到CPU: {e}\")\n        return extract_frames_cpu_fallback(video_path, max_frames, target_size, quality_threshold)\n\ndef extract_frames_cpu_fallback(video_path, max_frames=16, target_size=(224, 224), quality_threshold=20):\n    \"\"\"CPU回退的帧提取函数\"\"\"\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n\n    if not cap.isOpened():\n        print(f\"无法打开视频: {video_path}\")\n        return frames\n\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    if total_frames == 0:\n        cap.release()\n        return frames\n\n    # 均匀采样策略\n    if total_frames <= max_frames:\n        frame_indices = list(range(0, total_frames, max(1, total_frames // max_frames)))\n    else:\n        step = max(1, total_frames // max_frames)\n        frame_indices = list(range(0, total_frames, step))[:max_frames]\n\n    frame_count = 0\n    for frame_idx in frame_indices:\n        if frame_count >= max_frames:\n            break\n\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n        ret, frame = cap.read()\n\n        if ret:\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            \n            # 质量检测\n            if quality_threshold > 0:\n                gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n                quality = cv2.Laplacian(gray, cv2.CV_64F).var()\n                if quality <= quality_threshold:\n                    continue\n            \n            frame = cv2.resize(frame, target_size)\n            frames.append(frame)\n            frame_count += 1\n\n    cap.release()\n\n    # 如果帧数不足，重复最后一帧\n    while len(frames) < max_frames and len(frames) > 0:\n        frames.append(frames[-1].copy())\n\n    return frames[:max_frames]\n\n# 为了向后兼容，保留原函数名\ndef extract_frames_memory_efficient(video_path, max_frames=16, target_size=(224, 224),\n                                   quality_threshold=20, skip_frames=3):\n    \"\"\"兼容性包装函数，优先使用GPU加速\"\"\"\n    return extract_frames_gpu_accelerated(video_path, max_frames, target_size, quality_threshold)\n\ndef process_videos_simple(base_data_dir, max_videos_per_class=60, max_frames=16):\n    \"\"\"简化的视频处理函数\"\"\"\n    data_list = []\n    fake_methods = ['Deepfakes', 'Face2Face', 'FaceShifter', 'FaceSwap', 'NeuralTextures']\n\n    print(\"开始处理真实视频...\")\n    # 处理真实视频\n    original_dir = os.path.join(base_data_dir, 'original')\n    if os.path.exists(original_dir):\n        video_files = [f for f in os.listdir(original_dir)\n                      if f.endswith(('.mp4', '.avi', '.mov'))]\n        \n        if len(video_files) > max_videos_per_class:\n            video_files = random.sample(video_files, max_videos_per_class)\n\n        print(f\"找到 {len(video_files)} 个真实视频\")\n\n        for video_file in tqdm(video_files, desc=\"处理真实视频\"):\n            try:\n                video_path = os.path.join(original_dir, video_file)\n                frames = extract_frames_memory_efficient(video_path, max_frames)\n                \n                if len(frames) >= max_frames // 2:  # 至少要有一半的帧\n                    data_list.append({\n                        'video_path': video_path,\n                        'frames': frames,\n                        'label': 0,  # 真实视频\n                        'method': 'original'\n                    })\n            except Exception as e:\n                print(f\"处理视频 {video_file} 时出错: {e}\")\n                continue\n\n    # 处理伪造视频\n    print(\"开始处理伪造视频...\")\n    for method in fake_methods:\n        method_dir = os.path.join(base_data_dir, method)\n        if os.path.exists(method_dir):\n            video_files = [f for f in os.listdir(method_dir)\n                          if f.endswith(('.mp4', '.avi', '.mov'))]\n            \n            if len(video_files) > max_videos_per_class:\n                video_files = random.sample(video_files, max_videos_per_class)\n\n            print(f\"处理 {method}: {len(video_files)} 个视频\")\n\n            for video_file in tqdm(video_files, desc=f\"处理{method}\"):\n                try:\n                    video_path = os.path.join(method_dir, video_file)\n                    frames = extract_frames_memory_efficient(video_path, max_frames)\n                    \n                    if len(frames) >= max_frames // 2:\n                        data_list.append({\n                            'video_path': video_path,\n                            'frames': frames,\n                            'label': 1,  # 伪造视频\n                            'method': method\n                        })\n                except Exception as e:\n                    print(f\"处理视频 {video_file} 时出错: {e}\")\n                    continue\n\n    print(f\"\\n✅ 数据处理完成，共处理 {len(data_list)} 个视频\")\n    return data_list\n\ndef create_dataset_split(data_list, test_size=0.2, val_size=0.1):\n    \"\"\"创建数据集划分\"\"\"\n    # 分离真实和伪造数据\n    real_data = [item for item in data_list if item['label'] == 0]\n    fake_data = [item for item in data_list if item['label'] == 1]\n    \n    print(f\"真实视频: {len(real_data)} 个\")\n    print(f\"伪造视频: {len(fake_data)} 个\")\n    \n    # 分别划分真实和伪造数据\n    real_train, real_temp = train_test_split(real_data, test_size=test_size+val_size, random_state=42)\n    real_val, real_test = train_test_split(real_temp, test_size=test_size/(test_size+val_size), random_state=42)\n    \n    fake_train, fake_temp = train_test_split(fake_data, test_size=test_size+val_size, random_state=42)\n    fake_val, fake_test = train_test_split(fake_temp, test_size=test_size/(test_size+val_size), random_state=42)\n    \n    # 合并数据\n    train_data = real_train + fake_train\n    val_data = real_val + fake_val\n    test_data = real_test + fake_test\n    \n    # 打乱数据\n    random.shuffle(train_data)\n    random.shuffle(val_data)\n    random.shuffle(test_data)\n    \n    return train_data, val_data, test_data\n\ndef save_dataset_to_csv(data_list, filename):\n    \"\"\"将数据集保存为CSV文件\"\"\"\n    df_data = []\n    for item in data_list:\n        df_data.append({\n            'video_path': item['video_path'],\n            'label': item['label'],\n            'method': item['method'],\n            'num_frames': len(item['frames'])\n        })\n    \n    df = pd.DataFrame(df_data)\n    df.to_csv(filename, index=False)\n    print(f\"数据集已保存到: {filename}\")\n    return df\n\nprint(\"✅ 数据处理函数定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:53:31.785347Z","iopub.execute_input":"2025-07-06T09:53:31.785530Z","iopub.status.idle":"2025-07-06T09:53:31.812934Z","shell.execute_reply.started":"2025-07-06T09:53:31.785516Z","shell.execute_reply":"2025-07-06T09:53:31.812253Z"}},"outputs":[{"name":"stdout","text":"✅ 数据处理函数定义完成\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Cell 4: 数据集类定义\n","metadata":{}},{"cell_type":"code","source":"# Cell 4: 数据集类定义\n\nclass DeepfakeVideoDataset(Dataset):\n    \"\"\"深度伪造视频数据集类 - Kaggle T4 优化版本\"\"\"\n    \n    def __init__(self, csv_file=None, data_list=None, transform=None, max_frames=16, \n                 gpu_preprocessing=True, cache_frames=False):\n        if csv_file is not None:\n            self.df = pd.read_csv(csv_file)\n            self.data_list = None\n        elif data_list is not None:\n            self.data_list = data_list\n            self.df = None\n        else:\n            raise ValueError(\"必须提供csv_file或data_list\")\n            \n        self.transform = transform\n        self.max_frames = max_frames\n        self.gpu_preprocessing = gpu_preprocessing and torch.cuda.is_available()\n        self.cache_frames = cache_frames\n        \n        # 简化缓存系统 - 仅CPU缓存，避免GPU内存压力\n        self.frame_cache = {} if cache_frames else None\n        self.cache_hits = 0\n        self.cache_misses = 0\n        \n        # GPU预处理的标准化参数 - 统一使用FP32\n        if self.gpu_preprocessing:\n            self.mean = torch.tensor([0.485, 0.456, 0.406], device='cuda', dtype=torch.float32)\n            self.std = torch.tensor([0.229, 0.224, 0.225], device='cuda', dtype=torch.float32)\n            \n        print(f\"🚀 数据集初始化: GPU预处理={'启用' if self.gpu_preprocessing else '禁用'}, \"\n              f\"缓存={'启用' if self.cache_frames else '禁用'}, 数据类型=FP32\")\n    \n    def __len__(self):\n        if self.df is not None:\n            return len(self.df)\n        return len(self.data_list)\n    \n    def __getitem__(self, idx):\n        if self.data_list is not None:\n            # 直接从内存中的数据列表获取\n            item = self.data_list[idx]\n            frames = item['frames']\n            label = item['label']\n            video_path = None\n        else:\n            # 从CSV文件获取路径\n            row = self.df.iloc[idx]\n            video_path = row['video_path']\n            label = row['label']\n            frames = None\n        \n        # 简化的数据处理流程\n        if frames is None:\n            # 检查CPU缓存\n            if self.cache_frames and video_path in self.frame_cache:\n                frames = self.frame_cache[video_path]\n                self.cache_hits += 1\n            else:\n                frames = extract_frames_gpu_accelerated(video_path, self.max_frames, target_size=(224, 224))\n                self.cache_misses += 1\n                # 缓存帧数据\n                if self.cache_frames and len(frames) > 0:\n                    self.frame_cache[video_path] = frames\n        \n        # 确保有足够的帧\n        if len(frames) == 0:\n            frames = [np.zeros((224, 224, 3), dtype=np.uint8) for _ in range(self.max_frames)]\n        \n        while len(frames) < self.max_frames:\n            frames.append(frames[-1].copy() if frames else np.zeros((224, 224, 3), dtype=np.uint8))\n        \n        frames = frames[:self.max_frames]\n        \n        # 统一的数据预处理 - 全部使用FP32\n        if self.transform:\n            frames = [self.transform(frame) for frame in frames]\n            video_tensor = torch.stack(frames)\n        elif self.gpu_preprocessing:\n            # GPU预处理：减少CPU-GPU传输次数\n            frames_array = np.stack(frames)  # (T, H, W, C)\n            video_tensor = torch.from_numpy(frames_array).permute(0, 3, 1, 2).float()  # (T, C, H, W)\n            \n            # 移动到GPU并进行预处理 - 统一使用FP32\n            video_tensor = video_tensor.to('cuda', non_blocking=True, dtype=torch.float32) / 255.0\n            \n            # 标准化\n            video_tensor = (video_tensor - self.mean.view(1, 3, 1, 1)) / self.std.view(1, 3, 1, 1)\n        else:\n            # CPU预处理\n            frames = [torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0 for frame in frames]\n            video_tensor = torch.stack(frames)\n        \n        # 标签处理 - 统一使用FP32\n        label_tensor = torch.tensor(label, dtype=torch.float32)\n        if self.gpu_preprocessing:\n            label_tensor = label_tensor.to('cuda', non_blocking=True)\n        \n        return video_tensor, label_tensor\n    \n    def get_cache_stats(self):\n        \"\"\"获取缓存统计信息\"\"\"\n        total_requests = self.cache_hits + self.cache_misses\n        hit_rate = self.cache_hits / total_requests if total_requests > 0 else 0\n        return {\n            'cache_hits': self.cache_hits,\n            'cache_misses': self.cache_misses,\n            'hit_rate': hit_rate,\n            'cpu_cache_size': len(self.frame_cache) if self.frame_cache else 0\n        }\n\nprint(\"✅ 数据集类定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:53:31.813656Z","iopub.execute_input":"2025-07-06T09:53:31.813908Z","iopub.status.idle":"2025-07-06T09:53:31.840730Z","shell.execute_reply.started":"2025-07-06T09:53:31.813891Z","shell.execute_reply":"2025-07-06T09:53:31.840017Z"}},"outputs":[{"name":"stdout","text":"✅ 数据集类定义完成\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Cell 5: 模型定义","metadata":{}},{"cell_type":"code","source":"# Cell 5: 模型定义\n\nclass OptimizedDeepfakeDetector(nn.Module):\n    \"\"\"优化的深度伪造检测模型\"\"\"\n    \n    def __init__(self, backbone='resnet50', hidden_dim=512, num_layers=2, \n                 dropout=0.3, use_attention=True):\n        super(OptimizedDeepfakeDetector, self).__init__()\n        \n        self.use_attention = use_attention\n        \n        # 特征提取器\n        if backbone == 'resnet50':\n            self.backbone = models.resnet50(pretrained=True)\n            feature_dim = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        elif backbone == 'resnet18':\n            self.backbone = models.resnet18(pretrained=True)\n            feature_dim = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        else:\n            raise ValueError(f\"不支持的backbone: {backbone}\")\n        \n        # 时序建模\n        self.lstm = nn.LSTM(\n            input_size=feature_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0,\n            bidirectional=True\n        )\n        \n        lstm_output_dim = hidden_dim * 2  # 双向LSTM\n        \n        # 注意力机制\n        if self.use_attention:\n            self.attention = nn.MultiheadAttention(\n                embed_dim=lstm_output_dim,\n                num_heads=8,\n                dropout=dropout,\n                batch_first=True\n            )\n        \n        # 分类器 (移除 Sigmoid，因为使用 BCEWithLogitsLoss)\n        self.classifier = nn.Sequential(\n            nn.Linear(lstm_output_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, 1)\n        )\n        \n    def forward(self, x):\n        # x shape: (batch_size, num_frames, channels, height, width)\n        batch_size, num_frames = x.shape[:2]\n        \n        # 重塑为 (batch_size * num_frames, channels, height, width)\n        x = x.view(-1, *x.shape[2:])\n        \n        # 特征提取\n        features = self.backbone(x)  # (batch_size * num_frames, feature_dim)\n        \n        # 重塑回时序格式\n        features = features.view(batch_size, num_frames, -1)\n        \n        # LSTM处理\n        lstm_out, _ = self.lstm(features)  # (batch_size, num_frames, hidden_dim*2)\n        \n        # 注意力机制\n        attention_weights = None\n        if self.use_attention:\n            attended_out, attention_weights = self.attention(lstm_out, lstm_out, lstm_out)\n            # 全局平均池化\n            pooled = attended_out.mean(dim=1)  # (batch_size, hidden_dim*2)\n        else:\n            # 简单的全局平均池化\n            pooled = lstm_out.mean(dim=1)\n        \n        # 分类\n        output = self.classifier(pooled)\n        \n        return output.squeeze(-1), attention_weights\n\nprint(\"✅ 模型定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:53:31.841496Z","iopub.execute_input":"2025-07-06T09:53:31.841742Z","iopub.status.idle":"2025-07-06T09:53:31.862352Z","shell.execute_reply.started":"2025-07-06T09:53:31.841720Z","shell.execute_reply":"2025-07-06T09:53:31.861641Z"}},"outputs":[{"name":"stdout","text":"✅ 模型定义完成\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Cell 6: 损失函数和工具类","metadata":{}},{"cell_type":"code","source":"# Cell 6: 损失函数和工具类\n\nclass FocalLoss(nn.Module):\n    \"\"\"焦点损失函数 - 解决类别不平衡问题\"\"\"\n    \n    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        # 使用 BCEWithLogitsLoss 以兼容 autocast\n        ce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n        # 计算概率用于focal weight\n        pt = torch.exp(-ce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n\n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        else:\n            return focal_loss\n\nclass EarlyStopping:\n    \"\"\"早停机制\"\"\"\n    \n    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.restore_best_weights = restore_best_weights\n        self.best_loss = None\n        self.counter = 0\n        self.best_weights = None\n\n    def __call__(self, val_loss, model):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n            self.save_checkpoint(model)\n        elif val_loss < self.best_loss - self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0\n            self.save_checkpoint(model)\n        else:\n            self.counter += 1\n\n        if self.counter >= self.patience:\n            if self.restore_best_weights:\n                model.load_state_dict(self.best_weights)\n            return True\n        return False\n\n    def save_checkpoint(self, model):\n        self.best_weights = model.state_dict().copy()\n\ndef get_transforms(mode='train', image_size=160):\n    \"\"\"获取数据变换\"\"\"\n    if mode == 'train':\n        return transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((int(image_size * 1.1), int(image_size * 1.1))),\n            transforms.RandomCrop((image_size, image_size)),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n            transforms.RandomRotation(degrees=10),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))\n        ])\n    else:\n        return transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((image_size, image_size)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\nprint(\"✅ 损失函数和工具类定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:53:31.863051Z","iopub.execute_input":"2025-07-06T09:53:31.863268Z","iopub.status.idle":"2025-07-06T09:53:31.881479Z","shell.execute_reply.started":"2025-07-06T09:53:31.863244Z","shell.execute_reply":"2025-07-06T09:53:31.880809Z"}},"outputs":[{"name":"stdout","text":"✅ 损失函数和工具类定义完成\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Cell 7: 训练和验证函数","metadata":{}},{"cell_type":"code","source":"# Cell 7: 训练和验证函数\n\ndef train_epoch(model, train_loader, criterion, optimizer, device, scaler=None):\n    \"\"\"Kaggle T4 GPU优化的训练函数\"\"\"\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n\n    pbar = tqdm(train_loader, desc='Training', leave=False)\n    \n    for batch_idx, (data, target) in enumerate(pbar):\n        # 数据传输到GPU\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n        \n        # 梯度清零\n        optimizer.zero_grad(set_to_none=True)\n\n        # 前向传播（统一使用FP32）\n        output, _ = model(data)\n        loss = criterion(output, target)\n        \n        # 反向传播\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n\n        total_loss += loss.item()\n        \n        # 计算准确率\n        with torch.no_grad():\n            probs = torch.sigmoid(output)\n            predicted = (probs > 0.5).float()\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n            # 收集预测结果\n            all_preds.extend(probs.detach().cpu().numpy())\n            all_targets.extend(target.detach().cpu().numpy())\n\n        pbar.set_postfix({\n            'Loss': f'{loss.item():.4f}',\n            'Acc': f'{100.*correct/total:.2f}%'\n        })\n        \n        # 定期清理GPU缓存\n        if batch_idx % 50 == 0 and torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n    avg_loss = total_loss / len(train_loader)\n    accuracy = 100. * correct / total\n\n    try:\n        auc_score = roc_auc_score(all_targets, all_preds)\n    except:\n        auc_score = 0.0\n\n    return avg_loss, accuracy, auc_score\n\ndef validate_epoch(model, val_loader, criterion, device, scaler=None):\n    \"\"\"Kaggle T4 GPU优化的验证函数\"\"\"\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n        pbar = tqdm(val_loader, desc='Validation', leave=False)\n\n        for batch_idx, (data, target) in enumerate(pbar):\n            # 数据传输到GPU\n            data = data.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            \n            # 前向传播（统一使用FP32）\n            output, _ = model(data)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            \n            # 计算准确率\n            probs = torch.sigmoid(output)\n            predicted = (probs > 0.5).float()\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n            # 收集预测结果\n            all_preds.extend(probs.cpu().numpy())\n            all_targets.extend(target.cpu().numpy())\n\n            pbar.set_postfix({\n                'Loss': f'{loss.item():.4f}',\n                'Acc': f'{100.*correct/total:.2f}%'\n            })\n            \n            # 定期清理GPU缓存\n            if batch_idx % 50 == 0 and torch.cuda.is_available():\n                torch.cuda.empty_cache()\n\n    avg_loss = total_loss / len(val_loader)\n    accuracy = 100. * correct / total\n\n    try:\n        auc_score = roc_auc_score(all_targets, all_preds)\n    except:\n        auc_score = 0.0\n\n    return avg_loss, accuracy, auc_score\n\nprint(\"✅ 训练和验证函数定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:53:31.882273Z","iopub.execute_input":"2025-07-06T09:53:31.882572Z","iopub.status.idle":"2025-07-06T09:53:31.902988Z","shell.execute_reply.started":"2025-07-06T09:53:31.882553Z","shell.execute_reply":"2025-07-06T09:53:31.902466Z"}},"outputs":[{"name":"stdout","text":"✅ 训练和验证函数定义完成\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Cell 8: 评估函数和可视化","metadata":{}},{"cell_type":"code","source":"# Cell 8: 评估函数和可视化\n\ndef evaluate_model_optimized(model, test_loader, criterion, device):\n    \"\"\"优化的模型评估函数\"\"\"\n    model.eval()\n    total_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    all_scores = []\n    \n    inference_times = []\n    \n    print(\"🚀 开始模型评估...\")\n    \n    with torch.no_grad():\n        for batch_idx, (data, target) in enumerate(tqdm(test_loader, desc=\"评估进度\")):\n            data, target = data.to(device), target.to(device)\n            \n            # 记录推理时间\n            start_time = time.time()\n            output, attention_weights = model(data)\n            inference_time = time.time() - start_time\n            inference_times.append(inference_time)\n            \n            # 计算损失\n            loss = criterion(output, target)\n            total_loss += loss.item()\n            \n            # 收集预测结果 (应用 sigmoid 获得概率)\n            probs = torch.sigmoid(output)\n            predictions = (probs > 0.5).float()\n            all_predictions.extend(predictions.cpu().numpy())\n            all_targets.extend(target.cpu().numpy())\n            all_scores.extend(probs.cpu().numpy())\n    \n    avg_loss = total_loss / len(test_loader)\n    avg_inference_time = np.mean(inference_times)\n    total_inference_time = np.sum(inference_times)\n    \n    print(f\"✅ 评估完成\")\n    print(f\"平均损失: {avg_loss:.4f}\")\n    print(f\"平均推理时间: {avg_inference_time*1000:.2f} ms/batch\")\n    \n    return {\n        'loss': avg_loss,\n        'predictions': np.array(all_predictions),\n        'targets': np.array(all_targets),\n        'scores': np.array(all_scores),\n        'avg_inference_time': avg_inference_time,\n        'total_inference_time': total_inference_time\n    }\n\ndef calculate_comprehensive_metrics(predictions, targets, scores):\n    \"\"\"计算全面的评估指标\"\"\"\n    # 基础指标\n    accuracy = accuracy_score(targets, predictions)\n    balanced_acc = balanced_accuracy_score(targets, predictions)\n    precision = precision_score(targets, predictions, zero_division=0)\n    recall = recall_score(targets, predictions, zero_division=0)\n    f1 = f1_score(targets, predictions, zero_division=0)\n    \n    # 混淆矩阵\n    cm = confusion_matrix(targets, predictions)\n    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n    \n    # 特异性和负预测值\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n    \n    # AUC指标\n    try:\n        auc_roc = roc_auc_score(targets, scores)\n    except:\n        auc_roc = 0.0\n    \n    try:\n        precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)\n        auc_pr = auc(recall_curve, precision_curve)\n    except:\n        auc_pr = 0.0\n    \n    return {\n        'accuracy': accuracy,\n        'balanced_accuracy': balanced_acc,\n        'precision': precision,\n        'recall': recall,\n        'specificity': specificity,\n        'f1': f1,\n        'auc_roc': auc_roc,\n        'auc_pr': auc_pr,\n        'npv': npv,\n        'confusion_matrix': cm,\n        'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n    }\n\ndef plot_enhanced_confusion_matrix(cm, save_path):\n    \"\"\"绘制增强的混淆矩阵\"\"\"\n    plt.figure(figsize=(10, 8))\n    \n    # 计算百分比\n    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n    \n    # 创建标签\n    labels = np.array([[\n        f'{cm[i,j]}\\n({cm_percent[i,j]:.1f}%)' \n        for j in range(cm.shape[1])\n    ] for i in range(cm.shape[0])])\n    \n    # 绘制热图\n    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', \n                xticklabels=['真实', '伪造'],\n                yticklabels=['真实', '伪造'],\n                cbar_kws={'label': '样本数量'})\n    \n    plt.title('增强混淆矩阵', fontsize=16, fontweight='bold')\n    plt.xlabel('预测标签', fontsize=12)\n    plt.ylabel('真实标签', fontsize=12)\n    \n    # 添加统计信息\n    tn, fp, fn, tp = cm.ravel()\n    accuracy = (tp + tn) / (tp + tn + fp + fn)\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    stats_text = f'准确率: {accuracy:.3f}\\n精确率: {precision:.3f}\\n召回率: {recall:.3f}\\nF1分数: {f1:.3f}'\n    plt.text(2.1, 0.5, stats_text, fontsize=10, \n             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n    \n    plt.tight_layout()\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n    print(f\"混淆矩阵已保存到: {save_path}\")\n\ndef plot_roc_pr_curves(targets, scores, save_path):\n    \"\"\"绘制ROC和PR曲线\"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n    \n    # ROC曲线\n    fpr, tpr, _ = roc_curve(targets, scores)\n    roc_auc = auc(fpr, tpr)\n    \n    ax1.plot(fpr, tpr, color='darkorange', lw=2,\n             label=f'ROC曲线 (AUC = {roc_auc:.4f})')\n    ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    ax1.set_xlim([0.0, 1.0])\n    ax1.set_ylim([0.0, 1.05])\n    ax1.set_xlabel('假正率')\n    ax1.set_ylabel('真正率')\n    ax1.set_title('ROC曲线')\n    ax1.legend(loc='lower right')\n    ax1.grid(True, alpha=0.3)\n    \n    # PR曲线\n    precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)\n    pr_auc = auc(recall_curve, precision_curve)\n    \n    ax2.plot(recall_curve, precision_curve, color='darkgreen', lw=2,\n             label=f'PR曲线 (AUC = {pr_auc:.4f})')\n    ax2.set_xlim([0.0, 1.0])\n    ax2.set_ylim([0.0, 1.05])\n    ax2.set_xlabel('召回率')\n    ax2.set_ylabel('精确率')\n    ax2.set_title('精确率-召回率曲线')\n    ax2.legend(loc='lower left')\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n    print(f\"ROC/PR曲线已保存到: {save_path}\")\n\nprint(\"✅ 评估函数和可视化定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:53:31.903817Z","iopub.execute_input":"2025-07-06T09:53:31.904033Z","iopub.status.idle":"2025-07-06T09:53:31.927720Z","shell.execute_reply.started":"2025-07-06T09:53:31.904018Z","shell.execute_reply":"2025-07-06T09:53:31.927023Z"}},"outputs":[{"name":"stdout","text":"✅ 评估函数和可视化定义完成\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Cell 9: 数据处理和准备\n","metadata":{}},{"cell_type":"code","source":"# Cell 9: 数据处理和准备\n\n# 如果需要处理数据（首次运行）\nif not os.path.exists('./data/train.csv'):\n    print(\"📁 开始数据处理...\")\n    data_list = process_videos_simple(BASE_DATA_DIR, max_videos_per_class=120, max_frames=16)\n    \n    if len(data_list) == 0:\n        print(\"❌ 未找到数据，请检查数据路径\")\n        raise ValueError(\"数据路径错误或数据不存在\")\n    \n    train_data, val_data, test_data = create_dataset_split(data_list)\n    \n    # 保存数据集\n    save_dataset_to_csv(train_data, './data/train.csv')\n    save_dataset_to_csv(val_data, './data/val.csv')\n    save_dataset_to_csv(test_data, './data/test.csv')\n    \n    print(f\"训练集: {len(train_data)} 个样本\")\n    print(f\"验证集: {len(val_data)} 个样本\")\n    print(f\"测试集: {len(test_data)} 个样本\")\nelse:\n    print(\"📊 数据集已存在，跳过数据处理步骤\")\n    # 读取现有数据集信息\n    train_df = pd.read_csv('./data/train.csv')\n    val_df = pd.read_csv('./data/val.csv')\n    test_df = pd.read_csv('./data/test.csv')\n    \n    print(f\"训练集: {len(train_df)} 个样本\")\n    print(f\"验证集: {len(val_df)} 个样本\")\n    print(f\"测试集: {len(test_df)} 个样本\")\n    \n    # 显示数据分布\n    print(\"\\n数据分布:\")\n    print(\"训练集标签分布:\")\n    print(train_df['label'].value_counts())\n    print(\"\\n验证集标签分布:\")\n    print(val_df['label'].value_counts())\n    print(\"\\n测试集标签分布:\")\n    print(test_df['label'].value_counts())\n\nprint(\"✅ 数据准备完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:53:31.929417Z","iopub.execute_input":"2025-07-06T09:53:31.929607Z"}},"outputs":[{"name":"stdout","text":"📁 开始数据处理...\n开始处理真实视频...\n找到 120 个真实视频\n","output_type":"stream"},{"name":"stderr","text":"处理真实视频: 100%|██████████| 120/120 [09:37<00:00,  4.82s/it]\n","output_type":"stream"},{"name":"stdout","text":"开始处理伪造视频...\n处理 Deepfakes: 120 个视频\n","output_type":"stream"},{"name":"stderr","text":"处理Deepfakes: 100%|██████████| 120/120 [09:48<00:00,  4.91s/it]\n","output_type":"stream"},{"name":"stdout","text":"处理 Face2Face: 120 个视频\n","output_type":"stream"},{"name":"stderr","text":"处理Face2Face: 100%|██████████| 120/120 [08:53<00:00,  4.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"处理 FaceShifter: 120 个视频\n","output_type":"stream"},{"name":"stderr","text":"处理FaceShifter:  19%|█▉        | 23/120 [02:15<13:21,  8.26s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Cell 10: 创建数据加载器\n","metadata":{}},{"cell_type":"code","source":"# Cell 10: 创建数据加载器 - Kaggle T4 优化版本\n\nprint(\"📊 创建数据加载器...\")\n\n# 简化数据变换 - 使用GPU预处理替代CPU变换\ntrain_transform = None\nval_transform = None\n\nprint(f\"🔧 创建数据集（Kaggle T4优化配置）...\")\nprint(f\"📊 数据类型: FP32 (兼容性优先)\")\n\ntrain_dataset = DeepfakeVideoDataset(\n    csv_file='./data/train.csv',\n    transform=train_transform,\n    max_frames=16,\n    gpu_preprocessing=True,    # 启用GPU预处理\n    cache_frames=False        # 禁用缓存以节省内存\n)\n\nval_dataset = DeepfakeVideoDataset(\n    csv_file='./data/val.csv',\n    transform=val_transform,\n    max_frames=16,\n    gpu_preprocessing=True,    # 启用GPU预处理\n    cache_frames=False        # 禁用缓存以节省内存\n)\n\ntest_dataset = DeepfakeVideoDataset(\n    csv_file='./data/test.csv',\n    transform=val_transform,\n    max_frames=16,\n    gpu_preprocessing=True,    # 启用GPU预处理\n    cache_frames=False        # 禁用缓存以节省内存\n)\nprint(\"✅ 数据集创建完成，已优化Kaggle T4环境配置\")\n\n# Kaggle T4 GPU批次大小优化\nif torch.cuda.is_available():\n    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n    print(f\"GPU内存: {gpu_memory:.1f} GB\")\n    \n    # 保守的批次大小设置 - 确保稳定性和兼容性\n    if gpu_memory >= 15:  # T4 GPU\n        batch_size = 8  # 保守设置，确保稳定\n    elif gpu_memory >= 8:\n        batch_size = 6\n    else:\n        batch_size = 4\nelse:\n    batch_size = 4\n\nprint(f\"使用批次大小: {batch_size} (Kaggle T4优化，稳定性优先)\")\n\n# Kaggle环境多进程配置 - 简化版本\nif IS_KAGGLE:\n    # Kaggle环境：使用单进程避免序列化问题\n    num_workers = 0\n    prefetch_factor = None\n    persistent_workers = False\n    print(\"📝 Kaggle环境：使用单进程模式\")\nelse:\n    # 本地环境：使用少量worker\n    num_workers = 2\n    prefetch_factor = 2\n    persistent_workers = False\n    print(f\"🔥 本地环境：使用 {num_workers} workers\")\n\nprint(f\"数据加载配置: {num_workers} workers, 预取因子: {prefetch_factor}\")\n\n# 创建数据加载器 - Kaggle T4优化版本\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=batch_size, \n    shuffle=True, \n    num_workers=num_workers,\n    pin_memory=False,  # GPU预处理，无需pin_memory\n    drop_last=True,\n    prefetch_factor=prefetch_factor if num_workers > 0 else None,\n    persistent_workers=persistent_workers if num_workers > 0 else False\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=num_workers,\n    pin_memory=False,\n    prefetch_factor=prefetch_factor if num_workers > 0 else None,\n    persistent_workers=persistent_workers if num_workers > 0 else False\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=num_workers,\n    pin_memory=False,\n    prefetch_factor=prefetch_factor if num_workers > 0 else None,\n    persistent_workers=persistent_workers if num_workers > 0 else False\n)\n\nprint(f\"\\n📊 数据加载器统计:\")\nprint(f\"训练批次数: {len(train_loader)} (批次大小: {batch_size})\")\nprint(f\"验证批次数: {len(val_loader)}\")\nprint(f\"测试批次数: {len(test_loader)}\")\nprint(f\"数据加载worker数: {num_workers}\")\nprint(\"✅ 数据加载器创建完成\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 11: 模型初始化和训练配置\n","metadata":{}},{"cell_type":"code","source":"# Cell 11: 模型初始化和训练配置 - Kaggle T4 GPU优化版本\n\nprint(\"🤖 创建和配置模型...\")\n\n# 创建模型 - 针对Kaggle T4 GPU优化\nmodel = OptimizedDeepfakeDetector(\n    backbone='resnet50',\n    hidden_dim=512,      # 适中的隐藏层维度\n    num_layers=2,        # 减少LSTM层数\n    dropout=0.3,         # 适中的dropout\n    use_attention=True\n).to(device)\n\n# 单GPU配置\nif torch.cuda.is_available():\n    torch.cuda.set_per_process_memory_fraction(0.9)\n    print(\"使用单GPU训练\")\n\n# 计算模型参数数量\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"模型总参数数量: {total_params:,}\")\nprint(f\"可训练参数数量: {trainable_params:,}\")\nprint(f\"模型大小估计: {total_params * 4 / 1024**2:.1f} MB\")\n\n# 损失函数\ncriterion = FocalLoss(alpha=0.25, gamma=2.0)\nprint(f\"损失函数: FocalLoss\")\n\n# 优化器\nbase_lr = 0.001\noptimizer = optim.AdamW(\n    model.parameters(), \n    lr=base_lr,\n    weight_decay=0.01\n)\nprint(f\"优化器: AdamW (lr={base_lr})\")\n\n# 学习率调度器\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=base_lr * 5,\n    epochs=20,\n    steps_per_epoch=len(train_loader),\n    pct_start=0.3,\n    anneal_strategy='cos'\n)\nprint(f\"学习率调度器: OneCycleLR\")\n\n# 早停机制\nearly_stopping = EarlyStopping(patience=7, min_delta=0.001)\nprint(f\"早停机制: patience=7, min_delta=0.001\")\n\n# 训练配置 - 统一使用FP32数据类型\nscaler = None\nprint(\"数据类型: FP32 (确保兼容性)\")\n\nnum_epochs = 20\nprint(f\"训练轮数: {num_epochs}\")\n\n# 测试模型前向传播\nprint(\"\\n🔍 测试模型前向传播...\")\ntry:\n    model.eval()\n    with torch.no_grad():\n        sample_batch = next(iter(train_loader))\n        videos, labels = sample_batch\n        videos, labels = videos.to(device), labels.to(device)\n        \n        # 前向传播（统一使用FP32）\n        outputs, attention_weights = model(videos)\n        loss = criterion(outputs, labels)\n        \n        print(f\"输入形状: {videos.shape}\")\n        print(f\"输入数据类型: {videos.dtype}\")\n        print(f\"输出形状: {outputs.shape}\")\n        print(f\"损失值: {loss.item():.4f}\")\n        \n        # 显示概率范围\n        probs = torch.sigmoid(outputs)\n        print(f\"概率范围: [{probs.min():.3f}, {probs.max():.3f}]\")\n        \n        print(\"✅ 模型前向传播测试成功\")\nexcept Exception as e:\n    print(f\"❌ 模型前向传播测试失败: {e}\")\n    raise e\n\nprint(\"✅ 模型配置完成，准备开始训练\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 12: 模型训练主循环\n","metadata":{}},{"cell_type":"code","source":"# Cell 12: 训练循环 - Kaggle T4 GPU优化版本\n\n# 确保模型保存目录存在\nos.makedirs('./models', exist_ok=True)\n\nprint(\"🚀 开始训练...\")\nprint(f\"📊 训练配置: {len(train_loader)} 个训练批次, {len(val_loader)} 个验证批次\")\nprint(f\"🎯 模型参数数量: {sum(p.numel() for p in model.parameters()):,}\")\nprint(f\"💾 设备: {device}\")\nprint(f\"📦 批次大小: {batch_size}\")\n\nif torch.cuda.is_available():\n    print(f\"🎮 GPU: {torch.cuda.get_device_name(0)}\")\n    torch.cuda.reset_peak_memory_stats()\n\n# 训练历史记录\ntrain_history = {\n    'train_loss': [],\n    'val_loss': [],\n    'train_acc': [],\n    'val_acc': [],\n    'train_auc': [],\n    'val_auc': []\n}\nbest_val_loss = float('inf')\nbest_val_acc = 0.0\nbest_val_auc = 0.0\nbest_model_state = None\n\n# 训练循环\nprint(\"\\n🔄 开始训练循环...\")\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    \n    # 训练阶段\n    train_loss, train_acc, train_auc = train_epoch(model, train_loader, criterion, optimizer, device, scaler)\n    \n    # 验证阶段\n    val_loss, val_acc, val_auc = validate_epoch(model, val_loader, criterion, device, scaler)\n    \n    # 记录历史\n    train_history['train_loss'].append(train_loss)\n    train_history['train_acc'].append(train_acc)\n    train_history['train_auc'].append(train_auc)\n    train_history['val_loss'].append(val_loss)\n    train_history['val_acc'].append(val_acc)\n    train_history['val_auc'].append(val_auc)\n    \n    # 学习率调度\n    scheduler.step()\n    current_lr = optimizer.param_groups[0]['lr']\n    \n    # 计算epoch时间\n    epoch_time = time.time() - epoch_start_time\n    \n    # 打印结果\n    print(f\"训练: Loss={train_loss:.4f}, Acc={train_acc:.2f}%, AUC={train_auc:.4f}\")\n    print(f\"验证: Loss={val_loss:.4f}, Acc={val_acc:.2f}%, AUC={val_auc:.4f}\")\n    print(f\"学习率: {current_lr:.2e}, 用时: {epoch_time:.1f}s\")\n    \n    # 保存最佳模型\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        best_val_acc = val_acc\n        best_val_auc = val_auc\n        best_model_state = model.state_dict().copy()\n        print(f\"🎯 新的最佳模型! Loss: {best_val_loss:.4f}, Acc: {best_val_acc:.2f}%, AUC: {best_val_auc:.4f}\")\n        \n        # 保存最佳模型到文件\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': best_model_state,\n            'optimizer_state_dict': optimizer.state_dict(),\n            'best_val_loss': best_val_loss,\n            'best_val_acc': best_val_acc,\n            'best_val_auc': best_val_auc,\n            'train_history': train_history\n        }, './models/best_model.pth')\n        print(\"💾 最佳模型已保存\")\n    \n    # 早停检查\n    if early_stopping(val_loss, model):\n        print(f\"\\n⏹️ 早停触发，在第 {epoch+1} 轮停止训练\")\n        break\n    \n    # 清理GPU缓存\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\nprint(\"\\n✅ 训练完成!\")\nprint(f\"🏆 最终最佳性能: Loss={best_val_loss:.4f}, Acc={best_val_acc:.2f}%, AUC={best_val_auc:.4f}\")\nif torch.cuda.is_available():\n    print(f\"💾 峰值GPU内存使用: {torch.cuda.max_memory_allocated() / 1024**3:.1f}GB\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 13: 模型评估和结果分析\n","metadata":{}},{"cell_type":"code","source":"# Cell 13: 模型评估和结果分析\n\nprint(\"📊 开始模型评估...\")\nprint(\"=\" * 60)\n\n# 加载最佳模型\nprint(\"🔄 加载最佳模型...\")\ntry:\n    checkpoint = torch.load('./models/best_model.pth', map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    best_epoch = checkpoint['epoch']\n    best_val_acc = checkpoint['best_val_acc']\n    best_val_auc = checkpoint['best_val_auc']\n    \n    print(f\"✅ 成功加载第 {best_epoch+1} 轮的最佳模型\")\n    print(f\"最佳验证准确率: {best_val_acc:.2f}%\")\n    print(f\"最佳验证AUC: {best_val_auc:.4f}\")\nexcept Exception as e:\n    print(f\"❌ 加载模型失败: {e}\")\n    print(\"使用当前模型进行评估\")\n\n# 在测试集上评估模型\nprint(\"\\n🔍 在测试集上评估模型...\")\neval_results = evaluate_model_optimized(model, test_loader, criterion, device)\n\n# 计算全面的评估指标\nprint(\"\\n📈 计算评估指标...\")\nmetrics = calculate_comprehensive_metrics(\n    eval_results['predictions'], \n    eval_results['targets'], \n    eval_results['scores']\n)\n\n# 打印详细结果\nprint(\"\\n📊 详细评估结果:\")\nprint(\"=\" * 50)\nprint(f\"测试损失: {eval_results['loss']:.4f}\")\nprint(f\"准确率: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\nprint(f\"平衡准确率: {metrics['balanced_accuracy']:.4f} ({metrics['balanced_accuracy']*100:.2f}%)\")\nprint(f\"精确率: {metrics['precision']:.4f}\")\nprint(f\"召回率: {metrics['recall']:.4f}\")\nprint(f\"特异性: {metrics['specificity']:.4f}\")\nprint(f\"F1分数: {metrics['f1']:.4f}\")\nprint(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")\nprint(f\"AUC-PR: {metrics['auc_pr']:.4f}\")\nprint(f\"负预测值: {metrics['npv']:.4f}\")\n\n# 混淆矩阵详细信息\nprint(\"\\n🔍 混淆矩阵分析:\")\nprint(f\"真负例 (TN): {metrics['tn']}\")\nprint(f\"假正例 (FP): {metrics['fp']}\")\nprint(f\"假负例 (FN): {metrics['fn']}\")\nprint(f\"真正例 (TP): {metrics['tp']}\")\n\n# 性能分析\nprint(\"\\n⚡ 性能分析:\")\nprint(f\"平均推理时间: {eval_results['avg_inference_time']*1000:.2f} ms/batch\")\nprint(f\"总推理时间: {eval_results['total_inference_time']:.2f} 秒\")\nprint(f\"每个样本推理时间: {eval_results['avg_inference_time']*1000/batch_size:.2f} ms\")\n\n# 计算额外指标\ntotal_samples = len(eval_results['targets'])\nreal_samples = np.sum(eval_results['targets'] == 0)\nfake_samples = np.sum(eval_results['targets'] == 1)\nreal_accuracy = np.sum((eval_results['predictions'] == 0) & (eval_results['targets'] == 0)) / real_samples if real_samples > 0 else 0\nfake_accuracy = np.sum((eval_results['predictions'] == 1) & (eval_results['targets'] == 1)) / fake_samples if fake_samples > 0 else 0\n\nprint(\"\\n📋 类别特定分析:\")\nprint(f\"总样本数: {total_samples}\")\nprint(f\"真实视频样本: {real_samples} ({real_samples/total_samples*100:.1f}%)\")\nprint(f\"伪造视频样本: {fake_samples} ({fake_samples/total_samples*100:.1f}%)\")\nprint(f\"真实视频检测准确率: {real_accuracy:.4f} ({real_accuracy*100:.2f}%)\")\nprint(f\"伪造视频检测准确率: {fake_accuracy:.4f} ({fake_accuracy*100:.2f}%)\")\n\n# 生成可视化图表\nprint(\"\\n📊 生成评估图表...\")\n\n# 绘制增强混淆矩阵\nplot_enhanced_confusion_matrix(\n    metrics['confusion_matrix'], \n    './results/evaluation/confusion_matrix.png'\n)\n\n# 绘制ROC和PR曲线\nplot_roc_pr_curves(\n    eval_results['targets'], \n    eval_results['scores'], \n    './results/evaluation/roc_pr_curves.png'\n)\n\n# 预测分数分布图\nplt.figure(figsize=(12, 5))\n\n# 真实视频的预测分数分布\nplt.subplot(1, 2, 1)\nreal_scores = eval_results['scores'][eval_results['targets'] == 0]\nfake_scores = eval_results['scores'][eval_results['targets'] == 1]\n\nplt.hist(real_scores, bins=30, alpha=0.7, label='真实视频', color='blue', density=True)\nplt.hist(fake_scores, bins=30, alpha=0.7, label='伪造视频', color='red', density=True)\nplt.xlabel('预测分数')\nplt.ylabel('密度')\nplt.title('预测分数分布')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n# 预测分数箱线图\nplt.subplot(1, 2, 2)\nscores_data = [real_scores, fake_scores]\nlabels = ['真实视频', '伪造视频']\nplt.boxplot(scores_data, labels=labels)\nplt.ylabel('预测分数')\nplt.title('预测分数箱线图')\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('./results/evaluation/score_distribution.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"✅ 评估图表生成完成\")\nprint(\"=\" * 60)\nprint(\"🎉 模型评估完成！\")\nprint(\"📁 所有结果已保存到 ./results/evaluation/ 目录\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 14: 结果保存和总结\n","metadata":{}},{"cell_type":"code","source":"# Cell 14: 结果保存和总结\n\nprint(\"💾 保存实验结果...\")\nprint(\"=\" * 60)\n\n# 准备保存的结果数据\nresults_summary = {\n    'experiment_info': {\n        'timestamp': datetime.now().isoformat(),\n        'model_architecture': 'OptimizedDeepfakeDetector',\n        'backbone': 'resnet50',\n        'total_epochs': len(train_history['train_loss']),\n        'early_stopping': True\n    },\n    'dataset_info': {\n        'train_samples': len(train_dataset),\n        'val_samples': len(val_dataset),\n        'test_samples': len(test_dataset),\n        'batch_size': batch_size\n    },\n    'training_config': {\n        'optimizer': 'AdamW',\n        'learning_rate': 1e-4,\n        'weight_decay': 1e-4,\n        'loss_function': 'FocalLoss',\n        'scheduler': 'OneCycleLR',\n        'early_stopping_patience': 7\n    },\n    'final_metrics': {\n        'test_loss': float(eval_results['loss']),\n        'accuracy': float(metrics['accuracy']),\n        'precision': float(metrics['precision']),\n        'recall': float(metrics['recall']),\n        'f1_score': float(metrics['f1']),\n        'auc_roc': float(metrics['auc_roc'])\n    },\n    'confusion_matrix': {\n        'tn': int(metrics['tn']),\n        'fp': int(metrics['fp']),\n        'fn': int(metrics['fn']),\n        'tp': int(metrics['tp'])\n    },\n    'training_history': {\n        'train_loss': [float(x) for x in train_history['train_loss']],\n        'train_acc': [float(x) for x in train_history['train_acc']],\n        'train_auc': [float(x) for x in train_history['train_auc']],\n        'val_loss': [float(x) for x in train_history['val_loss']],\n        'val_acc': [float(x) for x in train_history['val_acc']],\n        'val_auc': [float(x) for x in train_history['val_auc']]\n    },\n    'class_specific_metrics': {\n        'real_video_accuracy': float(real_accuracy),\n        'fake_video_accuracy': float(fake_accuracy),\n        'real_samples_count': int(real_samples),\n        'fake_samples_count': int(fake_samples)\n    }\n}\n\n# 保存结果到JSON文件\nresults_file = './results/experiment_results.json'\nwith open(results_file, 'w', encoding='utf-8') as f:\n    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n\nprint(f\"✅ 实验结果已保存到: {results_file}\")\n\n# 保存训练历史到CSV\nhistory_df = pd.DataFrame(train_history)\nhistory_df.to_csv('./results/training_history.csv', index=False)\nprint(\"✅ 训练历史已保存到: ./results/training_history.csv\")\n\n# 保存预测结果\npredictions_df = pd.DataFrame({\n    'true_label': eval_results['targets'],\n    'predicted_label': eval_results['predictions'],\n    'prediction_score': eval_results['scores']\n})\npredictions_df.to_csv('./results/test_predictions.csv', index=False)\nprint(\"✅ 测试预测结果已保存到: ./results/test_predictions.csv\")\n\n# 生成实验报告\nprint(\"\\n📋 生成实验报告...\")\nreport = f\"\"\"\n深度伪造检测模型实验报告\n{'='*50}\n\n实验时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n模型架构: OptimizedDeepfakeDetector (ResNet50 + LSTM + Attention)\n\n数据集信息:\n- 训练样本: {len(train_dataset):,}\n- 验证样本: {len(val_dataset):,}\n- 测试样本: {len(test_dataset):,}\n- 批次大小: {batch_size}\n\n训练配置:\n- 优化器: AdamW (lr=1e-4, weight_decay=1e-4)\n- 损失函数: Focal Loss\n- 学习率调度: OneCycleLR\n- 早停机制: patience=7\n\n最终性能指标:\n- 准确率: {metrics['accuracy']*100:.2f}%\n- 精确率: {metrics['precision']:.4f}\n- 召回率: {metrics['recall']:.4f}\n- F1分数: {metrics['f1']:.4f}\n- AUC-ROC: {metrics['auc_roc']:.4f}\n\n混淆矩阵:\n- 真负例 (TN): {metrics['tn']}\n- 假正例 (FP): {metrics['fp']}\n- 假负例 (FN): {metrics['fn']}\n- 真正例 (TP): {metrics['tp']}\n\n类别特定性能:\n- 真实视频检测准确率: {real_accuracy*100:.2f}%\n- 伪造视频检测准确率: {fake_accuracy*100:.2f}%\n\n训练总结:\n- 训练轮数: {len(train_history['train_loss'])}\n- 最佳验证准确率: {max(train_history['val_acc']):.2f}%\n- 最佳验证AUC: {max(train_history['val_auc']):.4f}\n\n文件输出:\n- 模型权重: ./models/best_model.pth\n- 实验结果: ./results/experiment_results.json\n- 训练历史: ./results/training_history.csv\n- 预测结果: ./results/test_predictions.csv\n\n{'='*50}\n实验完成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\"\"\"\n\n# 保存报告\nwith open('./results/experiment_report.txt', 'w', encoding='utf-8') as f:\n    f.write(report)\n\nprint(\"✅ 实验报告已保存到: ./results/experiment_report.txt\")\n\n# 打印最终总结\nprint(\"\\n\" + \"=\"*60)\nprint(\"🎉 深度伪造检测模型训练和评估完成！\")\nprint(\"=\"*60)\nprint(f\"📊 最终测试准确率: {metrics['accuracy']*100:.2f}%\")\nprint(f\"📊 AUC-ROC分数: {metrics['auc_roc']:.4f}\")\nprint(f\"📊 F1分数: {metrics['f1']:.4f}\")\nprint(\"\\n📁 所有结果文件已保存到 ./results/ 目录\")\nprint(\"📁 最佳模型已保存到 ./models/best_model.pth\")\nprint(\"\\n✨ 实验成功完成！\")\nprint(\"=\"*60)\n\n# 显示文件结构\nprint(\"\\n📂 生成的文件结构:\")\nprint(\"\"\"\n./models/\n  └── best_model.pth\n./results/\n  ├── experiment_results.json\n  ├── experiment_report.txt\n  ├── training_history.csv\n  └── test_predictions.csv\n\"\"\")\n\nprint(\"\\n🚀 可以使用以下代码加载训练好的模型进行推理:\")\nprint(\"\"\"\n# 加载模型\nmodel = OptimizedDeepfakeDetector(...)\ncheckpoint = torch.load('./models/best_model.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\n\"\"\")\n\nprint(\"\\n✅ Kaggle T4 GPU优化版本 - 训练完成！\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}