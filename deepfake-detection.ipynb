{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10125851,"sourceType":"datasetVersion","datasetId":6248577}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cell 1: 导入库和环境设置","metadata":{}},{"cell_type":"code","source":"# Cell 1: 导入库和环境设置\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport random\nimport warnings\nimport gc\nimport json\nimport time\nimport sys\nfrom pathlib import Path\nfrom datetime import datetime\nwarnings.filterwarnings('ignore')\n\n# PyTorch相关\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as TF\nimport torchvision.models as models\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\nfrom torch.cuda.amp import GradScaler, autocast\n\n# 机器学习指标\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    roc_auc_score, confusion_matrix, classification_report,\n    roc_curve, auc, precision_recall_curve, balanced_accuracy_score\n)\nfrom sklearn.model_selection import train_test_split\n\n# 数据增强\ntry:\n    import albumentations as A\n    from albumentations.pytorch import ToTensorV2\n    ALBUMENTATIONS_AVAILABLE = True\nexcept ImportError:\n    ALBUMENTATIONS_AVAILABLE = False\n    print(\"警告: albumentations未安装，将使用基础数据增强\")\n\nprint(\"✅ 所有库导入完成\")","metadata":{"_uuid":"f6ebcf0d-d34a-4e53-b9c4-c85254661e41","_cell_guid":"4883bd2d-9463-4607-9e61-df4d76492a78","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-05T09:40:07.348947Z","iopub.execute_input":"2025-07-05T09:40:07.349307Z","iopub.status.idle":"2025-07-05T09:40:18.524845Z","shell.execute_reply.started":"2025-07-05T09:40:07.349271Z","shell.execute_reply":"2025-07-05T09:40:18.524222Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 2: 全局配置和工具函数","metadata":{}},{"cell_type":"code","source":"# Cell 2: 全局配置和工具函数\n\ndef set_seed(seed=42):\n    \"\"\"设置随机种子确保可重复性\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n# 检查GPU可用性\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"使用设备: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU型号: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n\n# 创建必要的目录\nfor dir_name in ['./data', './models', './logs', './results', './results/evaluation']:\n    os.makedirs(dir_name, exist_ok=True)\n\n# 检查是否在Kaggle环境中\nIS_KAGGLE = os.path.exists('/kaggle')\nBASE_DATA_DIR = '/kaggle/input/ff-c23/FaceForensics++_C23' if IS_KAGGLE else './FaceForensics++_C23'\n\nprint(f\"环境: {'Kaggle' if IS_KAGGLE else '本地'}\")\nprint(f\"数据基础路径: {BASE_DATA_DIR}\")\nprint(\"✅ 环境设置完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.525772Z","iopub.execute_input":"2025-07-05T09:40:18.526181Z","iopub.status.idle":"2025-07-05T09:40:18.650314Z","shell.execute_reply.started":"2025-07-05T09:40:18.526162Z","shell.execute_reply":"2025-07-05T09:40:18.649509Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 3: 数据处理模块\n","metadata":{}},{"cell_type":"code","source":"# Cell 3: 数据处理模块\n\ndef extract_frames_memory_efficient(video_path, max_frames=24, target_size=(160, 160),\n                                   quality_threshold=30, skip_frames=2):\n    \"\"\"内存友好的帧提取函数\"\"\"\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n\n    if not cap.isOpened():\n        print(f\"无法打开视频: {video_path}\")\n        return frames\n\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    if total_frames == 0:\n        cap.release()\n        return frames\n\n    # 均匀采样策略\n    if total_frames <= max_frames:\n        frame_indices = list(range(0, total_frames, skip_frames))\n    else:\n        step = max(1, total_frames // max_frames)\n        frame_indices = list(range(0, total_frames, step))[:max_frames]\n\n    frame_count = 0\n    for frame_idx in frame_indices:\n        if frame_count >= max_frames:\n            break\n\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n        ret, frame = cap.read()\n\n        if ret:\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            \n            # 简化质量检测\n            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n            quality = cv2.Laplacian(gray, cv2.CV_64F).var()\n\n            if quality > quality_threshold:\n                frame = cv2.resize(frame, target_size)\n                frames.append(frame)\n                frame_count += 1\n\n    cap.release()\n\n    # 如果帧数不足，重复最后一帧\n    while len(frames) < max_frames and len(frames) > 0:\n        frames.append(frames[-1].copy())\n\n    return frames[:max_frames]\n\ndef process_videos_simple(base_data_dir, max_videos_per_class=80, max_frames=24):\n    \"\"\"简化的视频处理函数\"\"\"\n    data_list = []\n    fake_methods = ['Deepfakes', 'Face2Face', 'FaceShifter', 'FaceSwap', 'NeuralTextures']\n\n    print(\"开始处理真实视频...\")\n    # 处理真实视频\n    original_dir = os.path.join(base_data_dir, 'original')\n    if os.path.exists(original_dir):\n        video_files = [f for f in os.listdir(original_dir)\n                      if f.endswith(('.mp4', '.avi', '.mov'))]\n        \n        if len(video_files) > max_videos_per_class:\n            video_files = random.sample(video_files, max_videos_per_class)\n\n        print(f\"找到 {len(video_files)} 个真实视频\")\n\n        for video_file in tqdm(video_files, desc=\"处理真实视频\"):\n            try:\n                video_path = os.path.join(original_dir, video_file)\n                frames = extract_frames_memory_efficient(video_path, max_frames)\n                \n                if len(frames) >= max_frames // 2:  # 至少要有一半的帧\n                    data_list.append({\n                        'video_path': video_path,\n                        'frames': frames,\n                        'label': 0,  # 真实视频\n                        'method': 'original'\n                    })\n            except Exception as e:\n                print(f\"处理视频 {video_file} 时出错: {e}\")\n                continue\n\n    # 处理伪造视频\n    print(\"开始处理伪造视频...\")\n    for method in fake_methods:\n        method_dir = os.path.join(base_data_dir, method)\n        if os.path.exists(method_dir):\n            video_files = [f for f in os.listdir(method_dir)\n                          if f.endswith(('.mp4', '.avi', '.mov'))]\n            \n            if len(video_files) > max_videos_per_class:\n                video_files = random.sample(video_files, max_videos_per_class)\n\n            print(f\"处理 {method}: {len(video_files)} 个视频\")\n\n            for video_file in tqdm(video_files, desc=f\"处理{method}\"):\n                try:\n                    video_path = os.path.join(method_dir, video_file)\n                    frames = extract_frames_memory_efficient(video_path, max_frames)\n                    \n                    if len(frames) >= max_frames // 2:\n                        data_list.append({\n                            'video_path': video_path,\n                            'frames': frames,\n                            'label': 1,  # 伪造视频\n                            'method': method\n                        })\n                except Exception as e:\n                    print(f\"处理视频 {video_file} 时出错: {e}\")\n                    continue\n\n    print(f\"\\n✅ 数据处理完成，共处理 {len(data_list)} 个视频\")\n    return data_list\n\ndef create_dataset_split(data_list, test_size=0.2, val_size=0.1):\n    \"\"\"创建数据集划分\"\"\"\n    # 分离真实和伪造数据\n    real_data = [item for item in data_list if item['label'] == 0]\n    fake_data = [item for item in data_list if item['label'] == 1]\n    \n    print(f\"真实视频: {len(real_data)} 个\")\n    print(f\"伪造视频: {len(fake_data)} 个\")\n    \n    # 分别划分真实和伪造数据\n    real_train, real_temp = train_test_split(real_data, test_size=test_size+val_size, random_state=42)\n    real_val, real_test = train_test_split(real_temp, test_size=test_size/(test_size+val_size), random_state=42)\n    \n    fake_train, fake_temp = train_test_split(fake_data, test_size=test_size+val_size, random_state=42)\n    fake_val, fake_test = train_test_split(fake_temp, test_size=test_size/(test_size+val_size), random_state=42)\n    \n    # 合并数据\n    train_data = real_train + fake_train\n    val_data = real_val + fake_val\n    test_data = real_test + fake_test\n    \n    # 打乱数据\n    random.shuffle(train_data)\n    random.shuffle(val_data)\n    random.shuffle(test_data)\n    \n    return train_data, val_data, test_data\n\ndef save_dataset_to_csv(data_list, filename):\n    \"\"\"将数据集保存为CSV文件\"\"\"\n    df_data = []\n    for item in data_list:\n        df_data.append({\n            'video_path': item['video_path'],\n            'label': item['label'],\n            'method': item['method'],\n            'num_frames': len(item['frames'])\n        })\n    \n    df = pd.DataFrame(df_data)\n    df.to_csv(filename, index=False)\n    print(f\"数据集已保存到: {filename}\")\n    return df\n\nprint(\"✅ 数据处理函数定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.651216Z","iopub.execute_input":"2025-07-05T09:40:18.651518Z","iopub.status.idle":"2025-07-05T09:40:18.672009Z","shell.execute_reply.started":"2025-07-05T09:40:18.651499Z","shell.execute_reply":"2025-07-05T09:40:18.671262Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 4: 数据集类定义\n","metadata":{}},{"cell_type":"code","source":"# Cell 4: 数据集类定义\n\nclass DeepfakeVideoDataset(Dataset):\n    \"\"\"深度伪造视频数据集类\"\"\"\n    \n    def __init__(self, csv_file=None, data_list=None, transform=None, max_frames=32):\n        if csv_file is not None:\n            self.df = pd.read_csv(csv_file)\n            self.data_list = None\n        elif data_list is not None:\n            self.data_list = data_list\n            self.df = None\n        else:\n            raise ValueError(\"必须提供csv_file或data_list\")\n            \n        self.transform = transform\n        self.max_frames = max_frames\n    \n    def __len__(self):\n        if self.df is not None:\n            return len(self.df)\n        return len(self.data_list)\n    \n    def __getitem__(self, idx):\n        if self.data_list is not None:\n            # 直接从内存中的数据列表获取\n            item = self.data_list[idx]\n            frames = item['frames']\n            label = item['label']\n        else:\n            # 从CSV文件获取路径并重新提取帧\n            row = self.df.iloc[idx]\n            video_path = row['video_path']\n            label = row['label']\n            frames = extract_frames_memory_efficient(video_path, self.max_frames)\n        \n        # 确保有足够的帧\n        if len(frames) == 0:\n            # 创建黑色帧作为fallback\n            frames = [np.zeros((160, 160, 3), dtype=np.uint8) for _ in range(self.max_frames)]\n        \n        while len(frames) < self.max_frames:\n            frames.append(frames[-1].copy() if frames else np.zeros((160, 160, 3), dtype=np.uint8))\n        \n        frames = frames[:self.max_frames]\n        \n        # 应用变换\n        if self.transform:\n            frames = [self.transform(frame) for frame in frames]\n        else:\n            # 默认变换\n            frames = [torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0 for frame in frames]\n        \n        # 堆叠帧 (T, C, H, W)\n        video_tensor = torch.stack(frames)\n        label_tensor = torch.tensor(label, dtype=torch.float32)\n        \n        return video_tensor, label_tensor\n\nprint(\"✅ 数据集类定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.673755Z","iopub.execute_input":"2025-07-05T09:40:18.673991Z","iopub.status.idle":"2025-07-05T09:40:18.693453Z","shell.execute_reply.started":"2025-07-05T09:40:18.673967Z","shell.execute_reply":"2025-07-05T09:40:18.692738Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 5: 模型定义","metadata":{}},{"cell_type":"code","source":"# Cell 5: 模型定义\n\nclass OptimizedDeepfakeDetector(nn.Module):\n    \"\"\"优化的深度伪造检测模型\"\"\"\n    \n    def __init__(self, backbone='resnet50', hidden_dim=512, num_layers=2, \n                 dropout=0.3, use_attention=True):\n        super(OptimizedDeepfakeDetector, self).__init__()\n        \n        self.use_attention = use_attention\n        \n        # 特征提取器\n        if backbone == 'resnet50':\n            self.backbone = models.resnet50(pretrained=True)\n            feature_dim = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        elif backbone == 'resnet18':\n            self.backbone = models.resnet18(pretrained=True)\n            feature_dim = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        else:\n            raise ValueError(f\"不支持的backbone: {backbone}\")\n        \n        # 时序建模\n        self.lstm = nn.LSTM(\n            input_size=feature_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0,\n            bidirectional=True\n        )\n        \n        lstm_output_dim = hidden_dim * 2  # 双向LSTM\n        \n        # 注意力机制\n        if self.use_attention:\n            self.attention = nn.MultiheadAttention(\n                embed_dim=lstm_output_dim,\n                num_heads=8,\n                dropout=dropout,\n                batch_first=True\n            )\n        \n        # 分类器 (移除 Sigmoid，因为使用 BCEWithLogitsLoss)\n        self.classifier = nn.Sequential(\n            nn.Linear(lstm_output_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, 1)\n        )\n        \n    def forward(self, x):\n        # x shape: (batch_size, num_frames, channels, height, width)\n        batch_size, num_frames = x.shape[:2]\n        \n        # 重塑为 (batch_size * num_frames, channels, height, width)\n        x = x.view(-1, *x.shape[2:])\n        \n        # 特征提取\n        features = self.backbone(x)  # (batch_size * num_frames, feature_dim)\n        \n        # 重塑回时序格式\n        features = features.view(batch_size, num_frames, -1)\n        \n        # LSTM处理\n        lstm_out, _ = self.lstm(features)  # (batch_size, num_frames, hidden_dim*2)\n        \n        # 注意力机制\n        attention_weights = None\n        if self.use_attention:\n            attended_out, attention_weights = self.attention(lstm_out, lstm_out, lstm_out)\n            # 全局平均池化\n            pooled = attended_out.mean(dim=1)  # (batch_size, hidden_dim*2)\n        else:\n            # 简单的全局平均池化\n            pooled = lstm_out.mean(dim=1)\n        \n        # 分类\n        output = self.classifier(pooled)\n        \n        return output.squeeze(-1), attention_weights\n\nprint(\"✅ 模型定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.694146Z","iopub.execute_input":"2025-07-05T09:40:18.694379Z","iopub.status.idle":"2025-07-05T09:40:18.713995Z","shell.execute_reply.started":"2025-07-05T09:40:18.694346Z","shell.execute_reply":"2025-07-05T09:40:18.713327Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 6: 损失函数和工具类","metadata":{}},{"cell_type":"code","source":"# Cell 6: 损失函数和工具类\n\nclass FocalLoss(nn.Module):\n    \"\"\"焦点损失函数 - 解决类别不平衡问题\"\"\"\n    \n    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        # 使用 BCEWithLogitsLoss 以兼容 autocast\n        ce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n        # 计算概率用于focal weight\n        pt = torch.exp(-ce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n\n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        else:\n            return focal_loss\n\nclass EarlyStopping:\n    \"\"\"早停机制\"\"\"\n    \n    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.restore_best_weights = restore_best_weights\n        self.best_loss = None\n        self.counter = 0\n        self.best_weights = None\n\n    def __call__(self, val_loss, model):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n            self.save_checkpoint(model)\n        elif val_loss < self.best_loss - self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0\n            self.save_checkpoint(model)\n        else:\n            self.counter += 1\n\n        if self.counter >= self.patience:\n            if self.restore_best_weights:\n                model.load_state_dict(self.best_weights)\n            return True\n        return False\n\n    def save_checkpoint(self, model):\n        self.best_weights = model.state_dict().copy()\n\ndef get_transforms(mode='train', image_size=160):\n    \"\"\"获取数据变换\"\"\"\n    if mode == 'train':\n        return transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((int(image_size * 1.1), int(image_size * 1.1))),\n            transforms.RandomCrop((image_size, image_size)),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n            transforms.RandomRotation(degrees=10),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))\n        ])\n    else:\n        return transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((image_size, image_size)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\nprint(\"✅ 损失函数和工具类定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.714907Z","iopub.execute_input":"2025-07-05T09:40:18.715604Z","iopub.status.idle":"2025-07-05T09:40:18.735617Z","shell.execute_reply.started":"2025-07-05T09:40:18.715581Z","shell.execute_reply":"2025-07-05T09:40:18.735066Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 7: 训练和验证函数","metadata":{}},{"cell_type":"code","source":"# Cell 7: 训练和验证函数\n\ndef train_epoch(model, train_loader, criterion, optimizer, device, scaler=None):\n    \"\"\"训练一个epoch\"\"\"\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n\n    pbar = tqdm(train_loader, desc='Training', leave=False)\n\n    for batch_idx, (data, target) in enumerate(pbar):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n\n        if scaler is not None:\n            with autocast():\n                output, _ = model(data)\n                loss = criterion(output, target)\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            output, _ = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n\n        total_loss += loss.item()\n        # 应用 sigmoid 获得概率进行预测\n        probs = torch.sigmoid(output)\n        predicted = (probs > 0.5).float()\n        total += target.size(0)\n        correct += (predicted == target).sum().item()\n\n        all_preds.extend(probs.detach().cpu().numpy())\n        all_targets.extend(target.detach().cpu().numpy())\n\n        pbar.set_postfix({\n            'Loss': f'{loss.item():.4f}',\n            'Acc': f'{100.*correct/total:.2f}%'\n        })\n\n    avg_loss = total_loss / len(train_loader)\n    accuracy = 100. * correct / total\n\n    try:\n        auc_score = roc_auc_score(all_targets, all_preds)\n    except:\n        auc_score = 0.0\n\n    return avg_loss, accuracy, auc_score\n\ndef validate_epoch(model, val_loader, criterion, device):\n    \"\"\"验证一个epoch\"\"\"\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n        pbar = tqdm(val_loader, desc='Validation', leave=False)\n\n        for data, target in pbar:\n            data, target = data.to(device), target.to(device)\n            output, _ = model(data)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            # 应用 sigmoid 获得概率进行预测\n            probs = torch.sigmoid(output)\n            predicted = (probs > 0.5).float()\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n            all_preds.extend(probs.cpu().numpy())\n            all_targets.extend(target.cpu().numpy())\n\n            pbar.set_postfix({\n                'Loss': f'{loss.item():.4f}',\n                'Acc': f'{100.*correct/total:.2f}%'\n            })\n\n    avg_loss = total_loss / len(val_loader)\n    accuracy = 100. * correct / total\n\n    try:\n        auc_score = roc_auc_score(all_targets, all_preds)\n    except:\n        auc_score = 0.0\n\n    return avg_loss, accuracy, auc_score\n\nprint(\"✅ 训练和验证函数定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.736344Z","iopub.execute_input":"2025-07-05T09:40:18.737079Z","iopub.status.idle":"2025-07-05T09:40:18.755906Z","shell.execute_reply.started":"2025-07-05T09:40:18.737055Z","shell.execute_reply":"2025-07-05T09:40:18.755245Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 8: 评估函数和可视化","metadata":{}},{"cell_type":"code","source":"# Cell 8: 评估函数和可视化\n\ndef evaluate_model_optimized(model, test_loader, criterion, device):\n    \"\"\"优化的模型评估函数\"\"\"\n    model.eval()\n    total_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    all_scores = []\n    \n    inference_times = []\n    \n    print(\"🚀 开始模型评估...\")\n    \n    with torch.no_grad():\n        for batch_idx, (data, target) in enumerate(tqdm(test_loader, desc=\"评估进度\")):\n            data, target = data.to(device), target.to(device)\n            \n            # 记录推理时间\n            start_time = time.time()\n            output, attention_weights = model(data)\n            inference_time = time.time() - start_time\n            inference_times.append(inference_time)\n            \n            # 计算损失\n            loss = criterion(output, target)\n            total_loss += loss.item()\n            \n            # 收集预测结果 (应用 sigmoid 获得概率)\n            probs = torch.sigmoid(output)\n            predictions = (probs > 0.5).float()\n            all_predictions.extend(predictions.cpu().numpy())\n            all_targets.extend(target.cpu().numpy())\n            all_scores.extend(probs.cpu().numpy())\n    \n    avg_loss = total_loss / len(test_loader)\n    avg_inference_time = np.mean(inference_times)\n    total_inference_time = np.sum(inference_times)\n    \n    print(f\"✅ 评估完成\")\n    print(f\"平均损失: {avg_loss:.4f}\")\n    print(f\"平均推理时间: {avg_inference_time*1000:.2f} ms/batch\")\n    \n    return {\n        'loss': avg_loss,\n        'predictions': np.array(all_predictions),\n        'targets': np.array(all_targets),\n        'scores': np.array(all_scores),\n        'avg_inference_time': avg_inference_time,\n        'total_inference_time': total_inference_time\n    }\n\ndef calculate_comprehensive_metrics(predictions, targets, scores):\n    \"\"\"计算全面的评估指标\"\"\"\n    # 基础指标\n    accuracy = accuracy_score(targets, predictions)\n    balanced_acc = balanced_accuracy_score(targets, predictions)\n    precision = precision_score(targets, predictions, zero_division=0)\n    recall = recall_score(targets, predictions, zero_division=0)\n    f1 = f1_score(targets, predictions, zero_division=0)\n    \n    # 混淆矩阵\n    cm = confusion_matrix(targets, predictions)\n    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n    \n    # 特异性和负预测值\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n    \n    # AUC指标\n    try:\n        auc_roc = roc_auc_score(targets, scores)\n    except:\n        auc_roc = 0.0\n    \n    try:\n        precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)\n        auc_pr = auc(recall_curve, precision_curve)\n    except:\n        auc_pr = 0.0\n    \n    return {\n        'accuracy': accuracy,\n        'balanced_accuracy': balanced_acc,\n        'precision': precision,\n        'recall': recall,\n        'specificity': specificity,\n        'f1': f1,\n        'auc_roc': auc_roc,\n        'auc_pr': auc_pr,\n        'npv': npv,\n        'confusion_matrix': cm,\n        'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n    }\n\ndef plot_enhanced_confusion_matrix(cm, save_path):\n    \"\"\"绘制增强的混淆矩阵\"\"\"\n    plt.figure(figsize=(10, 8))\n    \n    # 计算百分比\n    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n    \n    # 创建标签\n    labels = np.array([[\n        f'{cm[i,j]}\\n({cm_percent[i,j]:.1f}%)' \n        for j in range(cm.shape[1])\n    ] for i in range(cm.shape[0])])\n    \n    # 绘制热图\n    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', \n                xticklabels=['真实', '伪造'],\n                yticklabels=['真实', '伪造'],\n                cbar_kws={'label': '样本数量'})\n    \n    plt.title('增强混淆矩阵', fontsize=16, fontweight='bold')\n    plt.xlabel('预测标签', fontsize=12)\n    plt.ylabel('真实标签', fontsize=12)\n    \n    # 添加统计信息\n    tn, fp, fn, tp = cm.ravel()\n    accuracy = (tp + tn) / (tp + tn + fp + fn)\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    stats_text = f'准确率: {accuracy:.3f}\\n精确率: {precision:.3f}\\n召回率: {recall:.3f}\\nF1分数: {f1:.3f}'\n    plt.text(2.1, 0.5, stats_text, fontsize=10, \n             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n    \n    plt.tight_layout()\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n    print(f\"混淆矩阵已保存到: {save_path}\")\n\ndef plot_roc_pr_curves(targets, scores, save_path):\n    \"\"\"绘制ROC和PR曲线\"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n    \n    # ROC曲线\n    fpr, tpr, _ = roc_curve(targets, scores)\n    roc_auc = auc(fpr, tpr)\n    \n    ax1.plot(fpr, tpr, color='darkorange', lw=2,\n             label=f'ROC曲线 (AUC = {roc_auc:.4f})')\n    ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    ax1.set_xlim([0.0, 1.0])\n    ax1.set_ylim([0.0, 1.05])\n    ax1.set_xlabel('假正率')\n    ax1.set_ylabel('真正率')\n    ax1.set_title('ROC曲线')\n    ax1.legend(loc='lower right')\n    ax1.grid(True, alpha=0.3)\n    \n    # PR曲线\n    precision_curve, recall_curve, _ = precision_recall_curve(targets, scores)\n    pr_auc = auc(recall_curve, precision_curve)\n    \n    ax2.plot(recall_curve, precision_curve, color='darkgreen', lw=2,\n             label=f'PR曲线 (AUC = {pr_auc:.4f})')\n    ax2.set_xlim([0.0, 1.0])\n    ax2.set_ylim([0.0, 1.05])\n    ax2.set_xlabel('召回率')\n    ax2.set_ylabel('精确率')\n    ax2.set_title('精确率-召回率曲线')\n    ax2.legend(loc='lower left')\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n    print(f\"ROC/PR曲线已保存到: {save_path}\")\n\nprint(\"✅ 评估函数和可视化定义完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:40:18.756640Z","iopub.execute_input":"2025-07-05T09:40:18.756856Z","iopub.status.idle":"2025-07-05T09:40:18.777479Z","shell.execute_reply.started":"2025-07-05T09:40:18.756830Z","shell.execute_reply":"2025-07-05T09:40:18.776832Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 9: 数据处理和准备\n","metadata":{}},{"cell_type":"code","source":"# Cell 9: 数据处理和准备\n\n# 如果需要处理数据（首次运行）\nif not os.path.exists('./data/train.csv'):\n    print(\"📁 开始数据处理...\")\n    data_list = process_videos_simple(BASE_DATA_DIR, max_videos_per_class=200, max_frames=32)\n    \n    if len(data_list) == 0:\n        print(\"❌ 未找到数据，请检查数据路径\")\n        raise ValueError(\"数据路径错误或数据不存在\")\n    \n    train_data, val_data, test_data = create_dataset_split(data_list)\n    \n    # 保存数据集\n    save_dataset_to_csv(train_data, './data/train.csv')\n    save_dataset_to_csv(val_data, './data/val.csv')\n    save_dataset_to_csv(test_data, './data/test.csv')\n    \n    print(f\"训练集: {len(train_data)} 个样本\")\n    print(f\"验证集: {len(val_data)} 个样本\")\n    print(f\"测试集: {len(test_data)} 个样本\")\nelse:\n    print(\"📊 数据集已存在，跳过数据处理步骤\")\n    # 读取现有数据集信息\n    train_df = pd.read_csv('./data/train.csv')\n    val_df = pd.read_csv('./data/val.csv')\n    test_df = pd.read_csv('./data/test.csv')\n    \n    print(f\"训练集: {len(train_df)} 个样本\")\n    print(f\"验证集: {len(val_df)} 个样本\")\n    print(f\"测试集: {len(test_df)} 个样本\")\n    \n    # 显示数据分布\n    print(\"\\n数据分布:\")\n    print(\"训练集标签分布:\")\n    print(train_df['label'].value_counts())\n    print(\"\\n验证集标签分布:\")\n    print(val_df['label'].value_counts())\n    print(\"\\n测试集标签分布:\")\n    print(test_df['label'].value_counts())\n\nprint(\"✅ 数据准备完成\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:48:58.128768Z","iopub.execute_input":"2025-07-05T09:48:58.129254Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 10: 创建数据加载器\n","metadata":{}},{"cell_type":"code","source":"# Cell 10: 创建数据加载器\n\nprint(\"📊 创建数据加载器...\")\n\n# 获取数据变换\ntrain_transform = get_transforms('train')\nval_transform = get_transforms('val')\n\n# 创建数据集\ntrain_dataset = DeepfakeVideoDataset('./data/train.csv', transform=train_transform)\nval_dataset = DeepfakeVideoDataset('./data/val.csv', transform=val_transform)\ntest_dataset = DeepfakeVideoDataset('./data/test.csv', transform=val_transform)\n\n# 根据GPU内存调整批次大小 - 针对T4*2 GPU优化\nif torch.cuda.is_available():\n    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n    gpu_count = torch.cuda.device_count()\n    print(f\"检测到 {gpu_count} 个GPU，每个GPU内存: {gpu_memory:.1f} GB\")\n    \n    # T4*2配置优化\n    if gpu_count >= 2 and gpu_memory >= 15:  # T4*2配置\n        batch_size = 24\n    elif gpu_memory >= 16:\n        batch_size = 20\n    elif gpu_memory >= 8:\n        batch_size = 12\n    else:\n        batch_size = 6\nelse:\n    batch_size = 2\n\nprint(f\"使用批次大小: {batch_size}\")\n\n# 创建数据加载器 - 针对T4*2 GPU优化\nnum_workers = min(8, torch.cuda.device_count() * 4) if torch.cuda.is_available() else 2\nprint(f\"使用 {num_workers} 个数据加载worker\")\n\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=batch_size, \n    shuffle=True, \n    num_workers=num_workers,\n    pin_memory=torch.cuda.is_available(),\n    drop_last=True,\n    persistent_workers=True if num_workers > 0 else False\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=num_workers,\n    pin_memory=torch.cuda.is_available(),\n    persistent_workers=True if num_workers > 0 else False\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=num_workers,\n    pin_memory=torch.cuda.is_available(),\n    persistent_workers=True if num_workers > 0 else False\n)\n\nprint(f\"训练批次数: {len(train_loader)}\")\nprint(f\"验证批次数: {len(val_loader)}\")\nprint(f\"测试批次数: {len(test_loader)}\")\n\n# 测试数据加载器\nprint(\"\\n🔍 测试数据加载器...\")\ntry:\n    sample_batch = next(iter(train_loader))\n    videos, labels = sample_batch\n    print(f\"视频张量形状: {videos.shape}\")\n    print(f\"标签张量形状: {labels.shape}\")\n    print(f\"视频数据类型: {videos.dtype}\")\n    print(f\"标签数据类型: {labels.dtype}\")\n    print(f\"视频数据范围: [{videos.min():.3f}, {videos.max():.3f}]\")\n    print(f\"标签分布: {labels.unique(return_counts=True)}\")\n    print(\"✅ 数据加载器测试成功\")\nexcept Exception as e:\n    print(f\"❌ 数据加载器测试失败: {e}\")\n    raise e\n\nprint(\"✅ 数据加载器创建完成\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 11: 模型初始化和训练配置\n","metadata":{}},{"cell_type":"code","source":"# Cell 11: 模型初始化和训练配置\n\nprint(\"🤖 创建和配置模型...\")\n\n# 创建模型 - 针对T4*2 GPU优化\nmodel = OptimizedDeepfakeDetector(\n    backbone='resnet50',  # 使用ResNet50以充分利用T4*2 GPU性能\n    hidden_dim=512,      # 增加隐藏层维度\n    num_layers=2,        # 增加LSTM层数\n    dropout=0.4,         # 适当增加dropout防止过拟合\n    use_attention=True\n).to(device)\n\n# 多GPU支持 - 充分利用T4*2配置\nif torch.cuda.device_count() > 1:\n    print(f\"使用 {torch.cuda.device_count()} 个GPU进行并行训练\")\n    model = nn.DataParallel(model)\nelse:\n    print(\"使用单GPU训练\")\n\n# 计算模型参数数量\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"模型总参数数量: {total_params:,}\")\nprint(f\"可训练参数数量: {trainable_params:,}\")\nprint(f\"模型大小估计: {total_params * 4 / 1024**2:.1f} MB\")\n\n# 损失函数\ncriterion = FocalLoss(alpha=1, gamma=2)\nprint(\"使用焦点损失函数 (Focal Loss)\")\n\n# 优化器 - 针对ResNet50优化\noptimizer = optim.AdamW(\n    model.parameters(), \n    lr=2e-4,  # 稍微提高学习率以适应更大模型\n    weight_decay=1e-4,\n    betas=(0.9, 0.999)\n)\nprint(\"使用AdamW优化器 (lr=2e-4)\")\n\n# 学习率调度器 - 更保守的调度\nscheduler = ReduceLROnPlateau(\n    optimizer, \n    mode='min', \n    factor=0.6,  # 更保守的衰减因子\n    patience=4,  # 增加patience\n    verbose=True,\n    min_lr=1e-7\n)\nprint(\"使用ReduceLROnPlateau学习率调度器 (factor=0.6, patience=4)\")\n\n# 早停机制 - 增加patience以适应更大模型\nearly_stopping = EarlyStopping(patience=8, min_delta=0.001)\nprint(\"配置早停机制 (patience=8)\")\n\n# 混合精度训练\nif torch.cuda.is_available():\n    scaler = GradScaler()\n    print(\"启用混合精度训练 (AMP)\")\nelse:\n    scaler = None\n    print(\"CPU模式，不使用混合精度训练\")\n\n# 训练配置 - 针对T4*2 GPU和更大数据集优化\nnum_epochs = 25  # 增加训练轮数以充分训练更大的模型\nprint(f\"训练轮数: {num_epochs}\")\n\n# 测试模型前向传播\nprint(\"\\n🔍 测试模型前向传播...\")\ntry:\n    model.eval()\n    with torch.no_grad():\n        sample_batch = next(iter(train_loader))\n        videos, labels = sample_batch\n        videos, labels = videos.to(device), labels.to(device)\n        \n        # 前向传播\n        outputs, attention_weights = model(videos)\n        loss = criterion(outputs, labels)\n        \n        print(f\"输入形状: {videos.shape}\")\n        print(f\"输出形状: {outputs.shape}\")\n        print(f\"损失值: {loss.item():.4f}\")\n        print(f\"Logits范围: [{outputs.min():.3f}, {outputs.max():.3f}]\")\n        \n        # 显示概率范围\n        probs = torch.sigmoid(outputs)\n        print(f\"概率范围: [{probs.min():.3f}, {probs.max():.3f}]\")\n        \n        if attention_weights is not None:\n            print(f\"注意力权重形状: {attention_weights.shape}\")\n        \n        print(\"✅ 模型前向传播测试成功\")\nexcept Exception as e:\n    print(f\"❌ 模型前向传播测试失败: {e}\")\n    raise e\n\nprint(\"✅ 模型配置完成，准备开始训练\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 12: 模型训练主循环\n","metadata":{}},{"cell_type":"code","source":"# Cell 12: 模型训练主循环\n\nprint(\"🎯 开始训练模型...\")\nprint(\"=\" * 60)\n\n# 训练历史记录\ntrain_history = {\n    'train_loss': [],\n    'train_acc': [],\n    'train_auc': [],\n    'val_loss': [],\n    'val_acc': [],\n    'val_auc': [],\n    'lr': []\n}\n\nbest_val_acc = 0\nbest_val_auc = 0\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    \n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    print(\"-\" * 50)\n    \n    # 训练阶段\n    train_loss, train_acc, train_auc = train_epoch(\n        model, train_loader, criterion, optimizer, device, scaler\n    )\n    \n    # 验证阶段\n    val_loss, val_acc, val_auc = validate_epoch(\n        model, val_loader, criterion, device\n    )\n    \n    # 学习率调度\n    scheduler.step(val_loss)\n    current_lr = optimizer.param_groups[0]['lr']\n    \n    # 记录历史\n    train_history['train_loss'].append(train_loss)\n    train_history['train_acc'].append(train_acc)\n    train_history['train_auc'].append(train_auc)\n    train_history['val_loss'].append(val_loss)\n    train_history['val_acc'].append(val_acc)\n    train_history['val_auc'].append(val_auc)\n    train_history['lr'].append(current_lr)\n    \n    # 计算epoch时间\n    epoch_time = time.time() - epoch_start_time\n    \n    # 打印结果\n    print(f\"训练 - 损失: {train_loss:.4f}, 准确率: {train_acc:.2f}%, AUC: {train_auc:.4f}\")\n    print(f\"验证 - 损失: {val_loss:.4f}, 准确率: {val_acc:.2f}%, AUC: {val_auc:.4f}\")\n    print(f\"学习率: {current_lr:.6f}\")\n    print(f\"Epoch时间: {epoch_time:.1f}s\")\n    \n    # 保存最佳模型\n    is_best = False\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        best_val_auc = val_auc\n        is_best = True\n        \n        # 保存模型\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'best_val_acc': best_val_acc,\n            'best_val_auc': best_val_auc,\n            'val_loss': val_loss,\n            'train_history': train_history\n        }, './models/best_model.pth')\n        \n        print(f\"💾 保存最佳模型 (验证准确率: {val_acc:.2f}%, AUC: {val_auc:.4f})\")\n    \n    # 早停检查\n    if early_stopping(val_loss, model):\n        print(f\"🛑 早停触发，在第 {epoch+1} 轮停止训练\")\n        print(f\"最佳验证准确率: {best_val_acc:.2f}%\")\n        break\n    \n    # 内存清理\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    gc.collect()\n\n# 训练完成\ntotal_time = time.time() - start_time\nprint(f\"\\n🎉 训练完成！\")\nprint(f\"总训练时间: {total_time/60:.1f} 分钟\")\nprint(f\"最佳验证准确率: {best_val_acc:.2f}%\")\nprint(f\"最佳验证AUC: {best_val_auc:.4f}\")\nprint(\"=\" * 60)\n\n# 绘制训练历史\nprint(\"📊 绘制训练历史...\")\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n\n# 损失曲线\nax1.plot(train_history['train_loss'], label='训练损失', color='blue')\nax1.plot(train_history['val_loss'], label='验证损失', color='red')\nax1.set_title('损失曲线')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# 准确率曲线\nax2.plot(train_history['train_acc'], label='训练准确率', color='blue')\nax2.plot(train_history['val_acc'], label='验证准确率', color='red')\nax2.set_title('准确率曲线')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Accuracy (%)')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\n# AUC曲线\nax3.plot(train_history['train_auc'], label='训练AUC', color='blue')\nax3.plot(train_history['val_auc'], label='验证AUC', color='red')\nax3.set_title('AUC曲线')\nax3.set_xlabel('Epoch')\nax3.set_ylabel('AUC')\nax3.legend()\nax3.grid(True, alpha=0.3)\n\n# 学习率曲线\nax4.plot(train_history['lr'], label='学习率', color='green')\nax4.set_title('学习率变化')\nax4.set_xlabel('Epoch')\nax4.set_ylabel('Learning Rate')\nax4.set_yscale('log')\nax4.legend()\nax4.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('./results/training_history.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"✅ 训练历史图表已保存\")\nprint(\"✅ 训练阶段完成，准备进行模型评估\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 13: 模型评估和结果分析\n","metadata":{}},{"cell_type":"code","source":"# Cell 13: 模型评估和结果分析\n\nprint(\"📊 开始模型评估...\")\nprint(\"=\" * 60)\n\n# 加载最佳模型\nprint(\"🔄 加载最佳模型...\")\ntry:\n    checkpoint = torch.load('./models/best_model.pth', map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    best_epoch = checkpoint['epoch']\n    best_val_acc = checkpoint['best_val_acc']\n    best_val_auc = checkpoint['best_val_auc']\n    \n    print(f\"✅ 成功加载第 {best_epoch+1} 轮的最佳模型\")\n    print(f\"最佳验证准确率: {best_val_acc:.2f}%\")\n    print(f\"最佳验证AUC: {best_val_auc:.4f}\")\nexcept Exception as e:\n    print(f\"❌ 加载模型失败: {e}\")\n    print(\"使用当前模型进行评估\")\n\n# 在测试集上评估模型\nprint(\"\\n🔍 在测试集上评估模型...\")\neval_results = evaluate_model_optimized(model, test_loader, criterion, device)\n\n# 计算全面的评估指标\nprint(\"\\n📈 计算评估指标...\")\nmetrics = calculate_comprehensive_metrics(\n    eval_results['predictions'], \n    eval_results['targets'], \n    eval_results['scores']\n)\n\n# 打印详细结果\nprint(\"\\n📊 详细评估结果:\")\nprint(\"=\" * 50)\nprint(f\"测试损失: {eval_results['loss']:.4f}\")\nprint(f\"准确率: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\nprint(f\"平衡准确率: {metrics['balanced_accuracy']:.4f} ({metrics['balanced_accuracy']*100:.2f}%)\")\nprint(f\"精确率: {metrics['precision']:.4f}\")\nprint(f\"召回率: {metrics['recall']:.4f}\")\nprint(f\"特异性: {metrics['specificity']:.4f}\")\nprint(f\"F1分数: {metrics['f1']:.4f}\")\nprint(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")\nprint(f\"AUC-PR: {metrics['auc_pr']:.4f}\")\nprint(f\"负预测值: {metrics['npv']:.4f}\")\n\n# 混淆矩阵详细信息\nprint(\"\\n🔍 混淆矩阵分析:\")\nprint(f\"真负例 (TN): {metrics['tn']}\")\nprint(f\"假正例 (FP): {metrics['fp']}\")\nprint(f\"假负例 (FN): {metrics['fn']}\")\nprint(f\"真正例 (TP): {metrics['tp']}\")\n\n# 性能分析\nprint(\"\\n⚡ 性能分析:\")\nprint(f\"平均推理时间: {eval_results['avg_inference_time']*1000:.2f} ms/batch\")\nprint(f\"总推理时间: {eval_results['total_inference_time']:.2f} 秒\")\nprint(f\"每个样本推理时间: {eval_results['avg_inference_time']*1000/batch_size:.2f} ms\")\n\n# 计算额外指标\ntotal_samples = len(eval_results['targets'])\nreal_samples = np.sum(eval_results['targets'] == 0)\nfake_samples = np.sum(eval_results['targets'] == 1)\nreal_accuracy = np.sum((eval_results['predictions'] == 0) & (eval_results['targets'] == 0)) / real_samples if real_samples > 0 else 0\nfake_accuracy = np.sum((eval_results['predictions'] == 1) & (eval_results['targets'] == 1)) / fake_samples if fake_samples > 0 else 0\n\nprint(\"\\n📋 类别特定分析:\")\nprint(f\"总样本数: {total_samples}\")\nprint(f\"真实视频样本: {real_samples} ({real_samples/total_samples*100:.1f}%)\")\nprint(f\"伪造视频样本: {fake_samples} ({fake_samples/total_samples*100:.1f}%)\")\nprint(f\"真实视频检测准确率: {real_accuracy:.4f} ({real_accuracy*100:.2f}%)\")\nprint(f\"伪造视频检测准确率: {fake_accuracy:.4f} ({fake_accuracy*100:.2f}%)\")\n\n# 生成可视化图表\nprint(\"\\n📊 生成评估图表...\")\n\n# 绘制增强混淆矩阵\nplot_enhanced_confusion_matrix(\n    metrics['confusion_matrix'], \n    './results/evaluation/confusion_matrix.png'\n)\n\n# 绘制ROC和PR曲线\nplot_roc_pr_curves(\n    eval_results['targets'], \n    eval_results['scores'], \n    './results/evaluation/roc_pr_curves.png'\n)\n\n# 预测分数分布图\nplt.figure(figsize=(12, 5))\n\n# 真实视频的预测分数分布\nplt.subplot(1, 2, 1)\nreal_scores = eval_results['scores'][eval_results['targets'] == 0]\nfake_scores = eval_results['scores'][eval_results['targets'] == 1]\n\nplt.hist(real_scores, bins=30, alpha=0.7, label='真实视频', color='blue', density=True)\nplt.hist(fake_scores, bins=30, alpha=0.7, label='伪造视频', color='red', density=True)\nplt.xlabel('预测分数')\nplt.ylabel('密度')\nplt.title('预测分数分布')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n# 预测分数箱线图\nplt.subplot(1, 2, 2)\nscores_data = [real_scores, fake_scores]\nlabels = ['真实视频', '伪造视频']\nplt.boxplot(scores_data, labels=labels)\nplt.ylabel('预测分数')\nplt.title('预测分数箱线图')\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('./results/evaluation/score_distribution.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"✅ 评估图表生成完成\")\nprint(\"=\" * 60)\nprint(\"🎉 模型评估完成！\")\nprint(\"📁 所有结果已保存到 ./results/evaluation/ 目录\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 14: 结果保存和总结\n","metadata":{}},{"cell_type":"code","source":"# Cell 14: 结果保存和总结\n\nprint(\"💾 保存实验结果...\")\nprint(\"=\" * 60)\n\n# 准备保存的结果数据\nresults_summary = {\n    'experiment_info': {\n        'timestamp': datetime.now().isoformat(),\n        'model_architecture': 'OptimizedDeepfakeDetector',\n        'backbone': 'resnet18',\n        'total_epochs': len(train_history['train_loss']),\n        'best_epoch': best_epoch + 1 if 'best_epoch' in locals() else len(train_history['train_loss']),\n        'early_stopping': True,\n        'mixed_precision': torch.cuda.is_available()\n    },\n    'dataset_info': {\n        'train_samples': len(train_dataset),\n        'val_samples': len(val_dataset),\n        'test_samples': len(test_dataset),\n        'batch_size': batch_size,\n        'num_workers': 2\n    },\n    'training_config': {\n        'optimizer': 'AdamW',\n        'learning_rate': 1e-4,\n        'weight_decay': 1e-4,\n        'loss_function': 'FocalLoss',\n        'scheduler': 'ReduceLROnPlateau',\n        'early_stopping_patience': 5\n    },\n    'final_metrics': {\n        'test_loss': float(eval_results['loss']),\n        'accuracy': float(metrics['accuracy']),\n        'balanced_accuracy': float(metrics['balanced_accuracy']),\n        'precision': float(metrics['precision']),\n        'recall': float(metrics['recall']),\n        'specificity': float(metrics['specificity']),\n        'f1_score': float(metrics['f1']),\n        'auc_roc': float(metrics['auc_roc']),\n        'auc_pr': float(metrics['auc_pr']),\n        'npv': float(metrics['npv'])\n    },\n    'confusion_matrix': {\n        'tn': int(metrics['tn']),\n        'fp': int(metrics['fp']),\n        'fn': int(metrics['fn']),\n        'tp': int(metrics['tp'])\n    },\n    'performance': {\n        'avg_inference_time_ms': float(eval_results['avg_inference_time'] * 1000),\n        'total_inference_time_s': float(eval_results['total_inference_time']),\n        'samples_per_second': float(len(eval_results['targets']) / eval_results['total_inference_time'])\n    },\n    'training_history': {\n        'train_loss': [float(x) for x in train_history['train_loss']],\n        'train_acc': [float(x) for x in train_history['train_acc']],\n        'train_auc': [float(x) for x in train_history['train_auc']],\n        'val_loss': [float(x) for x in train_history['val_loss']],\n        'val_acc': [float(x) for x in train_history['val_acc']],\n        'val_auc': [float(x) for x in train_history['val_auc']],\n        'learning_rates': [float(x) for x in train_history['lr']]\n    },\n    'class_specific_metrics': {\n        'real_video_accuracy': float(real_accuracy),\n        'fake_video_accuracy': float(fake_accuracy),\n        'real_samples_count': int(real_samples),\n        'fake_samples_count': int(fake_samples)\n    }\n}\n\n# 保存结果到JSON文件\nresults_file = './results/experiment_results.json'\nwith open(results_file, 'w', encoding='utf-8') as f:\n    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n\nprint(f\"✅ 实验结果已保存到: {results_file}\")\n\n# 保存训练历史到CSV\nhistory_df = pd.DataFrame(train_history)\nhistory_df.to_csv('./results/training_history.csv', index=False)\nprint(\"✅ 训练历史已保存到: ./results/training_history.csv\")\n\n# 保存预测结果\npredictions_df = pd.DataFrame({\n    'true_label': eval_results['targets'],\n    'predicted_label': eval_results['predictions'],\n    'prediction_score': eval_results['scores']\n})\npredictions_df.to_csv('./results/test_predictions.csv', index=False)\nprint(\"✅ 测试预测结果已保存到: ./results/test_predictions.csv\")\n\n# 生成实验报告\nprint(\"\\n📋 生成实验报告...\")\nreport = f\"\"\"\n深度伪造检测模型实验报告\n{'='*50}\n\n实验时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n模型架构: OptimizedDeepfakeDetector (ResNet18 + LSTM + Attention)\n\n数据集信息:\n- 训练样本: {len(train_dataset):,}\n- 验证样本: {len(val_dataset):,}\n- 测试样本: {len(test_dataset):,}\n- 批次大小: {batch_size}\n\n训练配置:\n- 优化器: AdamW (lr=1e-4, weight_decay=1e-4)\n- 损失函数: Focal Loss (alpha=1, gamma=2)\n- 学习率调度: ReduceLROnPlateau\n- 早停机制: patience=5\n- 混合精度训练: {'启用' if torch.cuda.is_available() else '禁用'}\n\n最终性能指标:\n- 准确率: {metrics['accuracy']*100:.2f}%\n- 平衡准确率: {metrics['balanced_accuracy']*100:.2f}%\n- 精确率: {metrics['precision']:.4f}\n- 召回率: {metrics['recall']:.4f}\n- F1分数: {metrics['f1']:.4f}\n- AUC-ROC: {metrics['auc_roc']:.4f}\n- AUC-PR: {metrics['auc_pr']:.4f}\n\n混淆矩阵:\n- 真负例 (TN): {metrics['tn']}\n- 假正例 (FP): {metrics['fp']}\n- 假负例 (FN): {metrics['fn']}\n- 真正例 (TP): {metrics['tp']}\n\n类别特定性能:\n- 真实视频检测准确率: {real_accuracy*100:.2f}%\n- 伪造视频检测准确率: {fake_accuracy*100:.2f}%\n\n推理性能:\n- 平均推理时间: {eval_results['avg_inference_time']*1000:.2f} ms/batch\n- 处理速度: {len(eval_results['targets'])/eval_results['total_inference_time']:.1f} samples/s\n\n训练总结:\n- 训练轮数: {len(train_history['train_loss'])}\n- 最佳验证准确率: {max(train_history['val_acc']):.2f}%\n- 最佳验证AUC: {max(train_history['val_auc']):.4f}\n\n文件输出:\n- 模型权重: ./models/best_model.pth\n- 训练历史图: ./results/training_history.png\n- 混淆矩阵图: ./results/evaluation/confusion_matrix.png\n- ROC/PR曲线图: ./results/evaluation/roc_pr_curves.png\n- 分数分布图: ./results/evaluation/score_distribution.png\n- 实验结果: ./results/experiment_results.json\n- 训练历史: ./results/training_history.csv\n- 预测结果: ./results/test_predictions.csv\n\n{'='*50}\n实验完成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\"\"\"\n\n# 保存报告\nwith open('./results/experiment_report.txt', 'w', encoding='utf-8') as f:\n    f.write(report)\n\nprint(\"✅ 实验报告已保存到: ./results/experiment_report.txt\")\n\n# 打印最终总结\nprint(\"\\n\" + \"=\"*60)\nprint(\"🎉 深度伪造检测模型训练和评估完成！\")\nprint(\"=\"*60)\nprint(f\"📊 最终测试准确率: {metrics['accuracy']*100:.2f}%\")\nprint(f\"📊 AUC-ROC分数: {metrics['auc_roc']:.4f}\")\nprint(f\"📊 F1分数: {metrics['f1']:.4f}\")\nprint(f\"⚡ 推理速度: {len(eval_results['targets'])/eval_results['total_inference_time']:.1f} samples/s\")\nprint(\"\\n📁 所有结果文件已保存到 ./results/ 目录\")\nprint(\"📁 最佳模型已保存到 ./models/best_model.pth\")\nprint(\"\\n✨ 实验成功完成！可以在Kaggle中查看所有生成的图表和结果文件。\")\nprint(\"=\"*60)\n\n# 显示文件结构\nprint(\"\\n📂 生成的文件结构:\")\nprint(\"\"\"\n./models/\n  └── best_model.pth\n./results/\n  ├── experiment_results.json\n  ├── experiment_report.txt\n  ├── training_history.csv\n  ├── training_history.png\n  ├── test_predictions.csv\n  └── evaluation/\n      ├── confusion_matrix.png\n      ├── roc_pr_curves.png\n      └── score_distribution.png\n\"\"\")\n\nprint(\"\\n🚀 可以使用以下代码加载训练好的模型进行推理:\")\nprint(\"\"\"\n# 加载模型\nmodel = OptimizedDeepfakeDetector(...)\ncheckpoint = torch.load('./models/best_model.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\n\n# 进行推理 (注意: 模型输出 logits，需要应用 sigmoid 获得概率)\nwith torch.no_grad():\n    logits, attention = model(video_tensor)\n    probs = torch.sigmoid(logits)  # 转换为概率\n    prediction = (probs > 0.5).float()\n    confidence = probs.item()\n\"\"\")\n\nprint(\"\\n💡 提示: 在Kaggle中运行时，建议按顺序执行所有cell，确保数据路径正确设置。\")\nprint(\"\\n⚠️  重要: 模型输出的是 logits，使用时必须先应用 sigmoid 函数转换为概率值！\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}